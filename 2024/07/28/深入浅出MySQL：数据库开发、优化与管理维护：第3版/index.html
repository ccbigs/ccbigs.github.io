<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深入浅出MySQL：数据库开发、优化与管理维护 | ccbigs blog</title><meta name="author" content="DingQuan Zuo"><meta name="copyright" content="DingQuan Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="深入浅出MySQL：数据库开发、优化与管理维护：第3版本书第3版分为基础篇、开发篇、优化篇、管理维护篇、架构篇5个部分，共32章。  第一部分，基础篇（第1~5章）：主要面向MySQL的初学者，包括MySQL的安装与配置、SQL基础、MySQL支持的数据类型、MySQL中的运算符、常用函数等内容。通过这部分内容的学习，读者可以熟悉MySQL基本的安装和相关使用方法。 第二部分，开发篇（第6～14章">
<meta property="og:type" content="article">
<meta property="og:title" content="深入浅出MySQL：数据库开发、优化与管理维护">
<meta property="og:url" content="http://example.com/2024/07/28/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E3%80%81%E4%BC%98%E5%8C%96%E4%B8%8E%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%EF%BC%9A%E7%AC%AC3%E7%89%88/index.html">
<meta property="og:site_name" content="ccbigs blog">
<meta property="og:description" content="深入浅出MySQL：数据库开发、优化与管理维护：第3版本书第3版分为基础篇、开发篇、优化篇、管理维护篇、架构篇5个部分，共32章。  第一部分，基础篇（第1~5章）：主要面向MySQL的初学者，包括MySQL的安装与配置、SQL基础、MySQL支持的数据类型、MySQL中的运算符、常用函数等内容。通过这部分内容的学习，读者可以熟悉MySQL基本的安装和相关使用方法。 第二部分，开发篇（第6～14章">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/ahead.jpg">
<meta property="article:published_time" content="2024-07-28T10:28:33.000Z">
<meta property="article:modified_time" content="2024-10-23T04:30:52.522Z">
<meta property="article:author" content="DingQuan Zuo">
<meta property="article:tag" content="黑皮书">
<meta property="article:tag" content="MySQL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/ahead.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/07/28/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E3%80%81%E4%BC%98%E5%8C%96%E4%B8%8E%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%EF%BC%9A%E7%AC%AC3%E7%89%88/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深入浅出MySQL：数据库开发、优化与管理维护',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-23 12:30:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/ahead.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/1558.png')"><nav id="nav"><span id="blog-info"><a href="/" title="ccbigs blog"><img class="site-icon" src="/img/favicon.png"/><span class="site-name">ccbigs blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深入浅出MySQL：数据库开发、优化与管理维护</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-07-28T10:28:33.000Z" title="发表于 2024-07-28 18:28:33">2024-07-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-10-23T04:30:52.522Z" title="更新于 2024-10-23 12:30:52">2024-10-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/MySQL/">MySQL</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">318.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>1269分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="深入浅出MySQL：数据库开发、优化与管理维护"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="深入浅出MySQL：数据库开发、优化与管理维护：第3版"><a href="#深入浅出MySQL：数据库开发、优化与管理维护：第3版" class="headerlink" title="深入浅出MySQL：数据库开发、优化与管理维护：第3版"></a>深入浅出MySQL：数据库开发、优化与管理维护：第3版</h1><p>本书第3版分为基础篇、开发篇、优化篇、管理维护篇、架构篇5个部分，共32章。</p>
<ol>
<li>第一部分，基础篇（第1~5章）：主要面向MySQL的初学者，包括MySQL的安装与配置、SQL基础、MySQL支持的数据类型、MySQL中的运算符、常用函数等内容。通过这部分内容的学习，读者可以熟悉MySQL基本的安装和相关使用方法。</li>
<li>第二部分，开发篇（第6～14章）：主要面向MySQL的设计和开发人员，包括表类型（存储引擎）的选择、选择合适的数据类型、字符集、索引的设计和使用、开发常用数据库对象、事务控制和锁定语句、SQL中的安全问题、SQLMode及相关问题、MySQL分区等内容。通过这部分内容的学习，读者可以了解MySQL设计和开发中需要关注的问题。</li>
<li>第三部分，优化篇（第15～21章）：主要面向开发人员和数据库管理员，包括SQL 优化、锁问题、优化MySQLServer、磁盘I&#x2F;O问题、应用优化、PS&#x2F;SYS数据库、故障诊断等内容。通过这部分内容的学习，读者可以了解MySQL中需要优化的对象和常用的优化方法。</li>
<li>第四部分，管理维护篇（第22~29章）：主要面向数据库管理员，包括MySQL高级安装和升级、MySQL中的常用工具、MySQL日志、备份与恢复、MySQL权限与安全、MySQL 监控、MySQL常见问题和应用技巧、自动化运维系统的开发等内容。通过这部分内容的学习，读者可以了解在MySQL中常用的管理维护方法。</li>
<li>第五部分，架构篇（第30～32章）：主要面向高级数据库管理人员和数据库架构设计师，包括MySQL复制、高可用架构、MySQL中间件等内容。通过这部分内容的学习，读者可以了解一些MySQL的高级应用。</li>
</ol>
<h1 id="第一部分-基础篇"><a href="#第一部分-基础篇" class="headerlink" title="第一部分 基础篇"></a>第一部分 基础篇</h1><h1 id="第1章-MySQL的安装与配置"><a href="#第1章-MySQL的安装与配置" class="headerlink" title="第1章 MySQL的安装与配置"></a>第1章 MySQL的安装与配置</h1><p>近几年，开源数据库逐渐流行起来。由于具有免费使用、配置简单、稳定性好、性能优良等优点，开源数据库在中低端应用中占据了很大的市场份额，而MySQL正是开源数据库中的杰出代表。</p>
<p>MySQL数据库隶属于MySQLAB公司，总部位于瑞典。</p>
<p>MySQL支持几乎所有的操作系统，并且支持容量很大的表（MyISAM存储引擎支持的最大表大小为65536TB，InnoDB为64TB）。这些特性使得MySQL的发展非常迅猛，目前已经广泛应用在各个行业中。</p>
<h2 id="1-1-MySQL的下载"><a href="#1-1-MySQL的下载" class="headerlink" title="1.1 MySQL的下载"></a>1.1 MySQL的下载</h2><p>MySQL数据库目前分为社区版（CommunityServer）和企业版（Enterprise）。它们最重要的区别在于：</p>
<ul>
<li>社区版是自由下载而且完全免费，但是官方不提供任何技术支持，适用于大多数普通用户；</li>
<li>企业版是收费的，下载的软件有试用期，但相应地提供了更多的功能和更完备的技术支持，更适合于对数据库的功能和可靠性要求较高的企业客户。</li>
</ul>
<p>MySQL不同版本之间的主要区别如表1-1所示。</p>
<table>
<thead>
<tr>
<th>版本</th>
<th>重要改进</th>
</tr>
</thead>
<tbody><tr>
<td>4.1</td>
<td>增加了子查询的支持：字符集中增加了对UTF-8的支持</td>
</tr>
<tr>
<td>5.0</td>
<td>增加了视图、过程、触发器的支持，增加了information_schema系统数据库</td>
</tr>
<tr>
<td>5.1</td>
<td>增加了表分区的支持：支持基于行的复制（row-basedreplication）</td>
</tr>
<tr>
<td>5.5</td>
<td>InnoDB成为默认存储引擎：支持半同步复制：引入performance_schema动态性能视图</td>
</tr>
<tr>
<td>5.6</td>
<td>支持部分OnlineDDL操作：支持ICP&#x2F;BKA&#x2F;MRR等优化器改进：引入GTID：支持多库并行复制</td>
</tr>
<tr>
<td>5.7</td>
<td>密码安全性提高；支持多线程并行复制、多源复制：支持JSON：引入sys系统库：引入MGR</td>
</tr>
<tr>
<td>8.0</td>
<td>在线持久化全局参数：大幅提高数据字典性能；引入窗口函数、ROLE、直方图、降序索引、不可见索引：修复自增列重启BUG</td>
</tr>
</tbody></table>
<h3 id="1-1-1-在Windows平台下下载MySQL"><a href="#1-1-1-在Windows平台下下载MySQL" class="headerlink" title="1.1.1 在Windows平台下下载MySQL"></a>1.1.1 在Windows平台下下载MySQL</h3><p>Windows平台提供了两种类型的安装包，如表1-2所示。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>noinstall压缩包</td>
<td>安装简单，解压即可使用：灵活性差，无法自主选择组件</td>
</tr>
<tr>
<td>MySQL Installer</td>
<td>安装简单，用向导式一步步提示安装，可以灵活选择安装、删除、更改MySQL提供的所有组件</td>
</tr>
</tbody></table>
<p>其中，MySQLInstaller为官方推荐安装方式，它的安装包又分为mysql-installer-web-community 和mysql-installer-community两种类型，主要区别是前者安装包很小，安装时需要连接互联网，组件需要在线下载最新版本；而后者安装时则不需要连网，安装包中包含了完整的组件，安装包较前者大很多，下载过程慢，但安装过程快。以8.0.11版本为例，mysql-installer-web-community 的安装文件为15.8MB，而mysql-installer-community为230MB。</p>
<h3 id="1-1-2-在Linux平台下下载MySQL"><a href="#1-1-2-在Linux平台下下载MySQL" class="headerlink" title="1.1.2 在Linux平台下下载MySQL"></a>1.1.2 在Linux平台下下载MySQL</h3><p>在Linux平台下，MySQL官方也提供了多种安装方式。不同的安装方式需要下载的安装包也不同，具体如表1-3所示。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>Yum&#x2F;APT&#x2F;SUSE Repository</td>
<td>安装仓库包极小，版本安装简单灵活，升级方便：其中YumRepository适合Red HatEnterprise Linux&#x2F;OracleLinux&#x2F;Fedora平台；APTRepository适合Debian&#x2F;Ubuntu平台：SUSE适合SUSELinux</td>
</tr>
<tr>
<td>RPM包</td>
<td>安装简单：灵活性差，无法灵活选择版本、升级</td>
</tr>
<tr>
<td>通用二进制包</td>
<td>安装较复杂，灵活性高，平台通用性好</td>
</tr>
<tr>
<td>源码包</td>
<td>安装最复杂，时间长，参数设置灵活，性能好</td>
</tr>
</tbody></table>
<h2 id="1-2-MySQL的安装"><a href="#1-2-MySQL的安装" class="headerlink" title="1.2 MySQL的安装"></a>1.2 MySQL的安装</h2><h3 id="1-2-1-在Windows平台下安装MySQL"><a href="#1-2-1-在Windows平台下安装MySQL" class="headerlink" title="1.2.1 在Windows平台下安装MySQL"></a>1.2.1 在Windows平台下安装MySQL</h3><p>略</p>
<h3 id="1-2-2-在Linux平台下安装MySQL"><a href="#1-2-2-在Linux平台下安装MySQL" class="headerlink" title="1.2.2 在Linux平台下安装MySQL"></a>1.2.2 在Linux平台下安装MySQL</h3><p>在Linux平台下安装MySQL和在Windows平台下安装有所不同，在Linux平台下不用图形化的方式来安装，并且Linux支持RPM包、通用二进制包、源码包3种安装方式。下面以RPM包为例来介绍如何在Linux平台下安装MySQL，其他安装方式会在第22章详细介绍。</p>
<p>RPM是RedhatPackageManage的缩写。通过RPM的管理，用户可以把源代码包装成一种以rpm为后缀的文件形式，更易于安装。对于RPM包的下载和安装，MySQL官方提供了两种方式：一种是直接在页面上按需下载对应的包；另一种是使用版本仓库（Repository）的方式进行安装，这种方式最大的特点是安装简单方便，对于不同版本的软件安装和升级尤为方便，本节将分别介绍这两种安装方式。</p>
<h4 id="1-直接安装RPM包"><a href="#1-直接安装RPM包" class="headerlink" title="1. 直接安装RPM包"></a>1. 直接安装RPM包</h4><p>MySQL的RPM包包括很多套件，老一点的版本一般只安装Server和Client就可以。其中Server包是MySQL服务端套件，为用户提供核心的MySQL服务；Client包是连接MySQL 服务的客户端工具，方便管理员和开发人员在服务器上进行各种管理工作。较新的版本由于包之间存在更多的依赖关系，通常要下载以下几个包才可以完成标准的安装。</p>
<ul>
<li>mysql-community-server. </li>
<li>mysql-community-client. </li>
<li>mysql-community-libs.</li>
<li>mysql-community-common. </li>
<li>mysql-community-libs-compat.</li>
</ul>
<p>在本例中，安装RPM包的具体操作步骤如下。<br>（1）切换到root下（只有root才可以执行RPM包）。<br>（2）按照以下顺序安装MySQL相关包（顺序不对可能提示包依赖）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hz 10 120240_251~]#rpm -ivh mysq1-community-common-8.0.11-1.e16.x86_64.rpm</span><br><span class="line">[root@hz 10_120_240 251~]#rpm -ivh mysql-community-1ibs-8.0.11-1.e16.x8664.rpm</span><br><span class="line">[root@hz 10 120 240 251 ~]#rpm -ivh mysql-community-1ibs-compat-8.0.11-1.e16.x86 64.rpm</span><br><span class="line">[root@hz_10_120_240_251 ~]# rpm -ivh mysql-community-c1ient-8.0.11-1.e16.x86_64.rpm</span><br><span class="line">[root@hz 10 120 240 251 ~]# rpm -ivh mysql-community-server-8.0.11-1.e16.x86 64.rpm</span><br></pre></td></tr></table></figure>

<p>（3）启动MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hz 10_120_240_251 1ib]# service mysqld start</span><br></pre></td></tr></table></figure>

<p>如果OS是redhadt7，则命令为<code>systemctl start mysqld.service</code>。通过下面的chkconfig命令，可以让操作系统重启时自动启动MySQL。 </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig --level 2345 mysqld on</span><br></pre></td></tr></table></figure>

<p>执行下面的命令，可以检查自启动状态，确认生效。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hz 10 120_240 251 ~]# chkconfig --1ist|grep mysql </span><br></pre></td></tr></table></figure>

<p>（4）登录MySQL。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hz_10_120_240_251 1og]#mysq] -uroot</span><br><span class="line">ERROR 1045 (28000): Access denied for user root&#x27;@&#x27;localhost&#x27; （using password: No)</span><br></pre></td></tr></table></figure>

<p>MySQL5.7之后的版本在默认安装时去掉了root用户的空密码，初次启动MySQL时系统会生成一个临时root密码，可以通过查看&#x2F;var&#x2F;log&#x2F;mysqld.log来查看。在本例中，临时密码以粗体代码显示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hz_10_120_240_251 1og]# more mysq1d.1og</span><br><span class="line">2018-07-11T06:42:22.233799z 0[System] [MY-013169] [Server] /usr/sbin/mysqld (mysqld 8.0.11) initializing of server in progress as process 28218</span><br><span class="line">2018-07-11T06:42:26.645905z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost:N&amp;Rg1lddrwl6</span><br><span class="line">2018-07-11T06:42:28.555800z 0 [System] [MY-013170] [server] /usr/sbin/mysqld (mysqld 8.0.11) initializing of server has completed</span><br></pre></td></tr></table></figure>

<p>用临时密码登录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hz_10_120_240_251 1og]<span class="comment">#mysql -uroot -p </span></span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MysQL monitor. cCommands end with ;or g.</span><br><span class="line">Your MysQL connection <span class="built_in">id</span> is 9 Server version: 8.0.11</span><br><span class="line">Copyright (c) 2000, 2018, oracle and/or its affiliates. All rights reserved. oracle is a registered trademark of oracle corporation and/or its</span><br><span class="line">affiliates. other names may be trademarks of their respective owners</span><br><span class="line">Type <span class="built_in">help</span>;or <span class="string">&#x27;h for help. Type &#x27;</span>\c<span class="string">&#x27; to clear the current input statement. mysq1&gt;</span></span><br></pre></td></tr></table></figure>

<p>但临时密码登录无法进行大多数操作，比如想查看当前数据库列表，会提示如下错误： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show databases;</span><br><span class="line">ERROR 1820 HY00o): You must reset your password using ALTER usER statement before executing this statement.</span><br></pre></td></tr></table></figure>

<p>提示必须要更改初始密码，才可以执行此命令，可以用以下命令进行更改：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter user root<span class="string">&#x27;@&#x27;</span>localhost<span class="string">&#x27; identified by &quot;Test@123&quot;; Query ok,0 rows affected (0.18 sec)</span></span><br></pre></td></tr></table></figure>

<p>新密码必须要满足密码强度规则，默认规则如下： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW VARIABLES LIKE <span class="string">&#x27;validate_password%&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>简单解释一下，新密码必须至少为8位（validate_password.length），其中至少要包含一个数字（validate_password.number_count）、一个特殊字符（validate_password.special_char_count），以及大小写字符至少各包含一个（validate_password.mixed_case_count）。如果不满足这些条件，则提示如下错误：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter user ′root<span class="string">&#x27;@&#x27;</span>localhost<span class="string">&#x27; identified by &quot;test@123&quot;;</span></span><br><span class="line"><span class="string">ERROR 1819 (Hyooo): Your password does not satisfy the current policy requirements</span></span><br></pre></td></tr></table></figure>

<p>至此，MySQL安装完毕。</p>
<h4 id="2-通过Yum-Repository安装"><a href="#2-通过Yum-Repository安装" class="headerlink" title="2.通过Yum Repository安装"></a>2.通过Yum Repository安装</h4><p>通过上面的介绍，我们发现RPM包安装方式虽然简单，但也有一些缺陷，比如需要下载的包较多，且包之间安装有先后依赖关系，最重要的是升级不方便。如果有新版本，则需要重新下载所有包进行替换。<br>为了解决这些不便之处，MySQL官方提供了一种新的安装方式——YumRepository。Yum（全称为YellowdogUpdater,Modified）是一个在Fedora和RedHat以及CentOS中的Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须烦琐地一次次下载和安装。<br>YumRepository的安装包非常小，8.0版本只有25KB，下载方式和其他RPM包类似，这里不再赘述。下面详细介绍YumRepository的安装和使用方法。<br>（1）安装YumRepository。<br>[root@hz_10_120 240_251~]#rpm-ivh mysq180-community-release-e16-1.noarch.rpm<br>warning:mysq180-community-release-e16-1.noarch.rpm: Header V3 DsA&#x2F;sHA1 signature,key ID 5072e1f5:NOKEY<br>Preparing…# ysl8crla###########################################]<br>安装完毕后，在&#x2F;etc&#x2F;yum.repos.d下多了mysql-community.repo 和mysql-community-source.repo这两个文件，它们分别是MySQL社区版RPM包和源码包的Yum源文件，里面记录了支持的软件版本和下载相关的一些参数。<br>（2）使用YumRepository来安装MySQL8.0。<br>用cat命令截取mysql-community.repo的部分内容，如下所示：<br>#Enable to use MysQL 5.7[mysq157-community]<br>name&#x3D;MysQL 5.7 Community Server<br>baseur1&#x3D;<a target="_blank" rel="noopener" href="http://repo.mysq1.com/yum/mysq1-5.7-community/e1/6/$basearch/">http://repo.mysq1.com/yum/mysq1-5.7-community/e1/6/$basearch/</a><br>enabled&#x3D;0 gpgcheck&#x3D;1<br>gpgkey&#x3D;fi1e:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysq1[mysq180-community]<br>name&#x3D;MySQL 8.0 Community Server<br>baseur1&#x3D;<a target="_blank" rel="noopener" href="http://repo.mysql.com/yum/mysq1-8.0-community/el/6/$basearch/">http://repo.mysql.com/yum/mysq1-8.0-community/el/6/$basearch/</a><br>enabled&#x3D;1 gpgcheck&#x3D;1<br>gpgkey&#x3D;file:&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-mysq1</p>
<p>≦ 29 ≧<br>1.2MySQL的安装 11<br>可以看出，最新GA版本8.0的enabled&#x3D;1，其他版本均为0。如果安装最新GA版本的 MySQL，则不用做任何设置，直接执行如下命令：<br>[root@hz-10-120-13-227 yum.repos.d]# yum insta11 mysql-community-server Resolving Dependencies<br>-&gt;Running transaction check</p>
<blockquote>
<p>Package mysql-community-embedded.x86 64 0:5.7.17-1.e16 wi11 be obso1eted<br>-&gt;Package mysq1-community-embedded-devel.x86_64 0:5.7.17-1.e16 wi11 be obsoleted<br>–&gt; Package mysql-community-server.x86 64 0:5.7.17-1.e16 wi11 be updated-&gt; Package mysql-community-server.x86 64 0:8.0.11-1.el6 wi11 be obsoleting<br>Processing Dependency: mysql-community-common(x86-64) &#x3D; 8.0.11-1.e16 for package:mysql-<br>community-server-8.0.11-1.e16.x86_64<br>-&gt; Processing Dependency:mysql-community-client(x86-64) &gt;&#x3D; 8.0.0 for package:mysql-community-server-8.0.11-1.e16.x86_64<br>-&gt;Running transaction check<br>–&gt; Package mysq1-community-c1ient.x86 64 0:5.7.17-1.e16wi11 be updated &gt;Package mysql-community-client.x86 64 0:8.0.11-1.e16 wi11 be an update<br>-&gt;Processing Dependency: mysq1-community-1ibs(x86-64) &gt;&#x3D;8.0.0 for package:mysql-community-client-8.0.11-1.e16.x86_64<br>Package mysql-community-common.x86 64 0:5.7.17-1.e16 wi11 be updated &gt;Package mysq1-community-common.x86 64 0:8.0.11-1.e16wi11be an update-&gt; Running transaction check<br>-&gt; Package mysql-community-1ibs.x8664 0:5.7.17-1.e16 wi71 be updated<br>Processing Dependency:1ibmysqlclient.so.20((64bit) for package:mysq1-community-devel-<br>5.7.17-1.e16.x8664<br>-&gt;Package mysq1-community-1ibs.x86 64 0:8.0.11-1.e16 wi11 be an update-&gt; Running transaction check<br>-&gt;Package mysql-community-devel.x86 64 0:5.7.17-1.el6 wi11 be updated-&gt;Package mysql-community-devel.x86 64 0:8.0.11-1.e16wi11 be an update<br>Finished Dependency Resolution Dependencies Resolved<br>Package Arch Version Repository size<br>Installing:<br>mysqT-community-server x8664 8.0.11-1.el6 mysq180-community 378M<br>rep1acing mysql-community-embedded.x86 64 5.7.17-1.e16<br>replacing mysql-community-embedded-deve1.x86_64 5.7.17-1.e16 Updating for dependencies:<br>mysql-community-client x8664 8.0.11-1.el6 mysq180-community 28M<br>mysql-community-common x86 64 8.0.11-1.el6 mysq180-community 656k<br>mysql-community-devel x8664 8.0.11-1.el6 mysq180-community 4.2M<br>mysql-community-libs x86_64 8.0.11-1.el6 mysq180-community 2.5M<br>Transaction Summary<br>Install 1package(s) Upgrade 4Package(s)<br>Total download size:413 M Is this ok[y&#x2F;N]:y<br>从安装过程可以看出，一些包被废弃，一些被更新，包之间的依赖被自动处理，整个过程几乎不需要人工介人，非常方便。<br>如果特殊需求，要安装其他低版本的MySQL，比如要安装5.7版本，那么可以将源文件中[mysql80-community]下的配置项enabled改为0，同时将[mysql57-community]下对应参数改</p>
</blockquote>
<p>≦ 30 ≧<br>12 第1章MySQL的安装与配置为1即可。或者使用如下命令更改更方便：<br>yum-config-manager –disable mysq180-community yum-config-manager –enable mysq157-community<br>1.3MySQL的配置<br>MySQL安装完毕后，大多数情况下都可以直接启动MySQL服务，而不需要设置参数。因为系统中所有的参数都有一个默认值。如果要修改默认值，则必须要配置参数文件。下面<br>就Windows和Linux两种平台下的配置方法进行介绍。 1.3.1Windows平台下配置MySQL<br>对于图形化的安装方式，MySQL提供了一个图形化的实例配置向导，可以引导用户逐步进行实例参数的设置，具体操作步骤如下。<br>（1）单击“开始”一MySQLInstallerCommunity菜单，进入安装界面，如图1-17所示。（2）选择产品下面的MySQLServer，单击图1-17中<br>nstaler<br>的Reconfigure，进人选择配置类型界面。可以发现，与 00<br>安装MySQL过程中配置产品的界面和内容一致，这里根据自已需求来设置即可，我们不再赘述。<br>（3）通过MySQLInstaller提供的图形化功能，可以对一些重要实例参数进行设置，但对于更详细的参数则无能为力。此时，常用的方法是通过修改配置文件进行设置。 Windows中配置文件命名为my.ini，通常位于MySQL安装<br>目录下，本例中位于C:ProgramData\MySQL\MySQLServer 图1-17MySQL实例配置界面 8.0my.ini。下面是过滤掉部分注释后的内容。<br>[client] port&#x3D;3306<br>[mysq1] no-beep<br>[mysq1d] port&#x3D;3306<br>datadir&#x3D;C:&#x2F;ProgramData&#x2F;MysQL&#x2F;MysQL Server 8.o&#x2F;Data</p>
<h1 id="The-default-authentication-plugin-to-be-used-when-connecting-to-the-server-default-authentication-plugin-x3D-caching-sha2-password"><a href="#The-default-authentication-plugin-to-be-used-when-connecting-to-the-server-default-authentication-plugin-x3D-caching-sha2-password" class="headerlink" title="The default authentication plugin to be used when connecting to the server default authentication plugin&#x3D;caching_sha2_password"></a>The default authentication plugin to be used when connecting to the server default authentication plugin&#x3D;caching_sha2_password</h1><h1 id="The-default-storage-engine-that-will-be-used-when-create-new-tables-when"><a href="#The-default-storage-engine-that-will-be-used-when-create-new-tables-when" class="headerlink" title="The default storage engine that will be used when create new tables when"></a>The default storage engine that will be used when create new tables when</h1><p>default-storage-engine&#x3D;INNODB# Set the SQL mode to strict<br>Sql-mOde&#x3D;”STRICT_TRANS_TABLES,NO ENGINE SUBSTITUTION”#General and slow logging.<br>log-output&#x3D;FILE general-log&#x3D;0<br>general_1og_file&#x3D;”BIH-L-2673.1og” slow-query-log&#x3D;1<br>slow_query_log_fiTe&#x3D;”BIH-L-2673-slow.log”” long query_time&#x3D;10</p>
<p>≦ 31 ≧<br>1.4启动和关闭MySQL服务 13<br>上面示例中的粗体代码代表了不同模块的参数，通常配置最多的参数模块是[mysqld]，也<br>就是MySQL实例相关参数，新增或修改参数只需要增加或者修改此模块下的条目即可。 1.3.2Linux平台下配置MySQL<br>在Linux下配置MySQL和在Windows下通过编辑参数文件配置非常类似，区别在于参数文件的位置和文件名不同。在Linux下也可以在多个位置部署配置文件，通过RPM包安装的放在&#x2F;etc下，文件名称只能是my.cnf（在Windows下文件名默认是my.ini）。<br>在MySQL5.6之前，MySQL提供了多个参数模板，用来适应不同环境的需求，它们的名称类似于my-<em><strong>.cnf，其中</strong></em>代表了环境对于资源大小的需求，比如my-huge.cnfmy-large.cnf my-medium.cnfmy-small.cnf等，在8.0版本中已经取消了这些模板，需要直接编辑my.cnf 或my.ini<br>1.4启动和关闭MySQL服务<br>安装配置完毕MySQL后，接下来就该启动MySQL服务了。这里强调一下，MySQL服务和MySQL数据库不同，MySQL服务是一系列后台进程，而MySQL数据库则是一系列的数据目录和数据文件；MySQL数据库必须在MySQL服务启动之后才可以进行访问。下面就<br>针对Windows和Linux两种平台，介绍MySQL服务的启动和关闭方法。 1.4.1在Windows平台下启动和关闭MySQL服务<br>对于采用图形化方式安装的MySQL，可以直接通过<br>Windows的“开始”菜单（单击“开始”→“控制面板” 常观登爱恢复依存关系<br>服务名称：<br>→“管理工具”→“服务”菜单）中找到MySQL80服务，显示名称双击后进人如图1-18所示的界面，单击“启动”或“停<br>可执行文件的路径<br>止”按钮来启动或关闭MySQL服务。<br>启动类型（E）<br>用户也可以在命令行中手工启动和关闭MySQL服<br>务，如下所示。 已停让<br>服务状态<br>（1）启动服务：<br>c:&gt;net start mysq180 MySQL80服务正在启动<br>启动教数（M)：<br>MySQL80服务已经启动成功.<br>（2）关闭服务： 定<br>c:&gt;net stop mysq180 图1-18服务列表中启动和关闭 MySQL80服务正在停止<br>MySQL80服务已成功停止 MySQL80 1.4.2在Linux平台下启动和关闭MySQL服务<br>在Linux平台下，可以采用如下命令查看MySQL服务的状态：[root@localhost bin]# netstat -nlp<br>Active Internet connections (only servers)<br>Proto Recv-Q Send-Q Local Address Foreign Address state PID&#x2F;Program name<br>OO0.0.0.0:33060.0.0.0LISTEN3168&#x2F;mySqld</p>
<p>≦ 32 ≧<br>14 第1章MySQL的安装与配置<br>tcp ：9922 · LISTEN1864&#x2F;sshd Active uNIx domain sockets (only servers)<br>Proto RefCnt Flags Type state I-Node PID&#x2F;Program name Path<br>unix2[ACC ]STREAM LISTENING 16537243 3168&#x2F;mysqld &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock unix2[ACC] STREAM LISTENING 4875 1915&#x2F;xfs &#x2F;tmp&#x2F;.font-unix&#x2F;fs7100 其中3306端口是MySQL服务器默认监听端口。<br>与在Windows平台上类似，在Linux平台上启动和关闭MySQL也有两种方法，一种是通过命令行方式启动和关闭，另一种是通过服务的方式启动和关闭（适用于RPM包安装方式）。下面分别对这两种方法进行介绍。<br>1.命令行方式<br>在命令行方式下，启动和关闭MySQL服务命令如下所示。（1）启动服务：<br>[root@localhost bin]# cd &#x2F;usr&#x2F;bin[root@localhost bin]#.&#x2F;mysqld safe&amp;[1]23013<br>[root@localhost bin]# Starting mysqld daemon with databases from &#x2F;var&#x2F;lib&#x2F;mysql（2）关闭服务：<br>[root@localhost bin]# mysqladmin -uroot shutdown<br>STOPPING server from pid file &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;localhost.localdomain.pid 07082004:36:30 mysq1d ended<br>[1]+ Done.&#x2F;mysqld safe 2.服务的方式<br>如果MySQL是用RPM包安装的，则启动和关闭MySQL服务过程如下所示。（1）启动服务：<br>[root@localhost]# service mysqld start Starting mysqld:<br>如果在启动状态，需要重启服务，可以用以下命令直接重启，而不需要先关闭再启动：[root@localhost]# service mysqld restart<br>Stopping mysqld: [OK] Starting mysqld: [OK]<br>（2）关闭服务：<br>[root@localhost]# service mysqld stop<br>Stopping mysqld: [OK] 注意：在命令行启动MySQL时，如果不加“–console”，启动关闭信息将不会在界面中显示，而<br>是记录在安装目录下的data目录里面，文件名字一般是hostname.err，可以通过此文件查看 MySQL的控制台信息。<br>1.5小结<br>本章以Windows平台和Linux平台为例，讲述了MySQL8.0在不同操作系统平台下的下载、安装、配置、启动和关闭的过程。其中在Windows平台下介绍了MySQLInstaller图形化安装包；在Linux平台下只介绍了RPM包的两种安装方法，而没有介绍二进制包和源码包。之所以选择这几种包进行介绍，主要是因为它们比较简单，适合初学者快速入门。第22章将会对Linux下的二进制包和源码包进行详细的介绍。</p>
<p>≦ 33 ≧<br>第2章SQL基础<br>本章将通过丰富的实例对SQL语言的基础进行详细介绍，读者不但能够学习到标准SQL<br>的使用方法，还能够学习到MySQL中一些扩展SQL的使用方法。 2.1SQL简介<br>当面对一个陌生的数据库时，通常需要一种方式与它进行交互，以完成用户所需要的各种工作。这个时候，就要用到SQL语言了。<br>SQL是StructureQueryLanguage（结构化查询语言）的缩写，它是使用关系模型的数据库应用语言，由IBM在20世纪70年代开发出来，作为IBM关系数据库原型SystemR的原型关系语言，实现了关系数据库中的信息检索。<br>20世纪80年代初，美国国家标准局（ANSI）开始着手制定SQL标准，最早的ANSI标准于1986年完成，就被叫做SQL-86。标准的出台使SQL作为标准关系数据库语言的地位得到了加强。SQL标准目前已几经修改，更趋完善。<br>正是由于SQL语言的标准化，所以大多数关系型数据库系统都支持SQL语言，它已经发展成为多种平台进行交互操作的底层会话语言。<br>2.2（My）SQL使用入门<br>这里用了(My)SQL这样的标题，目的是在介绍标准SQL的同时，也将一些MySQL在标准SQL上的扩展一同介绍给读者。希望读者看完本节后，能够对标准SQL的基本语法和<br>MySQL的部分扩展语法有所了解。 2.2.1SQL分类<br>SQL语句主要可以划分为以下3个类别。<br>ODDL（DataDefinitionLanguage）语句：数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、alter等。<br>ODML（DataManipulationLanguage）语句：数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性。常用的语句关键字主要包括insert、delete、update</p>
<p>≦ 34 ≧<br>16 第2章SQL基础和select等。<br>ODCL（DataControlLanguage）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。常<br>用的语句关键字主要包括grant、revoke等。 2.2.2 DDL语句<br>简单来说，DDL就是对数据库内部的对象进行创建、删除、修改等操作的语言。它和 DML语句的最大区别是DML只是操作表内部的数据，而不涉及表的定义、结构的修改，更不会涉及其他对象。DDL语句更多地是由数据库管理员（DBA）使用，开发人员一般很少使用。<br>下面通过一些例子来介绍MySQL中常用DDL语句的使用方法。 1.创建数据库<br>启动MySQL服务之后，输人以下命令连接到MySQL服务器：<br>[root~]#mysql -uroot -p Enter password:<br>welcome to the MysQL monitor.Commands end with ;or \g. Your MysQL connection id is 31<br>Server version: 8.0.11 MysQL Community Server- GPL<br>Copyright (c) 2000, 2018, oracle and&#x2F;or its affiliates.A1l rights reserved. oracle is a registered trademark of oracle Corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type ‘help; or \h’ for help. Type ‘\c’ to clear the current input statement. mysq1&gt;<br>在以上命令行中，mysql代表客户端命令，“-u”后面跟连接的数据库用户，“-p”表示需要输入密码。<br>如果数据库设置正常，并输人了正确的密码，将看到上面一段欢迎界面和一个“mysql&gt;” 提示符。在欢迎界面中说明了以下几部分内容。<br>命令的结束符，用“”或者“g”结束。<br>客户端的连接ID，这个数字记录了MySQL服务到目前为止的连接次数；每一个新连接都会自动加1，本例中是31。<br>MySQL服务器的版本和类型，本例中是“8.0.11MySQLCommunityServer-GPL”，说明是8.0.11的社区发行版。<br>O通过“help;”或者“\h”命令来显示帮助内容，通过“c”命令来清除命令行buffer。在mysqlI&gt;提示符后面输入所要执行的SQL语句，每个SQL语句以分号（；）或者“g”<br>结束，按回车键执行。<br>因为所有的数据都存储在数据库中，因此需要学习的第一个命令是创建数据库，语法如下所示：<br>CREATE DATABASE dbname<br>例如，创建数据库testl，命令执行如下：</p>
<p>≦ 35 ≧<br>2.2（My）SQL使用入门 17<br>mysql&gt; create database testl;<br>Query ok,1 row affected (o.o0 sec)<br>可以发现，执行完创建命令后，下面有一行提示“QueryOK，1rowaffected（0.00sec)”，这段提示可以分为3个部分。“QueryOK”表示上面的命令执行成功。读者可能会觉得奇怪，又不是执行查询操作，为什么显示查询成功？其实这是MySQL的一个特点，所有的DDL和DML（不包括SELECT）操作执行成功后都显示“QueryOK”，这里理解为执行成功就可以了。“1row affected”表示操作只影响了数据库中一行的记录，“0.00sec”则记录了操作执行的时间。<br>如果已经存在这个数据库，系统会提示： mysql&gt; create database testl;<br>ERROR 1007 (HY000): Can’t create database ‘test1’; database exists<br>这时，如果需要知道系统中都存在哪些数据库，可以用以下命令来查看：<br>mysql&gt; show databases; |Database<br>I information schema |mysql<br>performance schema<br>sys Itestl<br>5rows in set (0.o0 sec)<br>可以发现，在上面的列表中除了刚刚创建的test1外，还有另外4个数据库，它们都是安装MySQL时系统自动创建的，其功能分别如下。<br>information_schema：主要存储系统中的一些数据库对象信息，比如用户表信息、列信息、权限信息、字符集信息、分区信息等。每个用户都可以查看这个数据库，但根据权限的不同看到的内容不同。<br>Operformance_schema:MySQL5.5引入的系统库，用于存储系统性能相关的动态参数表。 Osys:MySQL5.7引入的系统库，本身不记录系统数据，基于information_schema和<br>performance_schema之上，封装了一层更加易于调优和诊断的系统视图。<br>Omysql：存储系统的用户权限信息。<br>在查看系统中已有的数据库后，可以用如下命令选择要操作的数据库： USE dbriame<br>例如，选择数据库testl：<br>mysql&gt; use test1 Database changed<br>然后再用以下命令来查看test1数据库中创建的所有数据表：<br>mysql&gt; show tables; Empty set (0.00 sec)<br>由于test1是刚创建的数据库，还没有表，所以显示为空。命令行下面的“Empty set”表示操作的结果集为空。如果查看一下mysql数据库里面的表，则可以得到以下信息：<br>mysql&gt; use mysql mysql&gt; show tables; |Tables in_mysql |columns priv</p>
<p>≦ 36 ≧<br>18 第2章SQL基础<br>component db<br>default roles engine_cost func<br>general log global_grants gtid executed help_category help_keyword help_ relation help_topic<br>innodb_index stats innodb table stats password history plugin<br>procs priv proxies priv role_edges server_cost servers<br>Islave_master_info I slave relay_log info 1 slave <em>worker_info<br>Islow_1og tables_priv time</em> zone<br>time zone_leap_second time zone name<br>time zone_transition<br>Itime zone transition type| 丨user<br>33 rows in set (0.00 sec) 2.删除数据库<br>删除数据库的语法很简单，如下所示：<br>drop databasedbname<br>例如，要删除test1数据库可以使用以下语句： mysql&gt; drop database testl;<br>Query ok, 0 rows affected (o.o0 sec)<br>可以发现，提示操作成功后，后面却显示“Orowsaffcted”，这个提示的含义是前一次 MySQL操作所影响的记录行数，通常只对增删改操作生效，drop等DDL操作通常显示“Orows affected”。<br>注意：数据库删除后，下面的所有表数据都会全部删除，所以删除前一定要仔细检查并做好相<br>应备份。<br>3.创建表<br>在数据库中创建一张表的基本语法如下： CREATE TABLE tablename<br>column_name_l column_type_l constraints, column_name_2 column_type_2 constraints,<br>column_name_n column_type_n constraints)<br>因为MySQL的表名是以文件的形式保存在磁盘上的，所以表名的字符可以用任何文件名允许的字符。column_name是列的名字；column_type是列的数据类型；constraints是这个列的约束条件，在后面的章节中会详细介绍。</p>
<p>≦ 37 ≧<br>2.2（My）SQL使用入门 19<br>例如，创建一个名称为emp的表。表中包括ename（姓名）、hiredate（雇用日期）和 sal（薪水）3个字段，字段类型分别为varchar（10)、date、int(2）（关于字段类型将会在第3章中介绍）：<br>mysql&gt; create table emp(ename varchar(10),hiredate date,sal decima1(10,2),deptno int(2)); Query ok, 0 rows affected (0.02 sec)<br>表创建完毕后，如果需要查看一下表的定义，可以使用如下命令：<br>DESC tablename 学<br>例如，查看emp表，将输出以下信息： mysql&gt; desc emp;<br>1 Field 1Type 1 Null 丨 Key | Default 丨 Extra 1<br>ename varchar(10) YES hiredate date YES<br>decima1(10,2) YES<br>1deptno int(2)<br>YES<br>4 rows in set (0.00 sec)<br>虽然desc命令可以查看表定义，但是其输出的信息还是不够全面。为了得到更全面的表<br>定义信息，有时就需要查看创建表的SQL语句，可以使用如下命令查看： mysql&gt; show create table emp \G;<br>*★会<br>Table:emp<br>Create Table: CREATE TABLE emp′（’ename’ varchar(20) DEFAULT NULL,*hiredate’ date DEFAULT NULL,<br>‘sal decimal(10,2) DEFAULT NULL,<br>deptno’ int(2) DEFAULT NULL, KEY ‘idx emp_ename’(‘ename’)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gbk<br>1 row in set (0.02 sec) ERROR:<br>No query specified mysq1&gt;<br>从上面创建表的SQL语句中，除了可以看到表定义以外，还可以看到表的engine（存储引擎）和charset（字符集）等信息。“G”选项的含义是使得记录能够按照字段竖向排列，以便更好地显示内容较长的记录。<br>4.删除表<br>表的删除命令如下： DROP TABLE tablename<br>例如，要删除数据库emp可以使用以下命令： mysql&gt; drop table emp;<br>Query ok,o rows affected （o.oo sec)<br>5.修改表<br>对于已经创建好的表，尤其是已经有大量数据的表，如果需要做一些结构上的改变，可以先将表删除（drop），然后再按照新的表定义重建表。这样做没有问题，但是必然要做一些额外的工作，比如数据的重新加载。而且，如果有服务在访问表，也会对服务产生影响。<br>因此，在大多数情况下，表结构的更改都使用alter table语句，以下是一些常用的命令。</p>
<p>≦ 38 ≧<br>20 第2章SQL基础<br>（1）修改表类型，语法如下：<br>ALTER TABLE tablename MODIFY [cOLUMN] coTumn_definition [FIRST &#x2F; AFTER col_name]<br>例如，修改表emp的ename字段定义，将varchar(10)改为varchar(20)： mysql&gt; desc emp;<br>I Field 1Type 丨 Null l Key | Default l Extra<br>ename varchar(10) YES hiredate date YES sal decima1（10,2) YES deptno int(2) YES<br>4rows in set (o.o0 sec)<br>mysql&gt; alter table emp modify ename varchar(20):<br>Query Ok,0 rows affected (o.03 sec) Records:O Duplicates:O warnings:0 mysql&gt; desc emp;<br>|Field 1Type |Null |Key 丨Default |Extral<br>ename varchar(20) YES hiredate date YES<br>sal decima1(10,2) YES deptno int(2) YES<br>4 rows in set (0.00 sec)<br>（2）增加表字段，语法如下：<br>ALTER TABLE tablename ADD [CoLUMN] column_definition [FIRST &#x2F; AFTER col_name]<br>例如，在表emp中新增加字段age，类型为int(3)： mysql&gt; desc emp;<br>Field IType 丨 Null l Key| Default I Extra<br>ename varchar(20) YES hiredate date YES sal decima1(10,2) YES<br>deptno int（2) IYES 4 rows in set (o.00 sec)<br>mysql&gt; alter table emp ad column age int(3); Query oK,0 rows affected (0.03 sec)<br>Records:0 Duplicates:O warnings:0 mysql&gt; desc emp;<br>Field 1Type 1Null |Key |Default|Extra|<br>ename varchar(20) hiredate date YES<br>YES<br>sal decima1(10,2) YES deptno int(2) YES<br>age int(3) IYES 5rows in set(0.00 sec)<br>（3）删除表字段，语法如下：<br>ALTER TABLE tabTename DROP [COLUMN] col_name<br>例如，将字段age删除掉： mysql&gt; desc emp;<br> Field Type Null |Key l DefaultlExtral</p>
<p>≦ 39 ≧<br>2.2 （My）SQL使用入门 21<br>ename varchar(20) YES hiredate date YES sal decima1（10,2) YES deptno int(2) YES age int（3) YES<br>5rows in set (0.00 sec)<br>mysql&gt; alter table emp drop column age; Query ok,0 rows affected (0.04 sec) Records:ODuplicates:Owarnings:0 mysql&gt; desc emp;<br> Field Type | Null |Key | Default | Extra1<br>ename varchar（20) YES hiredate date YES sal decima1(10,2) YES<br>deptno int(2) YES 4rows in set (o.00 sec)<br>（4）字段改名，语法如下：<br>ALTER TABLE tablename CHANGE [cOLuMN] old col_name column_definition[FIRST&#x2F;AFTER col_name]<br>例如，将age改名为 age1，同时修改字段类型为 int(4)： mysql&gt; desc emp;<br>Field 1Type |Null 丨Key | Default | Extra |<br>ename varchar(20) YES hiredate date YES<br>sal decima1(10,2) YES deptno int(2) YES age int(3) YES<br>mysq1&gt; alter table emp change age age1 int(4)；<br>Query ok,o rows affected (o.o2 sec) Records:ODuplicates:owarnings:0<br>mysq1&gt; desc emp<br>Field I Type I Null I Key l Default I Extra<br>ename varchar(20) IYES hiredate date YES sal decima1(10,2) YES<br>1deptno int(2) YES agel int（4) YES<br>5rows in set (o.00 sec)<br>注意：change和modify都可以修改表的定义，不同的是change后面需要写两次列名，不方便。<br>但是change的优点是可以修改列名称，modify则不能。<br>（5）修改字段排列顺序。<br>前面介绍的字段增加和修改语法（ADD&#x2F;CHANGE&#x2F;MODIFY）中，都有一个可选项firstlafter column_name，这个选项可以用来修改字段在表中的位置，ADD增加的新字段默认是加在表的最后位置，而CHANGE&#x2F;MODIFY默认都不会改变字段的位置。<br>例如，将新增的字段birth date加在ename之后： mysql&gt; desc emp;</p>
<p>≦ 40 ≧<br>22 第2章SQL基础<br>|Field IType 1 Null I Key 丨 Default l Extra|<br>ename varchar(20) YES hiredate I date YES sal decima1(10,2) YES deptno int(2) YES age int(3) IYES<br>5 rows in set (o.00 sec)<br>mysql&gt; alter table emp add birth date after ename;<br>Query oK,0 rows affected (0.03 sec) Records:ODuplicates:0 warnings:0<br>mysql&gt; desc emp;<br>| Field 1Type |Null |Key 丨 Default | Extra|<br>Iename 1varchar(20) YES birth date YES<br>hiredate date YES sal decima1（10,2) YES<br>deptno |int(2) YES |age |int(3) IYES<br>6rows in set (0.00 sec)<br>修改字段age，将它放在最前面：<br>mysql&gt; alter tabTe emp modify age int(3) first;<br>Query ok,0 rows affected (0.03 sec) Records:0Duplicates:0warnings:0<br>mysq1&gt; desc emp;<br>Field |Type 1Null |Key| Default | Extra|<br>age int(3) YES ename varchar(20) YES birth date YES<br>hiredate date IYES sal |decima1（10,2) YES<br>deptno int(2) YES 6rows in set (o.00 sec)<br>注意：CHANGE&#x2F;FIRSTIAFTERCOLUMN这些关键字都属于MySQL在标准SQL上的扩展，在其<br>他数据库上不一定适用。<br>（6）更改表名，语法如下：<br>ALTER TABLE tabTename RENAME [ToJ new_tabTename<br>例如，将表emp改名为empl，命令如下：<br>mysql&gt; alter table emp rename empl; Query ok, O rows affected (O.oo sec) mysql&gt; desc emp;<br>ERROR 1146 (42s02): Table’sakila.emp’ doesn’t exist mysql&gt; desc empl;<br>|Null 丨Key|Default|Extra|<br>|Field 1Type<br>1age |int(3) YES ename varchar(20) YES birth 1date hiredate | date YES<br>YES<br>sal decima1(10,2) YES deptno int(2) YES<br>6 rows in set (0.00 sec)</p>
<p>≦ 41 ≧<br>2.2（My）SQL使用入门 23<br>2.2.3DML语句<br>DML操作是指对数据库中表记录的操作，主要包括表记录的插入（insert）更新（update）、删除（delete）和查询（select），是开发人员日常频繁使用的操作。下面将依次对它们进行介绍。<br>1.插入记录<br>表创建好后，就可以往里插人记录了。插入记录的基本语法如下：<br>INSERT INTO tab1ename （field1,fie7d2,,fie7dn) VALUES(value1,value2,,valuen);<br>例如，向表emp中插入以下记录，即ename为zzx1，hiredate为2000-01-01，sal为2000， deptno为1，命令执行如下：<br>mysql&gt; insert into emp （ename,hiredate,sal,deptno) values(zzx1′,2000-01-01’，’2000’,1）; Query OK,1 row affected (0.00 sec)<br>也可以不用指定字段名称，但是values后面的顺序应该和字段的排列顺序一致：<br>mysql&gt; insert into emp values(1isa’,2003-02-01,’3000′,2）; Query Ok, 1 row affected (o.00 sec)<br>含可空的字段、非空但是含有默认值的字段以及自增字段，可以不在insert后的字段列表里面出现，values后面只写对应字段名称的值。这些没写的字段自动设置为NULL、默认值、自增的下一个数字，这样在某些情况下可以大大缩短SQL语句的复杂性。<br>例如，只对表中的ename和sal字段显式插入值：<br>mysql&gt; insert into emp （ename,sal) values(‘dony′,1000); Query ok,1 row affected (0.o0 sec)<br>来查看一下实际插入值： mysql&gt; select *from emp;<br>ename hiredate sal deptno<br>ZZX 2000-01-01 100.00 lisa 2003-02-01 400.00<br>bjguan 2004-04-02 100.00  dony INULL 11000.00 NULL<br>果然，设置为可空的两个字段都显示为NULL。在MySQL中，insert语句还有一个很好的特性，可以一次性插人多条记录，语法如下：<br>INSERT INTO tablename（field1,field2,,fieldn) VALUES<br>（recordl value1,record1_value2,,record1_valuesn),(record2_value1, record2_value2,,record2_valuesn),<br>(recordn_valuel,recordn_value2,,recordn_valuesn)<br>可以看出，每条记录之间都用逗号进行了分隔。下面的例子中，对表dept一次插人两条记录： mysq1&gt; insert into dept values(5,’dept5′),（6,’dept6′）;<br>Query ok,2rows affected (0.04 sec) Records:2Duplicates:0warnings:0<br>mysql&gt; select * from dept; 1deptno |deptname|<br>11 tech<br>lsale<br>2</p>
<p>≦ 42 ≧<br>24 第2章SQL基础<br>|fin dept5<br>6 1dept6<br>5rows in set (o.o0 sec)<br>这个特性可以使得MySQL在插人大量记录时，节省很多的网络开销，大大提高插入效率。 2.更新记录<br>表里的记录值可以通过update命令进行更改，语法如下：<br>UPDATE tabTename SET field1&#x3D;valuel,field2.&#x3D;value2,,fieldn&#x3D;valuen [WHERE CONDITION]<br>例如，将表emp中ename为“lisa”的薪水（sal）从3000更改为4000：<br>mysql&gt; update emp set sal&#x3D;4000 where ename&#x3D;’1isa’; Query ok,1 row affected (0.00 sec)<br>Rows matched:1changed:1warnings:0<br>在MySQL中，update命令可以同时更新多个表中数据，语法如下： UPDATE t1,t2,,tn set t1.field1&#x3D;expr1,tn.fie1dn&#x3D;exprn [WHERE cONDITION] 在下例中，同时更新表emp中的字段sal和表dept中的字段deptname： mysql&gt; select * from emp;<br>lename |hiredate |sal 1deptno1<br>ZZX 2000-01-01 1100.00 lisa 12003-02-01 200.00 2<br>bjguan 2004-04-02 100.00 |dony 2005-02-05 2000.00<br>4rows in set (0.00 sec) mysql&gt; select * from dept; |deptno |deptname|<br>tech<br>2 sale<br>I fin<br>3 rows in set (o.00 sec)<br>mysql&gt; update emp a,dept b set a.sal&#x3D;a.sal*b.deptno,b.deptname&#x3D;a.ename where a.deptno&#x3D;b.deptno; Query oK,3 rows affected (0.04 sec)<br>Rows matched:5Changed:3warnings:0 mysql&gt; select * from emp;<br>Iename hiredate sal Ideptno<br>ZZx 2000-01-01 100.00 lisa 2003-02-01 400.00 2 bjguan丨 2004-04-02 100.00 1 dony 12005-02-05 2000.001 4<br>4rows in set (0.01 sec) mysql&gt; select * from dept; |deptno|deptname|<br>ZZX<br>2 |lisa 15 fin<br>3 rows in set (0.00 sec)</p>
<p>≦ 43 ≧<br>2.2（My）SQL使用入门 25<br>至此，两个表的数据同时进行了更新。<br>注意：多表更新的语法更多地用于根据一个表的字段来动态地更新另外一个表的字段。 3.删除记录<br>如果记录不再需要，则可以用delete命令进行删除，语法如下： DELETE FROM tablename [WHERE CONDITION]<br>例如，在emp中将ename为“dony”的记录全部删除，命令如下：<br>mysql&gt; delete from emp where ename&#x3D;’dony’; Query ok, 1 row affected (0.00 sec)<br>在MySQL中可以一次删除多个表的数据，语法如下：<br>FW<br>如果from后面的表名用别名，则delete后面也要用相应的别名，否则会提示语法错误。<br>在下例中，同时删除表emp和dept中deptno为3的记录： mysql&gt; select * from emp;<br>ename Ihiredate sal deptnoI<br>ZZX 2000-01-01 100.00 1<br>一<br>lisa 2003-02-01 200.00 2  bjguan 12004-04-02 100.00 1<br>bzshen 1 2005-04-01 1300.00 3 dony 2005-02-05 2000.00<br>5rows in set (o.o0 sec) mysql&gt; select * from dept; deptno | deptname|<br>tech sale<br>3 hr<br>fin<br>4rows in set (o.00 sec)<br>mysql&gt; delete a,b from emp a,dept b where a.deptno&#x3D;b.deptno and a.deptno&#x3D;3; Query ok,2 rows affected (0.04 sec)<br>mysq1&gt; mysq1&gt;<br>mysql&gt; select * from emp;<br>Iename hiredate sal deptno1<br>ZZX 2000-01-011 100.00 lisa 2003-02-0112 200.00 2<br>bjguan 2004-04-021100.00 dony 2005-02-0512 2000.00<br>4 rows in set (o.00 sec)<br>mysql&gt; select*from dept; I deptno | deptname|<br>1 tech<br>sale<br>5 fin 3 rows in set (o.o0 sec)</p>
<p>≦ 44 ≧<br>26 第2章SQL基础<br>注意：不管是单表还是多表，不加where条件将会把表的所有记录删除，所以操作时一定要小心。 4.查询记录<br>数据插人到数据库中后，就可以用SELECT命令进行各种各样的查询，使得输出的结果<br>符合用户的要求。SELECT的语法很复杂，这里只介绍最基本的语法： SELECT * FROM tabTename [WHERE CONDITION]<br>查询最简单的方式是将记录全部选出。在下面的例子中，将表emp中的记录全部查询出来：<br>mysql&gt; select * from emp;<br>ename Ihiredate 1sal 1deptno| ZZX 2000-01-01 2000.00<br>lisa 2003-02-01 4000.00 1 bjguan 2004-04-02 5000.00<br>3 rows in set (o.00 sec)<br>其中“<em>”表示要将所有的记录都选出来，也可以用逗号分割所有字段来代替，例如，以下两个查询是等价的：<br>mysql&gt; select * from emp;<br>|ename hiredate sal 1deptno|<br>1zZX 2000-01-01 2000.00<br>2003-02-01 4000.00<br>|bjguan| 2004-04-02 5000.00 3rows in set (o.o0 sec)<br>mysql&gt; select ename,hiredate,sal,deptno from emp;<br>ename hiredate sal deptno1<br>ZZX 2000-01-01 2000.00 lisa 2003-02-01 4000.00<br>2<br>Ibjguan 12004-04-02 5000.00 3rows in set (o.o0 sec)<br>“</em>”的好处是当需要查询所有字段信息时，查询语句很简单，但是只查询部分字段的时候，必须要将字段一个一个列出来。<br>上例中已经介绍了查询全部记录的语法，但是在实际应用中，用户还会遇到各种各样的查询要求，下面将分别进行介绍。<br>（1）查询不重复的记录。<br>有时需要将表中的记录去掉重复后显示出来，可以用distinct关键字来实现： mysql&gt; select ename,hiredate,sal,deptno from emp;<br>1ename hiredate |sal 1deptno1<br>ZZX 2000-01-01 2000.00 Tisa 2003-02-01 4000.00 2<br>1bjguan12004-04-0215000.00 3rows in set (o.00 sec)<br>mysql&gt; select distinct deptno from emp; |deptno|</p>
<p>≦ 45 ≧<br>2.2（My）SQL使用入门 27<br>2<br>2rows in set (o.00 sec)（2）条件查询。<br>在很多情况下，用户并不需要查询所有的记录，而只是需要根据限定条件来查询一部分数据，用where关键字可以实现这样的操作。<br>例如，需要查询所有deptno为1的记录： mysql&gt; select * from emp;<br>Iename |hiredate |sal | deptno丨 ZZX 2000-01-01 2000.00 lisa 2003-02-01 4000.00 |bjguan丨2 2004-04-02 5000.00<br>3rows in set (o.00 sec)<br>mysql&gt; select deptno&#x3D;<br>ename lhiredate sal 1deptno1<br>1zzx 2000-01-0112000.00<br>|bjguan12004-04-0215000.00 2 rows in set (o.00 sec)<br>结果集中将符合条件的记录列出来。上面的例子中，where后面的条件是一个字段的&#x3D;比较，除了&#x3D;外，还可以使用&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、！&#x3D;等比较运算符；多个条件之间还可以使用or、 and等逻辑运算符进行多条件联合查询，运算符会在以后的章节中详细讲解。<br>以下是一个使用多字段条件查询的例子：<br>mysql&gt; select * from emp where deptno&#x3D;1 and sal&lt;3000;<br>1ename | hiredate sal | deptno1<br>Izzx 12000-01-0112000.0011<br>1 row in set(0.00 sec)（3）排序和限制。<br>我们经常会有这样的需求，取出按照某个字段进行排序后的记录结果集，这就用到了数据库的排序操作，用关键字ORDERBY来实现，语法如下：<br>SELECT *FROM tablename [WHERE CONDITION] [ORDER BY fieTd1 [DESC|ASC], field2 [DESC|ASC] fieldn [DESC|ASC]]<br>其中，DESC和ASC是排序顺序关键字，DESC表示按照字段进行降序排列，ASC则表示升序排列，如果不写此关键字默认是升序排列。ORDERBY后面可以跟多个不同的排序字段，并且每个排序字段可以有不同的排序顺序。<br>例如，把emp表中的记录按照工资高低进行显示： mysql&gt; select * from emp order by sal;<br>Iename |hiredate sal 1 deptno1<br>ZZX 2000-01-01 2000.001<br>1<br>bzshen 2005-04-01 3000.00 lisa 2003-02-011 4000.0012 bjguan 2004-04-02|5000.00丨1</p>
<p>≦ 46 ≧<br>28 第2章SQL基础<br>4rows in set (0.00 sec)<br>如果排序字段的值一样，则值相同的字段按照第二个排序字段进行排序，依次类推。如果只有一个排序字段，则这些字段相同的记录将会无序排列。<br>例如，把emp表中的记录按照部门编号deptno字段排序： mysql&gt; select * from emp order by deptno;<br>hiredate sal 1deptno丨<br>ename<br>2000-01-01 2000.00<br>ZZX<br>bjguan 2004-04-02 5000.00 lisa 2003-02-01 4000.00<br>bzshen 2005-04-01 4000.00 4rows in set (o.00 sec)<br>对于deptmno相同的前两条记录，如果要按照工资由高到低排序，可以使用以下命令： mysql&gt; select * from emp order by deptno,sal desc;<br>Iename hiredate sal deptno1<br>bjguan|z 2004-04-02 5000.00 ZZX 2000-01-01 2000.00<br>lisa 2003-02-01 4000.00 2 Ibzshen 1.2005-04-01| 4000.00 3<br>4rows in set (0.00 sec)<br>对于排序后的记录，如果希望只显示一部分，而不是全部，则可以使用LIMIT关键字来实现。LIMIT的语法如下：<br>SELECT .[LIMIT offset_start,roW_count]<br>其中offset_start表示记录的起始偏移量，row_count表示显示的行数。<br>在默认情况下，起始偏移量为0，只需要写记录的行数就可以，这时，实际显示的就是前<br>n条记录。例如，显示emp表中按照sal排序后的前3条记录： mysql&gt; select * from emp order by sal limit 3;<br>lename |hiredate sal Ideptno|<br>ZZX 2000-01-0112000.00 lisa 2003-02-01 4000.00<br>bzshen 2005-04-01 4000.00 3rows in set (o.00 sec)<br>如果要显示emp表中按照sal排序后从第二条记录开始的3条记录，可以使用以下命令： mysql&gt; select * from emp order by sal 1imit 1,3;<br>Iename |hiredate |sal |deptno1<br>1lisa 12003-02-011 4000.00 |bzshen| 2005-04-01 4000.00<br>3<br>1bjguan 12004-04-02 5000.0011 3rows in set (0.00 sec)<br>limit经常和orderby一起配合使用来进行记录的分页显示。<br>注意：limit属于MySQL扩展SQL92后的语法，在其他数据库上不能通用。</p>
<p>≦ 47 ≧<br>2.2（My）SQL使用入门 29<br>（4）聚合。<br>很多情况下，用户都需要进行一些汇总操作，比如统计整个公司的人数或者统计每个部门的人数，这时就要用到SQL的聚合操作。<br>聚合操作的语法如下：<br>SELECT [field1,field2.,fieldn] fun_name FROM tablename<br>[WHERE where_contition]<br>[GROUP BY field1,fie1d2,,fie1dn[WITH ROLLUP]]<br>[HAVING where_ contition] 其参数说明如下。<br>fun_name 表示要做的聚合操作，也就是聚合函数，常用的有sum（求和）、count(*)（记录数）、avg（平均值）、max（最大值）、min（最小值）。<br>OGROUPBY关键字表示要进行分类聚合的字段，比如要按照部门分类统计员工数量，部门就应该写在GROUPBY后面。<br>WITHROLLUP是可选参数，表明是否对分类聚合后的结果进行再汇总。 HAVING关键字表示对分类后的结果再进行条件的过滤。<br>注意：HAVING和WHERE的区别在于，HAVING是对聚合后的结果进行条件的过滤，而WHERE<br>是在聚合前就对记录进行过滤。如果逻辑允许，我们尽可能用WHERE先过滤记录，因为这样结果集减小，聚合的效率将大大提高，最后再根据逻辑看是否用HAVING进行再过滤。<br>例如，要在emp表中统计公司的总人数：<br>mysql&gt; select count(1) from emp; |count（1)1<br>1 row in set (0.00 sec)<br>在此基础上，要统计各个部门的人数：<br>mysql&gt; select deptno,count(1) from emp group by deptno;<br>|deptno count(1) 3rows in set (o.00 sec)<br>更细一些，既要统计各部门人数，又要统计总人数：<br>mysql&gt; select deptno,count(1) from emp group by deptno with rollup; 1 deptno I count(1)<br>NULL<br>rows in set (o.00 sec)<br>统计人数大于1人的部门：<br>mysql&gt; select deptno,count(1）from emp group by deptno having count（1)&gt;1;</p>
<p>≦ 48 ≧<br>30 第2章SQL基础<br>Ideptno l count(1)| 1 row in set (o.00 sec)<br>最后统计公司所有员工的薪水总额、最高和最低薪水： mysql&gt; select * from emp;<br>ename 1hiredate 1sal |deptno| E<br>ZZX 2000-01-01 11100.00 lisa 2003-02-01 400.00<br>|bjguan 2004-04-02 一 100.00 Idony 12005-02-0512000.00<br>4rows in set (0.00 sec)<br>mysql&gt; select sum(sal),max(sal),min(sal) from emp; sum(sal)1 max(sal) 1min(sa1)1<br>12600.00 12000.00 100.00<br>1row in set(0.00 sec)（5）表连接。<br>当需要同时显示多个表中的字段时，可以用表连接来实现。从大类上分，表连接分为内连接和外连接，它们之间的最主要区别是，内连接仅选出两张表中互相匹配的记录，而外连接会选出其他不匹配的记录。我们最常用的是内连接。<br>例如，查询出所有雇员的名字和所在部门名称，因为雇员名称和部门分别存放在表emp<br>和dept中，因此，需要使用表连接来进行查询： mysql&gt; select * from emp;<br>Iename | hiredate sal 1deptnol<br>ZZX 2000-01-01 2000.00 I lisa 2003-02-01 4000.00 bjguan 2004-04-02 5000.00<br>1<br>bzshen丨 2005-04-011 4000.00<br>4rows in set (o.00 sec) mysql&gt; select * from dept;<br>Ideptno deptname<br>1tech<br>2 1sale<br>ihr<br>3rows in set (o.o0 sec)<br>mysql&gt; select ename,deptname from emp,dept where emp.deptno&#x3D;dept.deptno;<br>deptname<br>ename<br>ZZX Itech lisa sale<br>bjguan tech 4 rows in set (0.00 sec)<br>外连接又分为左连接和右连接，具体定义如下。</p>
<p>≦ 49 ≧<br>2.2（My）SQL使用入门 31<br>左连接：包含所有的左边表中的记录甚至是右边表中没有和它匹配的记录。右连接：包含所有的右边表中的记录甚至是左边表中没有和它匹配的记录。<br>例如，查询emp中所有用户名和所在部门名称： mysql&gt; select * from emp;<br>I ename hiredate sal I deptno|<br>ZZX 2000-01-01 2000.00 lisa 2003-02-01 4000.00 bjguan 12 2004-04-02 5000.00 I bzshen | 2005-04-01 4000.00 dony 2005-02-05 2000.00<br>5rows in set (0.00 sec) mysql&gt; select * from dept;<br>|deptno | deptname|<br>1 tech 2 sale<br>|hr<br>3rows in set (o.o0 sec)<br>mysql&gt; select ename,deptname from emp left join dept on emp.deptno&#x3D;dept. deptno; ename deptname<br>ZZX tech#isa sale bjguan1 tech<br>bzshen| dony<br>5rows in set (o.o0 sec)<br>比较这个查询和上例中的查询，都是查询用户名和部门名，两者的区别在于本例中列出了所有的用户名，即使有的用户名（dony）并不存在合法的部门名称（部门号为4，在dept 中没有这个部门）；而上例中仅仅列出了存在合法部门的用户名和部门名称。<br>右连接和左连接类似，两者之间可以互相转化，例如，上面的例子可以改写为如下的右连接： mysql&gt; select ename,deptname from dept right join emp on dept.deptno&#x3D;emp.deptno;<br>ename deptname<br>ZZX tech lisa |sale bjguan tech<br>bzshen I hr dony<br>5 rows in set (o.00 sec)（6）子查询。<br>某些情况下，当进行查询的时候，需要的条件是另外一个select语句的结果，这个时候，就要用到子查询。用于子查询的关键字主要包括in、not in、&#x3D;、！&#x3D;、exists、notexists 等。<br>例如，从emp表中查询出所有部门在dept表中的所有记录： mysql&gt; select *from emp;<br>1ename 1 hiredate Isal 1deptno1<br>1zzx 12000-01-0112000.00 丨lisa 2003-02-011.4000.0012 1bjguan12004-04-0215000.001</p>
<p>≦ 50 ≧<br>32 第2章SQL基础<br>1 bzshen 1 2005-04-01 1 4000.00 1 3 I dony 12005-02-0512000.00<br>5rows in set (o.00 sec) mysql&gt; select * from dept;<br>|deptno | deptname 1 tech<br>2 sale 13 hr 15 fin<br>4rows in set (0.00 sec)<br>mysq1&gt; select<em>from emp where deptno in（select deptno from dept); Iename I hiredate Isal deptno1<br>ZZX 2000-01-01 2000.00 lisa 2003-02-01 4000.00 2 bjguan 2004-04-02 5000.00 bzshen 2005-04-01 4000.00<br>3<br>4rows in set (o.00 sec)<br>如果子查询记录数唯一，还可以用&#x3D;代替in：<br>mysql&gt; select * from emp where deptno &#x3D; (select deptno from dept); ERROR 1242 (21000): subquery returns more than 1 row<br>mysql&gt; select * from emp where deptno &#x3D; (select deptno from dept limit 1); ename I hiredate Isal deptno ZZX 1 2000-01-01 12000.0011 1bjguan 12004-04-02 5000.0011<br>2rows in set (0.o0 sec)<br>某些情况下，子查询可以转化为表连接，例如：<br>mysql&gt; select * from emp where deptno in（select deptno from dept);<br>|hiredate |deptno|<br>Iename sal<br>zzx 2000-01-01 2000.001 1 |lisa 2003-02-01 4000.00 2 bjguan 2004-04-02 5000.00 |bzshen 2005-04-01 4000.001 1<br>4rows in set (o.00 sec) 转换为表连接后：<br>mysql&gt; select emp.</em> from emp ,dept where emp.deptno&#x3D;dept.deptno;<br>|hiredate<br>ename Isal deptno1<br>ZZX 2000-01-01 2000.00 lisa 2003-02-01 4000.00 bjguan 2004-04-02 5000.00<br>I bzshen| 2005-04-01 4000.00 4rows in set (0.00 sec)<br>注意：表连接在很多情况下用于优化子查询。（7）记录联合。<br>我们经常会碰到这样的应用，将两个表的数据按照一定的查询条件查询出来后，将结果合并到</p>
<p>≦ 51 ≧<br>2.2（My）SQL使用入门 33<br>一起显示出来，这个时候，就需要用union和union all关键字来实现这样的功能，具体语法如下：<br>SELECT<em>FROM t1 UNION&#x2F;UNION ALL SELECT</em>FROM t2<br>UNION&#x2F; UNION ALL SELECT * FROM tn;<br>UNION和UNIONALL的主要区别是UNIONALL是把结果集直接合并在一起，而 UNION是将UNIONALL后的结果进行一次DISTINCT，去除重复记录后的结果。<br>来看下面的例子，将emp和dept表中的部门编号的集合显示出来： mysql&gt; select * from emp;<br>ename hiredate Isal I deptno<br>ZZX 2000-01-01 100.00 lisa 2003-02-0114 400.00 2 bjguan 2004-04-02 100.00 dony 2005-02-0512000.00<br>4rows in set (0.00 sec) mysql&gt; select * from dept;<br>Ideptno 丨 deptname<br>11 tech<br>I sale fin<br>3rows in set (o.o0 sec)<br>mysql&gt; select deptno from emp</p>
<blockquote>
<p>union all<br>-&gt; select deptno from dept; deptno|<br>2 5<br>7 rows in set (0.00 sec)<br>将结果去掉重复记录后显示如下： mysql&gt; select deptno from emp<br>-&gt;union<br>-&gt; select deptno from dept;<br>deptno1 x<br>4 rows in set (o.00 sec) 2.2.4DCL语句<br>DCL语句主要是DBA用来管理系统中的对象权限时使用，一般开发人员很少使用。下</p>
</blockquote>
<p>≦ 52 ≧<br>34 第2章SQL基础面通过一个例子简单说明一下。<br>创建一个数据库用户z1，具有对sakila数据库中所有表的SELECT&#x2F;INSERT权限：<br>mysql&gt; grant select,insert on sakila.* toz1‘@’localhost’identified by ‘123’; Query ok,0 rows affected (o.oo sec)<br>mysql&gt;exit Bye<br>[mysq1@db3<del>]smysq]-uz1-p123<br>mysql&gt; use sakila Database changed<br>mysql&gt; insert into emp values(‘bzshen′,2005-04-01′,3000,’3）; Query ok,1 row affected (0.04 sec)<br>由于权限变更，需要将z1的权限变更，收回INSERT，只能对数据进行SELECT操作：[mysq1@db3</del>]s mysq] -uroot<br>mysql&gt; revoke insert on sakila.* from z1‘@’localhost’; Query oK,0 rows affected (o.oo sec)<br>mysql&gt; exit Bye<br>用户z1重新登录后执行前面的语句：[mysq1@db3~]$mysq]-uz1-p123<br>mysql&gt; insert into emp values(‘bzshen’,’2005-04-01’,3000,’3’); ERROR 1046 (3D000):No database selected<br>mysql&gt; use sakila Database changed<br>mysql&gt; insert into emp values(bzshen′,2005-04-01,3000,’3’);<br>ERROR 1142 (42000): INsERT command denied to user ‘z1‘@’localhost for table’emp’<br>以上例子中的grant和revoke分别授出和收回了用户z1的部分权限，达到了我们的目的。<br>关于权限的更多内容，将会在本书的第26章中详细介绍。 2.3帮助的使用<br>在MySQL使用过程中，可能经常会遇到以下问题：某个操作语法忘记了，如何快速查找？<br>○如何快速知道当前版本上某个字段类型的取值范围？<br>当前版本都支持哪些函数？请举例说明。当前版本是否支持某个功能？<br>对于上面列出的各种问题，我们可能想到的办法是查找MySQL的文档。不错，这些问题在MySQL官方文档中都可以很清楚地查到，但是却要耗费大量的时间和精力。<br>所以对于以上问题，最好的解决办法是使用MySQL安装后自带的帮助文档，这样当遇<br>到问题时就可以方便快捷地进行查询。 2.3.1按照层次看帮助<br>如果不知道帮助能够提供些什么，那么就可以用“？contents”命令来显示所有可供查询<br>的分类，如下例所示： mysql&gt; ? contents<br>You asked for help about help category:”contents”</p>
<p>≦ 53 ≧<br>2.3帮助的使用 35<br>For more information, type help <item>‘,where <item> is one of the following categories:<br>Account Management Administration<br>Compound statements<br>Data Definition Data Manipulation<br>Data Types Functions<br>Functions and Modifiers for Use with GRouP BY<br>Geographic Features Help Metadata<br>Language Structure Plugins<br>Procedures<br>Storage Engines Table Maintenance Transactions<br>User-Defined Functions Utility<br>对于列出的分类，可以使用“？类别名称”的方式针对用户感兴趣的内容做进一步的查<br>看。例如，想看看MySQL中都支持哪些数据类型，可以执行“？data types”命令： mysql&gt;? data types<br>You asked for help about help category: “Data Types”<br>For more information, type ‘help <item>‘, where <item> is one of the following topics:<br>AUTO INCREMENT<br>BIGINT BINARY<br>BIT BLOB<br>BLOB DATA TYPE BOOLEAN<br>上面列出了此版本支持的所有数据类型，如果想知道int类型的具体介绍，也可以利用上面的方法进一步查看：<br>mysql&gt;?int Name:’INT’ Description:<br>INT[(M)] [UNSIGNED] [ZEROFILL]<br>A normal-size integer. The signed range is -2147483648 to 2147483647. The unsigned range is 0 to 4294967295.<br>帮助文档中显示了int类型的详细描述。通过这种“？类别名称”的方式，就可以一层<br>层地往下查找用户所关心的主题内容。 2.3.2快速查阅帮助<br>在实际应用当中，如果需要快速查阅某项语法时，可以使用关键字进行快速查询。例如，想知道show命令都能看些什么，可以用如下命令：<br>mysq1&gt;? show Name:’SHOW’ Description:<br>SHOw has many forms that provide information about databases, tables, columns, or status information about the server. This section describes<br>those following: SHOW AUTHORS<br>SHOW CHARACTER SET [LIKE ‘pattern’] SHOW COLLATION [LIKE‘pattern’]</p>
<p>≦ 54 ≧<br>36 第2章SQL基础<br>SHOW [FULL] COLUMNS FROM tbl name [FROM db name] [LIKEpattern’] SHOW CONTRIBUTORS<br>SHOW CREATE DATABASE db name SHOW CREATE EVENT eVent name SHOW CREATE FUNCTION funcname<br>例如，如果想参看CREATETABLE的语法，可以使用以下命令：<br>mysql&gt;? create table Name:’CREATE TABLE<br>Description: Syntax:<br>CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl name<br>(create definition,…)<br>[tableoption…][partition_options]<br>CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl name<br>[（create definition,…)][table options]<br>[partition options][IGNORE | REPLACE][As] query_expression<br>CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl name<br>[LIKE old tbl_name|（LIKE old tbl name)} 2.4查询元数据信息<br>在日常工作中，我们经常会遇到类似下面的应用场景： O删除数据库testl下所有前缀为tmp的表；<br>将数据库test1下所有存储引擎为myisam的表改为innodb。<br>对于这类需求，在MySQL5.0之前只能通过showtables、showcreatetable或者showtable status等命令来得到指定数据库下的表名和存储引擎，但通过这些命令显示的内容有限且不适合进行字符串的批量编辑。如果表很多，则操作起来非常低效。<br>MySQL5.0之后提供了一个新的数据库information_schema，用来记录MySQL中的元数据信息。元数据指的是数据的数据，比如表名、列名、列类型、索引名等表的各种属性名称。这个库比较特殊，它是一个虚拟数据库，物理上并不存在相关的目录和文件；库里showtables 显示的各种“表”也并不是实际存在的物理表，而全部是视图。对于上面的两个需求，可以简单地通过两个命令得到需要的SQL语句：<br>select concat(‘drop table testl.’,table name,’;) from tables where table schema&#x3D;’testl’and table_name like tmp%’;<br>select concat(‘alter table testi.,table name,engine&#x3D;innodb;’) from tables where table schema&#x3D;’testl’ and engine&#x3D;’MyISAM’;<br>下面列出一些比较常用的视图。<br>OSCHEMATA：该表提供了当前MySQL实例中所有数据库的信息，showdatabases的结果取之此表。<br>TABLES：该表提供了关于数据库中的表的信息（包括视图），详细表述了某个表属于哪个schema、表类型、表引擎、创建时间等信息。showtablesfrom schemaname的结果取之此表。<br>OCOLUMNS：该表提供了表中的列信息，详细表述了某张表的所有列以及每个列的信</p>
<p>≦ 55 ≧<br>2.5小结 37<br>息。showcolumnsfrom schemaname.tablename的结果取之此表。<br>OSTATISTICS：该表提供了关于表索引的信息。showindexfrom schemaname.tablename<br>的结果取之此表。 2.5小结<br>本章简单地介绍了SQL语句的基本分类DML&#x2F;DDL&#x2F;DCL，并对每一种分类下的常用SQL 的用法进行了举例说明。MySQL在标准SQL的基础上进行了很多扩展，本章对常用的一些语法做了简单介绍，对于更详细的说明，读者可以参考MySQL的帮助或者官方文档。在本章的最后，还介绍了用户应如何使用MySQL中的帮助文档，以便快速查找各种语法定义。</p>
<p>≦ 56 ≧<br>第3章 MySQL支持的数据类型每一个常量、变量和参数都有数据类型，它用来指定一定的存储格式、约束和有效范围。<br>MySQL提供了多种数据类型，主要包括数值型、字符串类型、日期和时间类型。不同的MySQL 版本支持的数据类型可能会稍有不同，用户可以通过查询相应版本的帮助文件来获得具体信<br>息。本章将以MySQL5.7为例，详细介绍MySQL中的各种数据类型。 3.1数值类型<br>MySQL支持所有标准SQL中的数值类型，其中包括严格数值类型（INTEGER、 SMALLINT、DECIMAL和NUMERIC），近似数值数据类型（FLOAT、REAL和DOUBLE PRECISION），并在此基础上做了扩展。扩展后增加了TINYINT、MEDIUMINT和BIGINT 这3种长度不同的整型，并增加了BIT类型，用来存放位数据。表3-1中列出了MySQL5.7 中支持的所有数值类型，其中INT是INTEGER的同名词，DEC是DECIMAL的同名词。<br>表3-1 MySQL中的数值类型整数类型字节最小值最大值<br>有符号-128 有符号127<br>TINYINT 1 无符号0 无符号255<br>有符号-32768 有符号32767<br>SMALLINT 2<br>无符号0 无符号65535<br>有符号-8388608 有符号8388607<br>MEDIUMINT 3<br>无符号0 无符号1677215<br>有符号-2147483648 有符号2147483647<br>INT、INTEGER 4<br>无符号0 无符号4294967295<br>BIGINT 8 有符号-9223372036854775808 有符号9223372036854775807<br>无符号0 无符号18446744073709551615<br>浮点数类型最小值最大值<br>FLOAT 4 ±1.175494351E-38 ±3.402823466E+38 DOUBLE 8 ±2.2250738585072014E-308 ±1.7976931348623157E+308<br>定点数类型描述 DEC(M,D), M+2 最大取值范围与DOUBLE相同，给定DECIMAL的有效取值范围由M和D决定 DECIMAL(M,D)</p>
<p>≦ 57 ≧<br>3.1数值类型 39<br>续表<br>位类型 最小值 最大值 BIT(M) 1~8 BIT(1) BIT(64)<br>在整数类型中，按照取值范围和存储方式的不同，分为tinyint、smallint、mediumint、int 和bigint这5个类型。如果超出类型范围的操作，会发生“Outofrange”错误提示。为了避免此类问题发生，在选择数据类型时要根据应用的实际情况确定其取值范围，最后根据确定的结果慎重选择数据类型。<br>对于整型数据，MySQL还支持在类型名称后面的小括号内指定显示宽度。例如，int(5) 表示当数值宽度小于5位时在数字前面填满宽度，如果不显示指定宽度，则默认为int(11)。一般配合zerofill使用，顾名思义，zerofill就是用“o”填充的意思，也就是在数字位数不够的空间用字符“0”填满。以下几个例子分别描述了填充前后的区别。<br>（1）创建表t1，有id1和id2两个字段，指定其数值宽度分别为int和int(5)： mysql&gt; create table t1 （id1 int,id2 int(5));<br>Query oK,0 rows affected (0.03 sec) mysql&gt; desc t1;<br>Field 丨Type |Null |Key|Default丨Extra|<br>|id1 int(11) YES INULL 1id2 int(5) YES NULL<br>2rows in set (o.00 sec)<br>（2）在idl和id2中都插入数值1，可以发现格式没有异常：<br>mysql&gt; insert into t1 values(1,1); Query ok,1 row affected (0.00 sec)<br>mysql&gt; select * from t1; |id1丨id2<br>1row in set (o.00 sec)<br>（3）分别修改id1和id2的字段类型，加人zerofill参数： mysql&gt; alter table t1 modify id1 int zerofill;<br>Query ok,1 row affected (0.04 sec) Records:1 Duplicates:0 warnings:0<br>mysql&gt; alter table tl modify id2 int(5) zerofill;<br>Query ok,1 row affected (0.03 sec) Records:1Duplicates:0 warnings:0<br>mysql&gt; select * from t1;<br>|id1 |id2<br>|00000000011000011 1row in set (o.00 sec)<br>可以发现，在数值前面用字符“0”填充了剩余的宽度。大家可能会有所疑问，设置了宽度限制后，如果插人大于宽度限制的值，会不会截断或者插不进去报错？答案是肯定的：不会对插入的数据有任何影响，还是按照类型的实际精度进行保存，这时，宽度格式实际已经没有意义，左边不会再填充任何的“0”字符。下面在表t1的字段id1中插入数值1，id2中</p>
<p>≦ 58 ≧<br>40 第3章MySQL支持的数据类型<br>插入数值1111111，位数为7，大于id2的显示位数5，再观察一下测试结果：<br>mysql&gt; insert into t1 values(1,1111111); Query ok,1 row affected (0.o0 sec)<br>mysql&gt; select * from t1; lidl lid2<br>00001<br>2rows in set (0.00 sec)<br>很显然，如上面所说，id2中显示了正确的数值，并没有受宽度限制影响。<br>所有的整数类型都有一个可选属性UNSIGNED（无符号），如果需要在字段里面保存非负数或者需要较大的上限值时，可以用此选项，它的取值范围是正常值的下限取0，上限取原值的2倍，例如，tinyint有符号范围是-128～+127，而无符号范围是0～255。如果一个列指定为zerofill，则MySQL自动为该列添加UNSIGNED属性。<br>另外，整数类型还有一个属性：AUTO_INCREMENT。在需要产生唯一标识符或顺序值时，可利用此属性，这个属性只用于整数类型。AUTO_INCREMENT值一般从1开始，每行增加1。在插人NULL到一个AUTO_INCREMENT列时，MySQL插人一个比该列中当前最大值大1 的值。一个表中最多只能有一个AUTO_INCREMENT列。对于任何想要使用AUTO_INCREMENT 的列，应该定义为NOTNULL，并定义为PRIMARYKEY或定义为UNIQUE键。例如，可按下列任何一种方式定义AUTO_INCREMENT列：<br>CREATE TABLE AI (ID INT AUTO INCREMENT NOT NULL PRIMARY KEY);<br>CREATE TABLE AI(ID INT AUTO INCREMENT NOT NULL,PRIMARY KEY(ID)); CREATE TABLE AI （ID INT AUTO INCREMENT NOT NULL ,UNIQUE(ID));<br>对于小数的表示，MySQL分为两种方式：浮点数和定点数。浮点数包括float（单精度）和double（双精度），而定点数则只有decimal一种表示。定点数在MySQL内部以字符串形式存放，比浮点数更精确，适合用来表示货币等精度高的数据。<br>浮点数和定点数都可以用类型名称后加“(M,D)”的方式来进行表示，“(M,D)”表示该值一共显示M位数字（整数位+小数位），其中D位位于小数点后面，M和D又称为精度和标度。例如，定义为float(7,4)的一个列可以显示为-999.9999。MySQL保存值时进行四舍五人，因此如果在float（7,4)列内插入999.00009，近似结果是999.0001。值得注意的是，浮点数后面跟“(M,D)”的用法是非标准用法，如果要用于数据库的迁移，则最好不要这么使用。float 和double在不指定精度时，默认会按照实际的精度（由实际的硬件和操作系统决定）来显示，而decimal在不指定精度时，默认的整数位为10，默认的小数位为0。<br>下面通过一个例子来比较float、double和decimal三者之间的不同。<br>（1）创建测试表，分别将idl、id2、id3字段设置为float(5,2)、double(5,2)、decimal(5.2)： CREATE TABLEtI’（<br>“id1′float(5,2) default NULL, id2′ doub1e(5,2) default NULL,’id3′ decimal(5,2) default NULL<br>（2）往id1、id2和id3这3个字段中插人数据1.23： mysq1&gt; insert into t1 values(1.23,1.23,1.23);<br>Query oK,1 row affected (o.o0 sec) mysq1&gt;</p>
<p>≦ 59 ≧<br>3.1 数值类型 41<br>id21id3<br>11.2311.2311.23 1 row in set (0.00 sec)<br>可以发现，数据都正确地插人了表t1。<br>（3）再向id1和id2字段中插入数据1.234，而id3字段中仍然插人1.23：<br>mysq1&gt; insert into t1 values(1.234,1.234,1.23); Query ok,1 row affected (o.o0 sec)<br>mysql&gt; select * from t1; idl<br>11.2311.2311.23 11.2311.2311.23<br>2 rows in set (o.o0 sec)<br>可以发现，idl、id2、id3都插入了表tl，但是id1和id2由于标度的限制，舍去了最后一位，数据变为了1.23。<br>（4）同时向id1、id2、id3字段中都插入数据1.234：<br>mysq1&gt; insert into t1 values(1.234,1.234,1.234）; Query ok,1 row affected, 1 warning (0.00 sec)<br>mysql&gt; show warnings; I Level I code I Message<br>I Note l 1265 | Data truncated for column id3’at row 1| 1row in set (o.00 sec)<br>mysql&gt; select from tl; idl<br>11.2311.2311.23<br>11.2311.23 1.23 3rows in set (o.00 sec)<br>此时发现，虽然数据都插入进去，但是系统出现了一个Warning，报告id3被截断。如果是在传统的SQLMode（第13章会详细介绍SQLMode）下，这条记录是无法插入的。<br>（5）将idl、id2、id3字段的精度和标度全部去掉，再次插人数据1.23：<br>mysql&gt; alter table t1 modify id1 float; Query ok,3 rows affected (o.03 sec) Records: 3 Duplicates:0 warnings:0<br>mysql&gt; alter table t1 modify id2 double;<br>Query ok,3 rows affected (0.04 sec) Records:3Duplicates:0warnings:0<br>mysql&gt; alter table t1 modify id3 decimal;<br>Query ok,3 rows affected,3 warnings (0.02 sec)<br>Records:3Duplicates:0 warnings:0 mysql&gt; desc t1;<br>1 Field l Type | Null l Key 丨 Default | Extra|</p>
<p>≦ 60 ≧<br>42 第3章MySQL支持的数据类型<br>|id1 1 float IYES NULL id2 1double YES NULL 1id3 Idecima1（10,0)1 YES INULL<br>3rows in set (o.o0 sec)<br>mysql&gt; insert into t1 values(1.234,1.234,1.234); Query ok, 1 row affected,1 warning (0.o0 sec)<br>mysql&gt; show warnings; |Level| code 丨 Message<br>|Note l1265 lData truncated for column id3’at row 1|<br>1row in set(0.00 sec) mysql&gt; select <em>from t1;<br>|id1 丨id2 |id3 11.23411.2341<br>1 row in set (o.o0 sec)<br>这个时候，可以发现id1、id2字段中可以正常插入数据，而id3字段的小数位被截断。上面这个例子验证了上面提到的浮点数如果不写精度和标度，则会按照实际精度值显示，<br>如果有精度和标度，则会自动将四舍五人后的结果插人，系统不会报错；定点数如果不写精度和标度，则按照默认值decimal(10.0)来进行操作，并且如果数据超越了精度和标度值，系统则会报错。<br>对于BIT（位）类型，用于存放位字段值，BIT(M)可以用来存放多位二进制数，M范围为1～64，如果不写，则默认为1位。对于位字段，直接使用SELECT命令将不会看到结果，可以用binO（显示为二进制格式）或者hexO（显示为十六进制格式）函数进行读取。<br>下面的例子中，对测试表t2中的bit类型字段id做insert和select操作，这里重点观察一下select的结果：<br>mysqT&gt; desc t2;<br>|Field I Type |Nul | Key | Default | Extra |<br>|id |bit(1)丨 YES INULL 1 row in set (0.00 sec)<br>mysql&gt; insert into t2 values(1); Query ok,1 row affected (o.o0 sec)<br>mysql&gt; select</em>from t2; Iid<br>1 row in set (o.00 sec)<br>可以发现，直接select*的结果为NULL。下面改用binO和hexO函数再试试：<br>mysql&gt; select bin(id),hex(id) from t2; 1bin(id)丨 hex（id)1<br>1 |1 1 row in set (o.00 sec)</p>
<p>≦ 61 ≧<br>3.2日期时间类型 43<br>结果可以正常显示为二进制数字和十六进制数字。<br>数据插入bit类型字段时，首先转换为二进制，如果位数允许，将成功插入；如果位数小于实际定义的位数，则插入失败。下面的例子中，在t2表插人数字2，因为它的二进制码是<br>“10”，而id的定义是bit（1)，将无法进行插入： mysql&gt; insert into t2 values(2);<br>Query ok,1 row affected,1 warning (0.o0 sec) mysql&gt; show warnings;<br>1Level |Code | Message<br>1warning 1 1264 | out of range value adjusted for columnid’at row11 1 row in set (0.01 sec)<br>将ID定义修改为bit(2)后，重新插入，插入成功：<br>mysql&gt; alter table t2 modify id bit(2); Query ok,1 row affected (0.02 sec)<br>Records:1Duplicates:0warnings:0<br>mysql&gt; insert into t2values(2); Query Ok,1 row affected (0.00 sec)<br>mysql&gt; select bin(id),hex(id) from t2; 1bin（id)丨 hex（id)1<br>|1&#x2F;1 110 12<br>2rows in set (o.00 sec) 3.2日期时间类型<br>MySQL中有多种数据类型可以用于日期和时间的表示，不同的版本可能有所差异，表3-2 列出了MySQL5.7中所支持的日期和时间类型。<br>表3-2 MySQL中的日期和时间类型<br>日期和时间类型最小值最大值 DATE 4 1000-01-01 9999-12-31<br>DATETIME 8 1000-01-0100:00:00 9999-12-3123:59:59 TIMESTAMP 4 19700101080001 2038年的某个时刻<br>TIME 3-838:59:59 838:59:59 YEAR 1 1901 2155<br>这些数据类型的主要区别如下。<br>如果要用来表示年月日，通常用DATE来表示。<br>O如果要用来表示年月日时分秒，通常用DATETIME或者TIMESTAMP表示。两者的主要区别在本章的后面会详述。<br>如果只用来表示时分秒，通常用TIME来表示。<br>如果只是表示年份，可以用YEAR来表示，它比DATE占用更少的空间。YEAR有 2位或4位格式的年。默认是4位格式。在4位格式中，允许的值是1901～2155和0000。在 2位格式中，允许的值是70~69，表示从1970～2069年。MySQL以YYYY格式显示YEAR</p>
<p>≦ 62 ≧<br>44 第3章MySQL支持的数据类型值（从5.5.27开始，2位格式的year已经不被支持）。<br>从表3-2中可以看出，每种日期时间类型都有一个有效值范围，如果超出这个范围，在默认的SQLMode下，系统会进行错误提示，并将以零值来进行存储。不同日期类型零值的表示如表3-3所示。<br>表3-3 MySQL中日期和时间类型的零值表示<br>数据类型 零值表示<br>DATETIME 0000-00-0000:00:00 DATE 0000-00-00<br>TIMESTAMP 00000000000000<br>TIME 00:00:00 YEAR 0000<br>DATE、TIME和DATETIME是经常使用的3种日期类型。以下例子在3种类型字段插入了相同的日期值，来看看它们的显示结果。<br>创建表t，字段分别为date、time、datetime这3种日期类型： mysql&gt; create table t (d date,t time,dt datetime);<br>Query ok,0 rows affected (0.01 sec) mysql&gt; desc t;<br>|Field 丨 Type Nu77 Key Default1<br>date IYES NULL<br>x time YES NULL dt datetime| YES INULL<br>3rows in set (0.01 sec)<br>用nowO函数插入当前日期：<br>mysql&gt; insert into t values(nowO,nowO,nowO);<br>Query ok, 1 row affected (o.o0 sec) 查看显示结果：<br>mysql&gt; select * from t;<br>Id lt 1dt<br>|2007-07-19|17:41:1312007-07-1917:41:13 1 row in set (o.00 sec)<br>显而易见，DATETIME是DATE和TIME的组合。用户可以根据不同的需要，来选择不同的日期或时间类型以满足不同的应用。<br>下面对TIMESTAMP类型的特性进行一些测试。<br>首先看一下explicit_defaults_for_timestamp（5.6版本后引l人）参数的默认值： mysql&gt; show variables likeexplicit%;<br>1variable_name I value |<br>Iexplicit defaults_for_timestamp | oFF 1 row in set (o.00 sec)<br>创建测试表t，字段id1为TIMESTAMP类型：</p>
<p>≦ 63 ≧<br>3.2日期时间类型 45<br>mysql&gt; create table t (idl timestamp); Query ok,0 rows affected (0.03 sec) mysql&gt; desct;<br>1Field 丨 Type Nu71 Default<br>Key Extra<br>|id1 |timestamp | No 1CURRENT TIMESTAMP IOn update CURRENT TIMESTAMP 1row in set (o.00 sec)<br>可以发现，系统给tm自动创建了默认值CURRENT_TIMESTAMP（系统日期），并且设置了notnull和onupdateCURRENT_TIMESTAMP属性。插入一个NULL值试试：<br>mysql&gt; insert into t values(null); Query ok,1 row affected (0.01 sec)<br>mysql&gt; select * from t; lidl<br>12018-08-0115:46:381 1row in set (o.00 sec)<br>果然，t中自动插入了系统日期。注意，MySQL只给表中的第一个TIMESTAMP字段设置默认值为系统日期，如果有第二个TIMESTAMP类型，则默认值设置为O值，测试如下：<br>mysql&gt; alter table t add id2 timestamp; Query ok,0 rows affected (o.08 sec) Records:0Duplicates:0warnings:0<br>mysql&gt; desct;<br>|Field 丨 Type |Null丨Key |Default 1 Extra<br>|idl timestamp NO CURRENT_TIMESTAMP on update CURRENT_TIMESTAMP 1id2 timestamp NO 0000-00-0000:00:00<br>2 rows in set (o.00 sec)<br>在MySQL5.6之前，可以修改id2的默认值为其他常量日期，但是不能再修改为current timestamp，因为MySQL规定TIMESTAMP类型字段只能有一列的默认值为current_ timestamp，如果强制修改，系统会报如下错误提示：<br>mysql&gt; alter table t modify id2 timestamp default current timestamp;<br>ERROR 1293 (HYooo): Incorrect table definition; there can be only one TIMESTAMP column with CURRENT_TIMESTAMP in DEFAULT or ON UPDATE clause<br>MySQL5.6版本之后，这个限制已经去掉，可以随意修改，如下例所示：<br>mysql&gt; alter table t modify id2 timestamp default current_timestamp on update cURRENT_TIMESTAMP;<br>Query oK,O rows affected (o.o0 sec) Records:ODuplicates:O warnings:0<br>mysql&gt; desct<br>|Field 丨 Type 1Nu77 |Key |Default IExtra<br>|id1 timestamp NO CURRENT_TIMESTAMP| on update CURRENT_TIMESTAMP id2 timestamp NO CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP<br>2 rows in set (o.00 sec)<br>如果将 explicit defaults_for_timestamp 设置为 on，则默认值、not null 和 on update CURRENT_TIMESTAMP属性都不会自动设置，需要手工操作，具体如下：<br>mysql&gt; set explicit defaults_for_timestamp&#x3D;on; Query oK,0rows affected (o.02 sec)</p>
<p>≦ 64 ≧<br>46 第3章MySQL支持的数据类型<br>mysql&gt; create table t (id timestamp); Query ok,0 rows affected (o.01 sec)<br>mysql&gt; desc t;<br>|Field 丨 Type | Null |Key 丨Default | Extra|<br>1id |timestamp I YES |NULL 1 row in set (o.00 sec)<br>TIMESTAMP还有一个重要特点，就是和时区相关。当插人日期时，会先转换为本地时区后存放；而从数据库里面取出时，也同样需要将日期转换为本地时区后显示。这样，两个不同时区的用户看到的同一个日期可能是不一样的，下面的例子演示了这个差别。<br>（1）创建表t8，包含字段id1（TIMESTAMP）和id2（DATETIME），设置id2的目的是为了和idl做对比：<br>CREATETABLEt8<br>‘id1’ timestamp NOT NULL default CURRENT TIMESTAMP’id2’ datetime default NULL<br>Query oK,0 rows affected (0.o3 sec)（2）查看当前时区：<br>mysql&gt; show variables like time zone’; 1variable name |value<br>|time_zone ISYSTEM| 1row in set (o.00 sec)<br>可以发现，时区的值为“SYSTEM”，这个值默认是和主机的时区值一致的，因为我们在中国，这里的“SYSTEM”实际是东八区（+8:00）。<br>（3）用now0函数插入当前日期： mysql&gt; select * from t8;<br>|id1 |id2<br>12018-09-2517:26:5012018-09-2517:26:501 1 row in set (o.01 sec)<br>结果显示id1和id2的值完全相同。<br>（4）修改时区为东九区，再次查看表中日期： mysql&gt; set time zone&#x3D;+9:00;<br>Query ok, 0 rows affected (o.oo sec) mysql&gt; select * from t8;<br>| id1 1 id2<br>12018-09-2518:26:5012018-09-2517:26:501 1 row in set (0.00 sec)<br>在结果中可以发现，id1的值比id2的值快了1个小时，也就是说，东九区的人看到的“2007-09-2518:26:50”是当地时区的实际日期，也就是东八区的“2007-09-2517:26:50”，如果还是以“2007-09-2517:26:50”理解时间必然导致误差。<br>TIMESTAMP的取值范围为19700101080001到2038年的某一天，因此它不适合存放比</p>
<p>≦ 65 ≧<br>3.2日期时间类型 47<br>较久远的日期。下面简单测试一下这个范围：<br>mysql&gt; insert into t values (19700101080001); Query ok, 1 row affected (0.00 sec)<br>mysql&gt; select * from t; 11970-01-0108:00:011 1 row in set (o.o0 sec)<br>mysql&gt; insert into t values (19700101080000); Query Ok,1 row affected, 1 warning (0.o0 sec)<br>其中19700101080000超出了tm的下限，系统出现警告提示。查询一下，发现插入值变成了0值：<br>mysql&gt; select * from t; 1970-01-0108:00:01 1 0000-00-0000:00:00 2 rows in set (0.00 sec)<br>再来测试一下TIMESTAMP的上限值：<br>mysql&gt; insert into t values(‘2038-01-19 11:14:07’); Query ok, 1 row affected (o.o0 sec)<br>mysql&gt; select * from t; 12038-01-1911:14:071 1 row in set (0.00 sec)<br>mysql&gt; insert into t values(‘2038-01-19 11:14:08’); Query ok, 1 row affected, 1 warning (0.o0 sec)<br>mysql&gt; select * from t; 1 2038-01-19 11:14:07 1 0000-00-00 00:00:001 2 rows in set (0.00 sec)<br>从上面的例子可以看出，TIMESTAMP和DATETIME的表示方法非常类似，主要有以下几个区别。<br>OTIMESTAMP支持的时间范围较小，其取值范围从19700101080001到2038年的某个时间，而DATETIME是从1000-01-0100:00:00到9999-12-3123:59:59，范围更大。两者都可以设置默认值和ONUPDATECURRENT_TIMESTAMP属性，使得日期列可以随其他列的更新而自动更新为最新时间。<br>OTIMESTAMP在MySQL5.6.6版本之后增加了控制参数explicit_defaults_for_timestamp，如果设置为on，则TIMESTAMP需要显式指定默认值和ONUPDATECURRENT TIMESTAMP属性；如果设置为off，则会自动设置默认值为CURRENT_TIMESTAMP（系统时间）和ONUPDATECURRENT_TIMESTAMP属性，并且自动设置为notnull。MySQL8.0.2</p>
<p>≦ 66 ≧<br>48 第3章MySQL支持的数据类型后此参数默认为on；之前版本默认为off。<br>O当explicit_defaults_for_timestamp设置为off时，表中的第一个TIMESTAMP列自动设置为系统时间。如果在一个TIMESTAMP列中插入NULL，则该列值将自动设置为当前的日期和时间。在插入或更新一行但不明确给TIMESTAMP列赋值时也会自动设置该列的值为当前的日期和时间，当插入的值超出取值范围时，MySQL认为该值溢出，使用“0000-00-00 00:00:00”进行填补。<br>TIMESTAMP的插入和查询都受当地时区的影响，更能反映出实际的日期。而 DATETIME则只能反映出插入时当地的时区，其他时区的人查看数据必然会有误差的。<br>OTIMESTAMP的属性受MySQL版本和服务器SQLMode的影响很大，本章都是以 MySQL5.7为例进行介绍的，对于不同的版本可以参考相应的MySQL帮助文档。<br>YEAR类型主要用来表示年份，当应用只需要记录年份时，用YEAR比DATE将更节省<br>空间。下面的例子在表t中定义了一个YEAR类型字段，并插人一条记录： mysql&gt; create table t(y year);<br>Query ok,0 rows affected (0.o1 sec) mysql&gt; desc t;<br>1Field 丨 Type Nul1 |Key 丨Default | Extra<br>ly |year(4)|YES INULL 1row in set (0.00 sec)<br>mysql&gt; insert into t values(2100); Query ok,1 row affected (o.o0 sec)<br>mysql&gt; select <em>from t; Iy<br>|21001<br>1row in set(o.00 sec)<br>MySQL以YYYY格式检索和显示YEAR值，范围是1901～2155。当使用两位字符串表示年份时，其范围为“00”到“99”。<br>“00”到“69”范围的值被转换为2000～2069范围的YEAR值。“70”到“99”范围的值被转换为1970～1999范围的YEAR值。<br>细心的读者可能发现，在上面的例子中，日期类型的插人格式有很多，包括整数（如2100）字符串（如2038-01-1911:14:08）、函数（如NOWO）等，读者可能会感到疑惑，到底什么样的格式才能够正确地插人到对应的日期字段中呢？<br>下面以DATETIME为例进行说明。<br>OYYYY-MM-DDHH:MM:SS或YY-MM-DDHH:MM:SS格式的字符串。允许“不严格” 语法，即任何标点符都可以用做日期部分或时间部分之间的间隔符。例如，“98-12-3111:30:45”“98.12.3111+30+45”“98&#x2F;12&#x2F;3111</em>30*45”和“98@12@3111<del>30</del>45”是等价的。对于包括日期部分间隔符的字符串值，如果日和月的值小于10，不需要指定两位数。“1979-6-9”与“1979-06-09”是相同的。同样，对于包括时间部分间隔符的字符串值，如果时、分和秒的值小于10，则不需要指定两位数。“1979-10-301:2:3”与“1979-10-3001:02:03”相同。<br>OYYYYMMDDHHMMSS或YYMMDDHHMMSS格式的没有间隔符的字符串，假定</p>
<p>≦ 67 ≧<br>3.3字符串类型 49<br>字符串对于日期类型是有意义的。例如，“19970523091528”和“970523091528”被解释为“1997-05-2309:15:28”，但“971122129015”是不合法的（它有一个没有意义的分钟部分），将变为“0000-00-0000:00:00”。<br>OYYYYMMDDHHMMSS或YYMMDDHHMMSS格式的数字，假定数字对于日期类型是有意义的。例如，19830905132800和830905132800被解释为“1983-09-0513:28:00”。数字值应为6、8、12或者14位长。如果一个数值是8位或14位长，则假定为YYYYMMDD或 YYYYMMDDHHMMSS格式，前4位数表示年。如果数字是6位或12位长，则假定为YYMMDD 或YYMMDDHHMMSS格式，前两位数表示年。其他数字被解释为仿佛用零填充到了最近的长度。<br>O函数返回的结果，其值适合DATETIME、DATE或TIMESTAMP上下文，例如NOWO 或CURRENT DATE.<br>对于其他数据类型，其使用原则与上面的内容类似，限于篇幅，这里就不再赘述。<br>最后通过一个例子，说明如何采用不同的格式将日期“2007-9-312:10:10”插入到 DATETIME列中。<br>mysql&gt; create table t6(dt datetime); Query ok, 0 rows affected (0.03 sec)<br>mysql&gt; insert into t6 values(2007-9-3 12:10:10′); Query ok, 1 row affected (o.o0 sec)<br>mysql&gt; insert into t6 values(‘2007&#x2F;9&#x2F;3 12+10+10’); Query ok, 1 row affected (0.00 sec)<br>mysql&gt; insert into t6 values(‘20070903121010); Query ok, 1 row affected (0.01 sec)<br>mysql&gt; insert into t6 values(20070903121010); Query ok, 1 row affected (0.o0 sec)<br>mysql&gt; select * from t6; |dt<br>12007-09-0312:10:10 2007-09-03 12:10:10 12007-09-03 12:10:10 12007-09-03 12:10:10<br>4rows in set (0.00 sec) 3.3字符串类型<br>MySQL中提供了多种对字符数据的存储类型，不同的版本可能有所差异。以5.7版本为例，MySQL包括了CHAR、VARCHAR、BINARY、VARBINARY、BLOB、TEXT、ENUM 和SET等多种字符串类型。表3-4详细列出了这些字符类型的比较。<br>表3-4 MySQL中的字符类型<br>字符串类型描述及存储需求<br>CHAR(M) M M为0<del>255之间的整数 VARCHAR(M) M为0</del>65535之间的整数，值的长度+1个字节 TINYBLOB 允许长度0~255字节，值的长度+1个字节</p>
<p>≦ 68 ≧<br>50 第3章MySQL支持的数据类型<br>续表<br>字符串类型 描述及存储需求<br>字<br>BLOB 允许长度0<del>65535字节，值的长度+2个字节<br>MEDIUMBLOB 允许长度0</del>167772150字节，值的长度+3个字节 LONGBLOB 允许长度0～4294967295字节，值的长度+4个字节<br>TINYTEXT 允许长度0<del>255字节，值的长度+2个字节 TEXT 允许长度0</del>65535字节，值的长度+2个字节<br>MEDIUMTEXT 允许长度0<del>167772150字节，值的长度+3个字节 LONGTEXT 允许长度0</del>4294967295字节，值的长度+4个字节<br>VARBINARY(M) 允许长度0～M个字节的变长字节字符串，值的长度+1个字节 BINARY(M) M 允许长度0~M个字节的定长字节字符串<br>下面将分别对这些字符串类型做详细的介绍。 3.3.1CHAR和VARCHAR类型<br>CHAR和VARCHAR很类似，都用来保存MySQL中较短的字符串。两者的主要区别在于存储方式的不同：CHAR列的长度固定为创建表时声明的长度，长度可以为从0～255的任何值；而VARCHAR列中的值为可变长字符串，长度可以指定为0～65535之间的值。在检索的时候，CHAR列删除了尾部的空格，而VARCHAR则保留这些空格。下面的例子中通过给表vc中的VARCHAR(4)和char(4)字段插人相同的字符串来描述这个区别。<br>（1）创建测试表vc，并定义两个字段“vVARCHAR（4)”和“cCHAR(4)”：<br>mysq1&gt; CREATE TABLE Vc (V VARCHAR(4),C CHAR(4)); Query ok,0 rows affected (0.16 sec)<br>（2）v列和c列中同时插入字符串“ab”： mysql&gt; INSERT INTO vc VALUES (‘abab: Query ok,1 row affected (o.o5 sec)<br>（3）显示查询结果：<br>mysql&gt; select length(v),length(c) from vc;<br>length(v)1length（c)1 1 row in set (0.01 sec)<br>可以发现，c字段的length只有2。给两个字段分别追加一个“+”字符，结果可以看得更清楚：<br>mySq1&gt; SELECT CONCAT（v,+),CONCAT（c,+)FROM VC; ICONCAT(V,+’)ICONCAT(C,·+’）1<br>Iab ab+ 1 row in set (o.00 sec)<br>显然，CHAR列最后的空格在做操作时都已经被删除，而VARCHAR依然保留空格。</p>
<p>≦ 69 ≧<br>3.3字符串类型 51<br>3.3.2BINARY和VARBINARY类型<br>BINARY和VARBINARY类似于CHAR和VARCHAR，不同的是它们包含二进制字符串而不包含非二进制字符串。在下面的例子中，对表t中的binary字段c插入一个字符，研究一下这个字符到底是如何存储的。<br>（1）创建测试表t，字段为cBINARY(3)：<br>mysq1&gt; CREATE TABLE t (c BINARY(3)); Query ok,0 rows affected (0.14 sec)<br>（2）往c字段中插人字符“a”： mysql&gt; INSERT INTO t SET c&#x3D;’a; Query ok,1 row affected (0.06 sec)<br>（3）分别用以下几种模式来查看c列的内容：<br>mysq1&gt; select *,hex(c),c&#x3D;’a,c&#x3D;’a\0’,c&#x3D;′a\o\o′from t;<br>hex（c)|c&#x3D;a1c&#x3D;a\0′1 c&#x3D;’a\0\o 610000<br>1row in set (0.00 sec)<br>可以发现，当保存BINARY值时，在值的最后通过填充“Ox0O”（零字节）以达到指定<br>的字段定义长度。从上例中看出，对于一个BINARY（3)列，当插入时“a”变为“a\OVO”。 3.3.3ENUM类型<br>ENUM中文名称叫枚举类型，它的值范围需要在创建表时通过枚举方式显式指定，对1～ 255个成员的枚举需要1个字节存储；对于255～65535个成员，需要2个字节存储。最多允许有65535个成员。下面往测试表t中插入几条记录来看看ENUM的使用方法。<br>（1）创建测试表t，定义gender字段为枚举类型，成员为“M”和“F”：<br>mysql&gt; create table t (gender enum(‘m’,’F’)); Query oK, 0 rows affected (0.14 sec)<br>（2）插人4条不同的记录：<br>mySql&gt; INSERT INTOtVALUES(M),(1),(f),(NULL);<br>Query ok,4rows affected (o.o0 sec) Records:4 Duplicates:0warnings:0<br>mysql&gt; select * from t; 丨gender<br>4rows in set (0.01 sec)<br>从上面的例子中，可以看出ENUM类型是忽略大小写的，在存储“M”“f”时将它们都转成了大写，还可以看出对于插入不在ENUM指定范围内的值时，并没有返回警告，而是插人了enum(M,F)的第一个值“M”，这点用户在使用时要特别注意。</p>
<p>≦ 70 ≧<br>52 第3章MySQL支持的数据类型<br>另外，ENUM类型只允许从值集合中选取单个值，而不能一次取多个值。 3.3.4SET类型<br>SET和ENUM类型非常类似，也是一个字符串对象，里面可以包含0～64个成员。根据成员的不同，存储上也有所不同。<br>1～8成员的集合，占1个字节。<br>9<del>16成员的集合，占2个字节。 17～24成员的集合，占3个字节。<br>25</del>32成员的集合，占4个字节。 33～64成员的集合，占8个字节。<br>SET和ENUM除了存储之外，最主要的区别在于SET类型一次可以选取多个成员，而<br>ENUM则只能选一个。下面的例子在表t中插入了多组不同的成员： Create table t （col set（a,b’,c,d’）；<br>insert into tvalues（’a,b’）,（’a,d,a’),(‘a,b’),(‘a,c’),（’a’）; mysql&gt; select * from t;<br>Icol a,b a,d a,b a,c<br>5rows in set (o.o0 sec)<br>SET类型可以从允许值集合中选择任意1个或多个元素进行组合，所以对于输入的值只要是在允许值的组合范围内，都可以正确地注人到SET类型的列中。对于超出允许值范围的值例如（a,d,f）将不允许注入到上面例子中设置的SET类型列中，而对于（’a,d,a’）这样包<br>含重复成员的集合将只取一次，写人后的结果为“a,d”，这一点请注意。 3.4JSON类型<br>JSON是JavaScriptObjectNotation的缩写，它是一种数据交换格式。JSON出现之前，数据交换大多使用XML来传递数据，但随着XML的规范越来越复杂，给开发人员的使用带来越来越多的困难。为了解决这个问题，雅虎工程师DouglasCrockford于2002年发明了JSON 这种超级轻量级的数据交换格式，随后风靡Web世界。<br>自5.7.8版本起，MySQL开始支持JSON类型，在此之前，通常使用VARCHAR或TEXT 来保存JSON格式数据。JSON类型比字符类型有如下优点：<br>OJSON数据类型会自动校验数据是否为JSON格式，如果不是JSON格式数据，则会报错。<br>○MySQL提供了一组操作JSON数据的内置函数，可以方便地提取各类数据，可以修改特定的键值。<br>O优化的存储格式，存储在JSON列中的JSON数据被转换成内部的存储格式，允许快速读取。</p>
<p>≦ 71 ≧<br>3.4JSON类型 53<br>简单地说，JSON实际就是JavaScript的一个子集，支持的数据类型包括NUMBER、 STRING、BOOLEAN、NULL、ARRAY、OBJECT共6种，一个JSON中的元素可以是这6 种类型元素的任意组合，其中BOOLEAN使用true&#x2F;false的字面值文本表示；null使用null的文本表示；字符串和日期类型都用双引号引起来表示；ARRAY要用中括号引I起来，OBJECT 保存的KV对要用大括号引起来，其中的K也要用双引号引起。下面是几个格式正确的例子：<br>[“abc”,10,null,true,false]{“k1”:“value”，”k2”:10}<br>[“12:18:29.000000”,“2015-07-29”“2015-07-29 12:18:29.000000”] ARRAY和OBJECT也可以嵌套引用，比如：<br>[99，[”id”:“HK500”，“cost”：75.99}，[“hot”，“cold”]] {“k1”:”value”,”k2”:[10,20]}<br>下面我们举例看一下JSON在MySQL中的使用。首先，创建表tl，列id1为JSON类型。<br>mysql&gt; create table tl(idi json); Query ok,0 rows affected (o.o0 sec)<br>往表tI中插入如下JSON格式数据：<br>mysql&gt; insert into t1values（age:20,time2018-07-14 10:52:00）; Query ok, 1 row affected (o.00 sec)<br>如果插人有语法错误的JSON数据，则直接报错： mysql&gt; INSERT INTO t1 VALUES(‘[1,2,’）;<br>ERROR 3140 (22032):Invalid JsoN text:“Invalid value.at position 6 in value for column ‘tl.id1 通过JSON_TYPE函数可以看到插人的JSON数据是哪种类型：<br>mysql&gt;select json type（”abc) js1,json type（’[1,2,”abc]′） js2,json type(‘“k1”:“value”’ js3; |js1 ljs2丨js3<br>ISTRING I ARRAYI OBJECTI 1row in set (o.00 sec)<br>JSON数据类型对于大小写是敏感的，x’和’X是不同的两个JSON数据，常见的null、true、 false必须是小写才合法，通过JSON_VALID函数可以判断一个JSON数据是否合法，如下例所示：<br>mySqSELECTSONVALDnTnI,SONVALIDUL2,SONVALIDfase1,SONVALIDFALSE<br>nl n2 1f2 1 row in set (o.00 sec)<br>可以看出，null’和false语法合法，而NULL’和FALSE则语法不合法。对大小写敏感的原因是JSON的默认排序规则是utf8mb4_bin（具体见字符集一章）所致，这里不再详述。<br>还有一种特殊情况，如果JSON数据的value中字符串value中包括双引l号或者单引l号，则插入时需要加反斜线进行转义，如下例插人value为ab”c的一个OBJECT类型的JSON 数据。<br>显式插入：<br>mysql&gt; insert into t1 values(json object(“name”,”ab&quot;c”)); Query ok, 1 row affected (o.o0 sec)</p>
<p>≦ 72 ≧<br>54 第3章MySQL支持的数据类型<br>隐式插入：<br>mysql&gt;insert into t1 values（’“name”:”ab&quot;c”}’);<br>ERROR 3140 (22032):Invalid JsoN text:Missing a comma or after an object member.”at position 13 in value for column ‘t1.idl’<br>mysql&gt;insert into t1 values(“name”:”ab\“c”}’）; Query ok,1 row affected (0.o1 sec)<br>可以发现，隐式插人时，要多加一个反斜线才可以正常识别。<br>MySQL对JSON的存储做了一些限制，JSON列不可有默认值，且文本的最大长度取决于系统常量：max_allowed_packet。该值仅在服务器进行存储的时候进行限制，在内存中进行计算的时候是允许超过该值的。<br>对于JSON数据的常用操作，MySQL提供了很多函数，比如上面提到的JSON<br>VALID&#x2F;JSON_OBJECT等，更多的函数在第5章中详细讲解。 3.5小结<br>本章主要介绍了MySQL支持的各种数据类型，并通过多个实例对它们的使用方法做了详细的说明。学完本章后，读者可以对每种数据类型的用途、物理存储、表示范围等有一个概要的了解。这样在面对具体应用时，就可以根据相应的特点来选择合适的数据类型，使得我们能够争取在满足应用的基础上，用较小的存储代价换来较高的数据库性能。</p>
<p>≦ 73 ≧<br>第4章 MySQL中的运算符<br>MySQL支持多种类型的运算符，这些运算符可以用来连接表达式的项。运算符的类型主要包括算术运算符、比较运算符、逻辑运算符和位运算符。本章将通过实例对MySQL5.7支<br>持的这几种运算符进行详细地介绍。 4.1算术运算符<br>MySQL支持的算术运算符包括加、减、乘、除和模运算。它们是最常使用、最简单的一类运算符。表4-1列出了这些运算符及其作用。<br>表4-1 MySQL支持的算术运算符<br>运算符<br>加法减法乘法<br>&#x2F;,DIV 除法，返回商<br>%,MOD 除法，返回余数<br>下例中简单地描述了这几种运算符的使用方法。<br>mysq1&gt; select 0.1+ 0.3333 ,0.1-0.3333, 0.1<em>0.3333, 1&#x2F;2,1%2;<br>10.1+0.333310.1-0.333310.1</em>0.333311&#x2F;2 11%2<br>0.433310.233310.0333310.500011 row in set (0.00 sec)<br>“十”运算符用于获得一个或多个值的和。“-”运算符用于从一个值中减去另一个值。<br>“*”运算符使数字相乘，得到两个或多个值的乘积。“”运算符用一个值除以另一个值得到商。<br>0“%”运算符用一个值除以另外一个值得到余数。在除法运算和模运算中，如果除数为0，将是非法除数，返回结果为NULL，如下例所示：<br>mysql&gt; select 1&#x2F;0, 100%0 ； 11&#x2F;01100%01</p>
<p>≦ 74 ≧<br>56 第4章MySQL中的运算符<br>|NULLINULL<br>1row in set (0.02 sec)<br>对于模运算，还有另一种表达方式，使用MOD(a,b)函数与a%b效果一样：<br>mysq1&gt; se1ect 3%2,mod(3,2）; 3%21mod（3,2)1<br>4.2 比较运算符<br>熟悉了最简单的算术运算符，再来看一下比较运算符。当使用SELECT语句进行查询时，MySQL允许用户对表达式的左边操作数和右边操作数进行比较，比较结果为真，则返回1，为假则返回0，比较结果不确定则返回NULL。表4-2列出了MySQL5.7支持的各种比较运算符。<br>表4-2 MySQL支持的比较运算符<br>运算符 作用<br>等于<br>或!&#x3D; 不等于<br>NULL安全的等于（NULL-safe）<br>小于小于等于大于</p>
<blockquote>
<p>大于等于<br>BETWEEN 存在于指定范围 IN 存在于指定集合<br>IS NULL 为NULL<br>IS NOTNULL 不为NULL LIKE 通配符匹配<br>REGEXP或RLIKE 正则表达式匹配<br>比较运算符可以用于比较数字、字符串和表达式。数字作为浮点数比较，而字符串以不区分大小写的方式进行比较。下面通过实例来学习各种比较运算符的使用。<br>“&#x3D;”运算符，用于比较运算符两侧的操作数是否相等，如果两侧操作数相等，则返回值为1，否则为0。注意NULL不能用于“&#x3D;”比较。<br>mysql&gt; select 1&#x3D;0,1&#x3D;1,NULL&#x3D;NULL; 11&#x3D;011&#x3D;11NULL&#x3D;NULL<br>NULL<br>row in set (o.00 sec)</p>
</blockquote>
<p>≦ 75 ≧<br>4.2比较运算符 57<br>“&lt;&gt;”运算符，和“&#x3D;”相反，如果两侧操作数不等，则值为1，否则为0。NULL不能用于“&gt;”比较。<br>mysq1&gt; select 1&lt;&gt;0,1&lt;&gt;1,nu11&lt;&gt;nu11;<br>&lt;&gt;1 1 null&lt;&gt;nu111<br>1&lt;&gt;0<br>NULL<br>1 row in set (0.00 sec)<br>“&lt;&#x3D;&gt;”运算符，和“&#x3D;”类似，在操作数相等时值为1，不同之处在于即使操作的值为NULL也可以正确比较。<br>mysq1&gt; select 1&lt;&#x3D;&gt;1,2&lt;&#x3D;&gt;0 ,0&lt;&#x3D;&gt;0,NULL&lt;&#x3D;&gt;NULL; 1 row in set (0.17 sec)<br>“&lt;”运算符，当左侧操作数小于右侧操作数时，其返回值为1，否则其值为0。<br>mysql&gt; select ‘a’&lt;’b′，’a’&lt;’a′,’a’&lt;’c′,1&lt;2; I’a’&lt;’b’I’a’&lt;’a’l‘a’&lt;’c<br>1&lt;2<br>1 row in set (0.03 sec)<br>“&lt;&#x3D;”运算符，当左侧操作数小于等于右侧操作数时，其返回值为1，否则返回值为0。 mysql&gt; select ‘bdf’&lt;&#x3D;’b’,’b’&lt;&#x3D;b，0&lt;1;<br>I’bdf’&lt;&#x3D;’b1’b’&lt;&#x3D;’b10&lt;1| 1 row in set (o.o0 sec)<br>“&gt;”运算符，当左侧操作数大于右侧操作数时，其返回值为1，否则返回值为0。<br>mysq1&gt; select’a’&gt;’b’,’abc’&gt;’a′,1&gt;0； I’a’&gt;’b’|‘abc’&gt;’a| 1&gt;0|<br>01<br>1 row in set (0.03 sec)<br>○“&gt;&#x3D;”运算符，当左侧操作数大于等于右侧操作数时，其返回值为1，否则返回值为0。 mysql&gt;select’a’&gt;&#x3D;’b,’abc’&gt;&#x3D;’a,1&gt;&#x3D;0,1&gt;&#x3D;1;<br>01<br>1 row in set (0.00 sec)<br>O“BETWEEN”运算符的使用格式为“aBETWEENminANDmax”，当a大于等于 min并且小于等于max，则返回值为1，否则返回0；当操作数a、min、max类型相同时，此表达式等价于（a&gt;&#x3D;minanda&lt;&#x3D;max），当操作数类型不同时，比较时会遵循类型转换原则进行转换后，再进行比较运算。下例中描述了BETWEEN的用法：</p>
<p>≦ 76 ≧<br>58 第4章MySQL中的运算符<br>mysq1&gt; select 10 between 10 and 20, 9 between 10 and 20;<br>110 between 10and 20 1 9 between 10 and 20 1 1 row in set (o.00 sec)<br>“IN”运算符的使用格式为“aIN（valuel,value2….)”，当a的值存在于列表中时，则整个比较表达式返回的值为1，否则返回0。<br>mysql&gt; select 1 in （1,2,3),t′in（’t,’a′,b′,1,e’）,0 in （1,2);<br>11in（1,2,3)1tin（’t,’a,b,1,e’)10in（1,2)1 1 row in set (0.00 sec)<br>O“ISNULL”运算符的使用格式为“aISNULL”，当a的值为NULL，则返回值为1，否则返回0。<br>mysql&gt; select 0 is null, null is null;<br>null is null<br>1 row in set (0.02 sec)<br>“ISNOTNULL”运算符的使用格式为“aISNOTNULL”。和“ISNULL”相反，当<br>a的值不为NULL，则返回值为1，否则返回0。 mysql&gt; select o is not null, null is not null;<br>0 is not null is not null 1row in set (0.00 sec)<br>“LIKE”运算符的使用格式为“aLIKE%123%”，当a中含有字符串“123”时，则返回值为1，否则返回0。<br>mysql&gt; select 123456 1ike 123%，123456 1ike%123%,123456 1ike%321% 11234561ike123%11234561ike%123%|1234561ike%321%<br>11 11 0<br>1 row in set (o.00 sec)<br>“REGEXP”运算符的使用格式为“strREGEXPstr_pat”，当str字符串中含有str_pat 相匹配的字符串时，则返回值为1，否则返回0。REGEXP运算符的使用方法将会在第15章中详细介绍。<br>mysql&gt; select ‘abcdef’regexp ‘ab’，’abcdefg′regexp ‘k’;<br>abcdef’ regexp’abcdefg’ regexp 1 row in set (o.o0 sec)</p>
<p>≦ 77 ≧<br>4.3逻辑运算符 59<br>4.3逻辑运算符<br>逻辑运算符又称为布尔运算符，用来确认表达式的真和假。MySQL支持4种逻辑运算符，如表4-3所示。<br>表4-3 MySQL中的逻辑运算符<br>运算符<br>NOT或！ 逻辑非 AND或&amp;&amp; 逻辑与 OR或II 逻辑或 XOR 逻辑异或<br>“NOT”或“!”表示逻辑非。返回和操作数相反的结果：当操作数为O（假），则返回值为1，否则值为O。但是有一点除外，那就是NOTNULL的返回值为NULL，如下例所示。 mysql&gt; select not 0, not 1, not null ;<br>1not o not nul7<br>not<br>11 0 NULL<br>1 row in set (0.00 sec)<br>“AND”或“&amp;&amp;”表示逻辑与运算。当所有操作数均为非零值并且不为NULL时，计算所得结果为1；当一个或多个操作数为0时，所得结果为0；操作数中有任何一个为 NULL，则返回值为NULL，如下例所示。<br>mysql&gt; select (1 and 1),(0 and 1),(3 and 1 ),(1 and nu11); 1(1 and 1)1(0and 1)1(3and 1)1(1and nul1)1<br>01 11 NULL<br>1 row in set (0.o0 sec)<br>○“OR”或“”表示逻辑或运算。当两个操作数均为非NULL值时，如有任意一个操作数为非零值，则结果为1，否则结果为0；当有一个操作数为NULL时，如另一个操作数为非零值，则结果为I，否则结果为NULL；假如两个操作数均为NULL，则所得结果为NULL，如下例所示。<br>mysq1&gt; se1ect （1 or0),(0or 0）,(1 or nu11),(1 or 1）,(nu71 ornu11);（1or0）1（0or0)1（1ornu11）1（1or1）1（nu11ornu11)1<br>NULL1<br>1 row in set (o.00 sec)<br>“XOR”表示逻辑异或。当任意一个操作数为NULL时，返回值为NULL；对于非 NULL的操作数，如果两个的逻辑真假值相异，则返回结果1，否则返回O，如下例所示。<br>mysql&gt; select 1 xor 1,0 xor 0,1 xor 0,0 xor 1,nu11 xor 1; 11xor110xor011xor010xor11nu11xor11</p>
<p>≦ 78 ≧<br>60 第4章MySQL中的运算符<br>NULL1<br>11<br>1 row in set (o.00 sec) 4.4位运算符<br>位运算是将给定的操作数转化为二进制后，对各个操作数每一位都进行指定的逻辑运算，得到的二进制结果转换为十进制数后就是位运算的结果。MySQL5.7支持6种位运算符，如表4-4所示。<br>表4-4 MySQL支持的位运算符<br>运算符<br>用<br>位与（位AND）<br>&amp;<br>位或（位OR）<br>1<br>位异或（位XOR）位取反</p>
<blockquote>
<blockquote>
<p>位右移<br>位左移<br>可以发现，位运算符中的位与“&amp;”、位或“”和前面介绍的逻辑与和逻辑或非常类似。其他操作符和逻辑操作有所不同，下面将分别举例介绍。<br>“位与”对多个操作数的二进制位做逻辑与操作，例如2&amp;3，因为2的二进制数是10， 3是11，所有10&amp;11的结果是10，十进制数字还是2，来看实际结果：<br>mysql&gt; select 283; 12831<br>1 row in set (0.00 sec)<br>可以对两个以上操作数做“或”操作，测试一下2&amp;3&amp;4，因为4的二进制是100，和上面的10做与操作100&amp;010后，结果应该是000，可以看实际结果：<br>mysql&gt; select 2&amp;384; 283841<br>1 row in set (o.00 sec)<br>○“位或”对多个操作数的二进制位做逻辑或操作，还是上面的例子，23的结果应该是1011，结果还是11，应该是3，实际结果如下：<br>mysq1&gt; select 213； 12131<br>1 row in set (0.00 sec)<br>“位异或”对操作数的二进制位做异或操作，10^11的结果是01，结果应该是1，可以看实际结果为：</p>
</blockquote>
</blockquote>
<p>≦ 79 ≧<br>4.5运算符的优先级 61<br>mysq1&gt; se1ect 2&lt;3；<br>1 23 1 11<br>1 row in set (o.o0 sec)<br>“位取反”对操作数的二进制位做NOT操作，这里的操作数只能是一位。下面看一<br>个经典的取反例子，对1做位取反，具体如下所示： mysql&gt; select <del>1,</del> 18446744073709551614;<br>1~184467440737095516141<br>1184467440737095516141 1 row in set (0.00 sec)<br>结果可能会令人感到疑惑，1的位取反怎么会是这么大的数字？来研究一下，在MySQL 中，常量数字默认会以8个字节来表示，8个字节就是64位，常量1的二进制表示为63个“0” 加1个“1”，位取反后就是63个“1”加一个“0”，转换为二进制后就是18446744073709551614，实际结果如下：<br>mysql&gt; select bin(18446744073709551614); 1bin(18446744073709551614)<br>111111111111111111111111111111111111111111111111111111111110 1 row in set (o.o0 sec)<br>○“位右移”对左操作数向右移动右操作数指定的位数。例如100&gt;&gt;3，就是对100的二进制数0001100100右移3位，左边补0，结果是0000001100，转换为二进制数是12，实际结果如下：<br>mysq1&gt; select 100&gt;&gt;3; 1100&gt;&gt;31<br>12<br>1row in set(0.00 sec)<br>“位左移”对左操作数向左移动右操作数指定的位数。例如100&lt;&lt;3，就是对100的二进制数0001100100左移3位，右边补0，结果是1100100000，转换为二进制数是800，实际结果如下：<br>mysql&gt; select 100&lt;&lt;3; 1100&lt;&lt;31<br>8001<br>1row in set(0.00 sec) 4.5运算符的优先级<br>前面介绍了MySQL支持的各种运算符的使用方法。在实际应用中，很可能将这些运算符进行混合运算，那么应该先进行哪些运算符的操作呢？表4-5中列出了所有的运算符，优先级由低到高排列，同一行中的运算符具有相同的优先级。</p>
<p>≦ 80 ≧<br>62 第4章MySQL中的运算符<br>表4-5 MySQL中的运算符优先级<br>优先级顺序 运算符<br>1 T<br>2 、OR、XOR 3 &amp;&amp;、AND 4 NOT<br>5 BETWEEN、CASE、WHEN、THEN和ELSE<br>6 、I&#x3D;、IS、LIKE、REGEXP和IN 7<br>8 &amp; 9 &lt;&lt;和&gt;&gt;<br>10-和+<br>11*、&#x2F;、DIV、%和MOD 12<br>13-（一元减号）和～（一元比特反转） 14!<br>在实际运行的时候，可以参考表4-5中的优先级。实际上，很少有人能将这些优先级熟练记忆，很多情况下我们都是用“）”将需要优先的操作括起来，这样既起到了优先的作用，<br>又使得其他用户看起来更易于理解。 4.6小结<br>本章主要介绍了MySQL中支持的各种运算符。这些运算符可以帮助用户完成算术、比较、逻辑和位逻辑操作，读者在使用时要注意运算符的优先级。另外，在使用比较运算符时要保证比较的操作数类型是一致的，这样可以避免由于操作数类型的不一致而得出错误的数据。</p>
<p>≦ 81 ≧<br>第5章 常用函数<br>经常编写程序的朋友一定体会得到函数的重要性，丰富的函数往往能使用户的工作事半功倍。函数能帮助用户做很多事情，比如说字符串的处理、数值的运算、日期的运算等，在这方面MySQL提供了多种内建函数帮助开发人员编写简单快捷的SQL语句，其中常用的函数有字符串函数、日期函数和数值函数。<br>在MySQL数据库中，函数可以用在SELECT语句及其子句（例如WHERE、ORDERBY、 HAVING等）中，也可以用在UPDATE、DELETE语句及其子句中。本章将配合一些实例对<br>这些常用函数进行详细的介绍。 5.1字符串函数<br>字符串函数是最常用的一种函数，如果读者编写过程序，不妨回过头去看看自己使用过的函数，可能会惊讶地发现字符串处理的相关函数占已使用过的函数很大一部分。在MySQL 中，字符串函数同样是最丰富的一类函数。表5-1列出了这些常用字符串函数，以供参考。<br>表5-1 MySQL中的常用字符串函数<br>函数功能<br>CONCAT(sI,s2..,.sn) 连接s1,s..,sn为一个字符串 INSERT(str,x,y,n) 将字符串str从第x位置开始，y个字符长的子串替换为字符串instr<br>LOWER(str) 将字符串str中所有字符变为小写 UPPER(str) 将字符串str中所有字符变为大写<br>LEFT(str,x) 返回字符串str最左边的x个字符 RIGHT(str,x) 返回字符串str最右边的x个字符<br>LPAD(str,n,pad) 用字符串pad对str最左边进行填充，直到长度为n个字符长度 RPAD(str,n,ad) 用字符串pad对str最右边进行填充，直到长度为n个字符长度 LTRIM(str) 去掉字符串str左侧的空格<br>RTRIM(str) 去掉字符串str行尾的空格 REPEAT(str,x) 返回str重复x次的结果 REPLACE(st,a,b) 用字符串b替换字符串str中所有出现的字符串a<br>STRCMP(s1,s2) 比较字符串s1和s2</p>
<p>≦ 82 ≧<br>64 第5章常用函数<br>续表<br>TRIM(str) 去掉字符串行尾和行头的空格<br>SUBSTRING(str,x,y) 返回从字符串strx位置起y个字符长度的字串<br>下面通过具体的实例来逐个地研究每个函数的用法，需要注意的是，这里的例子仅仅用于说明各个函数的使用方法，所以函数都是单个出现的，但是在一个具体的应用中通常可能需要综合几个甚至几类函数才能实现相应的应用。<br>CONCAT(sl,s2..,sn)函数：把传入的参数连接成为一个字符串。<br>下面的例子把“aaa”“bbb”“ccc”3个字符串连接成了一个字符串“aaabbbccc”。另外，任何字符串与NULL进行连接的结果都将是NULL。<br>mysql&gt; select concat(‘aaa’,bbb’,ccc’),concat(‘aaa′,null);<br>1concat(‘aaa,bbb’,’ccc’)| concat(‘aaa′,null) Iaaabbbccc NULL 1 row in set (o.05 sec)<br>INSERT(str,x,y,instr)函数：将字符串str从第x位置开始，y个字符长的子串替换为字符串instr。<br>下面的例子把字符串“beijing2008you”中从第12个字符开始以后的3个字符替换成“me”。 mysql&gt; select INSERT（’beijing2008you′,12,3,me）；<br>IINSERT(‘beijing2008you,12,3,me） 1 beijing2008me<br>1row in set (o.00 sec)<br>OLOWER(str)和UPPER(str)函数：把字符串转换成小写或大写。<br>在字符串比较中，通常要将比较的字符串全部转换为大写或者小写，如下例所示：<br>mysql&gt;select LOWER（’BEIJING2008’),UPPER(‘beijing2008’）; ILOWER（BEIJING2008’)|UPPERC’beijing2008)<br>I beijing2008 BEIJING2008 1 row in set (o.00 sec)<br>LEFT(str,x)和RIGHT(str,x)函数：分别返回字符串最左边的x个字符和最右边的x个字符。如果第二个参数是NULL，那么将不返回任何字符串。<br>下例中显示了对字符串“beijing2008”应用函数后的结果。<br>mysq1&gt; SELECT LEFT(beijing2008,7）,LEFT(beijing′,nu11),RIGHT（beijing2008′,4）; 1LEFT(beijing2008,7)ILEFT(‘beijing′，nu11)RIGHT(beijing2008,4）<br>1 beijing 2008 1 row in set (0.00 sec)<br>OLPAD(str,n,pad)和RPAD(str,n,pad)函数：用字符串pad对str最左边和最右边进行填充，直到长度为n个字符长度。</p>
<p>≦ 83 ≧<br>5.1字符串函数 65<br>下例中显示了对字符串“2008”和“beijing”分别填充后的结果。 mysq1&gt; select 1pad（2008′，20,beijing′），rpad（beijing′，20,2008′）; 11pad（’2008′,20,beijing)1rpad（’beijing′,20,2008’)1<br>| beijingbeijingbe2008 丨 beijing2008200820082 1 row in set (0.00 sec)<br>LTRIM(str)和RTRIM(str)函数：去掉字符串str左侧和右侧空格。下例中显示了字符串“beijing”加空格进行过滤后的结果。<br>mysql&gt; select ltrim(Tbeijing’),rtrim(‘beijing | 1ltrimC’Ibeijing’)I rtrim(‘beijingl<br>beijing |beijingl 1 row in set(0.o0 sec)<br>OREPEAT(str,x)函数：返回str重复x次的结果。<br>下例中对字符串“mysql”重复显示了3次。 mysql&gt; select repeat(‘mysql ,3）;<br>1repeat(‘mysq1,3）1 |mysql mysql mysql 1 row in set (o.00 sec)<br>OREPLACE(str,a,b)函数：用字符串b替换字符串str中所有出现的字符串a。<br>下例中用字符串“2008”代替了字符串“beijing_2010”中的“_2010”。 mysql&gt; select replace(‘beijing 2010′,2010′,2008）;<br>1replace（’beijing_2010′,2010′，’2008’） | beijing2008<br>1 row in set (o.00 sec)<br>OSTRCMP（s1,s2）函数：比较字符串s1和s2的ASCII码值的大小。<br>如果s1比s2小，那么返回-1；如果s1与s2相等，那么返回0；如果s1比s2大，那么返回1，如下例所示。<br>mysql&gt; select strcmp(‘a,’b’),strcmp(‘b,b’）,strcmp（’c’,b);<br>1strcmp（’a’,b’）1 strcmp（’b’,’b’）1strcmp(‘c,’b）1 1 row in set (0.00 sec)<br>OTRIM(str)函数：去掉目标字符串的开头和结尾的空格。<br>下例中对字符串“$beijing2008$”进行了前后空格的过滤。 mysql&gt; select trimC $ beijing2008 $）；<br>1 trimC’ $ beijing2008 $ 1$ beijing2008 $<br>1 row in set (0.00 sec)<br>SUBSTRING（str,x,y)函数：返回从字符串str中的第x位置起y个字符长度的字串。</p>
<p>≦ 84 ≧<br>66 第5章常用函数<br>此函数经常用来对给定字符串进行字串的提取，如下例所示。<br>mysql&gt; select substring(‘beijing2008′,8,4),substring(beijing2008′,1,7); substring(‘beijing2008′,8,4）1substring(‘beijing2008′,1,7)1<br>12008 1beijing 5.2数值函数<br>MySQL中另外一类很重要的函数就是数值函数，这些函数能处理很多数值方面的运算。可以想象，如果没有这些函数的支持，用户在编写有关数值运算方面的代码时将会困难重重。举个例子，如果没有ABS函数，要取一个数值的绝对值，就需要进行好多次判断才能返回这个值，而数值函数能够大大提高用户的工作效率。表5-2中列出了在MySQL中会经常使用的数值函数。<br>表5-2 MySQL中的常用数值函数<br>数 功 能<br>ABS(x) 返回x的绝对值 CEIL(x) 返回大于x的最小整数值<br>FLOOR(x) 返回小于x的最大整数值 MOD(x,y) 返回x&#x2F;y的模<br>RANDO 返回0~1内的随机值 ROUND(x,y) 返回参数x的四舍五入的有y位小数的值 TRUNCATE(x,y) 返回数字x截断为y位小数的结果<br>下面将结合实例对这些函数进行介绍。 OABS（x)函数：返回x的绝对值。<br>下例中显示了对正数和负数分别取绝对值之后的结果。<br>mysq1&gt; select ABS(-0.8) ,ABS(0.8); 1ABS(-0.8)IABS(O.8)1<br>0.81 0.81<br>1 row in set (0.09 sec)<br>CEIL（x)函数：返回大于x的最小整数。<br>下例中显示了对0.8和-0.8分别CEIL后的结果。<br>mysq1&gt; se1ect CEIL(-0.8),CEIL(O.8); |CEIL(-0.8）1CEIL(O.8)1<br>01<br>1 row in set (0.03 sec)<br>OFLOOR(x)函数：返回小于x的最大整数，和CEIL的用法刚好相反。下例中显示了对0.8和-0.8分别FLOOR后的结果。<br>mysq1&gt; se1ect FLOOR(-0.8),FLOOR(0.8); 1FLOOR(-0.8)1FLOOR(O.8)1</p>
<p>≦ 85 ≧<br>5.2数值函数 67<br>1<br>1 row in set (0.00 sec)<br>MOD(x,y)函数：返回x&#x2F;y的模。<br>和x%y的结果相同，模数和被模数任何一个为NULL结果都为NULL，如下例所示：<br>mysq1&gt; s1eCtMOD（15,10),MOD（1,11),MOD（NULL,10）; 1 MOD(15,10) 1 MOD(1,11) 1 MOD(NULL,10) 1<br>51 11 NULL1<br>1 row in set (0.00 sec)<br>ORANDO函数：返回O~1的随机值。每次执行结果都不一样，如下例所示： mysql&gt; select RANDO),RANDO;<br>|RANDO 1RAND)<br>10.1209032545992210.833697278829011 1 row in set (o.00 sec)<br>利用此函数可以取任意指定范围内的随机数，比如需要产生0～100的任意随机整数，可以进行如下操作：<br>mysql&gt;select cei1（100<em>rand0),cei1(100</em>rand(）; 1cei1(100<em>rand0)1cei1（100</em>rand0）1<br>91 15<br>1 row in set (o.00 sec)<br>OROUND(x,y)函数：返回参数x的四舍五入的有y位小数的值。<br>如果是整数，将会保留y位数量的0；如果不写y，则默认y为0，即将x四舍五人后取整。适合于将所有数字保留同样小数位的情况，如下例所示：<br>mysq1&gt; se1eCt ROUND(1.1）),ROUND(1.1,2）,ROUND(1,2）; 1ROUND(1.1)1ROUND（1.1,2)1ROUND(1,2)1<br>11 1.101 1.001<br>1row in set (0.00 sec)<br>OTRUNCATE(x,y)函数：返回数字x截断为y位小数的结果。<br>注意TRUNCATE和ROUND的区别在于TRUNCATE仅仅是截断，而不进行四舍五人。下例中描述了两者的区别：<br>mysq1&gt; se1ect ROUND(1.235,2),TRUNCATE(1.235,2); 1ROUND(1.235,2)1TRUNCATE（1.235,2)1<br>1.24 1.231<br>1 row in set (0.00 sec)</p>
<p>≦ 86 ≧<br>68 第5章常用函数 5.3日期和时间函数<br>有时我们可能会遇到这样的需求：当前时间是多少；下个月的今天是星期几；统计截止到当前日期前3天的收人总和；等等。这些需求就需要日期和时间函数来实现，表5-3列出了MySQL中支持的一些常用日期和时间函数。<br>表5-3 MySQL中的常用日期和时间函数<br>函数<br>CURDATEO 返回当前日期 CURTIMEO 返回当前时间<br>NOWO 返回当前的日期和时间<br>UNIX_TIMESTAMP(date) 返回日期date的UNIX时间戳 FROM_UNIXTIME 返回UNIX时间戳的日期值 WEEK(date) 返回日期date为一年中的第几周<br>YEAR(date) 返回日期date的年份 HOUR(time) 返回time的小时值 MINUTE(time) 返回time的分钟值<br>MONTHNAME(date) 返回date的月份名<br>DATE_FORMAT(date,fimt) 返回按字符串fmnt格式化日期date值<br>DATE_ADD（date,INTERVAL expr type) 返回一个日期或时间值加上一个时间间隔的时间值 DATEDIFF(expr,expr2) 返回起始时间expr和结束时间expr2之间的天数<br>下面结合一些实例来逐个讲解每个函数的使用方法。<br>CURDATEO函数：返回当前日期，只包含年、月、日。 mysql&gt; select CURDATEO;<br>CURDATE 1 2007-07-11<br>1 row in set (0.03 sec)<br>OCURTIMEO函数：返回当前时间，只包含时、分、秒。 mysql&gt; select CURTIMEO;<br>|CURTIMEO 114:13:46<br>1 row in set (0.00 sec)<br>NOWO函数：返回当前的日期和时间，年、月、日、时、分、秒全都包含。 mysql&gt; select NowO;<br>1NOWO 2007-07-<br>1 row in set (0.00 sec)<br>UNIX_TIMESTAMP(date)函数：返回日期date的UNIX时间戳。</p>
<p>≦ 87 ≧<br>5.3日期和时间函数 69<br>mysql&gt; select UNIx TIMESTAMP(nowO); 1UNIX_TIMESTAMP(nowO) 1<br>1184134516<br>1 row in set (0.02 sec)<br>OFROM_UNIXTIME(unixtime)函数：返回UNIXTIME时间戳的日期值，和UNIX TIMESTAMP（date)互为逆操作。<br>mysql&gt; select FROM_UNIXTIME(1184134516); 1FROM_UNIXTIME(1184134516)<br>1 2007-07-11 14:15:16 1 row in set (0.00 sec)<br>OWEEK(DATE)和YEAR(DATE)函数：前者返回所给的日期是一年中的第几周，后者返回所给的日期是哪一年。<br>mysql&gt; select wEEK(now(),YEAR(nowO); WEEK(nowC)) I YEAR(now())<br>271 2007<br>1 row in set (0.02 sec）<br>HOUR（time)和MINUTE（time)函数：前者返回所给时间的小时，后者返回所给时间的<br>分钟。<br>mysqT&gt; seTeCt HOUR(CURTIME),MINUTE(CURTIMEO）; IHOUR(CURTIMEO)IMINUTE(CURTIMEO)1<br>181<br>row in set (0.00 sec)<br>）MONTHNAME（date）函数：返回date的英文月份名称。 mysqT&gt; select MONTHNAME(now);<br>1 MONTHNAME(noWO) 1 1July<br>1row in set (o.00 sec)<br>ODATE_FORMAT(date,fmt）函数：按字符串fmt格式化日期date值，此函数能够按指定的格式显示日期，可以用到的格式符如表5-4所示。<br>表5-4 MySQL中的日期和时间格式<br>格式符格式说明<br>%S 和%s 两位数字形式的秒（00.01.，.59）<br>%i 两位数字形式的分（00.01,.,59）<br>%H 两位数字形式的小时，24小时（00.01..23）%h和% 两位数字形式的小时，12小时（01,02，12）<br>%k 数字形式的小时，24小时（0,1.，23）<br>% 数字形式的小时，12小时（1,2…，12）</p>
<p>≦ 88 ≧<br>70 第5章 常用函数<br>续表<br>格式符 格式说明<br>%T 24小时的时间形式（hh：mm:ss）<br>%r 12小时的时间形式（hh:mm:ssAM或hh：mm:ssPM）%p<br>AM或PM<br>%W 一周中每一天的名称（Sunday，MondaySaturday）<br>%a 一周中每一天名称的缩写（Sun，Mon,，Sat）%d 两位数字表示月中的天数（00.01..31）%e 数字形式表示月中的天数（1，2.…，31）<br>%D 英文后缀表示月中的天数（1st,2nd,3rd.…）<br>%w 以数字形式表示周中的天数（0&#x3D;Sunday,1&#x3D;Monday…,6&#x3D;Saturday）<br>% 以3位数字表示年中的天数（001,002,366）%U 周（0,1,52），其中Sunday为周中的第一天%u 周（0,1,52），其中Monday为周中的第一天%M 月名（January，February.…,December）<br>%b 缩写的月名（January，February,，December）%m 两位数字表示的月份（01,02.，12）<br>%C 数字表示的月份（1,.，12）<br>%Y 4位数字表示的年份%y 两位数字表示的年份%% 直接值“%”<br>下面的例子将当前时间显示为“月，日，年”格式： mysq1&gt; seleCt DATE FORMAT（nowO),%M，%D,%Y）;<br>1DATE FORMAT(nOW),%M,%D,%Y) 1July,11th,2007<br>1 row in set (o.o0 sec)<br>ODATE_ADD（date,INTERVALexpr type)函数：返回与所给日期date相差INTERVAL 时间段的日期。<br>其中INTERVAL是间隔类型关键字，expr是一个表达式，这个表达式对应后面的类型， type是间隔类型。MySQL提供了13种间隔类型，如表5-5所示。<br>表5-5 MySQL中的日期间隔类型<br>表达式类型描述格式<br>HOUR 小时 hh<br>MINUTE 分 mm SECOND 秒 ss YEAR 年 YY<br>MONTH 月 MM DAY 日 DD YEAR_MONTH 年和月 YY-MM<br>DAY_HOUR 日和小时 DD hh</p>
<p>≦ 89 ≧<br>5.4流程函数 71<br>续表<br>表达式类型 描 述 格式<br>DAY MINUTE 日和分钟 DD hh:mm DAY_SECOND 日和秒 DD hh:mm:ss<br>HOUR MINUTE 小时和分 hh:mm HOUR_SECOND 小时和秒 hh:ss MINUTE_SECOND 分钟和秒 mm:ss<br>来看一个具体的例子，在这个例子中第一列返回了当前日期时间，第二列返回距离当前日期31天后的日期时间，第三列返回距离当前日期一年两个月后的日期时间。<br>mysql&gt; select now current,date add（now,INTERVAL 31 day) after31days, date add(nowO,INTERVAL 1 2’year <em>month) after_oneyear</em> twomonth;<br>1current Iafter3ldays |after_oneyear twomonth|<br>12007-09-0311:30:4812007-10-0411:30:48|2008-11-0311:30:48 1 row in set (0.01 sec)<br>同样也可以用负数让它返回之前的某个日期时间，如下面这个例子第一列返回了当前日期时间，第二列返回距离当前日期31天前的日期时间，第三列返回距离当前日期一年两个月前的日期时间。<br>mysql&gt; select nowO) current,date add(nowO,INTERVAL -31 day) after31days, date a dd（nowO,INTERVAL-1-2’ year_month) after_oneyear_twomonth;<br>current |after31days lafter_oneyear_twomonth<br>12007-09-0311:36:3512007-08-0311:36:35|2006-07-0311:36:35 1row in set (0.00 sec)<br>DATEDIFF（datel，date2）函数：用来计算两个日期之间相差的天数。下面的例子计算出当前距离2008年8月8日的奥运会开幕式还有多少天：<br>mysq1&gt; select DATEDIFF(‘2008-08-08’,nowO)); 1DATEDIFF(‘2008-08-08′,noW）<br>328<br>1 row in set (0.01 sec) 5.4流程函数<br>流程函数也是常用的一类函数，用户可以使用这类函数在一个SQL语句中实现条件选择，这样做能够提高语句的效率。表5-6列出了MySQL中跟条件选择有关的流程函数。下面将通过具体的实例来讲解每个函数的用法。<br>表5-6 MySQL中的流程函数<br>函数功能<br>IF(value,t f) 如果value是真，返回t；否则返回f IFNULL(valuel,valu2) 如果value1不为空，返回valuel，否则返回value2<br>CASE WHEN[valuel]THEN[resultl]…ELSE [default]END 如果valuel是真，返回resultl，否则返回default CASE[expr] WHEN[valuel]THEN[result1]…ELSE[default]END 如果expr等于valuel，返回resultl，否则返回default</p>
<p>≦ 90 ≧<br>72 第5章常用函数<br>下面的例子中模拟了对职员薪水进行分类，这里首先创建并初始化一个职员薪水表： mysql&gt; create table salary （userid int,salary decimal(9,2));<br>Query Ok,0 rows affected (o.06 sec) 插人一些测试数据：<br>mysq1&gt; insert into salary values（1,1000),(2,2000),（3,3000),(4,4000),(5,5000),(1,nu71); Query ok, 6 rows affected (0.00 sec)<br>mysql&gt; select * from salary; |userid | salary<br>1000.00 2000.00 3000.00 4000.00 5000.00 NULL<br>6rows in set (0.00 sec)<br>接下来，通过这个表来介绍各个函数的应用。<br>IF（value,t,f)函数：这里认为月薪在2000元以上的职员属于高薪，用“high”表示；而2000元以下的职员属于低薪，用“1ow”表示。<br>mysql&gt; select userid,salary,if(salary&gt;2000, ‘high’,low) as salary_ level from salary; userid | salary salary_level|<br>1000.00 1ow 2000.00<br>2 1ow 3 3000.00 high<br>4000.00 high<br>4<br>5000.00 high<br>NULL 1ow<br>6rows in set (0.00 sec)<br>OIFNULL(valuel,value2)函数：这个函数一般用来替换NULL值，我们知道NULL值<br>是不能参与数值运算的。下面这个语句就是把NULL值用O来替换。 mysql&gt; select userid,salary,ifnull(salary,0) from salary;<br>userid I salary |ifnull(salary,0)1<br>1000.00 1000.00 2000.00 2000.00<br>3000.00 3000.001 4000.00 4000.001 15000.00 5000.00<br>0.001<br>1 NULL<br>6rows in set (0.03 sec)<br>OCASE[expr]WHEN[valuel]THEN[result1]…ELSE[default]END函数：这是case的简单函数用法，case后面跟列名或者列的表达式，when后面枚举这个表达式所有可能的值，但不能是值的范围。如果要实现上面例子中高薪低薪的问题，写法如下：<br>mysql&gt; select userid,salary,case salary when 1000 then low′ when 2000 then 1ow else ‘high end salary_ level from salary;<br>|userid | salary lsalary_level|<br>1|1000.00|1oW</p>
<p>≦ 91 ≧<br>5.5JSON函数 73<br>2000.0011ow 3 3000.00 I high 4 4000.00 high 5 5000.00 high 11 NULL |high<br>6rows in set (0.00 sec)<br>OCASEWHEN[expr]THEN[resultl]…ELSE[default]END函数：这是case的搜索函数用法，直接在when后面写条件表达式，并且只返回第一个符合条件的值，使用起来更加灵活，上例可以改写如下：<br>mysq1&gt; select userid,salary,case when salary&lt;&#x3D;2000 then ‘low’ else high’ end as salary_level from salary;<br>|userid salary salary_level<br>1000.00 1ow 2000.00 1ow<br>3 3000.00 high 4 4000.00 high<br>5 5000.00 high 11 NULL high<br>6rows in set (o.00 sec)<br>5.5 JSON函数<br>第3章已经介绍了MySQL5.7.8之后新引I人的JSON文档类型，对于JSON文档的操作，除了简单读写之外，通常还会有各种各样的查询、修改等需求，为此MySQL也提供了很多相应的函数，具体见表5-7。<br>表5-7 MySQL中的JSON函数<br>函数类型名称<br>功<br>JSON_ARRAYO 创建JSON数组<br>创建JSON JSON_OBJECTO 创建JSON对象<br>JSON_QUOTEO&#x2F;JSON_UNQUOTEO 加上&#x2F;去掉JSON文档两边的双引号 JSON_CONTAINSO 查询文档中是否包含指定的元素<br>JSON_CONTAINS_PATHO 查询文档中是否包含指定的路径<br>查询JSON JSON_EXTRACTO&#x2F;-&gt;&#x2F;-&gt;&gt; 根据条件提取文档中的数据<br>JSON_KEYSO 提取所有key的集合 JSON_SEARCHO 返回所有符合条件的路径集合 JSON_MERGEO(deprecated 5.7.22)<br>JSON_MERGE PRESERVE 将两个文档合并<br>JSON_ARRAY_APPENDO 数组尾部追加元素<br>修改JSON JSON_ARRAY_INSERTO 在数组的指定位置插入元素<br>JSON_REMOVEO 删除文档中指定位置的元素 JSON_REPLACEO 替换文档中指定位置的元素 JSON_SETO 给文档中指定位置的元素设置新值，如果元素不存在，则进行插入</p>
<p>≦ 92 ≧<br>74 第5章 常用函数<br>续表<br>函数类型 名 称 功能<br>JSON_DEPTHO JSON文档的深度（元素最大嵌套层数）<br>查询JSON元 JSON_LENGTHO JSON文档的长度（元素个数）<br>数据 JSON_TYPEO JSON文档类型（数组、对象、标量类型）<br>JSON_VALIDO JSON格式是否合法 JSON_PRETTYO 美化JSON格式<br>JSON_STORAGE_SIZEO JSON文档占用的存储空间<br>JSON_STORAGE_FREEO JSON文档更新操作后剩余的空间，MySQL8.0新增<br>其他函数 JSON_TABLEO 将JSON文档转换为表格，MySQL8.0新增<br>JSON_ARRAYAGGO 将聚合后参数中的多个值转换为JSON数组<br>把两个列或者是表达式解释为一个key和一个value，返回一个<br>JSON_OBJECTAGGO JSON对象<br>这些函数安装功能可以分为以下几类：创建JSON函数；<br>查询JSON函数；<br>0 修改JSON函数；<br>o 查询JSON元数据函数；<br>其他函数。<br>下面将详细介绍这些函数。<br>5.5.1 创建JSON函数<br>1.JSON_ARRAY([vaI[, val]…)<br>此函数可以返回包含参数中所有值列表的JSON数组。<br>以下示例创建了一个包含数字、字符串、null、布尔、日期类型在内的混合数组，需要注意的是，参数中的null和true&#x2F;false大小写不敏感。<br>mysql&gt; SELECT JSON ARRAY（1,abc”,NULL,TRUE,CURTIME）;<br>IJSON ARRAY（1,“abc”，NULL,TRUE,CURTIMEO）[1,”abc”,nu1l,true,“11:30:24.000000”]<br>2.JSON_OBJECT([key,val[, key, val]…)<br>此函数可以返回包含参数中所有键值对的对象列表。参数中的key不能为null，参数个数也不能为奇数，否则报语法错误。<br>以下示例使用了正确的语法：<br>mysq1&gt; SELECT JSON_OBJECT（’id’,100,namejack’）;<br>JSON OBJECT（’id’,100,name′,jack’） I {“id”:100,“name”:“jack”}<br>以下示例则使用了错误的语法：</p>
<p>≦ 93 ≧<br>5.5JSON函数 75<br>mysq1&gt; SELECTJSONoBJECTid，100，name）；&#x2F;&#x2F;参数个数为奇数<br>ERRoR 1582 (42000): Incorrect parameter count in the call to native function ‘JsoN oBJECT mysq1&gt; SELECT sON_oBJEcT(‘id，100,nu11,1）;&#x2F;&#x2F;key不能为nu11<br>ERROR 3158 (22032): JsON documents may not contain NULL member names. 3. JSON_QUOTE(string)<br>此函数可以将参数中的JSON文档转换为双引号引起来的字符串，如果JSON文档包含<br>双引号，则转换后的字符串自动加上转义字符“”，如以下示例： mySq1&gt; SELECT JSON QUOTE(‘[1,2,3]),JSON QUOTEC”nu7）;<br>1JSON QUOTE(‘[1,2,3]’)JSON QUOTEC”nu1”)1 1”[1,2,3]”“”nu…<br>如果需要将非JSON文档转换为JSON文档，或者反过来，可以使用CONVERT或者CAST 函数进行强制转换，这两个函数可以在不同数据类型之间进行强制转换，具体用法请参考官方文档。<br>5.5.2查询JSON函数<br>1.JSON_CONTAINS(target,candidate[,path])<br>此函数可以查询指定的元素（candidate）是否包含在目标JSON文档（target）中，包含则返回1，否则返回O，path参数可选。如果有参数为NULL或path不存在，则返回NULL。<br>以下示例分别要查询元素”abc”、1、10是否包含在JSON文档中： mysql&gt; select json contains（’[1,2,3,“abc”,null]′,”abc） ；<br>I json contains(‘[1,2，3,”abc”,null]′,”abc”) 1 row in set (o.00 sec)<br>mysql&gt; select json contains(‘[1,2,3,“abc,null],1’);<br>1 json contains（’[1,2,3，“abc”,null]′,1’）1 1 row in set(o.o0 sec)<br>mysql&gt; select json contains(‘[1,2,3,”abc”,nul1]′,10′）；<br>I json contains(‘[1,2,3,”abc”，nul1]′,10’） 1 row in set (o.00 sec)<br>显然结果符合我们的预期。元素如果是数组也是可以的：<br>mysql&gt; select json contains(‘[1, 2,3,”abc”,null]′,’[1,3]’)<br>1json contains(‘[1,2,3,”abc”,nul1]′,[1,3]′） 1 row in set (0.00 sec)</p>
<p>≦ 94 ≧<br>76 第5章常用函数<br>path 参数是可选的，可以指定在特定的路径下查询。如果JSON文档为对象，则路径格式通常类似于S.a或者S.a.b这种格式。S.a很好理解，表示key为a；S.a.b通常用在value也是对象列表的情况，表示键a下层的键b，比如{“id：{“id1”:1,”id2”:2}。如果JSON文档为数组，则路径通常写为$[这种格式，表示数组中第i个元素。<br>在下例中，要查询JSON文档j中是否包含value为10的对象，并指定路径为Sjack<br>（key&#x3D;jack’），如果包含则返回1，如果不包含则返回0。那么SQL代码可以这么写： mysql&gt; SET @j &#x3D;[jack”:10,“tom”:20,”1isa:30}′;<br>Query ok,O rows affected (o.o0 sec) mysql&gt;SET @j2&#x3D;10’;<br>Query oK,0 rows affected (o.o0 sec)<br>mysql&gt; select json _contains(@j,@j2,’$.jack’); 1json_contains（@j,@j2,’$.jack’）1<br>11<br>1row in set (0.00 sec)<br>返回1，表示在路径key&#x3D;jack下，存在value为10的值。将查询路径改为tom后，再次查询：<br>mysql&gt; select json contains（@j,@j2,’$.tom’); 1json contains(@j,@j2,’$.tom’)1<br>此时返回0，则表示JSON文档中不包含{“tom”:10}的元素。<br>2.JSON_CONTAINS_PATH(json_doc,one_or_all,path[,path]…)<br>此函数可以查询JSON文档中是否存在指定路径，存在则返回1，否则返回0。one_or_all 只能取值one或all，one表示只要有一个存在即可；all表示所有的都存在才行。如果有参数为NULL或path不存在，则返回NULL。<br>比如，要查询给定的3个path是否至少一个存在或者必须全部存在，可以分别写SQL代码如下：<br>mysql&gt; select json contains path(‘{“k1”:”jack”,”k2”:”tom”,”k3”:”Tisa”}’,’one′,’$.kl’,’$.k4’) one path ; lone path |<br>11<br>1 row in set (o.00 sec)<br>mysql&gt; select json contains path’{“k1”:jack”,”k2””:”tom”,”k3”:lisa”}’,all’,$.k1’,$.k4’）allpath; lall path |<br>01<br>1 row in set (0.o0 sec)<br>3.JSON_EXTRACT(json_doc, path[, path] ..)<br>此函数可以从JSON文档里抽取数据。如果有参数有NULL或path不存在，则返回NULL。如果抽取出多个path，则返回的数据合并在一个JSONARRAY里。<br>以下示例从JSON文档的第一和第二个元素中提取出对应的value：</p>
<p>≦ 95 ≧<br>5.5JSON函数 77<br>mySq1&gt; SELECT JSON EXTRACT（’[10,20,[30,40]]’,$[0]′,$[1]′）;<br>|JSON EXTRACTC’[10,20,[30,40]]′,’$[0],$[1]′)1[10,20]<br>1row in set (o.00 sec)<br>可以看到，返回的两个值以数组的形式进行了合并。如果要取第三个数组值，path可以写为S2或者S[2][<em>]:<br>mySq1&gt; SELECT JSON EXTRACTC[10,20,[30,40]]′,$[2]’）;<br>1JSON EXTRACT(‘[10,20,[30,40]],</em>$[2]’)1 1[30,40]<br>1row in set (o.00 sec)<br>mySq1&gt; SELECT JSON EXTRACTC[10,20,[30, 40]]′,$[2][<em>]）;<br>JSON EXTRACT（[10,20,[30,40]]′,‘$[2][</em>]’）1 1[30,40]<br>1 row in set (0.00 sec)<br>在MySQL5.7.9版本之后，可以用一种更简单的函数“-&gt;”来替代JSON_EXTRACT，语法如下：<br>co7umn-&gt;path<br>注意左边只能是列名，不能是表达式；右边是要匹配的JSON路径。上面的例子可以改写为：<br>mysql&gt; insert into t1 values（[10,20,[30,40]]′）; Query ok,1 row affected (o.oo sec)<br>mysql&gt; select idl,idl-&gt;”s[0]”,idl-&gt;”s[1]” from t1 where id1l-&gt;”s[0]”&#x3D;10;<br>|id1 1id1-&gt;”s[0]”|id1-&gt;”$[1]”1<br>1[10,20,[30,40]]110 120 1 row in set (o.00 sec)<br>如果JSON文档查询的结果是字符串，则显示结果默认会包含双引号，在很多情况下是不需要的，为了解决这个问题，MySQL提供了另外两个函数JSON_UNQUOTE和“-&gt;&gt;”，用法类似于JSON_EXTRACT和“-&gt;”，简单举例如下：<br>mysql&gt; selectjson ExTRACT(id1,’$.k1’),jsonunquote(idl-&gt;’$.k1’),id1-&gt;’$.k1’,id1-&gt;&gt;’$.k1 from t1 where idl-&gt;’$.kl’&#x3D;’jack’;<br>1json ExTRACT(id1,’$.k1’)1 json unquote(id1-&gt;’$.k1’)1id1-&gt;’s.k1′|id1-&gt;&gt;’s.k1<br>I“jack” jack”jack” jack 1row in set (o.00 sec)<br>即下面3种写法效果是一样的：<br>OJSON_UNQUOTE(JSON_EXTRACT(column, path))<br>OJSON_UNQUOTE(column -&gt; path) column-&gt;&gt;path<br>4. JSON_KEYS(json_doc[, path])<br>此函数可以获取JSON文档在指定路径下的所有键值，返回一个JSONARRAY。如果有</p>
<p>≦ 96 ≧<br>78 第5章常用函数参数为NULL或path不存在，则返回NULL。<br>参数path通常使用在嵌套对象列表中，如下例所示： mysq1&gt; select JsON KEYs(‘{“a”:1,”b””:{“c”: 30}}’）;<br>|JSONKEYS(‘{“a”:1,“b”:{“c”:30}}’)1 1[“a”,”b”]<br>1row in set (o.00 sec)<br>mysql&gt; select JsON KEYS(‘{“a”:1,”b””:{“c”: 30}},$.b’）;<br>IJSON KEYS（’”a”:1,”b”:”c”:30}’,<em>$.b’)1 1[“c”]<br>1row in set (o.00 sec)<br>如果元素中都是数组ARRAY，则返回为NULL。<br>5.JSON_SEARCH(json_doc,one_or_all,search_str[,escape_char[,path]…]) 此函数可以查询包含指定字符串的路径，并作为一个JSONARRAY返回。如果有参数为<br>NULL或path不存在，则返回NULL。各参数含义如下。<br>one_or_all:one表示查询到一个即返回；all表示查询所有。 search_str：要查询的字符串，可以用LIKE里的”%’或’_匹配。 Opath：表示在指定path下进行查询。<br>以下示例给出了如何查询JSON文档中以字母t开头的元素的第一个路径：<br>mysql&gt; select json search(</em>{“k1”:”jack”,”k2”:”tom”,”k3”:”lisa”,”k4”:”tony”}’,’one’,，t%’）;<br>1json search(’{“k1”:”jack”,”k2”:”tom”,”k3”:”lisa”,”k4”:”tony”}’,’one’,’t%’)| 1“$.k2”<br>1 row in set (o.00 sec)<br>可以看出，满足条件的第一个元素是”k2”:”tom”，path描述为”$.k2”。下面把条件“one”改成“all”，再看看结果：<br>mysql&gt; select json search(‘{“k1”:”jack”,“k2””:”tom”,“k3”:”lisa”,”k4”:”tony”}’，’al1′，’t%’);<br>1 json_search（′{“k1”:”jack”,”k2”:”tom”,”k3”:”lisa”,”k4”:”tony”}，’all′,′t%’) 1 1[“s.k2”，“s.k4”]<br>1 row in set (o.00 sec)<br>此时，满足条件的所有元素是”k2”:”tom”和”k4”:”tony”，路径描述为[“$.k2”，”$.k4”]数组。如果把JSON文档改为数组，则返回路径也将成为数组的描述格式，如下例所示：<br>mysql&gt; select json search（’[“tom”,”lisa”,”jack”，”name”:”tony”}]′，’all′，’t%’）; 1 json search(‘[“tom”,”lisa”,”jack”,{“name”:”tony”}]′,’all′,’t%’)|<br>1[“$[o]”,”$[3].name”] 1 row in set (0.00 sec)</p>
<p>≦ 97 ≧<br>5.5JSON函数 79<br>5.5.3修改JSON的函数<br>1.JSON_ARRAY_APPEND(json_doc,path,val[,path,val].)<br>此函数可以在指定path的jsonarray尾部追加val。如果指定path是一个jsonobject，则将其封装成一个json array再追加。如果有参数为NULL，则返回NULL。<br>以下示例在JSON文档的不同path处分别追加字符“1”：<br>mysql&gt; SELECTJSON ARRAY APPEND(’[“a”,[“b”，“c”],”d”]’，<em>S[O]，”1”）； 1JSON ARRAY APPENDC’[“a”,[“b”,“c”],”d”]’,S[O】’，“1”）<br>1 [[“a”，”1”]，[“b”，“c””]，”d”] 1 row in set (0.o0 sec)<br>mySql&gt; SELECT JSON ARRAY APPENDC’[”a”,[“b”,”c”],”d”]’,$[1]’,”1”）; IJSON ARRAY APPEND(‘”a”.[“b”， c”],“d”]’,s[1]’，“1”）<br>1[“a”,[“b”，”c”，”1”],”d”] 1 row in set (o.00 sec)<br>mySql&gt; SELECT JSON ARRAY APPENDC’[”a”,[“b”,“c”],”d”]’,</em>$[1][O]′,”1”）; IJSON ARRAY_APPENDC’[“a”,[“b”,”c”],”d”]’,S[1][O]′,”1”)<br>1[“a”，[[“b”，“1”]，“c”]，”d”] 1 row in set (o.o0 sec)<br>mySql&gt; SELECT JSON ARRAY APPEND(‘{“a”:1,”b”:[2,3],”c”:43′,’$.b′,”1”）; JSON ARRAY APPENDC’{“a”:1,”b”[2,3],”c””:4}′,’$.b,“1”）1<br>I”a”:1,”b”:[2,3,”1”],”c”:4} 1 row in set (0.o0 sec)<br>2.JSON_ARRAY_INSERT(json_doc,path,val[,path,val]…)<br>此函数可以在path指定的json array元素插入val，原位置及以右的元素顺次右移。如果 path指定的数据非json array元素，则略过此val；如果指定的元素下标超过json array的长度，则插入尾部。<br>将上面例子中的4个SQL语句改成JSON_ARRAY_INSERT，看一下结果：<br>mySql&gt; SELECT JSON ARRAY INSERT(‘[”a”，[“b”,”c],“d”],S[O]’，”1”）; ISON ARRAY INSERT（’[“a”,[“b”,”c”],“d”]’,S[O]’,”1”）<br>1 [“1”，“a”，[“b”，”c”]，“d”] 1 row in set (0.00 sec)<br>mySq1&gt; SELECT JSON ARRAY INSERTC′[“a”,[“b”,”c”].”d”]’,·$[1]’,”1”）;<br>JSON ARRAY_INSERT(‘[“a”,[“b”,”c”],“d”]’,$[1]′,”1”） 1 row in set (o.00 sec)</p>
<p>≦ 98 ≧<br>80 第5章常用函数<br>mysql&gt; SELECT JSON ARRAY INSERT(‘[“a”,[“b”,”c”],”d”]′,S[1] [O]′,”1”); JSON ARRAY INSERTC”a” [“b”，“c”]，“d”]′，$[1][o]’，“1”）<br>[“a”，[“1”，“b”，“c”]，“d”] 1row in set (o.00 sec)<br>mysql&gt; SELECT JSON ARRAY INSERTC’{“a”:1,”b”:[2,3],”c”: 4},$.b′,”1”); ERRoR 3165 (42000):A path expression is not a path to a cell in an array. 最后一个SQL报错，提示路径不对，将“$.b”改为“$[O]”试一下： mySql&gt; SELECT JSON ARRAY _INSERT(‘{“a”:1,”b”:[2, 3],”c”: 4}′,’$[O],”1”）; IJSON ARRAY INSERTC’”a”:1,”b”:[2,3],”c”:4}′,’S[O]′,“1”)<br>“b”[2，3]，“c”:4}<br>{“a”<br>1 row in set (0.00 sec)<br>插人路径正确，但字符并没有插人到JSON文档中，因为所有元素都是对象，跳过忽略。 3.JSON_REPLACE(json_doc, path, val[, path, val]…)<br>此函数可以替换指定路径的数据，如果某个路径不存在，则略过（存在才替换）。如果有参数为NULL，则返回NULL。<br>下例将JSON文档中的第一个元素和第二个元素分别替换为“1”和“2”：<br>1JSON REPLACE(′[“a”,[“b”,“c”],“d”],$[O]′,“1”,s[1]·,“2”) 1[“1”，“2”，”d”]<br>1 row in set (o.00 sec)<br>下例将JSON文档中key为a和d的对象的value分别替换为“10”和“20”： mySq1&gt; SELECT JSON REPLACE(‘{”a”:1,“b”:[2,3],“c”:43,<em>$.a，”10”,’$.d’，”20”）; 1JSON REPLACE(′{“a”:1,“b”:[2,3],”c”:4}′,$.a′,“10”,</em>$.d′,”20”）)1<br>1”a”:“10”，“b”:[2,3],”c”：4} 1row in set(o.o0 sec)<br>4.JSON_SET(json_doc,path,val[, path,val] …)<br>此函数可以设置指定路径的数据（不管是否存在）。如果有参数为NULL，则返回NULL。和JSON_REPLACE功能有些类似，最主要的区别是指定的路径不存在时，会在文档中自动添加，如下例所示：<br>mysql&gt; SELECT JSON SET（’{”a”：1,“b”:[2,3],“c”：4}，’$.a′,“10”,$.d’,”20”）; 1JSON SET（’”a”:1,“b”:[2,3],”c”:4}’,$.a′,”10”,，$.d’,”20”）1<br>1{“a”:“10”,“b”:[2，3],“c”:4,“d”:“20”} 1row in set (o.o0 sec)<br>5.JSON_MERGE_PRESERVE (json_doc,json_doc[, json_doc] ..) 此函数可以将多个JSON文档进行合并。合并规则如下：<br>如果都是json array，则结果自动merge为一个json array；如果都是json object，则结果自动merge 为一个json object;</p>
<p>≦ 99 ≧<br>5.5JSON函数 81<br>如果有多种类型，则将非json array的元素封装成jsonarray再按照规则一进行merge。<br>下例中分别将两个数组合并、两个对象合并、数组和对象合并： mySq1&gt; SELECT JSON MERGE PRESERVE(‘[1,2]’,[3,4]′）;<br>IJSON MERGE PRESERVE(‘[1,2]′,[3,4]’）1 1[1,2,3，4]<br>1 row in set (o.00 sec)<br>mysql&gt; SELECT JSON MERGE PRESERVE(’{“key1”:“tom”}’，{“key2”:”isa”}’）; I JSON MERGE PRESERVE(‘{“keyi”:”tom”}’,’”key2”:”lisa”}’）1<br>|{“key1”:“tom”，“key2”:“lisa”} 1 row in set (o.00 sec)<br>mysq]&gt; SELECT JSON MERGE PRESERVE(‘[1,2]′,{“key1”:“tom”}）; |JSON MERGE PRESERVE(‘[1,2]’,’{“Key1”:”tom”}’)<br>1[1,2,{“key1”:“tom”}] 1row in set(o.00 sec)<br>6.JSON_REMOVE(json_doc,path[,path]..)<br>此函数可以移除指定路径的数据，如果某个路径不存在则略过此路径。如果有参数为 NULL，则返回NULL。<br>下例中把JSON文档中第二个和第三个元素删除： mysq1&gt; SELECT JSON REMOVE(‘[1,2,3,4]′,$[1]’,’$[2]’）;<br>1JSON_REMOVE(‘[1,2,3,4]’,’$[1]′,’$[2])1 |[1,3]<br>1row in set (o.00 sec)<br>结果有些意外，$[1]，$[2]分别为2和3，删除后不是应该为[1，4]吗？这里要注意，如果指定了多个path，则删除操作是串行操作的，即先删除’$[1]后JSON文档变为[1,3,4]，然后在[1,3,4]上删除’$[2]后变为[1,3]。<br>5.5.4查询JSON元数据函数<br>1.JSON_DEPTH(json_doc) 此函数用来获取JSON文档的深度。<br>如果文档是空数组、空对象、null、true&#x2F;false，则深度为1；如果非空数组或者非空对象里面包含的都是深度为1的对象，则整个文档深度为2；依次类推，整个文档的深度取决于最大元素的深度。如下例所示：<br>mySql&gt; SELECT JSON DEPTH(）,JSON DEPTH(‘[),JSON DEPTH(‘true）; IJSON DEPTHC）IJSON DEPTHC’[‘IJSON DEPTHCtrue’）<br>11 11<br>1 row in set (0.00 sec)</p>
<p>≦ 100 ≧<br>82 第5章常用函数<br>mySq1&gt; SELECT JSON DEPTH(‘[10,20]’),JSON DEPTHC’[[],{]′）; IJSON DEPTHC’[10,2O]’）|JSON DEPTHC’[[],]’）<br>21<br>1row in set (o.00 sec)<br>mySql&gt; SELECT JSON DEPTH(‘[10,”a”:203]’); 1JSON DEPTHC’[10,{“a”:20}]’）<br>31<br>1 row in set (o.00 sec)<br>2. JSON_LENGTH(json_doc[, path])<br>此函数可以获取指定路径下的文档长度。长度的计算规则如下：<br>标量（字符串、数字）的长度为1； Ojsonarray的长度为元素的个数；<br>o. jsonobject的长度为对象的个数；<br>嵌套数组或者嵌套对象不计算长度。见下例所示：<br>mySq1&gt; SELECT JSON LENGTH(‘1′),JSON LENGTHC’[1,2,[3,4]]）,JSON LENGTHC{KEY”:”TOM”}）; 1JSON LENGTH（’1’)|JSON LENGTHC’[1,2,[3,4]]’）IJSON LENGTH(‘{“KEY”:”TOM”}’)<br>11<br>1 row in set (o.00 sec)<br>3.JSON_TYPE(json_val)<br>此函数可以获取JSON文档的具体类型，可以是数组、对象或者标量类型。<br>mysql&gt; select json_type(‘[1,3]’）,json_type(‘{“id”:”tom”}’）; 1 json_type(‘[1,3]’)| json_type（’{“id”:”tom”}′)1<br>|ARRAY 1OBJECT 1row in set (o.o0 sec)<br>mysq1&gt; select json_type(‘1’),json type(“abc”‘),json_type(‘null’),json type(‘true’); I json type(‘1’)I json type（”abc”)I json type(‘null’)1 json type(‘true’)<br>IINTEGER |STRING NULL BOOLEAN<br>1 row in set (o.00 sec) 4.JSON_VALID(val)<br>此函数判断val是否为有效的JSON格式，有效为1，否则为0。这个函数在第3章做过简单介绍，见下例所示：<br>mysql&gt; select json valid(‘abc’）,json valid（abc）,json valid（[1,2]′),json valid（’[1,2’）; |json valid(‘abc’）|json valid(“abc”）| json valid(‘[1,2]’）|json valid（’[1,2’)1<br>01 11 01<br>1 row in set (0.00 sec)</p>
<p>≦ 101 ≧<br>5.5JSON函数 83<br>显然，字符串两边不加双引号是无效的JSON格式，“1,2’少了右中括号也是无效的，都返回0。<br>5.5.5JSON工具函数<br>1.JSON_PRETTY(json_val)<br>此函数是在5.7.22版本中新增的，用来美化JSON的输出格式，使得结果更加易读。对于数组、对象，每一行显示一个元素，多层嵌套的元素会在新行中进行缩进，清楚地显示层次关系，如下例所示：<br>mySql&gt; SELECT JSON PRETTY（’”a”：”10”,”b”“15”，“x”:{“x1”:1,“x2”:2,“x3”:3}}’）; 1JSON PRETTY（’”a”:“10”,“b”:”15”,”x”:{”x1”:1,“x2”:2,”x3”:3}}′)<br>“a””:”10”，”b”：“15””x””：”x1”:”x2”：2，<br>2.JSON_STORAGE_SIZE(json_val)&#x2F;JSON_STORAGE_FREE(json_val)<br>JSON_STORAGE_SIZE(json_val)函数可以获取JSON文档占用的存储空间（byte），而 JSON_STORAGE_FREE(json_val)函数可以获取由于JSON_SET、JSON_REPLACE、 JSONREMOVE操作导致释放的空间。<br>其中，JSON_STORAGE_FREE是8.0版本新增的函数，用户可以在MySQL8.0环境下测试以下示例。下面的例子显示了对JSON字段update操作前和操作后，两个函数的显示结果。<br>update前：<br>mysql&gt; SELECT JSON_STORAGE SIZE(jcoT),JSON STORAGE FREE(jcoT),jcol FROM jtab1e; IJSON STORAGE SIZE(jcol) I JSON STORAGE FREE(jcol) I jcol<br>0”Name”:”Homer”“Stupid”“True”}<br>1 row in set (0.00 sec)<br>JSON_STORAGE_SIZE显示了jcol列所占用的空间为40字节，由于没有字段更新，所<br>以JSON_STORAGE_FREE显示为0。 update后：<br>mysql&gt; update jtable set jcol&#x3D;json set(jcol,’$.stupid’,1); Query ok, 1 row affected (0.07 sec)<br>Rows matched: 1changed:1warnings:0<br>mysql&gt; SELECT JSON STORAGE SIZE(jco1),JSON STORAGE FREE(jcol),jcol FROM jtable; IJSON STORAGE SIZE(jcol) I JSON STORAGE FREE(jcol) I jcol<br>40”Name””Homer””stupid”: 131<br>1 row in set (o.o0 sec)</p>
<p>≦ 102 ≧<br>84 第5章常用函数<br>从结果上看，update操作释放了5个字节的空间，但JSON_STORAGE_SIZE(jcol)返回的结果并没有改变，仍然是40字节，这是由于MySQL规定局部更新（使用JSON_SET&#x2F;JSON REPLACE&#x2F;JSON_REMOVE函数进行操作）后的文档存储只能大于等于更新前的size。如果更新的值大于原值，则JSON_STORAGE_SIZE则会大于原文档size，如下例所示：<br>mysql&gt; update jtable set jcol&#x3D;json set(jcol,’$.Stupid’,”True123”); Query ok,1 row affected (0.02 sec)<br>Rows matched:1 changed:1 warnings:0<br>mysql&gt; SELECT JSON STORAGE SIZE(jcoT),JSON_STORAGE _FREE(jco1),jcol FROM jtable; IJSON STORAGE SIZE(jcol) IJSON STORAGE FREE(jcoT) I jcol<br>43 0|{“Name”:“Homer”,”stupid”:“True123”}<br>1 row in set (0.00 sec)<br>由于更新操作没有释放空间，所以JSON_STORAGE_FREE返回为O。但JSON_STORAGE SIZE已经显示为增大后的size43。对于非局部更新（即不使用JSON_SET&#x2F;JSON_REPLACE&#x2F; JSON_REMOVE操作进行更新），上面的函数不满足之前的逻辑，如下例所示：<br>mysql&gt; update jtable set jcol&#x3D;′{”Name”:“Homer”,“Stupid”:“True”}′; Query oK,1 row affected (0.06 sec)<br>Rows matched:1Changed:1 warnings:0<br>mysql&gt; SELECT JSON_STORAGE_SIZE(jco1),JSON_STORAGE_FREE(jco1),jcol FROM jtab1e; IJSON STORAGE SIZE(jcoT) I JSON_STORAGE FREE(jcoT) I jcol<br>01”Name”:”Homer”, “stupid”:“True”}<br>1row in set (o.o0 sec)<br>mysql&gt; update jtable set jcol&#x3D;’{“Name”:”Homer”,”stupid”:1}′; Query ok,1row affected (0.01 sec)<br>Rows matched:1changed:1warnings:0<br>mySql&gt; SELECT JSON STORAGE SIZE(jco1),JSON STORAGE FREE(jco1),jco1 FROM jtable; IJSON STORAGE SIZE(jcol) I JSON STORAGE FREE(jcoT) I jcol<br>351 0|{“Name”:”Homer”，“Stupid”:131<br>1 row in set (0.00 sec)<br>显然，两个函数的结果和之前的结果都不一样，JSON_STORAGE_SIZE显示的都是JSON 文档的实际size，JSON_STORAGE_FREE则永远为0。<br>3.JSON_TABLE(expr,path COLUMNS (column_list)[AS] alias)<br>此函数可以将JSON文档映射为表格。参数中expr可以是表达式或者列；path是用来过滤的JSON路径；COLUMNS是常量关键字；columnlist是转换后的字段列表。<br>这个函数是MySQL8.0.4后新增的一个重要的函数，可以将复杂的JSON文档转换为表格数据，转换后的表格可以像正常表一样做连接、排序、creaet table as select等各种操作，对 JSON的数据展示、数据迁移等很多应用领域带来极大的灵活性和便利性。<br>下面的例子将JSON文档中的全部数据转换为表格，并按表格中的ac字段进行排序： mysql&gt; SELECT*<br>-&gt; FROM<br>JSON TABLE(</p>
<p>≦ 103 ≧<br>5.5JSON函数 85<br>‘[“a”:”3”},{“a”:2},{“b”:13,”a”:0},”a”:[1,2]3]′，<br>““$[<em>]” COLUMNS(<br>rowid FOR ORDINALITY,<br>aCVARCHAR(100) PATH$.a DEFAULT999ON ERROR DEFAULT111ON EMPTY,<br>aj JSON PATH “$.a”DEFAULT{“x”:333}ON EMPTY, bX INT EXISTS PATH “$.b”<br>)AStt<br>order by ac;<br>I rowid I ac<br>0<br>111{“x”：333}<br>“3. o<br>L<br>51999[1,2]<br>5rows in set (o.o0 sec)<br>对例子中的参数简单介绍一下。<br>（1）expr，即JSON对象数组[{“a”:”3”}，{“a”:2}，{“b”:1}，{“a”:0}，{“a”:[1,2]}]。<br>（2）过滤路径（path），其中”$[</em>]”表示文档中所有的数据，如果改为”$[O]”，则表示只转换文档中的第一个元素{“a”：”3”}。<br>（3）columnlist包含以下4个部分的内容。<br>OrowidFORORDINALITY：rowid是转换后的列名，FORORDINALITY表示按照序列顺序加一，类似于MySQL中的自增列。数据类型为UNSIGNEDINT，初始值为1。<br>Oac VARCHAR(100)PATH”$.a”DEFAULT‘999′ ON ERROR DEFAULT ‘111′ ON EMPTY：ac是转换后的列名；VARCHAR（100)是转换后的列类型；PATH”$.a”说明此字段只记录对象的key&#x3D;”a”的value;DEFAULT‘999’ONERROR说明发生error，则转换为默认值999，比如{“a”：[1,2]}，value为JSON数组，和VARCHAR不匹配，所以此对象转换后为“999”； DEFAULT’111’ONEMPTY说明对应的key不匹配’a’，此对象转换后为“111”，比如{“b”:1}。<br>Oaj和ac类似，只是转换后的列类型为JSON。<br>ObxINTEXISTS PATH”$.b:bx是转换后列名，如果存在路径”S.b”，即key&#x3D;”b’的对象，则转换为1；否则为0。<br>4.JSON_ARRAYAGG(col_or_expr)<br>此函数可以将聚合后参数中的多个值转换为JSON数组。<br>下面的例子中按照o_id聚合后的属性列表转换为一个字符串JSON数组： mysql&gt; select * from t;<br>I o_id I attribute | value<br>color<br>fabric silk color green shape<br>square<br>4rows in set (0.00 sec)<br>mysql&gt; SELECT o id, JsON ARRAYAGG(attribute) AS attributes FROM t GROUP BY oid; oid l attributes</p>
<p>≦ 104 ≧<br>86 第5章常用函数<br>I [“color”，“fabric”] 1<br>[“color”, “shape”]<br>2 rows in set (0.01 sec)<br>5.JSON_OBJECTAGG(key,value)<br>此函数可以把两个列或者是表达式解释为一个key和一个value，返回一个JSON对象。还是上例中的数据，这次按照o_id聚合后的attribute&#x2F;value作为对象的key&#x2F;value组成一<br>个JSON对象文档。<br>mysql&gt; SELECT o_id, JSON_OBJECTAGG(attribute,value) FROM t GROUP BY o_id; 1id I JSON_OBJECTAGG(attribute,value)<br>|[”color””:“red”，“fabric”:“si1k”}<br>{“color”:”green”，”shape”:“square”} 2 rows in set (0.00 sec)<br>5.6 窗口函数<br>日常开发工作中，经常会遇到下面这些需求。<br>去医院看病，怎样知道上次就医距现在的时长？环比如何计算？<br>怎样得到各部门工资排名前N名的员工列表？如何查找组内每人工资占总工资的百分比？<br>如果使用传统的SQL来解决这些问题，理论上都是可以的，但逻辑却会相当复杂。这类需求都有一个共同特点，为了得到结果，都需要在某个结果集内做一些特定的函数操作。为了很方便地解决这一类问题，MySQL8.0中引人了窗口函数。窗口的概念非常重要，它可以理解为记录集合，窗口函数也就是在满足某种条件的记录集合上执行的特殊函数，对于每条记录都要在此窗口内执行函数。有的函数，随着记录不同，窗口大小都是固定的，这种属于静态窗口；有的函数则相反，不同的记录对应着不同的窗口，这种动态变化的窗口叫滑动窗口。<br>窗口函数和聚合函数有些类似，两者最大的区别是聚合函数是多行聚合为一行，窗口函数则是多行聚合为相同的行数，每行会多一个聚合后的新列。窗口函数在其他数据库中（比如Oracle）也称为分析函数，功能也都大体相似。<br>MySQL中支持的窗口函数如表5-8所示。<br>表5-8 MySQL中的窗口函数<br>函数功能<br>ROW_NUMBERO 分区中的当前行号 RANKO 当前行在分区中的排名，含序号间隙<br>DENSE_RANKO 当前行在分区的排名，没有序号间隙<br>PERCENT_RANKO 百分比等级值 CUME_DISTO 累计分配值<br>FIRST_VALUEO 窗口中第一行的参数值 LAST_VALUEO 窗口中最后一行的参数值</p>
<p>≦ 105 ≧<br>5.6窗口函数 87<br>续表<br>功能<br>函 名<br>LAGO 分区中指定行落后于当前行的参数值<br>LEADO 分区中领先当前行的参数值 NTH_VALUEO 从第N行窗口框架的参数值 NTILE(N) 分区中当前行的桶号<br>下面以订单表order_tab为例，逐个讲解这些函数的使用。测试表中的数据如下，各字段<br>含义按顺序分别为订单号、用户id、订单金额、订单创建日期： mysql&gt; select * from order tab;<br>1order id | user no amount create date<br>一<br>1 001 100 2018-01-0100:00:001 2 001 300 2018-01-02 00:00:001 3 001 500 2018-01-02 00:00:00<br>001 800 2018-01-03 00:00:00 001 900 2018-01-04 00:00:00<br>002 500 2018-01-0300:00:00 002 600 2018-01-04 00:00:00<br>8 002 300 2018-01-1000:00:00<br>2018-01-16 00:00:00-<br>1002 800<br>10 80012018-01-2200:00:001<br>10 rows in set (0.00 sec)<br>5.6.1 ROW_NUMBERO)<br>如果要查询每个用户最新的一笔订单，我们希望的结果是order_id分别为5和10的记录，此时可以使用ROW_NUMBERO函数按照用户进行分组并按照订单日期进行由大到小排序，<br>最后查找每组中序号为1的记录，SQL语句如下： mysql&gt; select * from<br>-&gt;（<br>select row numberover(partition by user no order by create date desc) as row num,<br>order_id,user_no,amount,create_date from order_tab<br>-&gt;)t where row num&#x3D;1;<br>I row_num I order id 1 user_no I amount create_date<br>11 001 900 2018-01-04 00:00:00 11 101 002 800 2018-01-22 00:00:001<br>2rows in set (0.00 sec)<br>其中，row_numberO后面的over是关键字，用来指定函数执行的窗口范围，如果后面的括号中什么都不写，则意味着窗口包含所有行，窗口函数在所有行上进行计算；如果不为空，则支持以下4种语法。<br>window_name:给窗口指定一个别名，如果SQL中涉及的窗口较多，采用别名则更<br>清晰易读。上面的例子中如果指定一个别名W，则改写代码如下： select * from<br>select row_numberOover w as row_num, order_id,user_no,amount,create date from order_tab</p>
<p>≦ 106 ≧<br>88 第5章常用函数<br>WINDow w As (partition by user_no order by create_ date desc))twhere row num&#x3D;1;<br>partition子句：窗口按照哪些字段进行分组，窗口函数在不同的分组上分别执行。上面的例子就按照用户id进行分组。在每个用户id上，分别执行从1开始的顺序编号。<br>Oorderby子句：按照哪些字段进行排序，窗口函数将按照排序后的记录顺序进行编号，既可以和partition子句配合使用，也可以单独使用。上例中二者同时使用。<br>Oframe子句：frame是当前分区的一个子集，子句用来定义子集的规则，通常用来作为滑动窗口使用。比如要根据每个订单动态计算包括本订单和按时间顺序前后两个订单的平<br>均订单金额，则可以设置如下frame子句来创建滑动窗口： mysql&gt; select * from<br>-&gt;（<br>select<br>order_id,user_no,amount,<br>avg(amount)over w as avg num, create_ date<br>-&gt; from order _tab<br>WINDow w As (partition by user_no order by create date desc ROwS BETWEEN 1 PRECEDING<br>AND 1 FOLLOWING)<br>-&gt;）t;<br>order_id user_no Iamount I avg num create date<br>5 001 900 850.0000 2018-01-04 00:00:001 4 001 800 666.6667 2018-01-03 00:00:00 2 001 300 533.3333 2018-01-02 00:00:00<br>3 001 500 300.0000 源 2018-01-02 00:00:00 1 001 100 300.0000 2018-01-01 00:00:00 10 002 800 800.0000 2018-01-22 00:00:00<br>002 800 633.3333 2018-01-16 00:00:00<br>8 002 300 566.6667 2018-01-10 00:00:00 7 002 600 466.6667 12018-01-0400:00:00 6 002 500 550.0000 2018-01-0300:00:00<br>10 rows in set (o.00 sec)<br>从结果可以看出，order_id为5订单属于边界值，没有前一行，因此平均订单金额为（900+800）&#x2F;2&#x3D;850；order_id为4的订单前后都有订单，所以平均订单金额为（900+800+300）&#x2F;3&#x3D;666.6667，以此类推就可以得到一个基于滑动窗口的动态平均订单值。<br>对于滑动窗口的范围指定，有如下两种方式。<br>（1）基于行：通常使用BETWEENframe_startANDframe_end语法来表示行范围，<br>frame_start和frame_end可以支持如下关键字，来确定不同的动态行记录： CURRENTROW边界是当前行，一般和其他范围关键字一起使用<br>UNBOUNDED PRECEDING边界是分区中的第一行 UNBOUNDEDFOLLOWING边界是分区中的最后一行 expr PRECEDING边界是当前行减去expr的值 expr FOLLOwING边界是当前行加上expr的值<br>比如，下面都是合法的范围：<br>roWSBETWEEN 1PRECEDINGAND 1FOLLOWING窗口范围是当前行、前一行、后一行一共3行记录 rOWSUNBOUNDEDFOLLOWING窗口范围是当前行到分区中的最后一行<br>rOWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING 窗口范围是当前分区中所有行，等同于不写（2）基于范围：和基于行类似，但有些范围不是直接可以用行数来表示的，比如希望窗口范围是一周前的订单开始，截止到当前行，则无法使用rows来直接表示，此时就可以使用范围来表示窗口：INTERVAL7DAYPRECEDING。Linux中常见的计算最近1分钟、5分钟、 15分钟负载就是一个典型的应用场景。</p>
<p>≦ 107 ≧<br>5.6窗口函数 89<br>5.6.2RANK(&#x2F;DENSE_RANK()<br>RANKO和DENSE_RANKO这两个函数与row_numberO非常类似，只是在出现重复值时处理逻辑有所不同。这里稍微改一下上面的示例，假设需要查询不同用户的订单，按照订单金额进行排序，显示出相应的排名序号，SQL语句中用row_numberO、rankO、dense_rankO<br>分别显示序号，我们来看一下有什么区别。 mysql&gt; select * from<br>select row numberO over(partition by user no order by amount desc) as row numl, rankO over(partition by user no order by amount desc) as row num2,</p>
<blockquote>
<p>dense_rankO) over(partition by user_no order by amount desc) as row num3,<br>order_id,user_no,amount,create date from order_tab<br>-&gt;）t;<br>Irow_numl row_num2 rownum3|order id user_no amount create_date<br>1 001 900 2018-01-04 00:00:00 2 001 800 2018-01-03 00:00:00 3 001 500 2018-01-0200:00:00 4 4 001 300 2018-01-0200:00:00<br>5 5 5 001 100 2018-01-01 00:00:00 I 1 9 002 800 2018-01-16 00:00:00 2 1 1 10 002 800 2018-01-22 00:00:00 3 3 2 1 002 600 2018-01-04 00:00:00<br>002 2018-01-0300:00:00<br>6<br>4 002 2018-01-1000:00:00<br>10rows in set (0.00 sec)<br>上面的记录中倒数第3、4、5行的斜体显示了3个函数的区别，row_numberO在amount 都是800的两条记录上随机排序，但序号按照1、2递增，后面amount为600的的序号继续递增为3，中间不会产生序号间隙；rankO&#x2F;dense_rankO则把amount为800的两条记录序号都设置为1，但后续amount为600的需要则分别设置为3（rank）和2（dense_rank）。即rankO 会产生序号相同的记录，同时可能产生序号间隙；而dense_rankO也会产生序号相同的记录，但不会产生序号间隙。<br>5.6.3PERCENT_RANK(&#x2F;CUME_DIST()<br>PERCENT_RANKO和CUME_DISTO这两个函数都是计算数据分布的函数， PERCENT_RANKO和之前的RANKO函数相关，每行按照以下公式进行计算：<br>（rank-1)&#x2F;（rows-1) P<br>其中，rank为RANKO函数产生的序号，rows为当前窗口的记录总行数，上面的例子修改如下：<br>mysql&gt; select * from<br>-&gt;(<br>select<br>rankO over w as row num,<br>-&gt;percent rank() over w as percent,<br>order_id,user_no,amount,create _date from order tab<br>WINDow w As (partition by user_no order by amount desc) &gt;）t;<br>1row_num |percent | order_id | user no l amount | create date</p>
</blockquote>
<p>≦ 108 ≧<br>90 第5章 常用函数<br>0 5 001 90012018-01-04 00:00:001<br>2 0.25 4 001 8001 2018-01-0300:00:001 3 0.5 3 001 500 2018-01-02 00:00:00<br>300 2018-01-0200:00:001<br>4 0.75 001<br>001<br>1 100 2018-01-0100:00:00 9 002 800 2018-01-16 00:00:00 10 002 800 2018-01-2200:00:00<br>3 0.5 002 600 2018-01-04 00:00:00 1 4 0.75 6 002 500 2018-01-0300:00:001<br>1 8 002 300 12018-01-10 00:00:001<br>10rows in set (0.00 sec)<br>从结果中可以看出，percent列按照公式（rank-1）&#x2F;（rows-1)代人rank值（row_num列）和 rows值（user_no为001和r002’的值均为5）。此函数主要应用在分析领域，日常应用场景较少。<br>相比PERCENT_RANKO，CUME_DISTO函数的应用场景更多，它的作用是分组内小于等于当前rank值的行数&#x2F;分组内总行数。上例中，统计大于等于当前订单金额的订单数，占总<br>订单数的比例，SQL代码如下： mysql&gt; select * from<br>select<br>-&gt;rankO over w as row num, cume distO over w as cume,<br>order_id,user_no,amount,create_date from order_ tab<br>WINDow w As (partition by user no order by amount desc)<br>row_num cume | order_id user no |amount.| create_date<br>1 0.2 001 900 2018-01-0400:00:00 2 0.4 4 001 800 2018-01-0300:00:00 3 0.6 3 001 500 2018-01-0200:00:00<br>4 0.8 2 001 300 2018-01-0200:00:00 5 1 001 100 2018-01-01 00:00:00<br>2018-01-16 00:00:00<br>1 0.4 002 800<br>0.4 10 002 800 2018-01-2200:00:00 3 0.6 002 600 2018-01-04 00:00:00<br>0.8 6 002 500 2018-01-03 00:00:00<br>8 002 300 2018-01-10 00:00:001<br>10 rows in set (0.00 sec)<br>列cume 显示了预期的结果。 5.6.4NFILE(N)<br>NFILEO函数的功能是对一个数据分区中的有序结果集进行划分，将其分为N个组，并为每个小组分配一个唯一的组编号。继续上面的例子，对每个用户的订单记录分为3组，NFILEO<br>函数记录每组组编号，SQL代码如下： mysql&gt; select * from<br>-&gt;C<br>select<br>ntile(3) over w as nf,<br>order_id,user_no,amount,create date from order_tab<br>WINDow w As (partition by user_no order by amount desc )）t;<br>nf Iorder_id | user no I amount | create date<br>90012018-01-04 00:00:001<br>11 1001</p>
<p>≦ 109 ≧<br>5.6窗口函数 91<br>001 800 12018-01-03 00:00:00<br>2 001 500 2018-01-0200:00:00 2 2 001 300 2018-01-02 00:00:00 3 1 001 100 2018-01-01 00:00:00 1 9 002 800 2018-01-16 00:00:00 1 10 002 800 2018-01-22 00:00:00 2 7 002 600 2018-01-0400:00:00<br>6 002 500 2018-01-0300:00:001 8 002 300 12018-01-1000:00:001<br>10 rows in set (o.00 sec)<br>此函数在数据分析中应用较多，比如由于数据量大，需要将数据分配到N个并行的进程分别计算，此时就可以用NFILE(N)对数据进行分组，由于记录数不一定被N整除，所以<br>每组记录数不一定完全一致，然后将不同组号的数据再分配。 5.6.5 NTH_VALUE(expr,N)<br>NTH_VALUE(expr，N)函数可以返回窗口中第N个expr的值，expr既可以是表达式，也<br>可以是列名。这个函数不太好理解，来看下面的例子： mysql&gt; select * from</p>
<blockquote>
<p>-&gt;select<br>-&gt;ntile(3) over w as nf,<br>-&gt;nth value(order_id,3) over w as nth,<br>order_id,user no,amount,create date from order_tab<br>WINDow w As (partition by user_no order by amount desc)）t;<br>nf Inth |order_id user no amount1 create date<br>NULL 001 900 2018-01-04 00:00:00 1 NULL 4 001 800 2018-01-0300:00:00 2 3 001 500 2018-01-0200:00:00<br>2 001 300 2018-01-0200:00:00<br>100 2018-01-01 00:00:00<br>3 3 001<br>NULL 9 002 800 2018-01-16 00:00:00 NULL 10 002 800 2018-01-2200:00:00<br>2018-01-0400:00:00<br>2 002 600 2 7 6 002 500 2018-01-0300:00:00<br>P<br>3 002 300 2018-01-10:00:00:00 10 rows in set (0.00 sec)<br>nth列返回了分组排序后的窗口中order_id的第三个值，001用户返回3，002用户返回7，对于前N-1列，本函数返回NULL。<br>5.6.6 LAG(expr,N)&#x2F;LEAD(expr,N)<br>LAG(expr,N)和LEAD(expr,N)这两个函数的功能是获取当前数据行按照某种排序规则的上N行（LAG）／下N行（LEAD）数据的某个字段。比如，每个订单中希望增加一个字段，用来记录本订单距离上一个订单的时间间隔，那么就可以用LAG函数来实现，SQL代码如下：<br>mysql&gt; select order id,user no,amount,create date,last date,datediff(create date,last date)as diff<br>-&gt;from-&gt;(<br>select</p>
</blockquote>
<p>≦ 110 ≧<br>92 第5章常用函数<br>order_id,user no,amount,create date, lag（create date,1) over w as last date from order_tab<br>WINDow w As (partition by user_no order by create_date ）<br>|order_id | user no amount create date 1last date |diff1<br>1 001 100 2018-01-0100:00:001 NULL |NULL 2 001 300 2018-01-0200:00:001 2018-01-01 00:00:00<br>1<br>3 001 500 2018-01-02 00:00:00 2018-01-0200:00:00<br>4 001 800 2018-01-0300:00:0012 2018-01-0200:00:00 1 5 001 900 2018-01-0400:00:0012 2018-01-0300:00:00<br>6 002 500 2018-01-03 00:00:00 NULL NULL<br>002 600 2018-01-0400:00:001 2018-01-03 00:00:00<br>8 002 300 2018-01-1000:00:00 2018-01-0400:00:00 9 002 800 2018-01-1600:00:00 2018-01-1000:00:00 10 002 800 12018-01-2200:00:0012018-01-1600:00:001<br>10 rows in set (o.00 sec)<br>内层SQL先通过lag函数得到上一次订单的日期，外层SQL再将本次订单和上次订单日期做差得到时间间隔。<br>5.6.7FIRST_VALUE（eXpr)&#x2F;LAST_VALUE（eXpr)<br>FIRST_VALUE（expr）函数和LAST_VALUE（expr）函数的功能分别是获得滑动窗口范围内的参数字段中第一个（FIRST_VALUE）和最后一个（LAST_VALUE）的值。下例中，每个用户在每个订单记录中希望看到截止到当前订单为止，按照日期排序最早订单和最晚订单<br>的订单金额，SQL语句如下： mysql&gt; select*<br>-&gt;from C<br>select<br>order_id,user_no,amount,create date,<br>first value(amount) over w as first amount, last value(amount) over w as last amount from order_tab<br>WINDow w As （partition by user_no order by create date)）t;<br>order id| userno amount | create date Ifirst amount l last amount<br>001 100 2018-01-01 00:00:00 100 100 001 300 2018-01-02 00:00:00 100 500 001 500 2018-01-02 00:00:00 100 500<br>001 800 2018-01-03 00:00:00 100 800 001 900 2018-01-04 00:00:00 100 900 002 500 2018-01-03 00:00:00 500 500<br>002 600 2018-01-0400:00:00 500 600 002 300 2018-01-10 00:00:00 500 300<br>9 002 800 2018-01-1600:00:00 500 800 10 002 800 2018-01-2200:00:00 500 800<br>10 rows in set (0.00 sec)<br>结果和预期一致，比如order_id为4的记录，first_amount和last_amount分别记录了用户 001截止到时间2018-01-0300:00:00为止，第一条订单金额100和最后一条订单金额800，注意这里是按时间排序的最早订单和最晚订单，并不是最小金额和最大金额订单。</p>
<p>≦ 111 ≧<br>5.7其他常用函数 93<br>5.6.8聚合函数作为窗口函数<br>除了前面介绍的各类窗口函数外，我们经常使用的各种聚合函数（SUM&#x2F;AVG&#x2F;MAX&#x2F; MIN&#x2F;COUNT）也可以作为窗口函数来使用。比如要统计每个用户按照订单id，截止到当前的累计订单金额&#x2F;平均订单金额&#x2F;最大订单金额&#x2F;最小订单金额&#x2F;订单数是多少，可以用聚合函数作<br>为窗口函数实现如下： mysql&gt; seTect<br>-&gt; order_id,user_no,amount,create_date，<br>-&gt;sum(amount) over w as suml,-&gt; avg(amount) over w as avgl,-&gt; max(amount) over w as maxl,-&gt; min(amount) over w as minl,<br>-&gt; count(amount) over w as count1-&gt;from<br>-&gt;order_tab<br>-&gt;wINDow w As (partition by user no order by order _id)<br>|order id |user _no amount create date Isuml avg1 max1 min1 l countl<br>100 2018-01-0100:00:00 100 100.0000 100 100 1<br>2 001 300 2018-01-0200:00:00 400 200.0000 300 100 2<br>001 500 2018-01-02 00:00:00 900 300.0000 500 100 3 001 800 2018-01-03 00:00:00 1700 425.0000 800 100 4 001 900 2018-01-0400:00:00 2600 520.0000 900 100<br>002 500 2018-01-0300:00:00 500 500.0000 500 500 1<br>002 600 2018-01-04 00:00:00 1100 550.0000 600 500 7<br>002 300 2018-01-1000:00:00 1400 466.6667 600 300 3 91002 800 2018-01-1600:00:00 2200 550.0000 800 300 4 10 002 800 2018-01-22 00:00:00 3000 600.0000 800 300 5<br>10 rows in set (0.07 sec)<br>可以看到suml&#x2F;avg1&#x2F;max1&#x2F;min1&#x2F;count1的结果完全符合预期。 5.7其他常用函数<br>MySQL提供的函数很丰富，除了前面介绍的字符串函数、数字函数、日期函数、流程函数以外，还有很多其他函数，在此不再一一列举，有兴趣的读者可以参考MySQL官方手册。表5-9列举了一些其他常用的函数。<br>表5-9 MySQL中的其他常用函数<br>函数功<br>DATABASEO 返回当前数据库名<br>VERSIONO 返回当前数据库版本 USERO 返回当前登录用户名<br>INET_ATON(IP) 返回IP地址的数字表示 INET_NTOA(num) 返回数字代表的IP地址 PASSWORD(str) 返回字符串str的加密版本<br>MD50 返回字符串str的MD5值<br>下面结合实例简单介绍一下这些函数的用法。</p>
<p>≦ 112 ≧<br>94 第5章常用函数<br>0 DATABASEO函数：返回当前数据库名。 mysql&gt; select DATABASE();<br>|DATABASEO |test<br>1row in set (0.00 sec)<br>VERSIONO函数：返回当前数据库版本。 mysql&gt; select VERSIoNO）;<br>|VERSIONOI 15.0.18-nt1<br>1row in set (0.00 sec)<br>e USERO函数：返回当前登录用户名。<br>mysql&gt; select UsERO; IUSERO)<br>1root@localhost|<br>1 row in set (0.03 sec)<br>OINET_ATON(IP)函数：返回IP地址的网络字节序表示。<br>mysql&gt; select INET_ATONC’192.168.1.1’); 1INETATON(192.168.1.1’)1<br>3232235777<br>1 row in set (o.o0 sec)<br>OINET_NTOA（num）函数：返回网络字节序代表的IP地址。 mysql&gt; select INET_NTOA(3232235777);<br>IINET_NTOA(3232235777)1 1192.168.1.1<br>1 row in set (0.00 sec)<br>INET_ATON(IP)和INET_NTOA(num)函数主要的用途是将字符串的IP地址转换为数字表示的网络字节序，这样可以更方便地进行IP或者网段的比较。比如在下面的表t中，想要知道在“192.168.1.3”和“192.168.1.20”之间一共有多少IP地址，可以这么做：<br>mysql&gt; select * from t; lip<br>192.168.1.1 192.168.1.3 192.168.1.6 192.168.1.10 192.168.1.201 1192.168.1.301<br>6 rows in set (0.00 sec)<br>按照正常的思维，应该用字符串来进行比较。下面是字符串的比较结果：</p>
<p>≦ 113 ≧<br>5.8小结 95<br>mysql&gt; select <em>from t where ip&gt;&#x3D;192.168.1.3′ and ip&lt;&#x3D;192.168.1.20: Empty set (0.01 sec)<br>结果没有如我们所愿，竟然是个空集。其原因就在于字符串的比较是一个字符一个字符地比较，当对应字符相同时，就比较下一个，直到遇到能区分出大小的字符才停止比较，后面的字符也将忽略。显然，在此例中，“192.168.1.3”其实比“192.168.1.20”要“大”，因为“3”比“2”大，而不能用我们日常的思维3&lt;20，所以“ip&gt;&#x3D;192.168.1.3’andip&lt;&#x3D;192.168.1.20” 必然是个空集。<br>在这里，如果要想实现上面的功能，就可用函数INET_ATON来实现，将IP地址转换为字节序后再比较，如下所示：<br>mysq1&gt; select * from t where inet aton（ip)&gt;&#x3D;inet aton(‘192.168.1.3’) and inet aton（ip)&lt;&#x3D; inet_ aton(‘192.168.1.20)<br>lip<br>192.168.1.3 192.168.1.6 1192.168.1.10 1192.168.1.201<br>4 rows in set (0.00 sec)<br>结果完全符合我们的要求。<br>PASSWORD（str)函数：返回字符串str的加密版本，一个41位长的字符串。<br>此函数只用来设置系统用户的密码，但是不能用来对应用的数据加密。如果应用方面有加密的需求，可以使用MD5等加密函数来实现。<br>下例中显示了字符串“123456”的PASSWORD加密后的值：<br>mysq1&gt; select PASSWORD(‘123456’); PASSWORD(‘123456’)<br>1</em>6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9| 1row in set (0.08 sec)<br>MD5(str)函数：返回字符串str的MD5值，常用来对应用中的数据进行加密。下例中显示了字符串“123456”的MD5值：<br>mysq1&gt; se1ect MD5(‘123456’); |MD5（’123456’)<br>1e10adc3949ba59abbe56e057f20f883e1<br>1row in set (0.06 sec) 5.8小结<br>本章主要对MySQL常用的各类函数通过实例做了介绍。MySQL有很多内建函数，这些内建函数实现了很多应用需要的功能并且拥有很好的性能，如果用户在工作中需要实现某种功能，最好先查一下MySQL官方文档或者帮助，看是否已经有相应的函数实现了用户需要的功能，这样可以大大提高工作效率。由于篇幅所限，本章并没有介绍所有的函数，读者可以进一步查询相关文档。</p>
<p>≦ 115 ≧<br>2<br>第二部分开发篇<br>·计证 B</p>
<p>≦ 116 ≧<br>第6章表类型（存储引擎）的选择和大多数数据库不同，MySQL中有一个存储引擎的概念，针对不同的存储需求可以选择<br>最优的存储引擎。本章将详细介绍存储引擎的概念、分类以及实际应用中的选择原则。 6.1·MySQL存储引擎概述<br>插件式存储引擎是MySQL数据库最重要的特性之一，用户可以根据应用的需要选择如何存储和索引数据、是否使用事务等。MySQL默认支持多种存储引擎，以适用于不同领域的数据库应用需要，用户可以通过选择使用不同的存储引擎提高应用的效率，提供灵活的存储，用户甚至可以按照自己的需要定制和使用自己的存储引擎，以实现最大程度的可定制性。<br>MySQL5.7支持的存储引擎包括InnoDB、MyISAM、MEMORY、CSV、BLACKHOLE、 ARCHIVE、MERGE（MRG_MyISAM）、FEDERATED、EXAMPLE、NDB等，其中InnoDB 和NDB提供事务安全表，其他存储引擎都是非事务安全表。<br>创建新表时如果不指定存储引擎，那么系统就会使用默认存储引擎，MySQL5.5之前的默认存储引擎是MyISAM，5.5版本之后改为了InnoDB。如果要修改默认的存储引擎，可以在参数文件中设置default_storage_engine。查看当前的默认存储引擎，可以使用以下命令： mysql&gt; show variables like ‘default storage engine’;<br>variable name I value<br>|default storage engine | InnoDB| 1 row in set (0.00 sec)<br>可以通过以下方法查询当前数据库支持的存储引擎： mysql&gt; show engines \G<br>1.row ***<br>Engine:InnoDB Support: DEFAULT<br>Comment: supports transactions, row-level locking,and foreign keys Transactions: YES<br>XA: YES<br>Savepoints: YES<br>2row<br>Engine: cSV Support: YES<br>Comment: csv storage engine Transactions: NO<br>XA:NO</p>
<p>≦ 117 ≧<br>6.1MySQL存储引擎概述 99<br>Savepoints: NO<br>Engine: MyISAM Support: YES<br>Comment: MyISAM storage engine Transactions: No<br>XA:NO<br>Savepoints: NO<br>北★★业★业★★业★ ★★★★*★<br>Engine:BLACKHOLE Support: YES<br>Comment: &#x2F;dev&#x2F;null storage engine (anything you write to it disappears) Transactions: NO<br>XA:NO<br>Savepoints: NO<br>Engine: PERFORMANCE SCHEMA Support: YES<br>Comment: Performance Schema Transactions: NO<br>XA:NO<br>Savepoints: NO<br>******6.row<br>★★专业★★★★业★★业★★业<br>Engine: MRG MYISAM Support: YES<br>Comment:Collection of identical MyISAM tables Transactions: NO<br>XA:NO<br>Savepoints: NO 北业业会业业业会业业★业业会会会<br>Engine: ARCHIVE Support:YES<br>Comment: Archive storage engine Transactions: NO<br>XA:NO<br>Savepoints: NO 武会会业业会业业业会会会会会司<br>Engine:MEMORY Support: YES<br>Comment: Hash based, stored in memory, useful for temporary tables Transactions: No<br>XA:NO<br>Savepoints:NO<br>Engine: FEDERATED Support: NO<br>Comment: Federated MysQL storage engine Transactions: NULL<br>XA:NULL<br>Savepoints: NULL<br>9rows in set (o.00 sec)<br>通过上面的结果可以查看当前支持哪些存储引擎，其中Support不同值的含义分别为：<br>DEFAULT-支持并启用，并且为默认引擎；YES 一支持并启用；NO-—不支持；<br>DISABLED-一支持，但是数据库启动的时候被禁用。<br>在创建新表的时候，可以通过增加ENGINE关键字设置新建表的存储引擎，例如，在下<br>面的例子中，表ai的存储引擎是MyISAM，而country表的存储引擎是InnoDB： CREATE TABLE ai（<br>ibigint(2O) NOT NULL AUTO_INCREMENT, PRIMARY KEY（i)<br>)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;utf8; CREATE TABLE Country（<br>Country_id SMALLINT UNSIGNED NOT NULL AUTO INCREMENT, Country VARCHAR(5O) NOT NULL,<br>last update TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY(country_id)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</p>
<p>≦ 118 ≧<br>100 第6章表类型（存储引擎）的选择<br>也可以使用ALTERTABLE语句，将一个已经存在的表修改成其他的存储引擎。下面的例子介绍了如何将表ai从MyISAM存储引擎修改到InnoDB存储引擎：<br>mysql&gt; alter table ai engine &#x3D; innodb; Query ok,0 rows affected (0.13 sec) Records:O Duplicates:Owarnings:0<br>mysql&gt; show create table ai \G<br>Table:ai<br>Create Table: CREATE TABLE ai（<br>‘ibigint(2O) NOT NULL AUTO INCREMENT, PRIMARY KEY(‘i’)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 1 row in set (o.00 sec)<br>这样修改后，表ai的存储引擎是InnoDB，可以使用InnoDB存储引擎的相关特性。<br>注意：修改表的存储引擎需要锁表并复制数据，对于线上环境的表进行这个操作非常危险，除<br>非你非常了解可能造成的影响，否则在线上环境请使用其他方式，例如percona的OSC 工具，后续章节会有详细介绍。<br>6.2各种存储引擎的特性<br>下面重点介绍几种常用的存储引擎，并对比各个存储引擎之间的区别，以帮助读者理解不同存储引擎的使用方式，如表6-1所示。<br>表6-1 常用存储引擎的对比<br>特点 MyISAM Memory InnoDB Archive NDB<br>B树索引支持支持支持备份&#x2F;时间点恢复支持支持支持支持 支持<br>支持集群 支持聚簇索引 支持<br>数据压缩支持支持支持数据缓存 N&#x2F;A 支持 支持<br>数据加密支持支持支持支持支持支持外键支持 支持<br>全文索引支持支持地理坐标数据类型支持支持支持支持<br>地理坐标索引支持支持哈希索引支持 支持<br>索引缓存支持 N&#x2F;A 支持支持锁粒度表级表级行级行级行级<br>MVCC多版本控制支持支持复制支持有限支持支持支持支持<br>存储限制 256TB RAM 64TB None 384EB T树索引 支持<br>支持事务支持支持统计信息支持支持支持支持支持</p>
<p>≦ 119 ≧<br>6.2各种存储引擎的特性 101<br>下面将重点介绍常用的4种存储引擎：MyISAM、MEMORY、InnoDB和Archive。 6.2.1MyISAM<br>MyISAM是MySQL5.5之前版本的默认的存储引引擎。MyISAM既不支持事务，也不支持外键，在5.5之前的版本中，MyISAM在某些场景中相对InnoDB的访问速度有明显的优势，对事务完整性没有要求或者以SELECT、INSERT为主的应用可以使用这个引I擎来创建表。 MySQL5.6之后，MyISAM已经越来越少地被使用。<br>每个MyISAM在磁盘上存储成3个文件，其文件名都和表名相同，但扩展名分别如下：.frm（存储表定义）;<br>.MYD（MYData，存储数据）; MYI（MYIndex，存储索引1）。<br>数据文件和索引文件可以放置在不同的目录，平均分布IO，获得更快的速度。<br>要指定索引文件和数据文件的路径，需要在创建表的时候通过DATADIRECTORY和 INDEXDIRECTORY语句指定，也就是说不同MyISAM表的索引I文件和数据文件可以放置到不同的路径下。文件路径需要是绝对路径，并且具有访问权限。<br>MyISAM类型的表可能会损坏，原因可能是多种多样的，损坏后的表可能不能被访问，会提示需要修复或者访问后返回错误的结果。MyISAM类型的表提供修复的工具，可以用 CHECKTABLE语句来检查MyISAM表的健康，并用REPAIRTABLE语句修复一个损坏的 MyISAM表。表损坏可能导致数据库异常重新启动，需要尽快修复并尽可能地确认损坏的原因。<br>MyISAM的表还支持3种不同的存储格式，分别如下：静态（固定长度）表；<br>动态表；压缩表。<br>其中，静态表是默认的存储格式。静态表中的字段都是非变长字段，这样每个记录都是！固定长度的，这种存储方式的优点是存储非常迅速，容易缓存，出现故障容易恢复；缺点是占用的空间通常比动态表多。静态表的数据在存储时会按照列的宽度定义补足空格，但是在应用访问的时候并不会得到这些空格，这些空格在返回给应用之前已经去掉。<br>但是也有些需要特别注意的问题，如果需要保存的内容后面本来就带有空格，那么在返回结果的时候也会被去掉，开发人员在编写程序的时候需要特别注意，因为静态表是默认的存储格式，开发人员可能并没有意识到这一点，从而丢失了尾部的空格。下面的例子演示了插人的记录包含空格时处理的情况：<br>mysql&gt; create table Myisam_char (name char(10)) engine&#x3D;myisam; Query ok, 0 rows affected (o.04 sec)<br>mysql&gt; insert into Myisam char values(‘abcde’),(‘abcde ),(‘abcde’）),(‘abcde );<br>Query ok, 4rows affected (0.o0 sec) Records:4Duplicates:0 warnings:0<br>mysql&gt; select name,length(name) from Myisam char;<br>1name 1 length(name) Iabcde</p>
<p>≦ 120 ≧<br>102 第6章表类型（存储引擎）的选择<br>Iabcde<br>abcde| abcdei<br>4rows in set (0.01 sec)<br>从上面的例子可以看出，插人记录后面的空格都被去掉了，前面的空格保留了。<br>动态表中包含变长字段，记录不是固定长度的，这样存储的优点是占用的空间相对较少，但是频繁地更新和删除记录会产生碎片，需要定期执行OPTIMIZETABLE语句或myisamchk-r 命令来改善性能，并且在出现故障时恢复相对比较困难。<br>压缩表由myisampack工具创建，占用非常小的磁盘空间。因为每个记录是被单独压缩的，<br>所以只有非常小的访问开支。 6.2.2InnoDB<br>InnoDB作为MySQL5.5之后的默认存储引擎，提供了具有提交、回滚和崩溃恢复能力的事务安全保障，同时提供了更小的锁粒度和更强的并发能力，拥有自己独立的缓存和日志，在MySQL5.6和5.7版本中性能有较大的提升。<br>对比MyISAM存储引擎，InnoDB会占用更多的磁盘空间以保留数据和索引。但是在大多数场景下，InnoDB都会是更好的选择，这也是为何MySQL将默认存储引擎改为InnoDB，并且在最新的MySQL8.0中，将所有系统表也都改为InnoDB存储引擎。<br>下面将重点介绍存储引擎为InnoDB的表在使用过程中不同于使用其他存储引擎的表的特点，以及如何更好地使用InnoDB存储引擎。<br>1.自动增长列<br>InnoDB表的自动增长列可以手工插入，但是插入的值如果是空，则实际插入的将是自动增长后的值。下面定义新表autoincre_demo，其中列i使用自动增长列，对该表插人记录，然<br>后查看自动增长列的处理情况，可以发现插入空时，实际插入的都将是自动增长后的值： mysql&gt; create table autoincre demo l<br>-&gt;(i smallint not null auto increment,<br>-&gt;name varchar(10),primary key（i) &gt;）engine&#x3D;innodb;<br>Query ok,0 rows affected (0.13 sec)<br>mysql&gt; insert into autoincre demo values(nu1l,’1),(2,’2’),(null,’3’）;<br>Query ok,3 rows affected (0.o0 sec) Records:3Duplicates:0 warnings:0<br>mysql&gt; select * from autoincre demo; lilnamel<br>1212 1313<br>3 rows in set (0.00 sec)<br>可以通过“ALTERTABLE***AUTO_INCREMENT&#x3D;n;”语句强制设置自动增长列的初始值，默认从1开始，但是在MySQL8.0之前，对于InnoDB存储引擎来说，这个值只保留在内存中，如果数据库重新启动，那么这个值就会丢失，数据库会自动将AUTO_INCREMENT 重置为自增列当前存储的最大值+1，这可能会导致在数据库重启后，自增列记录的值和预期</p>
<p>≦ 121 ≧<br>6.2各种存储引擎的特性 103<br>不一致，从而导致数据冲突。以下示例演示了在MySQL5.7中，AUTO_INCREMENT值在重启前后的表现。<br>首先，创建测试表test_auto_incre，id为自增主键： mysql&gt; show create table test auto_incre\G<br>Table: test auto incre<br>Create Table: CREATE TABLE test auto incre（ id int(i1) NOT NULL AUTO INCREMENT,<br>name  varchar(10) coLLATE utf8 unicode ci DEFAULT NULL PRIMARY KEY（id)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci 1row in set (o.o0 sec)<br>修改AUTO_INCREMENT&#x3D;100:<br>mysql&gt; alter table test auto_incre auto _increment&#x3D;100;<br>Query ok, 0 rows affected (0.04 sec) Records:ODuplicates:owarnings:0<br>尝试写人一行数据，看一下是否生效：<br>mysql&gt; insert into test_auto _incre values(null,’abc’);<br>Query ok,1 row affected (0.03 sec) mysql&gt; select * from test auto _incre;<br>1row in set(0.00 sec)<br>id值为预期的100，接下来再次修改AUTO_INCREMENT的值为200： mysql&gt; alter table test auto_incre auto increment&#x3D;200;<br>Query ok,0 rows affected (0.01 sec) Records:O Duplicates:warnings:0<br>mysql&gt; show create table test auto_incre\G<br>Table: test auto_incre<br>Create Table: CREATE TABLE test auto incre id int(11) NOT NULL AUTo INCREMENT,<br>name varchar(10) coLLATE utf8 unicode_ci DEFAULT NULL, PRIMARY KEY (id)<br>) ENGINE&#x3D;InnoDB AUTO INCREMENT&#x3D;2OO DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci<br>1 row in set (o.o0 sec) 然后重启MySQL实例：<br>mysql&gt; show create table test auto_incre\G<br>ERROR 2006 (HY000): MySQL server has gone away<br>No connection. Trying to reconnect… Connection id:3<br>Current database: employees<br>Table: test auto_incre<br>Create Table: CREATE TABLE test auto incre（<br>id int(11) NOT NULL AUTo INCREMENT,<br>namevarchar(10) cOLLATE utf8 unicode_ci DEFAULT NULL PRIMARY KEY (id)<br>) ENGINE&#x3D;InnoDB AUTO INCREMENT&#x3D;101 DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci 1rowin set (0.21 sec)<br>可以看到，重启之后，AUTOINCREMENT的值变成了101，是当前自增列的最大值+1，而不是重启前设置的200，这种情况可能导致在某些历史数据归档或者复制环境中发生数据冲</p>
<p>≦ 122 ≧<br>104 第6章表类型（存储引擎）的选择<br>突。在MySQL8.0中，这个BUG得到了修复，具体实现方式是将自增主键的计数器持久化到REDOLOG中，每次计数器发生改变，都会将其写人到REDOLOG。如果数据库发生重启，InnoDB会根据REDOLOG中的计数器信息来初始化其内存值。<br>可以使用LAST_INSERT_IDO查询当前线程最后插入记录使用的值。如果一次插人了多条记录，那么返回的是第一条记录使用的自动增长值，需要注意的是，如果人为指定自增列的值，那么LAST_INSERT_IDO的值不会更新。下面的例子演示了使用LAST_INSERT_IDO 的情况：<br>mysql&gt; select LAST INSERT IDO；<br>ILAST INSERT IDO 1 row in set (o.00 sec)<br>mysql&gt; insert into autoincre demo values(4,4’);<br>Query ok, 1 row affected (0.04 sec) mysql&gt; select LAST INSERT IDO;<br>ILAST INSERT IDO 11<br>1 row in set(o.00 sec)<br>可以看到，手工指定自增列的值为4，LAST_INSERT_IDO的值并不会更新。接下来一次插入3行，这次自增列的值将自动生成。由于此时自增列的最大值是4，对于插入的这3行，自增列会自动分配5、6、7这3个值。<br>mysq1&gt; insert into autoincre demo(name) values(‘5),(6’),(‘7’);<br>Query ok,3 rows affected (0.05 sec) Records:3 Duplicates:0 warnings:0<br>mysql&gt; select LAST INSERT IDO;<br>ILAST INSERT ID 15<br>1 row in set(o.o0 sec)<br>这时LAST_INSERT_IDO的值等于批量插人的第一条记录的值5，而不是最后插入的7。对于InnoDB表，自动增长列必须被索引。如果是组合索引，也必须是组合索引的第一列，<br>但是对于MyISAM表，自动增长列可以是组合索引的其他列，这样插人记录后，自动增长列是按照组合索引的前面几列进行排序后递增的。例如，创建一个新的MyISAM类型的表 autoincre_demo，自动增长列d1作为组合索引的第二列，对该表插人一些记录后，可以发现<br>自动增长列是按照组合索引的第一列d2进行排序后递增的： mysql&gt; create table autoincre demo</p>
<blockquote>
<p>(dl smallint not null auto increment,<br>-&gt; d2 smallint not null,-&gt;name varchar(10),-&gt;index(d2,d1)<br>-&gt;）engine&#x3D;myisam;<br>Query ok,0 rows affected (0.03 sec)<br>mysq1&gt; insert into autoincre demo（d2,name） values(2,2’）,（3,’3′）,（4,4’）,(2,’2′）,(3,3′）,（4,4’）;<br>Query ok,6rows affected (o.00 sec) Records:6Duplicates:0warnings:0</p>
</blockquote>
<p>≦ 123 ≧<br>6.2各种存储引擎的特性 105<br>mysql&gt; select * from autoincre demo; |d1|d2lname<br>2<br>6rows in set (o.00 sec) 2.外键约束<br>MySQL支持外键的常用存储引引擎只有InnoDB，在创建外键的时候，要求父表必须有对应的索引，子表在创建外键的时候也会自动创建对应的索引。<br>下面是样例数据库中的两个表，country表是父表，country_id为主键索引l，city表是子表，<br>country_id字段为外键，对应于country表的主键country_id。 CREATE TABLE country<br>country_id SMALLINT UNSIGNED NOT NULL AUTO INCREMENT, country VARCHAR(5O) NOT NULL,<br>last update TIMESTAMP NOT NULL DEFAULT CURRENT TIMESTAMP ON UPDATE CURRENT_ TIMESTAMP, PRIMARY KEY (country_id)<br>DENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8; CREATE TABLE city （<br>city id SMALLINT UNSIGNED NOT NULL AUTO INCREMENT, city VARCHAR(5O) NOT NULL,<br>country_id SMALLINT UNSIGNED NOT NULL,<br>last update TIMESTAMP NOT NULL DEFAULT CURRENT TIMESTAMP ON UPDATE CURRENT TIMESTAMP, PRIMARY KEY(city_id),<br>KEY idx fk country_id (country_id),<br>CoNSTRAINT fk city_country FOREIGN KEY (country_id) REFERENCES country (country_id) ON DELETE<br>RESTRICT ON UPDATE CASCADE<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;<br>在创建索引时，可以指定在删除、更新父表时，对子表进行的相应操作，包括RESTRICT、 CASCADE、SETNULL和NOACTION。其中RESTRICT和NOACTION相同，是指限制在子表有关联记录的情况下父表不能更新；CASCADE表示父表在更新或者删除时，更新或者删除子表对应记录；SETNULL则表示父表在更新或者删除的时候，子表的对应字段被SET NULL。选择后两种方式的时候要谨慎，可能会因为错误的操作导致数据的丢失。<br>例如，对上面创建的两个表，子表的外键指定是ONDELETERESTRICTONUPDATE CASCADE方式的，那么在主表删除记录的时候，如果子表有对应记录，则不允许删除；主<br>表在更新记录的时候，如果子表有对应记录，则子表对应更新： mysql&gt; select * from country where country_id &#x3D; 1;<br>1 country_id I country 1last update<br>|Afghanistan 1 2006-02-15 04:44:00<br>1<br>1 row in set (0.00 sec) mysql&gt; select<br>city_id city country_id last update<br>1251 Kabul1 12006-02-1504:45:251 1 row in set (0.00 sec)</p>
<p>≦ 124 ≧<br>106 第6章表类型（存储引擎）的选择<br>mysql&gt; delete from country where country_id&#x3D;1;<br>ERROR 1451 (23000): cannot delete or update a parent row: a foreign key constraint fai1s（’sakila&#x2F;city’, cONSTRAINT fk city_country’ FOREIGN KEY (‘countryid’) REFERENCEs country(‘country_id’) ON uPDATE CASCADE)<br>mysql&gt; update country set country_id &#x3D; 10000 where country id &#x3D; 1; Query ok,1 row affected (0.04 sec)<br>Rows matched:1changed:1 warnings:0<br>mysql&gt; select * from country where country &#x3D;Afghanistan’; Icountry_id I country last update<br>10000 | Afghanistan | 2007-07-17 09:45:231 1row in set (o.o0 sec)<br>mysql&gt; select * from city where city_id &#x3D; 251; Icity_id| city country_id | last update<br>251 1Kabul 10000 12006-02-1504:45:25 1row in set (0.00 sec)<br>当某个表被其他表创建了外键参照，那么该表的对应索引或者主键禁止被删除。<br>在导人多个表的数据时，如果需要忽略表之前的导人顺序，可以暂时关闭外键的检查；同样，在执行LOADDATA和ALTERTABLE操作的时候，可以通过暂时关闭外键约束来加快处理的速度，关闭的命令是“SETFOREIGN_KEY_CHECKS&#x3D;O;”，执行完成之后，通过执行“SETFOREIGN_KEY_CHECKS&#x3D;1;”语句改回原状态。<br>对于InnoDB类型的表，外键的信息可以通过使用showcreate table或者showtable status 命令显示。<br>mysql&gt; show table status like ‘city’ \G<br>Name:city Engine: InnoDB Version:10<br>Row_format: Compact<br>ROWS:427<br>Avg_row_length: 115 Data_length:49152 Max data length:0 Index length:16384<br>Data_free:0 Auto_increment: 601<br>create_time:2007-07-17 09:45:33<br>Update_time: NULL Check_time: NULL<br>Collation:utf8 general_ci Checksum: NULL<br>Create_options:<br>Comment: InnoDB free:O kB;(‘country id’) REFER‘sakila&#x2F;country’（’country id’) oN<br>UPDATE<br>1 row in set(0.00 sec)<br>注意：外键需要注意的细节较多，一旦使用不当，可能会带来性能下降或者数据不一致的问题，<br>尤其在OLTP类型的应用中，需要慎重使用外键。<br>3.主键和索引<br>不同于其他存储引擎，InnoDB的数据文件本身就是以聚簇索引的形式保存的，这个聚簇</p>
<p>≦ 125 ≧<br>6.2各种存储引擎的特性 107<br>索引也被称为主索引l，并且也是InnoDB表的主键，InnoDB表的每行数据都保存在主索引的叶子节点上。因此，所有InnoDB表都必须包含主键，如果创建表时候，没有显式指定主键，那么InnoDB存储引擎会自动创建一个长度为6个字节的long类型隐藏字段作为主键。<br>考虑到聚簇索引的特点和对于查询的优化效果，所有InnoDB表都应该显式的指定主键，一般来说，主键应该按照下列原则来选择：<br>满足唯一和非空约束；<br>优先考虑使用最经常被当作查询条件的字段或者自增字段；<br>字段值基本不会被修改；使用尽可能短的字段。<br>在InnoDB表上，除了主键之外的其他索引都叫作辅助索引或者二级索引，二级索引会指向主索引，并通过主索引获取最终数据。因此，主键是否合理的创建，会对所有索引的效率产生影响。<br>关于索引使用的更多内容，会在第9章做更加详细的介绍。 4.存储方式<br>InnoDB存储表和索引|有以下两种方式。<br>使用共享表空间存储：这种方式创建的表的表结构保存在.frm文件中，数据和索引保存在innodb_data_home_dir和innodb_data_file_path定义的表空间中，可以是多个文件。<br>使用多表空间存储：这种方式创建的表的表结构仍然保存在.frm文件中，但是每个表的数据和索引单独保存在.ibd中。如果是一个分区表，则每个分区对应单独的.ibd文件，文件名是“表名+分区名”，可以在创建分区的时候指定每个分区的数据文件的位置，以此将表的IO均匀分布在多个磁盘上。<br>使用共享表空间时，随着数据的不断增长，表空间的管理维护会变得越来越困难，所以一般都建议使用多表空间。要使用多表空间的存储方式，需设置参数innodb_file_per_table，在MySQL5.7中，此参数默认设置为ON，即新建的表默认都是按照多表空间的方式创建。如果修改此参数为OFF，则新创建的表都会改为共享表空间存储，但已有的多表空间的表仍然保存原来的访问方式。<br>一些老版本中的表，很多是共享表空间，可以通过下面的命令改为多表空间：<br>mysql&gt; SET GLOBAL innodb_file_per_table&#x3D;1; mysql&gt; ALTER TABLE table_name ENGINE&#x3D;InnoDB;<br>多表空间的数据文件没有大小限制，既不需要设置初始大小，也不需要设置文件的最大限制、扩展大小等参数。<br>对于使用多表空间特性的表，可以比较方便地进行单表备份和恢复操作，但是直接复制.ibd文件是不行的，因为没有共享表空间的数据字典信息，直接复制的.ibd文件和.frm文件恢复时是不能被正确识别的，但可以通过以下命令：<br>ALTER TABLE tbl _name DISCARD TABLESPACE; ALTER TABLE tbl name IMPORT TABLESPACE;<br>将备份恢复到数据库中。<br>注意：即便在多表空间的存储方式下，共享表空间仍然是必须的，InnoDB把内部数据词典和在线<br>重做日志放在这个文件中。</p>
<p>≦ 126 ≧<br>108 第6章表类型（存储引擎）的选择 6.2.3 MEMORY<br>MEMORY存储引擎使用存在于内存中的内容来创建表。每个MEMORY表只实际对应一个磁盘文件，格式是.frm。MEMORY类型的表访问非常地快，因为它的数据是放在内存中的，并且默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失掉。<br>下面的例子创建了一个MEMORY的表，并从city表中获得记录： mysql&gt; CREATE TABLE tab_memory ENGINE&#x3D;MEMORY<br>SELECT city_id,city,country_id</p>
<blockquote>
<p>FROM city GROUP BY city_id;</p>
<p>Query ok, 600 rows affected (0.06 sec) Records: 600  Duplicates:0 warnings:0<br>mysql&gt; select count(<em>) from tab memory;<br>count（</em>） 1600<br>1row in set (0.00 sec)<br>mysql&gt; show table status like ‘tab memory’\G<br>Name:tab memory Engine: MEMORY<br>Version:10 Row format: Fixed<br>RoWs:600<br>Avg_row_length:155 Data 1ength:127040 Max_data 1ength:16252835<br>Index length:0 Data free:0<br>Auto_increment: NULL<br>Create_time:2018-05-2815:10:04<br>Update time: NULL Check time: NULL<br>Collation: gbk_chinese_ci Checksum:NULL<br>Create_options:<br>Comment:<br>1 row in set (0.00 sec)<br>给MEMORY表创建索引的时候，可以指定使用HASH索引还是BTREE索引： mysql&gt; create index mem hash usING HASH on tab_memory (city_id);<br>Query oK, 600 rows affected (0.04 sec) Records: 600 Duplicates:0 warnings:0<br>mysql&gt; SHOW INDEX FROM tab memory \G<br>Table: tab memory Non unique:1<br>Key name:mem hash Seq_in index:1<br>Column name:city_id<br>Collation: NULL Cardinality:300 Sub part: NULL<br>Packed:NULL Null:<br>Index type: HASH Comment:<br>1row in set (0.01 sec)<br>mysql&gt; drop index mem_hash on tab_memory;</p>
</blockquote>
<p>≦ 127 ≧<br>6.2各种存储引擎的特性 109<br>Query oK, 600 rows affected (0.04 sec) Records: 600 Duplicates:0 Warnings:0<br>mysql&gt; create index mem hash usING BTREE on tab memory (city id);<br>Query ok, 600 rows affected (0.03 sec) Records: 600 Duplicates:0 warnings:0<br>mysql&gt; SHOW INDEX FROM tab memory G<br>1.row<br>Table: tab_memory Non_unique : 1<br>Key_name : mem_hash Seq_in_index : 1<br>Column name:city_id<br>collation:A Cardinality:NULL Sub part: NULL<br>Packed: NULL Nu11:<br>Index type: BTREE Comment:<br>1row in set (o.00 sec)<br>在启动MySQL服务的时候使用–init-file选项，把INSERTINTO.SELECT或LOAD DATAINFILE这样的语句放人这个文件中，就可以在服务启动时从持久稳固的数据源装载表。<br>服务器需要足够的内存来维持所有在同一时间使用的MEMORY表，当不再需要 MEMORY表的内容之时，要释放被MEMORY表使用的内存，应该执行DELETEFROM或 TRUNCATETABLE，或者整个删除表（使用DROPTABLE操作）。<br>每个MEMORY表中可以放置的数据量的大小，受到max_heap_table_size系统变量的约束，这个系统变量的初始值是16MB，可以根据需要加大。此外，在定义MEMORY表的时候，可以通过MAX_ROWS子句指定表的最大行数。<br>MEMORY类型的存储引擎主要用于那些内容变化不频繁的代码表，或者作为统计操作的中间结果表，便于高效地对中间结果进行分析并得到最终的统计结果。对存储引擎为 MEMORY的表进行更新操作要谨慎，因为数据并没有实际写入到磁盘中，所以一定要对下次<br>重新启动服务后如何获得这些修改后的数据有所考虑。 6.2.4MERGE<br>MERGE存储引擎也被称为MRG_MyISAM，是一组MyISAM表的组合。这些MyISAM 表必须结构完全相同，MERGE表本身并没有数据，对MERGE类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的MyISAM表进行的。对于MERGE类型表的插人操作，是通过INSERT_METHOD子句定义插人的表，可以有3个不同的值，使用FIRST或LAST 值使得插入操作被相应地作用在第一个或最后一个表上，不定义这个子句或者定义为NO，表示不能对这个MERGE表执行插入操作。<br>可以对MERGE表进行DROP操作，这个操作只是删除MERGE的定义，对内部的表没有任何影响。<br>MERGE表在磁盘上保留两个文件，文件名以表的名字开始，一个.frm文件存储表定义，另一个.MRG文件包含组合表的信息，包括MERGE表由哪些表组成、插入新的数据时的依据。可以通过修改.MRG文件来修改MERGE表，但是修改后要通过FLUSHTABLES刷新。<br>下面是一个创建和使用MERGE表的示例。</p>
<p>≦ 128 ≧<br>110 第6章表类型（存储引擎）的选择<br>（1）创建3个测试表payment_2006、payment_2007和payment_all，其中payment_all是前两个表的MERGE表：<br>mysql&gt; create table payment 2006(<br>-&gt; country_id smallint,-&gt; payment date datetime,-&gt;amount DECIMAL（15,2)，<br>-&gt;KEY idx fk country_id (country_id)-&gt;）engine&#x3D;myisam;<br>Query ok, 0 rows affected (0.03 sec) mysql&gt; create table payment 2007(</p>
<blockquote>
<p>country_id smallint,-&gt;payment date datetime,-&gt;amount DECIMAL（15,2),<br>-&gt;KEY idx_fk country_id (country_id)-&gt;）engine&#x3D;myisam;<br>Query oK,0 rows affected (0.02 sec) mysql&gt; CREATE TABLE payment all(<br>-&gt; country_id smallint,-&gt;payment date datetime，-&gt;amount DECIMAL（15,2)-&gt;INDEx(country_id)<br>-&gt;）engine&#x3D;merge union&#x3D;(payment 2006,payment 2007） INSERT METHOD&#x3D;LAST; Query Ok,0 rows affected (0.04 sec)<br>（2）分别向payment_2006和payment_2007表中插入测试数据：<br>mysql&gt; insert into payment 2006 values(1,2006-05-01′,100000),(2,2006-08-15′,150000);<br>Query ok,2 rows affected (0.o0 sec) Records:2Duplicates:0 warnings:0<br>mysql&gt; insert into payment 2007 values（1,2007-02-20′,35000),(2,2007-07-15′,220000);<br>Query ok,2 rows affected (o.o0 sec) Records:2Duplicates:0 warnings:0<br>（3）分别查看这3个表中的记录： mysql&gt; select *from payment 2006;<br>I country id I payment date I amount<br>11 12006-05-0100:00:00 100000.00<br>12006-08-1500:00:00 150000.00<br>2rows in set (0.00 sec)<br>mysql&gt; select * from payment 2007;<br>Icountry_id | payment date amount<br>1 2007-02-20 00:00:00 35000.00 2 2007-07-15 00:00:00 220000.00<br>2rows in set (o.00 sec)<br>mysql&gt; select * from payment all;<br>country_id | payment date Iamount<br>2006-05-01 00:00:00 100000.00<br>2 2006-08-1500:00:00 150000.00<br>2007-02-20 00:00:00 135000.00 2007-07-1500:00:001220000.00<br>4rows in set (0.00 sec)<br>可以发现，payment_all表中的数据是payment_2006和payment_2007表的记录合并后的</p>
</blockquote>
<p>≦ 129 ≧<br>6.2各种存储引擎的特性 111<br>结果集。<br>下面向MERGE表中插人一条记录，由于MERGE表的定义是INSERT_METHOD&#x3D;LAST，就会向最后一个表中插人记录，所以虽然这里插人的记录是2006年的，但仍然会写到 payment_2007表中。<br>mysql&gt; insert into payment a11 values(3,’2006-03-31′,112200);<br>Query ok,1 row affected (0.00 sec) mysql&gt; select * from payment all;<br>|country_id | payment date Iamount<br>2006-05-0100:00:001100000.00<br>12 2006-08-15 00:00:00 1150000.00<br>2007-02-2000:00:00 135000.00 2007-07-1500:00:00 220000.00<br>13 12006-03-31 00:00:001112200.00 5rows in set (o.00 sec)<br>mysql&gt; select *from payment_2007;<br>Icountry_id dI payment date<br>|2007-02-20 00:00:00 35000.00 2007-07-15 00:00:00 220000.00 12006-03-3100:00:001112200.00<br>3 rows in set (0.00 sec)<br>这也是MERGE表和分区表的区别，MERGE表并不能智能地将记录写到对应的表中，而分区表是可以的（分区功能在5.1版中正式推出，经过多个版本的更新，目前已经比较完善）。通常我们使用MERGE表来透明地对多个表进行查询和更新操作，而对这种按照时间记录的<br>操作日志表则可以透明地进行插入操作。 6.2.5TokuDB<br>前面介绍的都是MySQL自带的存储引擎，除了这些之外，还有一些常见的第三方存储引擎，在某些特定应用中也有广泛使用，比如列式存储引擎Infobright以及高写性能、高压缩的TokuDB就是其中非常有代表性的两种。本节将简单介绍TokuDB。<br>TokuDB是一个高性能、支持事务处理的存储引引擎，在MySQL5.6版本之前，可以安装到MySQL和MariaDB中，被Percona公司收购之后，目前最新版本可以在PerconaServerfor MySQL之中使用。TokuDB存储引擎具有高扩展性、高压缩率、高效的写入性能，支持大多数在线DDL操作。最新版本已经开源，读者可以从Percona官方网站中进行下载和安装(<a target="_blank" rel="noopener" href="https://www.percona.com/software/mysql-database/percona-server/">https://www.percona.com/software/mysql-database/percona-server/</a>)<br>针对TokuDB存储引擎的主要特性，Tokutek网站公布了这款优秀存储引擎与经典的 InnoDB存储引引擎的对比结果，如图6-1所示。由于本书内容以MySQL社区版为主，因此下面的内容是针对MySQL5.6和其对应的TokuDB版本。<br>通过对比，可以看出TokuDB主要有以下几项特性：<br>O使用Fractal树索引保证高效的插入性能；优秀的压缩特性，比InnoDB高近10倍；<br>OHotSchema Changes 特性支持在线创建索引和添加、删除属性列等DDL操作；</p>
<p>≦ 130 ≧<br>112 第6章表类型（存储引擎）的选择<br>使用BulkLoader达到快速加载大量数据；<br>提供了主从延迟消除技术；支持ACID和MVCC。<br>TokuDB vs.InnoDB<br>InnoDB TokuDB<br>Index Type FractalTrendex[]<br>10000s&#x2F;second（me]<br>No（h+）<br>No(hs+) Yes（secs to mins） Lmare<br>es<br>NO<br>(mo]<br>Mutiple[mcre] Yes[]<br>图6-1TokuDB与InnoDB的比较<br>关于TokuDB最新各特性的具体性能测试数据，读者可以从Percona网站获得(<a target="_blank" rel="noopener" href="https://www.percona.com/doc/percona-server/LATEST/index.html">https://www.percona.com/doc/percona-server/LATEST/index.html</a>)<br>通过上面的介绍，可以发现TokuDB特别适用以下几种场景：日志数据，因为日志通常插入频繁且存储量大；<br>。历史数据，通常不会再有写操作，可以利用TokuDB的高压缩特性进行存储；在线DDL较频繁的场景，使用TokuDB可以大大增加系统的可用性。<br>6.3如何选择合适的存储引擎<br>在选择存储引擎时，应根据应用特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。<br>下面是几种常用的存储引擎的适用环境。<br>OMyISAM：MySQL5.5之前版本默认的存储引擎。如果应用是以读操作和插入操作为主，只有极少的更新和删除操作，并且对事务的完整性没有要求、没有并发写操作，那么选择这个存储引擎是适合的。OLTP环境一般建议不要再使用MyISAM。<br>OInnoDB:MySQL5.5之后版本的默认存储引擎，用于事务处理应用程序，支持外键。对于大多数的应用系统，InnoDB都是合适的选择。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性。数据操作除了插入和查询以外，还包括很多的更新、删除操作，那么应该优先选择InnoDB存储引擎。InnoDB存储引擎除了有效地降低由于删除和更新导致的锁定，还可以确保事务的完整提交（Commit）和回滚（Rollback）。<br>OMEMORY：将所有数据保存在RAM中，在需要快速定位记录和其他类似数据的环境下，可提供极快的访问速度。MEMORY的缺陷是对表的大小有限制，太大的表无法缓存在内存中，其次是要确保表的数据可以恢复，数据库异常终止后表中的数据是可以恢复的。</p>
<p>≦ 131 ≧<br>6.4小结 113<br>MEMORY表通常用于更新不太频繁的小表，用以快速得到访问结果。<br>OMERGE：用于将一系列等同的MyISAM表以逻辑方式组合在一起，并作为一个对象引用它们。MERGE表的优点在于可以突破对单个MyISAM表大小的限制，并且通过将不同的表分布在多个磁盘上，可以有效地改善MERGE表的访问效率。这对于诸如数据仓储等 VLDB环境十分适合。<br>注意：以上只是我们按照实施经验提出的关于存储引擎选择的一些建议，但是不同应用的特点是<br>千差万别的。选择使用哪种存储引擎才是最佳方案也不是绝对的，这需要根据用户各自的应用进行测试，从而得到最适合自己的结果。<br>6.4小结<br>本章重点介绍了MySQL提供的几种主要的存储引擎及其使用特性，以及如何根据应用的需要选择合适的存储引擎。这些存储引擎有各自的优势和适用的场合，正确地选择存储引擎对改善应用的效率可以起到事半功倍的效果。<br>正确地选择了存储引擎之后，还需要正确选择表中的数据类型。第7章将详细介绍如何选择合适的数据类型。</p>
<p>≦ 132 ≧<br>第7章 选择合适的数据类型<br>在使用MySQL创建数据表时都会遇到一个问题，即如何为字段选择合适的数据类型。例如，创建一张员工表用来记录员工的信息，这时对员工的各种属性如何来进行定义？也许读者会想，这个问题很简单，每个字段可以使用很多种数据类型来定义，比如int、float、double、 decimal等。其实正因为可选择的数据类型太多，才需要依据一些原则来“挑选”最适合的数<br>据类型。本章将详细介绍字符、数值、日期数据类型的一些选择原则。 7.1 CHAR 与 VARCHAR<br>CHAR和VARCHAR类型类似，都用来存储字符串，但它们保存和检索的方式不同。CHAR 属于固定长度的字符类型，而VARCHAR属于可变长度的字符类型。<br>表7-1显示了将各种字符串值保存到CHAR（4)和VARCHAR（4)列后的结果，说明了CHAR 和VARCHAR之间的差别。<br>表7-1 CHAR和VARCHAR的对比值 CHAR(4) 存储需求 VARCHAR(4) 存储需求<br>4个字节 1个字节<br>‘ab’’ab’ 4个字节’ab’ 3个字节’abcd’’abcd’ 4个字节’abcd’ 5个字节’abcdefgh’’abcd’ 4个字节’abcd’ 5个字节<br>注意表7-1中最后一行的值只适用MySQL运行在非“严格模式”时，如果MySQL运行在严格模式，超过列长度的值将不会保存，并且会出现错误提示。关于“严格模式”，将在第 13章中详细介绍。VARCHAR（4)列显示的存储需求比实际字符长度多1是因为VARCHAR类型要用一到两个字节来记录字节长度，如果数据位占用字节数小于255时，用一个字节记录；大于255时，用两个字节记录。<br>从CHAR(4)和VARCHAR(4)列检索的值并不总是相同，因为检索时从CHAR列删除了尾部的空格。下面通过一个例子来说明该差别：<br>mySq1&gt; CREATE TABLE VC (V VARCHAR(4),c CHAR(4); Query ok,0 rows affected (0.o2 sec)<br>mysql&gt; INSERT INTO Vc VALUES （’ab,’ab）;</p>
<p>≦ 133 ≧<br>7.2TEXT与BLOB 115<br>Query oK,1 row affected (0.00 sec)<br>mysq1&gt;SELECT CONCAT(v,+’),CONCAT(c,+’）FROMVC; 1CONCAT(V,+’)ICONCAT(C,+’）<br>Iab+ l ab+ 1 row in set (o.00 sec)<br>由于CHAR是固定长度的，所以它的处理速度比VARCHAR快，但是其缺点是浪费存储空间，程序需要对行尾空格进行处理，所以对于那些长度变化不大并且对查询速度有较高要求的数据可以考虑使用CHAR类型来存储。<br>在使用VARCHAR类型的时候，不能因为VARCHAR类型长度可变就都为VARCHAR 定义一个很大的长度，仍然需要按需定义长度，定义一个远超实际需求长度的VARCHAR字段可能影响应用程序的效率，并且有更大的概率触发MySQL在VARCHAR上存在的一些 BUG.<br>在MySQL中，不同的存储引擎对CHAR和VARCHAR的使用原则有所不同，这里简单概括如下。<br>MyISAM存储引擎：建议使用固定长度的数据列代替可变长度的数据列。<br>OMEMORY存储引擎：目前都使用固定长度的数据行存储，因此无论使用CHAR或 VARCHAR列都没有关系，两者都是作为CHAR类型处理。<br>OInnoDB存储引擎：建议使用VARCHAR类型。对于InnoDB数据表，内部的行存储格式没有区分固定长度和可变长度列（所有数据行都使用指向数据列值的头指针），因此在本质上，使用固定长度的CHAR列不一定比使用可变长度VARCHAR列性能要好。因而，主要的性能因素是数据行使用的存储总量。由于CHAR平均占用的空间多于VARCHAR，因此使<br>用VARCHAR来最小化需要处理的数据行的存储总量和磁盘I&#x2F;O是比较好的。 7.2TEXT与BLOB<br>一般在保存少量字符串的时候，我们会选择CHAR或者VARCHAR；而在保存较大文本时，通常会选择使用TEXT或者BLOB。二者之间的主要差别是BLOB能用来保存二进制数据，比如照片；而TEXT只能保存字符数据，比如一篇文章或者日记。TEXT和BLOB中又分别包括TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT和TINYBLOB、BLOB、 MEDIUMBLOB、LONGBLOB等不同的类型，它们之间的主要区别是存储文本长度不同和存储字节不同，用户应该根据实际情况选择能够满足需求的最小存储类型。本节主要对BLOB 和TEXT存在的一些常见问题进行介绍。<br>（1）BLOB和TEXT值会引起一些性能问题，特别是在执行大量的删除操作时。<br>删除操作会在数据表中留下很大的“空洞”，以后填入这些“空洞”的记录在插人的性能上会有影响。为了提高性能，建议定期使用OPTIMIZETABLE功能对这类表进行碎片整理，避免因为“空洞”导致性能问题。<br>下面的例子描述了OPTIMIZETABLE的碎片整理功能。首先创建测试表t，字段id和 context的类型分别为varchar(100)和text：<br>mysql&gt; create table t （id varchar(100),context text); Query ok, 0 rows affected (0.01 sec)</p>
<p>≦ 134 ≧<br>116 第7章选择合适的数据类型<br>然后往t中插入大量记录，这里使用repeat函数插入大量字符串：<br>mysql&gt; insert into t values(1,repeat(‘haha,100)); Query ok,1 row affected (0.o0 sec)<br>mysql&gt; insert into t values(2,repeat(‘haha′,100)); Query ok,1 row affected (o.o0 sec)<br>mysql&gt; insert into t values(3,repeat(‘haha′,100));<br>Query ok,1 row affected (0.o0 sec) mysql&gt; insert into t select * from t; mysql&gt; insert into t select * from t;<br>Query ok, 196608 rows affected (4.86 sec) Records:196608 Duplicates:0warnings:0<br>mysql&gt; exit<br>退出到操作系统下，查看表t的物理文件大小：[root@hz 10 120_240 251 employees]s du -sh t.*<br>12Kt.frm 155Mt.ibd<br>这里数据文件显示为155MB。从表t中删除id为“1”的数据，这些数据占总数据量的1&#x2F;3： mysql&gt; delete from t where id&#x3D;l;<br>Query 0K,131072 rows affected (4.33 sec)<br>再次退出到操作系统下，查看表t的物理文件大小：[root@hz_10 120_240_251 employees]s du -sh t.<br>12kt.frm 155Mt.ibd<br>可以发现，表t的数据文件仍然为155MB，并没有因为数据删除而减少。接下来对表进<br>行OPTIMIZE（优化）操作： mysql&gt; OPTIMIZE TABLE t\G<br>Table: employees.t op:optimize<br>Msg type:note<br>Msg_text: Table does not support optimize, doing recreate + analyze instead<br>Table:employees.t op:optimize<br>Msg.type: status Msg_text:oK<br>2rows in set (2.09 sec)<br>再次查看表t的物理文件大小：<br>[root@hz 10 120 240 251 emp1oyees]s du -sh t.*<br>12kt.frm 104Mt.ibd<br>可以发现，表的数据文件大大缩小，“空洞”空间已经被回收。另外，注意到，对于InnoDB 引擎，OPTIMIZE语句被自动转换为recreate+analyze语句。<br>（2）可以使用合成的（Synthetic）索引来提高大文本字段（BLOB或TEXT）的查询性能。简单来说，合成索引就是根据大文本字段的内容建立一个散列值，并把这个值存储在单<br>独的数据列中，接下来就可以通过检索散列值找到数据行了。但是，要注意这种技术只能用于精确匹配的查询（散列值对于类似“&lt;”或“&gt;&#x3D;”等范围搜索操作符是没有用处的）。<br>可以使用MD5O函数生成散列值，也可以使用SHA10或CRC32O，或者使用自己的应用</p>
<p>≦ 135 ≧<br>7.2TEXT与BLOB 117<br>程序逻辑来计算散列值。请记住数值型散列值可以高效率地存储。<br>同样，如果散列算法生成的字符串带有尾部空格，就不要把它们存储在CHAR字段中，而是使用VARCHAR字段，因为CHAR字段会受到尾部空格去除的影响。合成的散列索引I对于那些BLOB或TEXT数据列特别有用。用散列标识符值查找的速度比搜索BLOB列本身的速度快很多。<br>下面通过实例介绍一下合成索引的使用方法。首先创建测试表t，字段id、context、hash_ value字段类型分别为varchar(100)、blob、varchar(40)，并且在hash_value列上创建索引：<br>mysq1&gt; create table t （id varchar(100),context b1ob,hash value varchar(40)); Query ok,O rows affected (o.03 sec)<br>mysql&gt; create index idx hash value on t(hash_value);<br>Query ok,0 rows affected (o.04 sec) Records:ODuplicates:O warnings:0<br>然后往t中插入测试数据，其中hash_value用来存放context列的MD5散列值：<br>mysql&gt; insert into t values(1,repeat（’beijing,2),md5(context)); Query ok,1 row affected (0.o0 sec)<br>mysq1&gt; insert into t values(2,repeat(‘beijing’,2),md5（context)); Query ok,1 row affected (0.00 sec)<br>mysq1&gt; insert into t values(3,repeat(‘beijing 2008,2),md5（context));<br>Query ok,1 row affected (0.o0 sec) mysql&gt; select * from t;<br>id context Ihash_value<br>beijingbeijing 109746eef633dbbccb7997dfd795cff17 beijingbeijing 109746eef633dbbccb7997dfd795cff17 1 beijing 2008beijing 2008 1 1c0ddb82cca9ed63e1cacbddd3f74082<br>3 rows in set (o.o0 sec)<br>如果要查询context值为“beijing2008beijing2008”的记录，则可以通过相应的散列值来查询：<br>mysql&gt; select * from t where hash value&#x3D;md5(repeat(‘beijing 2008’,2));<br>id context Ihash_value<br>beijing 2008beijing 2008 1 1c0ddb82cca9ed63e1cacbddd3f740821<br>1row in set (0.00 sec)<br>上面的例子展示了合成索引的用法，由于这种技术只能用于精确匹配，在一定程度上减少了I&#x2F;O，从而提高了查询效率。如果需要对BLOB或者CLOB字段进行模糊查询，MySQL<br>提供了前缀索引，也就是只为字段的前n列创建索引，举例如下： mysql&gt; create index idx blob on t(context(100));<br>Query ok,0rows affected (o.o4 sec) Records:ODuplicates:0 warnings:0<br>mysql&gt; desc select * from t where context like beijing%’ G<br>id:1<br>select type: SIMPLE<br>table:t partitions: NULL<br>type : ALL<br>possible keys : idx blob<br> key : NULL key_len: NULL ref:NULL</p>
<p>≦ 136 ≧<br>118 第7章选择合适的数据类型<br>rows:3<br>filtered:100.00<br>Extra: using where<br>1 row in set, 1 warning (0.o0 sec)<br>可以发现，对context前100个字符进行模糊查询，就可能用到前缀索引。注意，由于这个表只有3行数据，虽然索引可用，但优化器最终并没有选择使用索引，关于索引是否被使用的更多内容，将会在后面的章节中介绍。另外，这里的查询条件中，“%”不能放在最前面，否则索引将不会被使用。<br>（3）在不必要的时候避免检索大型的BLOB或TEXT值。<br>例如，SELECT<em>查询就不是很好的想法，除非能够确定作为约束条件的WHERE子句只会找到所需要的数据行。否则，很可能毫无目的地在网络上传输大量的值。这也是BLOB 或TEXT标识符信息存储在合成的索引列中对用户有所帮助的例子。用户可以搜索索引列，决定需要哪些数据行，然后从符合条件的数据行中检索BLOB或TEXT值。<br>（4）把BLOB或TEXT列分离到单独的表中。<br>在某些环境中，确实有使用BLOB或TEXT类型的需求，这时建议将BLOB或TEXT类型的字段分离到单独的表中存储。这会减少主表中的碎片，显著减小主表的数据量从而获得性能优势，主数据表在运行SELECT</em>查询的时候也不会再需要通过网络传输大量的BLOB 或TEXT值。<br>例如，在user_info表中需要一个BLOB字段来保存用户的身份证图像信息，更好的做法是新建一个user_id_pic的表，包含user_id和id_pic两列，大多数的查询需求通过访问user_info 表就可以完成，只有需要访问身份证图像时候才关联user_id_pic表进行查询。<br>注意：尽可能在OLTP环境避免使用BLOB或者TEXT类型，优先使用VARCHAR。VARCHAR<br>类型最长可以支持65533字节的长度，已经可以满足绝大多数的需求。<br>7.3浮点数与定点数<br>浮点数一般用于表示含有小数部分的数值。当一个字段被定义为浮点类型后，如果插入数据的精度超过该列定义的实际精度，则插人值会被四舍五入到实际定义的精度值，然后插人，四舍五人的过程不会报错。在MySQL中，float和double（或real）用来表示浮点数。<br>定点数不同于浮点数，定点数实际上是以字符串形式存放的，所以定点数可以更精确地保存数据。如果实际插入的数值精度大于实际定义的精度，则MySQL会进行警告（默认的 SQLMode下），但是数据按照实际精度四舍五人后插人；如果SQLMode是在TRADITIONAL（传统模式）下，则系统会直接报错，导致数据无法插人。在MySQL中，decimal（或numberic）用来表示定点数。<br>在简单了解了浮点数和定点数的区别之后，来看一个例子，回顾一下前面讲到的浮点数精确性问题。<br>mysql&gt; create table t（f float（ 8,1）); Query ok,0 rows affected (o.03 sec)<br>mysql&gt; desc t;<br>|Field 丨 Type |Null l Key| Default I Extra|<br>1float(8,1)1YES</p>
<p>≦ 137 ≧<br>7.3浮点数与定点数 119<br>1 row in set (o.00 sec)<br>mysql&gt; insert into t values (1.23456); Query ok, 1 row affected (0.00 sec)<br>mysql&gt; select * from t; 11.21<br>1 row in set (o.o0 sec)<br>mysql&gt; insert into t values (1.25456); Query ok, 1 row affected (0.o0 sec)<br>mysql&gt; select * from t; If<br>11.21 11.31<br>2 rows in set (o.o0 sec)<br>从上面的例子中，可以发现对于第一次插人值1.23456到float（8,1）时，该值被截断，并保存为1.2，而第二次插人值1.25456到float（8,1）时，该值进行了四舍五入然后被截断，并保存为1.3，所以在选择浮点型数据保存小数时，要注意四舍五人的问题，并尽量保留足够的小数位，避免存储的数据不准确。<br>为了能够让读者了解浮点数与定点数的区别，再来看一个例子：<br>mysq1&gt; CREATE TABLE test (c1 float(10,2),c2 decima1(10,2)); Query oK,0rows affected (0.29 sec)<br>mysql&gt; insert into test values(131072.32,131072.32);<br>Query ok, 1 row affected (0.07 sec) mysql&gt; select * from test;<br>cl 1c2<br>1131072.311131072.321 1 row in set (o.00 sec)<br>从上面的例子中可以看到，c1列的值由131072.32变成了131072.31，这是上面的数值在使用单精度浮点数表示时，产生了误差。这是浮点数特有的问题。因此在精度要求比较高的应用中（比如货币）要使用定点数而不是浮点数来保存数据。<br>另外，浮点数的比较也是一个普遍存在的问题，下面的程序片断中对两个浮点数做减法运算：<br>public class Test<br>public static void main(string[] args) throws Exception<br>System.out.printc”7.22-7.0&#x3D;”+(7.22f-7.0f));<br>对上面Java程序的输出结果可能会想当然地认为是0.22，但是，实际结果却是7.22-7.0&#x3D; 0.21999979，因此，在编程中应尽量避免浮点数的比较。如果非要使用浮点数的比较，则最好使用范围比较，而不要使用“&#x3D;&#x3D;”比较。<br>下面使用定点数来实现上面的例子： import java.math.BigDecimal;</p>
<p>≦ 138 ≧<br>120 第7章选择合适的数据类型<br>*提供精确的减法运算。<br><em>@param v1</em>@paramv2<br>public class Test<br>public static void main(string[] args） throws Exception [<br>System.out.print(“7.22-7.0&#x3D;”+subtract(7.22,7.0)); public static double subtract(double v1,double v2)<br>BigDecimal bi &#x3D;new BigDecimal(Double.toString(v1)); BigDecimal b2&#x3D;new BigDecimal(Double.tostring（v2)); return bl.subtract(b2).doublevalueO;<br>上面的实例使用Java的BigDecimal类实现了定点数的精确计算，所以7.22减7.0的结果和预想的相同，为7.22-7.0&#x3D;0.22。<br>注意：在今后关于浮点数和定点数的应用中，用户要考虑到以下几个原则：<br>浮点数存在误差问题；<br>对货币等对精度敏感的数据，应该用定点数表示或存储；<br>在编程中，如果用到浮点数，要特别注意误差问题，并尽量避免做浮点数比较；要注意浮点数中一些特殊值的处理。<br>7.4日期类型选择<br>MySQL提供的常用日期类型有DATE、TIME、DATETIME和TIMESTAMP，它们之间的区别在第3章中已经进行过详细论述，这里就不再赘述。下面主要总结一下选择日期类型的原则。<br>○根据实际需要选择能够满足应用的最小存储的日期类型。如果应用只需要记录“年份”，那么用1个字节来存储的YEAR类型完全可以满足，而不需要用4个字节来存储的DATE 类型。这样不仅仅能节约存储，更能够提高表的操作效率。<br>如果要记录年月日时分秒，并且记录的年份比较久远，那么最好使用DATETIME，而不要使用TIMESTAMP。因为TIMESTAMP表示的日期范围比DATETIME要短得多。<br>如果记录的日期需要让不同时区的用户使用，那么最好使用TIMESTAMP，因为日<br>期类型中只有它能够和实际时区相对应。 7.5小结<br>本章主要介绍了常见数据类型的选择原则，简单归纳如下。对于字符类型，要根据实际需求来选择类型和长度。<br>对精度要求较高的应用中，建议使用定点数来存储数值，以保证结果的准确性。<br>O尽可能减少使用TEXT和BLOB字段，对含有这两种字段的表，如果经常做删除和修改记录的操作，要定时执行OPTIMIZETABLE对表进行碎片整理。<br>●日期类型要根据实际需要选择能够满足应用的最小存储的日期类型。</p>
<p>≦ 139 ≧<br>第8章 字符集<br>从本质上来说，计算机只能识别二进制代码，因此，不论是计算机程序还是其处理的数据，最终都必须转换成二进制码，计算机才能认识。为了使计算机不仅能做科学计算，也能处理文字信息，人们想出了给每个文字符号编码，以便于计算机识别处理的办法，这就是计<br>算机字符集的由来。本章将详细介绍字符集的发展历程和MySQL中字符集的使用。 8.1字符集概述<br>简单地说，字符集就是一套文字符号及其编码、比较规则的集合。20世纪60年代初期，美国标准化组织ANSI发布了第一个计算机字符集—ASCII（AmericanStandardCodefor InformationInterchange），后来进一步变成了国际标准ISO-646。这个字符集采用7位编码，定义了包括大小写英文字母、阿拉伯数字和标点符号，以及33个控制符号等。虽然现在看来，这个美式的字符集很简单，包括的符号也很少，但直到今天它依然是计算机世界里奠基性的标准，其后制定的各种字符集基本都兼容ASCII字符集。<br>自ASCII之后，为了处理不同的文字，各大计算机公司、各国政府、标准化组织等先后发明了几百种字符集，如人们熟悉的ISO-8859系列、GB2312-80、GBK、BIG5等。这些五花八门的字符集，从收录的字符到编码规则各不相同，给计算机软件开发和移植带来了很大困难。一个软件要在使用不同文字的国家或地区发布，必须进行本地化开发！基于这个原因，<br>统一字符编码，成了20世纪80年代计算机业的迫切需要和普遍共识。 8.2Unicode 简述<br>为了统一字符编码，国际标准化组织（InternationalOrganizationforStandardization，ISO）的一些成员国于1984年发起制定新的国际字符集标准，以容纳全世界各种语言文字和符号。这个标准最后叫做“UniversalMultiple-OctetCodedCharacterSet”，简称UCS，标准编号则定为ISO-10646。ISO-10646标准采用4字节（32bit）编码，因此简称UCS-4。<br>具体编码规则是：将代码空间划分为组（group）面（plane）行（row）和格（ceil）；第一个字节代表组（group），第二个字节代表面（plane），第三个字节代表行（row），第四个字节代表格（ceil），并规定字符编码的第32位必须为0，且每个面（plane）的最后两个码位</p>
<p>≦ 140 ≧<br>122 第8章字符集<br>FFFEh和FFFFh保留不用；因此，ISO-1064共有128个群组（0～0x7F），每个群组有256个字面（00～0xFF），每个字面有256行（00<del>0xFF），每行包括256格（0</del>0xFF），共有 256×128&#x3D;32768个字面，每个字面有256×256-2&#x3D;65534个码位，合计65534×32768&#x3D; 2147418112个码位。<br>ISO-10646发布以后，遭到了部分美国计算机公司的反对。1988年Xerox公司提议制定新的以16位编码的统一字符集Unicode，并联合Apple、IBM、DEC、Sun、Microsoft、Novell 等公司成立Unicode协会（TheUnicodeConsortium），并成立Unicode技术委员会（Unicode TechnicalCommittee），专门负责Unicode文字的搜集、整理和编码，并于1991年推出了 Unicode 1.0<br>都是为了解决字符编码统一问题，ISO和Unicode协会却推出了两个不同的编码标准，这显然是不利的。后来，大家都认识到了这一点，经过双方谈判，1991年10月达成协议，ISO 将Unicode编码并人ISO-10646的0组0字面，称之为基本多语言文字面（BasicMulti-lingual Plane，BMP），共有65534个码位，并根据不同用途分为若干区域。<br>除BMP外的32767个字面又分为辅助字面（SupplementaryPlane）和专用字面（PrivateUse Plane）两部分，辅助字面用以收录ISO-10646后续搜集的各国文字，专用字面供使用者自定义收录ISO-10646未收录的文字符号。<br>其实，大部分用户使用BMP字面就足够了，早期的ISO-10646-1标准也只要求实现BMP 字面，这样只需要2字节来编码就足够了，Unicode也正是这么做的，这叫做ISO-10646编码的基本面形式，简称为UCS-2编码。UCS-2编码转换成UCS-4编码也很容易，只要在前面加两个取值为0的字节即可。<br>ISO-10646的编码空间足以容纳人类从古至今使用过的所有文字和符号，但其实许多文字符号都已经很少使用了，超过99%的在用文字符号都编入了BMP，因此，绝大部分情况下， Unicode的双字节编码方式都能满足需求，而这种双字节编码方式比起ISO-10646的4字节原始编码来说，在节省内存和处理时间上都具有优势，这也是Unicode编码方式更流行的原因。<br>但如果万一要使用ISO-10646BMP字面以外的文字怎么办呢？Unicode提出了名为 UTF-16或代理法（Surrogates）的解决方案。UTF是UCS&#x2F;UnicodeTransformationFormat的缩写。UTF-16的解决办法是：对BMP字面的编码保持2字节不变，对其他字面的文字按一定规则将其32位编码转换为两个16位的Unicode编码，其两个字节的取值范围分别限定为 0xD800<del>0xDBFF和0xDC00</del>0xDFFF，因此，UTF-16共有（4×256）×（4×256）&#x3D;1048576 个码位。<br>虽然UTF-16解决了ISO-10646除BMP外第1～15字面的编码问题，但当时的计算机和网络世界还是ASCII的天下，只能处理单字节数据流，UTF-16离开Unicode环境后，在传输和处理中都存在问题。<br>于是Unicode又提出了名为UTF-8的解决方案，UTF-8按一定规则将一个ISO-10646或 Unicode字元码转换成1～4个字节的编码，其中将ASCⅡI码（0～0x7F）转换成单字节编码，也就是严格兼容ASCII字符集；UTF-8的2字节编码，用于转换ISO-10646标准0x0080~ 0x07FF的UCS-4原始码；UTF-8的3字节编码，用于转换ISO-10646标准0x0800<del>0xFFFF 的UCS-4原始码；UTF-8的4字节编码，用于转换ISO-10646标准0x00010000</del>0001FFFF 的UCS-4原始码。</p>
<p>≦ 141 ≧<br>8.3汉字及一些常见字符集 123<br>上述各种编码方式，看起来有点让人迷惑。其实，ISO-10646只是给每一个文字符号分配了一个4字节无符号整数编号（UCS-4），并未规定在计算机中如何去表示这个无符号整数编号。UTF-16和UTF-8就是其两种变通表示方式。<br>ISO-10646与Unicode统一以后，两个组织虽然都继续发布各自的标准，但两者之间是一致的。由于Unicode最早投入应用，其编码方式更加普及，因此，许多人都知道Unicode，但对ISO-10646却了解不多。但由于两者是一致的，因此，区分ISO-10646和Unicode的意义也就不大了。现在，人们说Unicode和ISO-10646，一般指的是同一个东西，只是Unicode更直接、更普及罢了。两者不同版本的对应关系如下：<br>OUnicode2.0等同于ISO&#x2F;IEC10646-1:1993; OUnicode 3.0 等同于ISO&#x2F;IEC 10646-1:2000; OUnicode 4.0等同于ISO&#x2F;IEC10646:2003。<br>最后要说的是，UTF-16和UTF-32因字节序的不同，又有了UTF-16BE（BigEndian） UTF-16LE（Little Endian）和UTF-32BE（BigEndian）、UTF-32LE（Little Endian）等，在此不做进一步介绍。<br>8.3汉字及一些常见字符集<br>在计算机发展的不同阶段，我国也参照当时的国际标准和实际需要，制定了一些汉字字符集编码标准，主要内容如下。<br>OGB2312-80：全称《信息交换用汉字编码字符集基本集》，于1980年发布。根据 ISO&#x2F;IEC2022提供的字符编码扩充规范，形成双字节编码的字符集，收录了6763个常用汉字和682个非汉字图形符号。<br>OGB13000：全称《信息技术通用多八位编码字符集（UCS）第一部分：体系结构与基本多文种平面》，于1993年发布。根据ISO&#x2F;IEC10646-1:1993，在CJK（中、日、韩简称）统一汉字区和CJK统一汉字扩充区A，除收录GB2312-80外，还收录了第1、3、5、7辅助集的全部汉字，共27484个，以及一些偏旁部首等。但GB13000推出后，几乎没有得到业界的支持，也就成了一个形式上的标准。<br>OGBK：全称《汉字内码扩展规范》1.0版，发布于1995年。GBK在GB2312内码系统的基础上进行了扩充，收录了GB13000.1-1993的全部20902个CJK统一汉字，包括GB2312 全部的6763个汉字。此外，它增补编码了52个汉字，13个汉字结构符（在ISO&#x2F;IEC10646.1:2000 中称为表意文字描述符）和一些常用部首与汉字部件。在GBK的内码系统中，GB2312汉字所在码位保持不变，这样，保证了GBK对GB2312的完全兼容。同时，GBK内码与GB13000.1 代码一一对应，为GBK向GB13000.1的转换提供了解决办法。有意思的是，GBK并不是一个强制性的国家标准，只是一个行业指导规范，并没有强制力，但由于得到了Microsoft Windows95的支持而大为流行。<br>OGB18030:全称《信息技术信息交换用汉字编码字符集、基本集的扩充》，发布于2000 年。根据ISO&#x2F;IEC10646-1:2000，收录了ISO&#x2F;IEC10646.1:2000全部27484个CJK统一汉字， 13个表意文字描述符、部分汉字部首和部件、欧元符号等。GB18030采用2字节或4字节编码，其2字节编码部分与GBK保持一致，因此，GB18030是GBK的超集，也完全与GB13000</p>
<p>≦ 142 ≧<br>124 第8章字符集<br>向上兼容，制定GB18030也是为了解决GBK强制力不够的问题。<br>以上简要介绍了几种汉字字符集，下面将一些常用字符集的特点归纳如表8-1所示。表8-1 常用字符集比较<br>字符集是否定长 编码方式 其他说明 ACSII 是 单字节7位编码 最早的奠基性字符集<br>ISO-8859-1&#x2F;latin1 是 单字节8位编码 西欧字符集，经常被一些程序员用来转码 GB 2312-80 是双字节编码 早期标准，不推荐使用<br>GBK 是双字节编码 虽然不是国标，但支持的系统不少<br>GB18030 否 2字节或4字节编码 开始有一些支持，但数据库支持的还少见<br>UTF-32 是 4字节编码 UCS-4原始编码，目前很少采用 UCS-2 是 2字节编码 Windows2000内部用UCS-2<br>UTF-16 否 2字节或4字节编码 Java和WindowsXP&#x2F;NT等内部使用UTF-16<br>UTF-8 否 1~4字节编码互联网和UNIX&#x2F;Linux广泛支持的Unicode字符集；<br>MySQLServer也使用UTF-8。包含两个子集utf8和utf8mb4。<br>8.4怎样选择合适的字符集<br>对数据库来说，字符集更加重要，因为数据库存储的数据大部分都是各种文字，字符集对数据库的存储、处理性能，以及日后系统的移植、推广都会有影响。<br>MySQL5.7目前支持几十种字符集，包括UCS-2、UTF-16、UTF-16LE、UTF-32、UTF-8 等Unicode字符集。面对众多的字符集，我们该如何选择呢？<br>虽然没有一定之规，但在选择数据库字符集时，可以根据应用的需求，结合上面介绍的一些字符集的特点来权衡，主要考虑以下几方面的因素。<br>（1）满足应用支持语言的需求，如果应用要处理各种各样的文字，或者将发布到使用不同语言的国家或地区，就应该选择Unicode字符集。对MySQL来说，最常用的字符集就是 UTF-8。更严谨的说法是字符的编码规则是UTF-8，其中utf8mb3和utf8mb4是这种编码规则下最常用的两种字符集，后者是前者的超集。我们常说的utf8其实是utf8mb3的别名，其中的3表明这种字符集由1～3个字节组成。顾名思义，utf8mb4表明每个字符由1～4个字节组成，如果需要支持emoji表情，通常需要选择utf8mb4。随着互联网和手机应用的飞速发展，即使英文应用，也越来越多的需要utf8mb4的字符集来支持。在最新的MySQL8.0中，默认字符集已经由latin1变为utf8mb4。<br>（2）如果应用中涉及已有数据的导人，就要充分考虑数据库字符集对已有数据的兼容性。假如已有数据是GBK文字，如果选择GB2312-80为数据库字符集，就很可能出现某些文字无法正确导人的问题。<br>（3）如果数据库只需要支持一般中文，数据量很大，性能要求也很高，那就应该选择双字节定长编码的中文字符集，比如GBK。因为，相对于UTF-8而言，GBK比较“小”，每个汉字只占2个字节，而UTF-8（包括utf8和utf8mb4）汉字编码需要3个字节，这样可以减少磁盘I&#x2F;O、数据库Cache以及网络传输的时间，从而提高性能。相反，如果应用主要处理英文字符，仅有少量汉字数据，那么选择UTF-8更好，因为GBK、UCS-2、UTF-16的西文字符编码都是2个字节，会造成很多不必要的开销。</p>
<p>≦ 143 ≧<br>8.5MySQL支持的字符集简介 125<br>（4）如果数据库需要做大量的字符运算，如比较、排序等，那么选择定长字符集可能更好，因为定长字符集的处理速度要比变长字符集的处理速度快。<br>（5）如果所有客户端程序都支持相同的字符集，则应该优先选择该字符集作为数据库字<br>符集。这样可以避免因字符集转换带来的性能开销和数据损失。 8.5MySQL支持的字符集简介<br>MySQL服务器可以支持多种字符集，在同一台服务器、同一个数据库甚至同一个表的不同字段都可以指定使用不同的字符集，相比Oracle等其他数据库管理系统，在同一个数据库只能使用相同的字符集，MySQL明显存在更大的灵活性。<br>查看所有可用的字符集的命令是showcharacter set： mysql&gt; show character set;<br>charset I Description | Default collation Maxlen 1big5 1 Big5 Traditional chinese 1big5 chinese_ci 2 dec8 IDEC west European Idec8 swedish_ci 1<br>cp850 I Dos west European |cp850 general_ci |hp8 IHP West European 1hp8 english_ci<br>或者查看information_schema.character_set，可以显示所有的字符集和该字符集默认的排序规则。<br>mysql&gt; desc information_schema.character_sets;<br>|Field Type |Null |Key | Default 丨 Extra<br>|CHARACTER_SET_NAME varchar(32) NO IDEFAULT_COLLATENAME varchar(32)<br>DESCRIPTION varchar(60) NO 1MAXLEN 1bigint(3) 10<br>4rows in set (o.00 sec)<br>MySQL的字符集包括字符集（CHARACTER）和排序规则（COLLATION）两个概念。其中字符集用来定义MySQL存储字符串的方式，排序规则用来定义比较字符串的方式。字符集和排序规则是一对多的关系，MySQL支持30多种字符集的70多种排序规则。<br>每个字符集至少对应一个排序规则。可以用“SHOWCOLLATIONLIKE”***：”命令或者<br>通过系统表information_schema.COLLATIONS来查看相关字符集的排序规则。 mySql&gt; SHOW SHOW COLLATION LIKE utf8%’;<br>|Collation 1charset Id I Default | compiled | Sortlenl<br>一<br>|utf8_general ci |utf8 33 丨Yes Yes | utf8 bin utf8 83<br>排序规则命名约定：它们以其相关的字符集名开始，通常包括一个语言名，并且以_ci（大小写不敏感）、_cs（大小写敏感）或_bin（二元，即比较是基于字符编码的值而与language 无关）结束。<br>例如，上面例子中utf8的排序规则，其中utf8_general_ci是默认的排序规则，对大小写不敏感；而utf8_bin按照编码的值进行比较，对大小写敏感。</p>
<p>≦ 144 ≧<br>126 第8章字符集<br>下面的这个例子中，如果指定“A”和“a”按照utf8_general_ci排序规则进行比较，则认为两个字符是相同的，如果按照utf8_bin排序规则进行比较，则认为两个字符是不同的。我们事先需要确认应用的需求，是需要按照什么样的排序方式，是否需要区分大小写，以确定排序规则的选择。<br>mysql&gt; select case when ‘A’ coLLATE utf8 general ci &#x3D;’a’ collate utf8 general ci then 1 else 0 end as CaseInsensitive;<br>| CaseInsensitive|<br>1 row in set (o.00 sec)<br>mysql&gt; select case when ‘A’ coLLATE utf8 bin&#x3D;’a’collate utf8 bin then 1 else O end as CaseInsensitive;<br>|CaseInsensitive<br>01<br>1row in set (o.00 sec)<br>8.6MySQL字符集的设置<br>MySQL的字符集和排序规则有4个级别的默认设置：服务器级、数据库级、表级和字段<br>级。它们分别在不同的地方设置，作用也不相同。 8.6.1服务器字符集和排序规则<br>服务器字符集和排序规则，可以在MySQL服务启动的时候确定。<br>可以在my.cnf中设置：[mysq1d]<br>character-set-server&#x3D;utf8<br>或者在启动选项中指定：<br>mysgld–characterset-server&#x3D;utf8<br>或者在编译时指定：<br>shell&gt; Cmake-DDEFAULT CHARSET&#x3D;utf8<br>如果没有特别的指定服务器字符集，那么在MySQL5.7中默认使用latin1作为服务器字符集。上面3种设置的方式都只指定了字符集，没有指定排序规则，这样意味着使用该字符集默认的排序规则。如果要使用该字符集的非默认排序规则，则需要在指定字符集的同时指定排序规则。<br>注意：在最新的MySQL8.0中，默认字符集已经变为utf8mb4。<br>可以用“showvariableslikecharacter_set_server;；”命令查询当前服务器的字符集和排序规则。<br>mysql&gt; show variables like *character_set server’;<br>Ivariable name 1 Value | | character_set server |utf8</p>
<p>≦ 145 ≧<br>8.6MySQL字符集的设置 127<br>1 row in set (0.00 sec)<br>mysql&gt; show variables like collation server’; variable name value<br>|collation server l utf8 unicode ci 1 row in set (0.00 sec)<br>8.6.2数据库字符集和排序规则<br>数据库的字符集和排序规则既可以在创建数据库的时候指定，也可以在创建完数据库后通过“alterdatabase”命令进行修改。需要注意的是，如果数据库里已经存在数据，因为修改字符集并不能将已有的数据按照新的字符集进行存放，所以不能通过修改数据库的字符集直接修改数据的内容。8.7节会通过一个具体的例子介绍字符集的修改方法。<br>设置数据库字符集的规则如下：<br>如果指定了字符集和排序规则，则使用指定的字符集和排序规则；<br>如果指定了字符集没有指定排序规则，则使用指定字符集的默认排序规则；<br>●如果指定了排序规则但未指定字符集，则字符集使用与该排序规则关联的字符集；如果没有指定字符集和排序规则，则使用服务器字符集和排序规则作为数据库的字<br>符集和排序规则。<br>推荐在创建数据库时明确指定字符集和排序规则，避免受到默认值的影响。要显示当前数据库的字符集和排序规则，可以使用“showvariables like’character_set_database”和“show variableslike’collation_database”命令查看：<br>mysql&gt; show variables likecharacter_set database’；<br>Ivariable name 1value<br>Icharacter_set database Iutf8 1row in set (o.00 sec)<br>mysql&gt; show variables like ‘collation database’;<br>1 variable name |value<br>Icollation database utf8_unicode_ci 1 row in set (o.00 sec)<br>8.6.3表字符集和排序规则<br>表的字符集和排序规则在创建表的时候指定，可以通过altertable命令进行修改，同样，如果表中已有记录，修改字符集对原有的记录并没有影响，不会按照新的字符集进行存放。表的字段仍然使用原来的字符集。<br>设置表的字符集的规则和上面基本类似：<br>●如果指定了字符集和排序规则，使用指定的字符集和排序规则；<br>●如果指定了字符集没有指定排序规则，使用指定字符集的默认排序规则；</p>
<p>≦ 146 ≧<br>128 第8章字符集<br>如果指定了排序规则但未指定字符集，则字符集使用与该排序规则关联的字符集； ○如果没有指定字符集和排序规则，使用数据库字符集和排序规则作为表的字符集和<br>排序规则。<br>推荐在创建表的时候明确指定字符集和排序规则，以避免受到默认值的影响。要显示表<br>的字符集和排序规则，可以使用showcreatetable命令查看： mysql&gt; show create table person\G<br>*1row<br>Table: person<br>Create Table: CREATE TABLE perSon（<br>idsmallint(5) unsigned NOT NULL AUTO INCREMENT, name char(6O) coLLATE utf8 unicode ci NOT NULL, PRIMARY KEY（id)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci 1 row in set (0.00 sec)<br>8.6.4列字符集和排序规则<br>MySQL可以定义列级别的字符集和排序规则，主要是针对相同的表不同字段需要使用不同的字符集的情况，应该说一般遇到这种情况的概率比较小，这只是MySQL提供给我们一个灵活设置的手段。<br>列字符集和排序规则的定义可以在创建表时指定，或者在修改表时调整。如果在创建表<br>的时候没有特别指定字符集和排序规则，则默认使用表的字符集和排序规则。 8.6.5连接字符集和排序规则<br>上面4种设置方式，确定的是数据保存的字符集和排序规则，对于实际的应用访问来说，还存在客户端和服务器之间交互的字符集和排序规则的设置。<br>对于客户端和服务器的交互操作，MySQL提供了3个不同的参数：character_set_client、 character_set_connection和character_setresults，分别代表客户端、连接和返回结果的字符集。通常情况下，这3个字符集应该是相同的，才可以确保用户写入的数据可以正确地读出，特别是对于中文字符，不同的写入字符集和返回结果字符集将导致写入的记录不能正确读出。<br>通常情况下，不会单个地设置这3个参数，可以通过以下命令： SET NAMES ***；<br>来设置连接的字符集和排序规则，这个命令可以同时修改这3个参数的值。使用这个方法修改连接的字符集和排序规则，需要应用每次连接数据库后都执行这个命令。<br>另一个更简便的办法，是在my.cnf中设置以下语句：[mysq1]<br>default-character-set&#x3D;utf8<br>这样服务器启动后，所有连接默认就是使用utf8字符集进行连接的，而不需要在程序中再执行setnames命令。另外，字符串常量的字符集也是由character_set_connection参数来指定的。<br>可以通过“Lcharset_name]’string’[COLLATEcollation_name]”命令强制字符串的字符集和排序规则。例如：<br>select_utf8字符集’； selectlatinl字符集；<br>通常情况下，基本不需要用户强制指定字符串字符集。</p>
<p>≦ 147 ≧<br>8.8小结 129<br>8.7字符集的修改步骤<br>如果在应用开始阶段没有正确地设置字符集，在运行一段时间以后才发现存在不能满足要求需要调整，又不想丢弃这段时间的数据，那么就需要进行字符集的修改。字符集的修改不能直接通过“alter database character set***”或者“alter table tablename character set ***” 命令进行，这两个命令都没有更新已有记录的字符集，而只是对新创建的表或者记录生效。已有记录的字符集调整，需要先将数据导出，经过适当的调整重新导人后才可完成。<br>以下模拟的是将latinI字符集的数据库修改成utf8字符集的数据库的过程。（1）导出表结构。<br>mysqldump -uroot -p –default-character-set&#x3D;utf8 -d databasename&gt; createtab.sql<br>其中–default-character-set-utf8表示设置以什么字符集连接；-d表示只导出表结构，不导出数据。<br>（2）手工修改createtab.sql中表结构定义中的字符集为新的字符集。（3）确保记录不再更新，导出所有记录。<br>mysqldump -uroot -p –quick –no-create-info –extended-insert –default- character-set&#x3D; latin1 databasename&gt; data.sql<br>O–quick：该选项用于转储大的表。它强制mysqldump从服务器一次一行地检索表中的行而不是检索所有行，并在输出前将它缓存到内存中。<br>O–extended-insert:使用包括几个VALUES列表的多行INSERT语法。这样使转储文件更小，重载文件时可以加速插入。<br>–no-create-info：不导出每个转储表的CREATETABLE语句。<br>O–default-character-set&#x3D;latinl:按照原有的字符集导出所有数据，这样导出的文件中，所有中文都是可见的，不会保存成乱码。<br>（4）打开 data.sql，将SETNAMES latin1修改成SETNAMES utf8。（5）使用新的字符集创建新的数据库。<br>createdatabasedatabasenamedefaultcharsetut8<br>（6）创建表，执行createtab.sql。<br>mysqurootpdatabasenamecreatetab.sql<br>（7）导人数据，执行data.sql。<br>mysql -uroot -p databasename&lt; data.sql<br>注意：选择目标字符集的时候，要注意最好是源字符集的超集，或者确定比源字符集的字库更大，<br>否则如果目标字符集的字库小于源字符集的字库，那么目标字符集中不支持的字符导入后会变成乱码，丢失一部分数据。例如，gbk字符集的字库大于gb2312字符集，那么gbk字符集的数据，如果导入gb2312数据库中，就会丢失gb2312中不支持的那部分汉字的数据。<br>8.8小结<br>本章主要介绍了MySQL中字符集和排序规则的概念、设置方法，以及推荐读者使用的字符集。最后，举例介绍了字符集修改的步骤和修改过程中遇到的问题，希望会对读者有所帮助。</p>
<p>≦ 148 ≧<br>第9章 索引的设计和使用<br>索引是数据库中用来提高性能的常用工具。本章主要介绍了MySQL5.7支持的索引类型，<br>并简单介绍了索引的设计原则。在后面的优化篇中，将会对索引做更多的介绍。 9.1索引概述<br>所有MySQL列类型都可以被索引，对相关列使用索引是提高SELECT操作性能的最佳途径。根据存储引擎可以定义每个表的最大索引数和最大索引长度，每种存储引擎（如 MyISAM、InnoDB、BDB、MEMORY等）对每个表至少支持16个索引，总索引长度至少为 256字节。大多数存储引擎有更高的限制。<br>MyISAM和InnoDB存储引擎的表默认创建的都是BTREE索引。除了直接在单列或者多列上直接创建索引外，MySQL5.7之后可以通过虚拟列索引来实现函数索引的功能，同时 MySQL也支持前缀索引，即对索引字段的前N个字符创建索引。前缀索引的长度跟存储引擎相关，对于MyISAM存储引擎的表，索引的前缀长度可以达到1000字节长，而对于InnoDB 存储引擎的表，索引的前缀长度最长是3072字节。请注意前缀的限制应以字节为单位进行测量，而CREATETABLE语句中的前缀长度解释为字符数。在为使用多字节字符集的列指定前缀长度时一定要加以考虑。<br>MySQL中还支持全文本（FULLTEXT）索引，该索引可以用于全文搜索。在MySQL5.6 之后，InnoDB和MyISAM存储引擎都可以支持FULLTEXT索引，但只限于CHAR、VARCHAR 和TEXT列。索引总是对整个列进行的，不支持局部（前缀）索引。<br>MySQL也可以为空间列类型创建索引，MySQL5.7之前只有MyISAM存储引擎支持空间类型索引l，且索引的字段必须是非空的。MySQL5.7中，InnoDB存储引引擎也开始支持空间类型索引l，索引I以R-Trees的数据结构保存。<br>默认情况下，MEMORY存储引擎使用HASH索引，但也支持BTREE索引。<br>索引在创建表的时候可以同时创建，也可以随时增加新的索引。创建新索引的语法如下：<br>CREATE CUNIQUE&#x2F;FULLTEXT&#x2F; SPATIALJ INDEX indeX_name[index type]<br>ON tb_name （index_co_name,…)[index_option]<br>[algorithm_option &#x2F; lock_option.. index_col_name:<br>col_name [(length)] [Asc &#x2F; DESc]</p>
<p>≦ 149 ≧<br>9.2设计索引的原则 131<br>也可以使用ALTERTABLE的语法来增加索引I，语法与CREATEINDEX类似，可以查询帮助获得详细的语法，这里不再复述。<br>例如，要为city表创建10字节的前缀索引，代码如下： mysql&gt; create index cityname on city （city(10));<br>Query 0K, 600 rows affected (0.26 sec) Records:600 Duplicates:0 Warnings:0<br>如果以city为条件进行查询，可以发现索引cityname被使用：<br>mysql&gt; explain select * from city where city &#x3D;’Fuzhou* AG select_ type: SIMPLE<br>table:city type:ref<br>possible_keys:cityname<br>key:cityname key_1en:32<br>ref:const rows:1<br>Extra:using where<br>1 row in set (0.00 sec) 索引的删除语法如下：<br>DROP INDEX index_name ON tbl_name<br>例如，想要删除city表上的索引cityname，可以操作如下：<br>mysql&gt; drop index cityname on city; Query ok, 600 rows affected (0.23 sec) Records:600 Duplicates:0 warnings:0<br>9.2设计索引的原则<br>索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率，更高效地使用索引。<br>要在条件列上创建索引，而不是查询列。换句话说，最适合索引的列是出现在WHERE 子句中的列，或连接子句中指定的列，而不是出现在SELECT关键字后的选择列表中的列。<br>尽量使用唯一索引。考虑某列中值的分布。索引的列的基数越大，索引的效果越好。例如，存放出生日期的列具有不同值，很容易区分各行。而用来记录性别的列，只含有“M” 和“F”，则对此列进行索引没有多大用处，因为不管搜索哪个值，都会得出大约一半的行。<br>使用短索引。如果对字符串列进行索引，应该指定一个前缀长度，只要有可能就应该这样做。例如，有一个CHAR(200)列，如果在前10个或20个字符内，多数值是唯一的，那么就不要对整个列进行索引。对前10个或20个字符进行索引能够节省大量索引空间，也可能会使查询更快。较小的索引涉及的磁盘I0较少，较短的值比较起来更快。更为重要的是，对于较短的键值，索引高速缓存中的块能容纳更多的键值，因此，MySQL也可以在内存中容纳更多的值。这样就增加了找到行而不用读取索引中较多块的可能性。<br>利用最左前缀。在创建一个n列的索引时，实际相当于创建了MySQL可利用的n个索引。多列索引可起几个索引的作用，因为可利用索引中最左边的列集来匹配行。这样的列集称为最左前缀。例如以a、b、c的顺序在3列上创建一个组合索引之后，利用a&#x3D;？或者a&#x3D;？</p>
<p>≦ 150 ≧<br>132 第9章索引的设计和使用<br>andb&#x3D;？或者a&#x3D;？andb&#x3D;？andc&#x3D;？这3种条件的查询，都可以使用这个索引l。通过这种方式，可以有效的降低索引的数量，提高索引的使用效率。<br>O对于InnoDB存储引擎的表，尽量手工指定主键。记录默认会按照一定的顺序保存，如果有明确定义的主键，则按照主键顺序保存。如果没有主键，但是有唯一索引，那么就是按照唯一索引的顺序保存。如果既没有主键又没有唯一索引，那么表中会自动生成一个内部列，按照这个列的顺序保存。按照主键或者内部列进行的访问是最快的，所以InnoDB表尽量自己指定主键。当表中同时有几个列都是唯一的，都可以作为主键的时候，要选择最常作为访问条件的列作为主键，提高查询的效率。另外，还需要注意，InnoDB表的普通索引都会保存主键的键值，所以主键要尽可能选择较短的数据类型，有效地减少索引的磁盘占用，提高索引的缓存效果。<br>9.3索引设计的误区<br>设计索引时，有一些常见的误区，总结如下。<br>不是所有的表都需要创建索引。通常来说，常见的代码表、配置表等数据量很小的表，除了主键外，再创建索引没有太大的意义，索引扫描和全表扫描相比，并不会带来性能的大幅提升。而大表的查询、更新、删除操作则要尽可能通过索引。对于大表来说，任何全表扫描对于系统来说都会是非常大的冲击，因此每个操作都尽可能通过索引进行。这类表要经常统计操作频率较高的SQL，然后对这些SQL进行分析，提取最常用的一些选择性高的列来创建索引。<br>不要过度索引。不要以为索引“越多越好”，什么东西都用索引是错误的。每个额外的索引都要占用额外的磁盘空间，并降低写操作的性能。在修改表的内容时，索引必须进行更新，有时可能需要重构，因此，索引越多，所花的时间越长。如果有一个索引很少利用或从不使用，那么会不必要地减缓表的修改速度。此外，MySQL在生成一个执行计划时，要考虑各个索引，这也要花费时间。创建多余的索引给查询优化带来了更多的工作。索引太多，也可能会使MySQL选择不到所要使用的最好索引。因此，只保持所需的索引有利于查询优化。<br>谨慎创建低选择度索引。对于选择性低并且数据分布均衡的列，因为过滤的结果集大，创建索引的效果通常不好；但如果列的选择性低但数据分布不均衡，比如男女比例为99%： 1%，那么此时创建索引对于查询条件为‘女”的过滤结果集就比较小，索引的效率较高，此<br>时创建索引就比较合适。在MySQL8.0之后也可以使用直方图取得类似的优化效果。 9.4索引设计的一般步骤<br>通过上面的介绍，当对一个大表做索引设计时，一般可以采用下面的步骤。<br>（1）整理表上的所有SQL，重点包括select、update、delete操作的where条件所用到的列的组合、关联查询的关联条件等。<br>（2）整理所有查询SQL的预期执行频率。<br>（3）整理所有涉及的列的选择度，列的不同值相比总非空行数的比例越大，选择度越好，比如全部都是唯一值的主键列选择度最高。当然，上面所提到的查询频率、选择度，都是估</p>
<p>≦ 151 ≧<br>9.5BTREE索引与HASH索引 133<br>算的值，能够在设计索引时作为参考即可。<br>（4）遵照之前提到的设计原则，给表选择合适的主键。<br>（5）优先给那些执行频率最高的SQL创建索引，执行频率很高的SQL，使用到的索引的效率对整体性能影响也会比较大，选择其中选择度最高的列来创建索引，如果选择度都不够好，那么应该考虑是否可以使用其他选择度更好的条件，或者选择创建联合索引。<br>（6）按执行频率排序，依次检查是否需要为每个SQL创建索引I，可以复用之前已经创建的索引的SQL，无须再重复创建索引，除非SQL执行频率很高，新创建的索引，对选择度提升也很大。<br>（7）索引合并，利用复合索引来降低索引的总数，充分利用最左前缀的原则，让索引可以被尽可能多地复用，同时在保证复用率的情况下，把选择度更高的列放到索引的更左侧。<br>（8）上线之后，通过慢查询分析、执行计划分析、索引使用统计，来确定索引的实际使用情况，并根据情况做出调整。<br>9.5 BTREE索引I与HASH索引I<br>MEMORY存储引擎的表可以选择使用BTREE索引或者HASH索引I，两种不同类型的索引各有其不同的适用范围。HASH索引有一些重要的特征在使用时需特别注意，如下所示。<br>只用于使用&#x3D;或&lt;&#x3D;&gt;操作符的等式比较。<br>O优化器不能使用HASH索引来加速ORDERBY操作。<br>MySQL不能确定在两个值之间大约有多少行。如果将一个MyISAM表改为HASH 索引的MEMORY表，会影响一些查询的执行效率。<br>只能使用整个关键字来搜索一行。<br>而对于BTREE索引I，当使用&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、BETWEEN、！&#x3D;或者&lt;&gt;，或者LIKE’pattern（其中’patterm’不以通配符开始）操作符时，都可以使用相关列上的索引。下列范围查询适用于 BTREE索引和HASH索引：<br>SELECTFROMWHEREKe1ORKeyIN（151820）<br>下列范围查询只适用于BTREE索引：<br>SELECT*FROM tI WHERE Key_col &gt;1 AND key col &lt;10;<br>SELECT *FROM tI WHERE key col LIKE *ab% OR key col BETWEEN lisa’ AND simon’; 例如，创建一个和city表完全相同的MEMORY存储引擎的表city_memory： mysql&gt; CREATE TABLE city_memory (<br>city id SMALLINT UNSIGNED NOT NULL AUTO INCREMENT city VARCHAR(5O) NOT NULL,<br>country_id SMALLINT UNSIGNED NOT NULL,<br>last update TIMESTAMP NOT NULL DEFAULT CURRENT TIMESTAMP ON UPDATE CURRENT_ TIMESTAMP PRIMARY KEY(city_id),<br>KEY idx_fk country_id (country_id)-&gt;）ENGINE&#x3D;Memory DEFAULT CHARSET&#x3D;utf8;<br>Query ok, 0 rows affected (o.03 sec)<br>mysql&gt; insert into city_memory select * from city;<br>Query ok, 600 rows affected (0.00 sec) Records: 600 Duplicates:0 warnings:0<br>当对索引字段进行范围查询的时候，只有BTREE索引可以通过索引访问：</p>
<p>≦ 152 ≧<br>134 第9章索引的设计和使用<br>mysql&gt; explain SELECT *FROM city WHERE country id &gt; 1 and country_id&lt; 10 \G<br>★★★*<br>id：1<br>select type: SIMPLE<br>table: city type:range<br>possible_keys:idx_fk_country_id<br>key:idx_fk_country_id key_len:2<br>ref: NULL rows:24<br>Extra: using where<br>1row in set (0.00 sec)<br>而HASH索引I实际上是全表扫描的：<br>mysql&gt; explain SELECT *FROM city memory WHERE country_id &gt; 1 and country id &lt; 10 ΛG<br>id:1<br>select type:SIMPLE<br>table :city_memory type : ALL<br>possible_keys:idx_fk_country_id<br>key: NULL key_len :NULL<br>ref:NULL rows:600<br>Extra:using where<br>1row in set (o.oo sec)<br>了解了BTREE索引和HASH索引I不同后，当使用MEMORY表时，如果是默认创建的 HASH索引I，就要注意SQL语句的编写，确保可以使用上索引I；如果一定要使用范围查询，<br>那么在创建索引I时，就应该选择创建成BTREE索引。 9.6索引在MySQL8.0中的改进<br>索引的正确使用，对于MySQL的性能优化，起着非常关键的作用。在MySQL8.0中，<br>索引也引人了不少新的特性。下面介绍几个比较重点的改进。 9.6.1不可见索引<br>在MySQL8.0中，增加了对于不可见索引（invisibleindex）的支持，这也是一个从Oracle 数据库借鉴而来的新特性。所谓不可见，指的是对于查询优化器不可见，SQL在执行时自然也就不会选择，但在查看表结构时候索引仍然能看到，也可以通过information_schema.statistics 或者showindex来查看索引l是否可见的状态。<br>索引默认是可见的，可以通过在创建索引时指定invisible关键字来创建不可见索引l： CREATE TABLE t1（<br>iINT, jINT, k INT,<br>INDEX i_idx (i) INVISIBLE）ENGINE &#x3D; InnoDB;<br>也可以通过命令来单独添加不可见索引： CREATE INDEX j idX ON t1 (j) INVISIBLE;<br>ALTER TABLE tI ADD INDEX k idX (k) INVISIBLE;</p>
<p>≦ 153 ≧<br>9.6索引在MySQL8.0中的改进 135<br>可以通过altertable命令来修改索引是否可见：<br>ALTER TABLE tI ALTER INDEX i idX INVISIBLE; ALTER TABLE tl ALTER INDEX i idX VISIBLE;<br>为什么数据库中要设计这么一种消耗资源，却又不能够对SQL起到任何优化左右的索引呢？实际上，引人不可见索引的目的，主要是为了减小对于表上的索引进行调整时的潜在风险。<br>随着表的数据量增大，达到了几百GB，几TB甚至更大的时候，如果此时对表上的索引进行调整，往往面临着很大的风险。例如，当删除一个认为不再需要的索引时，一旦系统中还存在个别使用这个索引的SQL，那么这些SQL的执行计划有可能会变成对这个大表的全表扫描，这会对数据库服务器造成巨大冲击，很有可能直接导致服务不可用。而由于表的数据量大，重建索引需要的时间和消耗的系统资源也会很大，很难马上通过重建索引解决问题。<br>有了不可见索引，当需要删除一个表上的余索引时，可以先将索引设置为不可见，而不是直接删除，一旦发现没有这个索引之后，对系统性能产生了负面影响，可以很方便地恢复这个索引，而不再需要重建索引。<br>同样，当增加一个索引之后，如果发现对系统带来了负面影响，可以首先将索引设置为<br>不可见，待系统负载恢复正常后，再做索引的删除，避免了系统压力大的时候雪上加霜。 9.6.2倒序索引<br>在MySQL8.0中，正式增加了对于倒序索引（descending index）的支持，在之前的版本中，<br>虽然在创建索引的时候可以指定desc关键字，但是实际上MySQL仍然会保存为正序索引l。 mysql 5.7&gt; CREATE TABLE t1 (a INT, b INT, INDEX a desc b_asc (a DESC, b ASC));<br>Query Ok,0 rows affected (0.47 sec) mysq1 5.7&gt; SHOW CREATE TABLE t1\G<br>Table:t1<br>Create Table:CREATE TABLEt1（<br>int(11) DEFAULT NULL, bint（11) DEFAULT NULL，<br>KEY a descb asc(a,b) &lt;– order is not preserved<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1 1 row in set (0.00 sec)<br>在MySQL8.0中，倒序索引能够被正确创建：<br>mysql 8.O&gt; CREATE TABLE t1 (a INT,b INT,INDEX a desc_b asC (a DESC,b ASC)); Query ok,0 rows affected (0.47 sec)<br>mysql 8.0&gt; show create table t1; |Table I Create Table|<br>CREATE TABLEt1（<br>t1<br>int（11) DEFAULT NULL， bint（11) DEFAULT NULL，<br>KEYa desc b_asc(aDEsc,b）<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl| 1 row in set (o.00 sec)<br>倒序索引在某些情况下，可以起到更好的作用。但是相比于Oracle倒序索引对于查询的优化效果，MySQL倒序索引起到的作用还是比较弱的，有待未来的版本继续加强。但是需要注意的是，由于倒序索引的引l人，MySQL8.0取消了对于groupby操作的隐式排序，如果业务中有依赖于此特性的，在升级数据库版本的时候要谨慎。</p>
<p>≦ 154 ≧<br>136 第9章索引的设计和使用 9.7小结<br>索引用于快速找出在某个列中有某个特定值的行。如果不使用索引，MySQL必须从第1 条记录开始然后读完整个表直到找出相关的行。表越大，花费的时间越多。如果表中查询的列有一个索引，MySQL能快速到达一个位置去搜寻数据文件的中间，没有必要看所有数据。如果一个表有1000行，这比顺序读取至少快100倍。注意如果需要访问大部分行，顺序读取要快得多，因为此时应避免磁盘搜索。<br>大多数MySQL索引I（如PRIMARYKEY、UNIQUE、INDEX和FULLTEXT等）在BTREE 中存储。只是空间列类型的索引使用RTREE，并且MEMORY表还支持HASH索引。<br>本节简单地介绍了在设计索引时需要注意的一些常见问题，至于数据库何时会使用索引，何时不会使用索引，可参见优化篇的相关章节，这里不再赘述。</p>
<p>≦ 155 ≧<br>第10章 开发常用数据库对象<br>10.1视图<br>MySQL从5.0.1版本开始提供视图功能，本节将对MySQL中的视图进行介绍。 10.1.1什么是视图<br>视图（View）是一种虚拟存在的表，对于使用视图的用户来说基本上是透明的。视图并不在数据库中实际存在，行和列数据来自定义视图的查询中使用的表，并且是在使用视图时动态生成的。<br>视图相对于普通的表的优势主要包括以下几项。<br>简单：使用视图的用户完全不需要关心后面对应的表的结构、关联条件和筛选条件，对用户来说已经是过滤好的复合条件的结果集。<br>安全：使用视图的用户只能访问他们被允许查询的结果集，对表的权限管理并不能限制到某个行某个列，但是通过视图就可以简单地实现。<br>数据独立：一旦视图的结构确定了，可以屏蔽表结构变化对用户的影响，源表增加列对视图没有影响；源表修改列名，则可以通过修改视图来解决，不会造成对访问者的影响。 10.1.2视图操作<br>视图的操作包括创建或者修改视图、删除视图，以及查看视图定义。 10.1.3创建或者修改视图<br>创建视图需要有CREATEVIEW的权限，并且对于查询涉及的列有SELECT权限。如果使用CREATEORREPLACE或者ALTER修改视图，那么还需要该视图的DROP权限。<br>创建视图的语法如下：<br>CREATE [OR REPLACE] [ALGORITHM&#x3D;{UNDEFINED &#x2F; MERGE&#x2F; TEMPTABLE]]<br>VIEW view_name [（(column_list)] AS select_statement<br>[WITH [CASCADED &#x2F; LOCAL] CHECK OPTION]</p>
<p>≦ 156 ≧<br>138 第10章开发常用数据库对象<br>修改视图的语法如下：<br>ALTER [ALGORITHM&#x3D;{UNDEFINED &#x2F; MERGE&#x2F; TEMPTABLE}]<br>VIEW view_name [(column_list)] AS select_statement<br>[WITH [CASCADED &#x2F; LOCAL] CHECK OPTION]<br>例如，要创建视图staff_list_view，可以使用以下命令： mysql&gt; CREATE OR REPLACE VIEW staff_list_view AS</p>
<blockquote>
<p>SELECT s.staff_id,s.first_name,s.last name,a.address &gt;FROM staff As s,address AS a<br>where s.address_id &#x3D; a.address id;<br>Query Ok,0 rows affected (o.o0 sec)<br>MySQL视图的定义有一些限制，例如，在5.7.7版本之前，FROM关键字后面不能包含子查询，这和其他数据库是不同的，如果视图是从其他数据库迁移过来的，那么可能需要因此做一些改动。<br>视图的可更新性和视图中查询的定义有关系，以下类型的视图是不可更新的。<br>O包含以下关键字的SQL语句：聚合函数（SUM、MIN、MAX、COUNT等）、DISTINCT、 GROUPBY、HAVING、UNION或者UNIONALL。<br>常量视图。<br>SELECT中包含子查询。 JOIN.<br>FROM一个不能更新的视图。<br>WHERE字句的子查询引用了FROM字句中的表。<br>例如，以下的视图都是不可更新的：包含聚合函数<br>mysql&gt; create or replace view payment sum as<br>select staff id,sum(amount) from payment group by staff id;<br>Query ok,O rows affected (o.o0 sec)–常量视图<br>mysql&gt; create or replace view pi as select 3.1415926 as pi;<br>Query ok,0 rows affected (o.o0 sec)–select中包含子查询<br>mysql&gt; create view city_view as<br>-&gt; select (select city from city where city_id &#x3D; 1); Query ok,0 rows affected (o.o0 sec)<br>WITH[CASCADED|LOCAL]CHECKOPTION决定了是否允许更新数据使记录不再满足视图的条件。这个选项与Oracle数据库中的选项是类似的，其中：<br>LOCAL只要满足本视图的条件就可以更新；<br>OCASCADED则必须满足所有针对该视图的所有视图的条件才可以更新。如果没有明确是LOCAL还是CASCADED，则默认是CASCADED。<br>例如，对payment表创建两层视图，并进行更新操作： mysql&gt; create or replace view payment view as<br>-&gt; select payment id,amount from payment &gt;where amount&lt;10 WITH CHECK OPTION;<br>Query ok,0 rows affected (o.o0 sec) mysq1&gt;<br>mysql&gt; create or replace view payment viewl as<br>-&gt; select payment id,amount from payment view &gt;where amount &gt; 5 WITH LOCAL CHECK OPTION;</p>
</blockquote>
<p>≦ 157 ≧<br>10.1视图 139<br>Query oK,O rows affected (o.oo sec) mysq1&gt;<br>mysql&gt; create or replace view payment view2 as<br>-&gt; select payment_id,amount from payment view &gt; where amount &gt; 5 WITH CASCADED CHECK oPTIoN;<br>Query ok, 0 rows affected (o.o0 sec)<br>mysql&gt; select * from payment_view1 limit 1; I payment_id I amount 1<br>13 15.99 1 row in set (o.00 sec)<br>mysql&gt; update payment view1 set amount&#x3D;10<br>-&gt;where payment id &#x3D; 3；<br>Query ok, 1 row affected (o.03 sec)<br>Rows matched:1changed:1warnings:0 mysql&gt; update payment view2 set amount&#x3D;10<br>-&gt; where payment id &#x3D; 3;<br>ERROR 1369 (HY000): CHECK OPTION failed’sakila.payment View2<br>从测试结果可以看出，payment_view1是WITHLOCALCHECKOPTION的，所以只要满足本视图的条件就可以更新，但是payment_view2是WITHCASCADEDCHECKOPTION 的，必须满足针对该视图的所有视图才可以更新，因为更新后记录不再满足payment_view的<br>条件，所以更新操作提示错误退出。 10.1.4删除视图<br>用户可以一次删除一个或者多个视图，前提是必须有该视图的DROP权限。<br>DROP VIEW[IF EXISTS] VieWnameViewname】[RESTRICT CASCADE】<br>例如，删除staff_list视图： mysql&gt; drop view staff_list;<br>Query ok, o rows affected (o.oo sec) 10.1.5查看视图<br>从MySQL5.1版本开始，使用SHOWTABLES命令的时候不仅显示表的名字，同时也会显示视图的名字，而不存在单独显示视图的SHOWVIEWS命令。<br>mysql&gt; use sakila Database changed mysql&gt; show tables;<br>1 Tables_in sakila |staff<br>staff_list store<br>26 rows in set (o.00 sec)<br>同样，在使用SHOWTABLESTATUS命令的时候，不但可以显示表的信息，同时也可以显示视图的信息。所以，可以通过下面的命令显示视图的信息：<br>SHOWTABLESTATUSFROMdbnae】[IKEpattern </p>
<p>≦ 158 ≧<br>140 第10章开发常用数据库对象<br>下面演示的是查看stafflist视图信息的操作： mysql&gt; show table status like ‘staff_list’\G<br>Name: staff_list<br>Engine: NULL Version: NULL Row_format : NULL<br>ROWS:NULL<br>Avg_row_length: NULL<br>Data_length: NULL Max data length: NULL Index_length : NULL<br>Data free: NULL Auto increment : NULL Create_time : NULL Update time : NULL Check_time: NULL Collation: NULL Checksum: NULL<br>Create_options: NULL<br>Comment: VIEW<br>1 row in set (o.01 sec)<br>如果需要查询某个视图的定义，可以使用SHOWCREATEVIEW命令进行查看： mysql&gt; show create view staff list \G<br>★*<em>业</em> ★★★会<br>view: staff_list<br>Create View: CREATE ALGORITHM&#x3D;UNDEFINED DEFINER&#x3D;‘root‘@’locaThost’ SQL SECURITY DEFINER VIEW’staff list’As select‘s’.staff id’As‘ID’,concat(‘s.firstname,utf8’,s’.last name’) As ‘name′,’a’.’address′As ‘address’,’a’.’postal code′As ‘zip code’,’a’.’phone′As ‘phone’，’city’.’city’As’city’,country’.’country’As ‘country’,’s’’.’store id’As’sID’from （((‘staff’’s’join <em>address′’a′on（(‘s’.’address id’&#x3D;‘a’.’address_id’））) join ‘city′on（（’a’.’city_id<br>&#x3D;’city’.’city id’))) join country’on（（’city</em>.’country_id’&#x3D;country’.’country id’))) CHARACTER SET CLIENT:Utf8<br>COLLATION CONNECTION:utf8_general ci 1row in set (o.00 sec)<br>最后，通过查看系统表information_schema.views也可以查看视图的相关信息： mysql&gt; select * from views where table_name &#x3D;’staff_list’\G<br>六业★★★★业★★六业★★六★★会 中中六会会会<br>TABLE CATALOG: NULL TABLE SCHEMA: Sakila<br>TABLE NAME: staff list<br>VIEW DEFINITIoN: select <em>s′.’staff id’As</em>ID’,concat（’s’.first name’,utf8′,’s’.last name’) As ‘name′,*a’.’address′As ‘address’,’a’.’postal code′As zip code’,’a’.’phone′As ‘phone’,‘sakila.’city’.’city′As ‘city’,’sakila’.country’.’country′As ‘country’,’s’.’store id’As SID′ from (（(‘sakila’.’staff’’s’ join‘sakila’.’address′’a′on（(‘s.’address id’&#x3D;’a′.’address id’))) join *sakila’.’city′on(C’a’.’city_id’&#x3D;’sakila’.’city’.’city_id’))) join ‘sakila′.country’ on((‘sakila′.’city’.’country_id’&#x3D;’sakila’.’country’.’country_id’)))<br>CHECK OPTION: NONE IS UPDATABLE:YES<br>DEFINER: root@localhost<br>SECURITY TYPE: DEFINER CHARACTER SET_CLIENT:utf8<br>COLLATION CONNECTION:utf8_general_ci 1row in set (o.00 sec)<br>10.2 存储过程和函数<br>MySQL从5.0版本开始支持存储过程和函数。</p>
<p>≦ 159 ≧<br>10.2存储过程和函数 141<br>10.2.1什么是存储过程和函数<br>存储过程和函数是事先经过编译并存储在数据库中的一段SQL语句的集合，调用存储过程和函数可以简化应用开发人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。<br>存储过程和函数的区别在于函数必须有返回值，而存储过程没有，存储过程的参数可以使用IN、OUT、INOUT类型，而函数的参数只能是IN类型的。如果有函数从其他类型的数<br>据库迁移到MySQL，那么就可能因此需要将函数改造成存储过程。 10.2.2存储过程和函数的相关操作<br>在对存储过程或函数进行操作时，需要首先确认用户是否具有相应的权限。例如，创建存储过程或者函数需要CREATEROUTINE权限，修改或者删除存储过程或者函数需要<br>ALTERROUTINE权限，执行存储过程或者函数需要EXECUTE权限。 10.2.3创建、修改存储过程或者函数<br>创建、修改存储过程或者函数的语法如下： CREATE<br>[DEFINER &#x3D; user &#x2F; CURRENT_USER ]<br>PROCEDuRE sp_name ([proc_parameter….J)[characteristic…]routine_body<br>CREATE<br>[DEFINER &#x3D;uSer I CURRENT_USER }]<br>FUNCTroN sp_name ([func parameter,..J]) RETURNS type<br>[characteristic…] routine_body[IN &#x2F; OuT &#x2F; INouT ] param_name type<br>func_parameter:<br>param_name type type:<br>Any valid MysQL data type characteristic:<br>COMMENT‘string” ILANGUAGE SQL<br>I[NOT] DETERMINISTIC<br>I CONTAINS SQL I NO SQLI READS SQL DATA I MODIFIES SQL DATA  ISQL SECURITY  DEFINER&#x2F; INVOKER-<br>routine_body:<br>valid sQL routine statement 调用过程的语法如下：<br>sptr<br>MySQL的存储过程和函数中允许包含DDL语句，也允许在存储过程中执行提交（Commit，即确认之前的修改）或者回滚（Rollback，即放弃之前的修改），但是存储过程和函数中不允许执行LOADDATAINFILE语句。此外，存储过程和函数中可以调用其他的过程</p>
<p>≦ 160 ≧<br>142 第10章开发常用数据库对象或者函数。<br>下面创建了一个新的过程film_in_stock：<br>mysql&gt; DELIMITER $$ mysq1&gt;<br>mysql&gt; CREATE PROCEDURE film in stock（IN p_film_id INT,IN p store id INT,OUT p_film_count INT)<br>-&gt;READS SQL DATA-&gt;BEGIN<br>SELECT inventory_id FROM inventory<br>WHERE film id &#x3D;p_film id AND store_id &#x3D; p_store_id</p>
<blockquote>
<p>AND inventory_in_stock(inventory_id); SELECT FOUND ROWSO INTO p_film_count;<br>-&gt;ENDSS<br>Query ok,0 rows affected (o.o0 sec) mysq1&gt;<br>mysql&gt; DELIMITER:<br>上面是在使用的样例数据库中创建的一个过程，该过程用来检查film_id和store_id对应的inventory是否满足要求，并且返回满足要求的inventory_id以及满足要求的记录数。<br>通常我们在执行创建过程和函数之前，都会通过“DELIMITERSS”命令将语句的结束符从“”修改成其他符号，这里使用的是“$S”，这样在过程和函数中的“；”就不会被MySQL 解释成语句的结束而提示错误。存储过程或者函数创建完毕，通过“DELIMITER；”命令再将结束符改回成“；”。<br>可以看到在这个过程中调用了函数inventory_in_stockO，并且这个过程有两个输入参数和一个输出参数。下面可以通过调用这个过程来看看返回的结果。<br>如果需要检查film_id&#x3D;2store_id&#x3D;2对应的inventory的情况，则首先手工执行过程中的 SQL语句，以查看执行的效果：<br>mysql&gt; SELECT inventory_id<br>-&gt; FROM inventory-&gt;WHERE film id&#x3D;2-&gt;AND store_id&#x3D;2<br>AND inventory_in_stock(inventory_id); |inventory_id1<br>10 111<br>2 rows in set (o.00 sec)<br>满足条件的记录应该是两条，inventory_id分别是10和11。如果将这个查询封装在存储<br>过程中调用，那么调用过程的执行情况如下： mysq1&gt; CALL fi7m_in stock(2,2,@a）;<br>|inventory_id1 110<br>2rows in set (o.00 sec)<br>Query ok,0 rows affected (o.o0 sec)<br>mysql&gt; select @a; 1@a</p>
</blockquote>
<p>≦ 161 ≧<br>10.2存储过程和函数 143<br>1 row in set (0.00 sec)<br>可以看到调用存储过程与直接执行SQL的效果是相同的，但是存储过程的好处在于处理逻辑都封装在数据库端，调用者不需要了解中间的处理逻辑。一旦处理逻辑发生变化，只需要修改存储过程即可，而对调用者的程序完全没有影响。<br>另外，和视图的创建语法稍有不同，存储过程和函数的CREATE语法不支持使用CREATE ORREPLACE对存储过程和函数进行修改，如果需要对已有的存储过程或者函数进行修改，需要执行ALTER语法。<br>下面对characteristic特征值的部分进行简单的说明。<br>OLANGUAGESQL：说明下面过程的BODY是使用SQL编写，这条是系统默认的，为今后MySQL会支持的除SQL外的其他语言支持的存储过程而准备。<br>O[NOT]DETERMINISTIC：DETERMINISTIC确定的，即每次输入一样输出也一样的程序，NOTDETERMINISTIC非确定的，默认是非确定的。当前，这个特征值还没有被优化程序使用。<br>O{CONTAINSSQL|NO SQL|READS SQL DATA|MODIFIES SQLDATA}：这些特征值提供子程序使用数据的内在信息，这些特征值目前只是提供给服务器，并没有根据这些特征值来约束过程实际使用数据的情况。CONTAINSSQL表示子程序不包含读或写数据的语句。NOSQL表示子程序不包含SQL语句。READSSQLDATA表示子程序包含读数据的语句，但不包含写数据的语句。MODIFIESSQLDATA表示子程序包含写数据的语句。如果这些特征没有明确给定，默认使用的值是CONTAINSSQL。<br>OSQLSECURITY（DEFINER|INVOKER}：可以用来指定子程序该用创建子程序者的许可来执行，还是使用调用者的许可来执行，默认值是DEFINER。<br>COMMENT’string：存储过程或者函数的注释信息。<br>下面的例子对比了SQLSECURITY特征值的不同，使用root用户创建了两个相似的存储过程，分别指定使用创建者的权限执行和调用者的权限执行，然后使用一个普通用户调用这两个存储过程，对比执行的效果。<br>首先用root用户创建以下两个存储过程film_in_stock_definer和film_in_stock_invoker：<br>mysql&gt; DELIMITER $$ mysq1&gt;<br>mysql&gt; cREATE PROCEDURE film in stock definer(IN p film id INT, IN p store id INT, ouT p film count INT)<br>-&gt;SQL SECURITY DEFINER-&gt; BEGIN<br>SELECT inventory_id FROM inventory<br>WHERE film_id &#x3D;p_film id AND store id &#x3D; p store id<br>AND inventory_in stock(inventory_id); SELECT FOUND ROWSO) INTO p_film_count;<br>-&gt;ENDS$<br>Query ok,0 rows affected (o.oo sec) mysq1&gt;<br>mysql&gt; CREATE PROcEDURE film in stock invoker(IN p_film id INT, IN p store_id INT,OUT p film count INT)<br>-&gt;SQL SECURITY INVOKER</p>
<p>≦ 162 ≧<br>144 第10章开发常用数据库对象<br>-&gt;BEGIN</p>
<ul>
<li>SELECT inventory_id<br>FROM inventory<blockquote>
<p>WHERE film_id &#x3D;p_film_id<br>AND store id &#x3D; p_store id<br>AND inventory_in_stock（inventory_id); SELECT FOUND_ROWSO) INTO p_film_count;<br>END$S<br>Query ok, 0 rows affected (o.oo sec) mysq1&gt;<br>mysql&gt; DELIMITER；<br>给普通用户lisa赋予可以执行存储过程的权限，但是不能查询inventory表：<br>mysql&gt; GRANT EXECUTE ON sakila.* To lisa‘@’locaThost’; Query ok, 0 rows affected (o.o0 sec)<br>使用lisa登录后，直接查询inventory表会提示查询被拒绝： mysql&gt; select count(*) from inventory;<br>ERROR 1142 (42000): SELECT command denied to user ‘lisa‘@’localhost’ for table’inventory lisa用户分别调用filmin_stock_definer和film_in_stock_invoker：<br>mysql&gt; CALL film_in_stock_definer(2,2,@a); |inventory_id|<br>10 11<br>2rows in set (0.03 sec)<br>Query ok, 0 rows affected (0.03 sec)<br>mysql&gt; CALL film in_stock invoker(2,2,@a）;<br>ERROR 1142 (42000): sELECT command denied to user lisa‘@’localhost for table inventory’ 从上面的例子可以看出，film_in_stock_definer是以创建者的权限执行的，因为是root用户创建的，所以可以访问inventory表的内容，film_in_stock_invoker是以调用者的权限执行的，<br>lisa用户没有访问inventory表的权限，所以会提示权限不足。 10.2.4删除存储过程或者函数<br>一次只能删除一个存储过程或者函数，删除存储过程或者函数需要有该过程或者函数的 ALTERROUTINE权限，具体语法如下：<br>DROP {PROCEDURE  FUNCTION [IF EXISTS] Sp_name<br>例如，使用DROP语法删除film_in_stock过程：<br>mysqT&gt; DROP PROcEDURE film_in stock; Query oK,O rows affected (o.o0 sec)<br>10.2.5查看存储过程或者函数<br>存储过程或者函数被创建后，用户可能需要查看存储过程、函数的状态、定义等信息，便于了解存储过程或者函数的基本情况。下面介绍如何查看存储过程或函数相关信息。<br>1.查看存储过程或者函数的状态<br>SHOW {PROCEDURE &#x2F; FUNCTION} STATUS [LIKE ‘pattern’]</p>
</blockquote>
</li>
</ul>
<p>≦ 163 ≧<br>10.2存储过程和函数 145<br>下面演示的是查看过程film_in_stock的信息：<br>mysql&gt; show procedure status like ‘film in stock’\G<br>Db:sakila<br>Name: film in_stock Type:PROCEDURE<br>Definer:root@localhost<br>Modified:2007-07-06 09:29:00 Created:2007-07-06 09:29:00<br>Security_type: DEFINER<br>Comment:<br>1 row in set (o.00 sec)<br>2.查看存储过程或者函数的定义<br>SHOW CREATE PROCEDURE  FUNCTIONJ Sp_name<br>下面演示的是查看过程film_in_stock的定义： mysql&gt; show create procedure film_in stock \G<br>Procedure: film in stock sql mode:<br>Create Procedure: CREATE DEFINER&#x3D;‘root‘@’localhost PROCEDURE ‘film in stock’（IN p_film id INT, IN p_store_id INT,oUT p film count INT)<br>READS SQL DATA<br>BEGIN<br>SELECT inventory_id FROM inventory<br>WHERE film_id &#x3D; p_film_id AND store_id&#x3D; p store id<br>AND inventory_in_stock（inventory_id); SELECT FOUND ROWSO INTO p_film count;<br>END<br>1 row in set (0.00 sec)<br>3.通过查看information_schema.Routines了解存储过程和函数的信息<br>除了以上两种方法，我们还可以查看系统表来了解存储过程和函数的相关信息，通过查看information_schema.Routines 就可以获得存储过程和函数的名称、类型、语法、创建人等信息。<br>例如，通过查看information_schema.Routines 得到过程film_in_stock的定义： mysql&gt; select * from routines where RoUTINE_NAME &#x3D; film_in stock’\G<br>*<br>SPECIFIC NAME: film_in_stock<br>ROUTINE CATALOG: NULL ROUTINE SCHEMA: Sakila<br>ROUTINE NAME: film_in_stock ROUTINE TYPE: PROCEDURE<br>DTD IDENTIFIER:NULL ROUTINE BODY: SQL<br>ROUTINE DEFINITION: BEGIN<br>SELECT inventory_id FROM inventory<br>WHERE film_id &#x3D;p_film_id AND store_id &#x3D; p store_id<br>AND inventory_in_stock（inventory_id); SELECT FOUND_ROWSO) INTO p_film count;<br>END<br>EXTERNAL NAME:NULL EXTERNAL LANGUAGE:NULL PARAMETER STYLE: SQL IS DETERMINISTIC:NO<br>SQL DATA ACCESS:READS SQL DATA<br>SQL PATH:NULL<br>SECURITY_TYPE:DEFINER</p>
<p>≦ 164 ≧<br>146 第10章开发常用数据库对象<br>CREATED:2007-07-0609:29:00 LAST ALTERED:2007-07-06 09:29:00 SQL MODE:<br>ROUTINE COMMENT:<br>DEFINER:root@localhost<br>1row in set (0.00 sec) 10.2.6变量的使用<br>存储过程和函数中可以使用变量，而且在MySQL5.1版本中，变量是不区分大小写的。 1.变量的定义<br>通过DECLARE可以定义一个局部变量，该变量的作用范围只能在BEGIN…END块中，可以用在嵌套的块中。变量的定义必须写在复合语句的开头，并且在任何其他语句的前面。可以一次声明多个相同类型的变量。如果需要，可以使用DEFAULT赋默认值。<br>定义一个变量的语法如下：<br>DECLARE var_nameL,… type [DEFAULT value]<br>例如，定义一个DATE类型的变量，名称是last_month_start: DECLARE last month start DATE;<br>2.变量的赋值<br>变量可以直接赋值，或者通过查询赋值。直接赋值使用SET，可以赋常量或者赋表达式，具体语法如下：<br>SET var_name &#x3D; expr [, var_name &#x3D; expr].<br>给刚才定义的变量lastmonth_start赋值，具体语法如下：<br>SET Tast_month_Start&#x3D; DATE_SUB(CURRENT_DATEO, INTERVAL 1 MONTH);<br>也可以通过查询将结果赋给变量，这要求查询返回的结果必须只有一行，具体语法如下：<br>SELECT col_name,…] INTo var_name,…] table_expr 通过查询将结果赋值给变量v_payments:<br>CREATE FUNCTIoN get_customer balance(p_ customer id INT,<br>p_effective_ date DATETIME) RETURNS DECIMAL(5,2)<br>DETERMINISTIC READS SQL DATA BEGIN<br>DECLARE V_payments DECIMAL(5,2): #SUM OF PAYMENTS MADE PREVIOUSLY<br>SELECT IFNULL(SUM(payment.amount),O) INTO V payments FROM payment<br>WHERE payment.payment date &lt;&#x3D; p_effective date AND payment.customer id &#x3D; p customer_id;<br>RETURN v_rentfees +V_overfees -V_payments; END $S<br>10.2.7定义条件和处理<br>条件的定义和处理可以用来定义在处理过程中遇到问题时将如何进行相应的处理。</p>
<p>≦ 165 ≧<br>10.2存储过程和函数 147<br>1.条件的定义<br>DECLARE condition_name CONDITION FOR condition_value condition_value:<br>mysql_error_code<br>I SQLSTATE [VALUE] sqlstate value 2.条件的处理<br>DECLARE handTer_type HANDLER FOR condition_value,…]<br>statement handler_type:<br>CONTINUE<br>IEXIT&#x2F;UNDO<br>condition_value:<br>mysq7_error_code<br>SQLSTATE [VALUE] sqlstate value&#x2F;condition_name<br>&#x2F;SQLWARNING&#x2F;NOT FOUND<br>&#x2F;SQLEXCEPTIONe<br>下面将通过两个例子来说明：在向actor表中插入记录时，如果没有进行条件的处理，那么在主键冲突的时候会抛出异常并退出；如果对条件进行了处理，那么就不会再抛出异常。<br>（1）当没有进行条件处理时，执行结果如下： mysql&gt; select max(actor_id) from actor;<br>Imax（actor_id)1 1200<br>1row in set (o.00 sec)<br>mysql&gt; delimiter $$ mysq7&gt;<br>mysql&gt; CREATE PROCEDURE actor_insert O<br>-&gt;BEGIN<br>SET @x&#x3D;1;<br>INSERTINT actor(actor_id,firstname,lastname）VALUES （201,Test’,201）; SET@x&#x3D;2;<br>INSERT INTO actor（actor_id,first_name,last name) VALUEs (1,’Test’,’1’); SET@X&#x3D;3；<br>-&gt;END;-&gt;$s<br>Query ok,O rows affected (o.o0 sec) mysql&gt; delimiter;<br>mysql&gt; call actor insert(;<br>ERROR 1062 (23000): Duplicate entry’1′ for key‘PRIMARY<br>mysql&gt; select @x; ax<br>1 row in set (o.o0 sec)<br>从上面的例子可以看出，执行到插入actor_id&#x3D;1的记录时，会主键冲突并退出，没有执行到下面其他的语句。<br>（2）当对主键冲突的异常进行处理时，执行结果如下：</p>
<p>≦ 166 ≧<br>148 第10章开发常用数据库对象<br>mysql&gt; delimiter ss mysq1&gt;<br>mysql&gt; CREATE PRoCEDURE actor_insert ()<br>-&gt;BEGIN<br>DECLARE CONTINUE HANDLER FOR SQLSTATE 23000 SET @X2&#x3D;1; SET@x&#x3D;1;<br>INSERT INTO actor(actorid,firstname,lastname）VALUES（201,Test’,201）; SET@x&#x3D;2;<br>INSERT INTO actor(actor_id,first name,last name) VALUES （1,Test’,’1’）; SET @x&#x3D;3；<br>-&gt;END;-&gt;ss<br>Query oK, 0 rows affected (o.o0 sec) mysql&gt; delimiter;<br>mysql&gt; call actor_insertO;<br>Query oK, 0 rows affected (0.06 sec) mysq1&gt; select @x,@x2;<br>I@x@x21 1 row in set (0.00 sec)<br>调用条件处理的过程，再遇到主键冲突的错误时，会按照定义的处理方式进行处理，由于例子中定义的是CONTINUE，所以会继续执行下面的语句。<br>handler_type现在还只支持CONTINUE和EXIT两种，CONTINUE表示继续执行下面的语句，EXIT则表示执行终止，UNDO现在还不支持。<br>condition_value的值既可以是通过DECLARE定义的condition_name，也可以是SQLSTATE 的值或者mysql-error-code的值或者SQLWARNING、NOT FOUND、SQLEXCEPTION，这3 个值是3种定义好的错误类别，分别代表不同的含义。<br>OSQLWARNING是对所有以01开头的SQLSTATE代码的速记。 ONOTFOUND是对所有以O2开头的SQLSTATE代码的速记。<br>OSQLEXCEPTION是对所有没有被SQLWARNING或NOTFOUND捕获的SQLSTATE 代码的速记。<br>因此，上面的例子还可以写成以下几种方式：–捕获mysql-error-code:<br>DECLARE CONTINUE HANDLER FOR 1062 SET @X2&#x3D;1;–事先定义condition_name：<br>DECLARE DuplicateKey CONDITION FOR SQLSTATE23000: DECLARE CONTINUE HANDLER FOR DuplicateKey SET @x2 &#x3D; 1;-捕获SQLEXCEPTION<br>DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET @X2 &#x3D; 1; 10.2.8光标的使用<br>在存储过程和函数中，可以使用光标对结果集进行循环的处理。光标的使用包括光标的声明、OPEN、FETCH和CLOSE，其语法分别如下。<br>声明光标：<br>DECLARE cursor_name CURSOR FOR select_statement<br>OOPEN光标： OPEN cursor_name</p>
<p>≦ 167 ≧<br>10.2存储过程和函数 149<br>OFETCH光标：<br>FETCH [NEXT] FROM] cursornameINTO varnamevarame i<br>CLOSE光标：<br>CLosEcursorame<br>以下例子是一个简单的使用光标的过程，对payment表按照行进行循环的处理，按照 staff_id值的不同累加amount的值，判断循环结束的条件是捕获NOTFOUND的条件，当 FETCH光标找不到下一条记录的时候，就会关闭光标然后退出过程。<br>mysql&gt; delimiter $$ mysq1&gt;<br>mysql&gt; CREATE PRocEDuRE payment stat O)</p>
<blockquote>
<p>BEGIN<br>DECLARE i staff_id int；<br>DECLARE d amount decima1(5,2）；<br>DECLARE cur _payment cursor for select staff <em>id,amount from payment; DECLARE EXIT HANDLER FOR NOT FOUND CLOSE cur_Payment;<br>set @x1&#x3D;0; set @x2&#x3D;0;<br>OPEN cur_payment; REPEAT<br>FETCH cur</em> payment INTO i staff id, d amount; ifi staff id &#x3D;2 then<br>set @x1 &#x3D;@x1 +d amount; else<br>set @x2&#x3D;@x2+d amount; end if;<br>UNTIL O END REPEAT; CLosE cur payment;<br>-&gt;END;-&gt;ss<br>Query ok, 0 rows affected (o.oo sec)<br>mysql&gt; delimiter : mysq1&gt;<br>mysql&gt; call payment statO;<br>Query ok, 0 rows affected (0.11 sec) mysq1&gt; select @x1,@x2;<br>1@x1 1@x2<br>133927.04133489.471 1row in set (o.00 sec)<br>注意：变量、条件、处理程序、光标都是通过DECLARE定义的，它们之间是有先后顺序要求的。<br>变量和条件必须在最前面声明，然后才能是光标的声明，最后才可以是处理程序的声明。<br>10.2.9流程控制<br>下面将逐一进行说明如何使用IF、CASE、LOOP、LEAVE、ITERATE、REPEAT及WHILE 语句来控制流程。<br>1.IF语句<br>IF实现条件判断，满足不同的条件执行不同的语句列表，具体语法如下：</p>
</blockquote>
<p>≦ 168 ≧<br>150 第10章开发常用数据库对象 IF search_condition THEN statement Tist<br>[ELSEIF search_condition THEN statement_list] …[ELSE statement_Tist]<br>END IF<br>10.2.8节中使用光标的例子中已经涉及了IF语句的使用，这里就不再举例说明了。 2.CASE语句<br>CASE实现比IF更复杂一些的条件构造，具体语法如下： CASE case_value<br>WHEN when_value THEN statement_list<br>[WHEN when_value THEN statement_Tist].[ELSE statement_list]<br>END CASE<br>或者： CASE<br>WHEN search_condition THEN statement_list<br>[WHEN search_condition THEN statement_list].[ELSE statement_list]<br>END CASE<br>在上文光标的使用例子中，IF语句也可以使用CASE语句来完成：<br>case<br>when i staff_id&#x3D;2 then set @x1&#x3D;@x1+ damount; else<br>set @x2&#x3D;@x2+damount; end case;<br>或者：<br>case i _staff_id when 2 then<br>set @x1&#x3D;@x1+d amount; else<br>set @x2&#x3D;@x2+d amount; end case;<br>3.LOOP语句<br>LOOP实现简单的循环，退出循环的条件需要使用其他的语句定义，通常可以使用LEAVE<br>语句实现，具体语法如下：[begin_label:] Loop<br>statement_list<br>END LoOP [end_labe7]<br>如果不在statementlist中增加退出循环的语句，那么LOOP语句可以用来实现简单的死循环。 4.LEAVE语句<br>LEAVE语句用来从标注的流程构造中退出，通常和BEGIN..END或者循环一起使用。下面是一个使用LOOP和LEAVE的简单例子，循环100次向actor表中插入记录，当插<br>人100条记录后，退出循环：<br>mysql&gt; CREATE PROCEDURE actor_insert ()<br>-&gt;BEGIN<br>set @x&#x3D;0; ins: LOOP<br>set@x&#x3D;@x+1; IF @x&#x3D;100 then<br>leave ins; END IF;</p>
<p>≦ 169 ≧<br>10.2存储过程和函数 151<br>INSERT INTO actor(first name,last_name) VALUEs （’Test’,<em>201’);<br>END LOOP ins;<br>-&gt;END;-&gt;ss<br>Query ok,0 rows affected (o.o0 sec) mysql&gt; call actor_insertO;<br>Query oK,0 rows affected (0.01 sec)<br>mysql&gt; select count(</em>) from actor where first_name&#x3D;’Test’;<br>count（*）1 100<br>1row in set (o.00 sec) 5.ITERATE语句<br>ITERATE语句必须用在循环中，作用是跳过当前循环的剩下的语句，直接进入下一轮循环。下面的例子使用了ITERATE语句，当@x变量是偶数的时候，不再执行循环中剩下的语句，<br>而直接进行下一轮循环：<br>mysql&gt; CREATE PROCEDURE actor_insert ()<br>-&gt;BEGIN<br>set@x&#x3D;0;</p>
<blockquote>
<p>ins:LOOP-&gt; set@x&#x3D;@x+1;-&gt; IF @x&#x3D;10 then<br>leave ins;-√ ELSEIF mod（@x,2)&#x3D;0 then<br>ITERATE ins;<br>-&gt; END IF;<br>-&gt; INSERT INTO actor(actor_id,first name,last name) VALUEs （@x+20O,Test’,@x）;<br>END LOOP ins;</p>
<p>-&gt;END;-&gt;ss<br>Query oK,0 rows affected (o.oo sec) mysql&gt; call actor_insertO;<br>Query oK,O rows affected (o.o0 sec)<br>mysql&gt; select actor id,first name,last name from actor where first name&#x3D;’Test’; Iactor id| first name | last name|<br>1201 ITest 11 203 Test<br>205 Test 5 207 ITest 17 209 |Test 19<br>5 rows in set (0.00 sec) 6.REPEAT语句<br>有条件的循环控制语句，当满足条件的时候退出循环，具体语法如下：[begin_label:] REPEAT<br>statement_7ist<br>UNTIL search_condition END REPEAT [end_label]<br>10.2.8节中的示例使用了REPEAT语句来实现光标的循环获得，下面节选的代码就是其中使用REPEAT语句的部分，详细的执行过程可以参照10.2.8节，这里不再赘述。</p>
</blockquote>
<p>≦ 170 ≧<br>152 第10章开发常用数据库对象<br>REPEAT<br>FETCH cur <em>payment INTo i staff_id, d amount;<br>-&gt; ifi staff id &#x3D;2 then<br>-&gt; set @x1 &#x3D; @x1 + d amount;<br>else<br>set @x2&#x3D;@x2+d amount;<br>-&gt; end if;<br>UNTIL O END REPEAT;<br>7.WHILE语句<br>WHILE语句实现的也是有条件的循环控制语句，即当满足条件时执行循环的内容，具体语法如下：<br>[begin</em> label:] WHILE search_condition Do<br>statement list<br>END WHILE [end labe7]<br>WHILE循环和REPEAT循环的区别在于：WHILE是满足条件才执行循环，REPEAT是满足条件退出循环；WHILE在首次循环执行之前就判断条件，所以循环最少执行O次，而 REPEAT是在首次执行循环之后才判断条件，所以循环最少执行1次。<br>以下例子用来对比REPEAT和WHILE语句的功能： mysql&gt; delimiter ss<br>mysql&gt; CREATE PROCEDURE loop_demo O</p>
<blockquote>
<p>BEGIN<br>set @x&#x3D;1,@x1&#x3D;1; REPEAT<br>set@x&#x3D;@x+1;<br>until @x&gt;0 end repeat; while@x1&lt;0do<br>set @x1&#x3D;@x1+1; end while;<br>END;-&gt;$$<br>Query ok,0 rows affected (o.oo sec) mysql&gt; delimiter ；<br>mysql&gt; call 1oop demo(）;<br>Query ok,o rows affected (o.oo sec) mysql&gt; select @x,@x1;<br>@x1<br>1 row in set (0.00 sec)<br>从判断的条件上看，初始值都是满足退出循环的条件的，但是REPEAT循环仍然执行了<br>一次以后才退出循环，而WHILE循环则一次都没有执行。 10.2.10事件调度器<br>事件调度器是MySQL5.1后新增的功能，可以将数据库按自定义的时间周期触发某种操作，可以理解为时间触发器，类似Linux系统下的任务调度器crontab。<br>下面是一个最简单的事件调度器： CREATE EVENTmyeVent<br>ON SCHEDULE AT CURRENT TIMESTAMP +INTERVAL 1 HOUR</p>
</blockquote>
<p>≦ 171 ≧<br>10.2存储过程和函数 153<br>DO<br>UPDATE myschema.mytable SET mycol &#x3D; mycol + 1; 其中：<br>事件名称在create event关键字后指定；<br>O通过ONSCHEDULE子句指定事件在何时执行及执行频次；通过DO子句指定要执行的具体操作或事件。<br>上述创建的调度事件首先创建了myevent调度事件，然后执行更新操作，起始执行时间为调度器创建时间，后续在起始时间的基础上每隔1小时触发一次。<br>下面通过一个完整的实例来熟悉事件调度器的使用。（1）创建测试表test：<br>mysql&gt; create table test(idl varchar(10),create time datetime); Query ok,0rows affected (0.19 sec)<br>（2）创建事件调度器test_event_1，每隔5s向test表插人一条记录： mysql&gt; CREATE EVENT test event 1<br>-&gt;ON SCHEDULE-&gt;EVERY 5 SECOND-V DO</p>
<blockquote>
<p>INSERT INTO test.test（idl,create time)-&gt;VALuEs （’test′,nowO）;<br>Query oK,0 rows affected (0.o5 sec)（3）查看调度器状态：<br>mysql&gt; show events \G;<br>1<br>光米水水道<br>Db:test<br>Name:test event_1 Definer: root@localhost Time zone: SYSTEM<br>Type: RECURRING<br>Execute at: NULL Interval value:5<br>Interval field: SEcoND<br>starts:2013-07-26 14:02:02<br>Ends:NULL Status: ENABLED originator:8306<br>character set_client:latinl<br>collation_connection :latinl swedish_ci Database Collation: gbk_chinese_ci 1 row in set(o.00 sec)<br>（4）隔几秒后，查看test表，发现并没有数据插入：<br>mysql&gt; select * from test; Empty set (O.00 sec)<br>（5）查看事件调度器状态，发现默认是关闭的： mysql&gt; show variables like %scheduler%;<br>Ivariable_name IValue丨<br>I event scheduler | oFF 1row in set (0.01 sec)<br>（6）通过下面的命令打开调度器，同时showprocesslist发现新产生一个后台进程：<br>mysql&gt; SET GLoBAL event scheduler &#x3D; 1; Query ok, 0 rows affected (o.oo sec)<br>mysql&gt; show variables like %scheduler%’;</p>
</blockquote>
<p>≦ 172 ≧<br>154 第10章开发常用数据库对象<br>|variable_name |Value|<br>| event scheduler | ON 1row in set (0.01 sec)<br>mysql&gt; show processlist \G;（前面省略）<br>Id:464905<br>User: event_scheduler<br>Host:localhost db:NULL<br>Command :Daemon Time :1<br>State : waiting for next activation Info :NULL<br>Rows sent:0 Rows examined:0<br>Rows read:1<br>4rows in set (o.00 sec)<br>（7）隔几秒后，再次查看test表，发现已经有了一些数据，且日期间隔都为5s：<br>mysql&gt; select * from test; I idl l create time<br>1test|2013-07-2905:28:48 1test|2013-07-2905:28:53 1 test12013-07-2905:28:581 |test|2013-07-2905:29:03<br>（8）为了防止表变得很大，创建一个新的调度器，每隔1min清空一次test表：<br>CREATE EVENT trunC test ON SCHEDULE eVery 1 MINUTE DO TRUNCATE TABLE teSt;<br>隔一段时间后，可以发现，test表中数据会定期清空，这类触发器非常适合去定期清空临时表或者日志表。<br>（9）如果事件调度器不再使用，可以禁用（disable）或者删除（drop）掉：–禁用event<br>mysql&gt; alter event test event 1 disable; Query oK,O rows affected (o.o0 sec)–删除event<br>mysql&gt; drop event test event 1;<br>Query ok,O rows affected (o.05 sec)<br>对于事件调度器，还有很多选项，比如指定事件开始时间和结束时间，或者指定某个时间执行一次而不是循环执行，详细信息可以参考事件调度器的相关帮助，这里不再详述。<br>最后，总结一下事件调度器的优势、适用场景及使用中的注意事项，如表10-1所示。<br>表10-1 事件调度器的优势、适用场景及注意事项<br>事件调度器说明<br>MySQL事件调度器部署在数据库内部由DBA或专人统一维护和管理，避免将一些数据库相关的定<br>优势时任务部署在操作系统层，减少操作系统管理员产生误操作的风险，对后续的管理和维护也非常有<br>益。例如，后续进行数据库迁移时无须再迁移操作系统层的定时任务，数据库迁移本身已经包含了调度事件的迁移<br>适用场景事件调度器适用于定期收集统计信息、定期清理历史数据、定期数据库检查（例如，自动监控和恢<br>复Slave失败进程）</p>
<p>≦ 173 ≧<br>10.3触发器 155<br>续表<br>事件调度器 说明<br>在繁忙且要求性能的数据库服务器上要慎重部署和启用调度器<br>注意事项 过于复杂的处理更适合用程序实现<br>开启和关闭事件调度器需要具有超级用户权限<br>10.3触发器<br>MySQL从5.0.2版本开始支持触发器的功能。触发器是与表有关的数据库对象，在满足定义条件时触发，并执行触发器中定义的语句集合。触发器的这种特性可以协助应用在数据<br>库端确保数据的完整性。本章将详细介绍MySQL中触发器的使用方法。 10.3.1创建触发器<br>创建触发器的语法如下：<br>CREATE TRIGGER trigger_name trigger_time trigger_event<br>ON tbl_name FOR EACH RoW [trigger_order] trigger_body<br>注意：触发器只能创建在永久表（PermanentTable）上，不能对临时表（TemporaryTable）创建触<br>发器。<br>其中trigger_time是触发器的触发时间，可以是BEFORE或者AFTER，BEFORE的含义指在检查约束前触发，而AFTER是在检查约束后触发。<br>而trigger_event就是触发器的触发事件，可以是INSERT、UPDATE或者DELETE。<br>使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还只支持行级触发，不支持语句级触发。<br>在样例数据库中，为film表创建了AFTERINSERT的触发器，具体如下： DELIMITER $S<br>CREATE TRIGGER ins_film<br>AFTER INSERT ON film FOR EACH ROW BEGIN<br>INSERT INTo film_text （film id,title,description)<br>VALUEs (new.film_id,new.title,new.description);<br>END; $S<br>delimiter;<br>插入film表记录的时候，会向film_text表中也插入相应的记录。<br>mysql&gt; INSERT INTo film VALUEs-&gt;(1001,’ACADEMY DINOSAUR′，</p>
<blockquote>
<p>‘A Epic Drama of a Feminist And a Mad Scientist who must Battle a Teacher in The Canadian Rockies’,-&gt;2006,1,UL,6,0.9986,20.99,G,eted Scenes,ehind theSnes206-02-1505:03:42； Query ok,1 row affected (o.o5 sec)<br>mysql&gt; select * from film text where film id&#x3D;1001 \G<br>film_id:1001<br>title: ACADEMY DINOSAUR<br>description:A Epic Drama of a Feminist And a Mad Scientist who must Battle a Teacher in The Canadian Rockies<br>1row in set (o.00 sec)<br>对于INSERTINTO…ONDUPLICATEKEYUPDATE…语句来说，触发触发器的顺序可</p>
</blockquote>
<p>≦ 174 ≧<br>156 第10章开发常用数据库对象<br>能会造成疑惑。下面对film表分别创建BEFOREINSERT、AFTERINSERT、BEFORE<br>UPDATE、AFTERUPDATE触发器，然后插入记录，观察触发器的触发情况：一创建 BEFORE INSERT、AFTER INSERT、BEFORE UPDATE、AFTER UPDATE触发器<br>mysql&gt; create table tri _demo(id int AUTo INCREMENT,note varchar(2O),PRIMARY KEY (id));<br>Query ok,0 rows affected (o.03 sec) mysql&gt; CREATE TRIGGER ins _film_bef</p>
<blockquote>
<p>BEFORE INSERT ON film FOR EACH ROW BEGIN<br>INSERT INTo tri demo (note) VALUEs (‘before insert’);<br>-&gt; END;-&gt;Ss<br>Query ok,o rows affected (o.oo sec) mysql&gt; CREATE TRIGGER ins_film aft<br>AFTER INSERT ON film FOR EACH ROW BEGIN<br>INSERT INTo tri demo (note) VALUES (‘after insert’）;<br>-&gt; END-&gt;SS<br>Query ok,o rows affected (o.oo sec) mysql&gt; CREATE TRIGGER upd film bef<br>-&gt; BEFORE update ON film FOR EACH ROW BEGIN<br>INSERT INTo tri demo (note) VALUEs (‘before update’）;<br>-&gt;END;-&gt;SS<br>Query ok,o rows affected co.oo sec) mysql&gt; CREATE TRIGGER upd film_aft<br>AFTER update ON film FOR EACH ROW BEGIN<br>INSERT INTO tri demo (note) VALUEs (‘after update’）；<br>-&gt; END;-&gt;S$<br>Query ok,o rows affected (o.oo sec) 一插入记录已经存在的情况<br>mysql&gt; select film id,title from film where film id &#x3D; 1001; I filmid l title<br>11001 ACADEMY DINOSAUR 1 row in set (o.00 sec)<br>mysql&gt; INSERT INTo film VALUEs-&gt;(1001,’only test’，<br>0n1y test′,2006,1,NULL,6,0.99,86,’20.99′,PG<br>Deleted Scenes,Behind the scenes,2006-02-15 05:03:42’)-&gt; ON DUPLICATE KEY<br>-&gt; UPDATE title&#x3D;’update record’; Query ok,2 rows affected (0.05 sec) mysql&gt; select * from tri demo;<br>id note<br>before insert Ibefore update after update<br>3rows in set (o.o0 sec) 插入新记录的情况<br>mysql&gt; delete from tri demo;<br>Query ok, 3 rows affected (o.o0 sec)<br>mysql&gt; select fi1m id,title from film where film id &#x3D; 1002; Empty set (o.00 sec)</p>
</blockquote>
<p>≦ 175 ≧<br>10.3触发器 157<br>mysql&gt; INSERT INTo film VALUES<br>-&gt;（1002,‘only test’</p>
<blockquote>
<p>on1y test,2006,1,NULL,6,0.99′,86,20.99,PG’，<br>Deleted Scenes,Behind the Scenes,2006-02-15 05:03:42’) &gt;ON DUPLICATE KEY<br>-&gt; UPDATE title&#x3D;’update record’; Query ok,1 row affected (0.05 sec) mysq1&gt;<br>mysql&gt; select * from tri_demo; Iid lnote<br>I before insert lafter insert<br>2rows in set (0.00 sec)<br>从上面的例子可以知道，对于有重复记录、需要进行UPDATE操作的INSERT，触发器触发的顺序是BEFOREINSERT、BEFOREUPDATE、AFTERUPDATE；对于没有重复记录的INSERT，就是简单地执行INSERT操作，触发器触发的顺序是BEFOREINSERT、AFTER INSERT。对于那些实际执行UPDATE操作的记录，仍然会执行BEFOREINSERT触发器的<br>内容，在设计触发器的时候一定要考虑这种情况，避免错误地触发触发器。 10.3.2 删除触发器<br>一次可以删除一个触发程序，如果没有指定schema_name，默认为当前数据库，具体语法如下：<br>DRoPRGGERschemanaetriggername<br>例如，要删除film表上的触发器ins_film，可以使用以下命令： mysql&gt; drop trigger ins_fi1m;<br>Query ok,0 rows affected (o.o0 sec) 10.3.3查看触发器<br>可以通过执行SHOWTRIGGERS命令查看触发器的状态、语法等信息，但是因为不能查询指定的触发器，所以每次都返回所有的触发器的信息，使用起来不是很方便，具体语法如下：<br>mysql&gt; show triggers \G<br>Trigger: customer create date<br>Event: INSERT Table: customer<br>Statement: SET NEw.create date &#x3D; NoW)<br>Timing: BEFORE Created:NULL<br>SqmOdTICANSTAEITAAESEINATEEATEFOIVI BY_ZERO,TRADITIONAL,NO_AUTO_CREATEUSER<br>Definer: root@localhost ★★★<strong>★</strong>★<em>★★★★★</em><br>另一个查看方式是查询系统表的information_schema.triggers表，这个方式可以查询指定触发器的指定信息，操作起来明显很方便：</p>
</blockquote>
<p>≦ 176 ≧<br>158 第10章开发常用数据库对象 mysql&gt; desc triggers;<br>Field 丨Type |Null |Key 丨 Default 丨 Extra丨<br>TRIGGER CATALOG 1varchar(512)|YEs TRIGGER SCHEMA 1varchar(64) NO TRIGGER NAME 1varchar(64) NO EVENT MANIPULATION varchar(6) NO EVENT OBJECT_CATALOG 1varchar(512) YES EVENTOBJECT_SCHEMA 1varchar(64) NO IEVENT OBJECT TABLE 1varchar(64) NO ACTION_ORDER 1bigint(4) NO ACTION_CONDITION 1 longtext YES ACTION STATEMENT longtext NO ACTION ORIENTATION |varchar(9) NO ACTION_TIMING varchar(6) NO ACTION REFERENCE OLD_TABLE varchar(64) YES ACTION REFERENCE NEW TABLE varchar(64) YES IACTION REFERENCE OLD_ROW varchar(3) NO ACTION REFERENCE NEW ROW Ivarchar(3) NO 1CREATED datetime IYES ISQL MODE |longtext INO IDEFINER Tongtext INO<br>19 rows in set (o.00 sec)<br>mysql&gt; select * from triggers where trigger name &#x3D;’ins film bef’G<br>TRIGGER CATALOG:NULL TRIGGER SCHEMA: sakila<br>TRIGGER NAME: ins film bef<br>EVENT MANIPULATION:INSERT EVENT_OBJECT CATALOG:NULL EVENT OBJECT SCHEMA: sakila EVENT OBJECT_TABLE:film<br>ACTION ORDER:0 ACTION CONDITION: NULL ACTION_STATEMENT: BEGIN<br>INSERT INTo tri demo (note) VALuEs (‘before insert’）; END<br>ACTION ORIENTATION: ROW<br>ACTION TIMING: BEFORE<br>ACTION REFERENCE OLD TABLE: NULL ACTION REFERENCE NEW TABLE: NULL ACTION REFERENCE OLD ROW:OLD ACTION REFERENCE NEW ROW: NEW<br>CREATED: NULL SQL MODE:<br>DEFINER:root@localhost<br>1 row in set (0.01 sec) 10.3.4触发器的使用<br>触发器执行的语句有以下两个限制。<br>触发程序既不能调用将数据返回客户端的存储程序，也不能使用采用CALL语句的动态SQL语句，但是允许存储程序通过参数将数据返回触发程序。也就是存储过程或者函数通过OUT或者INOUT类型的参数将数据返回触发器是可以的，但是不能调用直接返回数据的过程。<br>不能在触发器中使用以显式或隐式方式开始或结束事务的语句，如STARTTRANS-ACTION、COMMIT 或ROLLBACK。</p>
<p>≦ 177 ≧<br>10.4小结 159<br>MySQL的触发器是按照BEFORE触发器、行操作、AFTER触发器的顺序执行的，其中任何一步操作发生错误都不会继续执行剩下的操作。如果是对事务表进行的操作，那么会整个作为一个事务被回滚（Rollback），但是如果是对非事务表进行的操作，那么已经更新的记<br>录将无法回滚，这也是设计触发器的时候需要注意的问题。 10.4小结<br>本章主要介绍了MySQL提供的视图、存储过程、函数、触发器的创建、维护等相关语法，也介绍了它们分别适用的场合，但是由于篇幅问题，本章并没有对这部分内容进行深入，读者如果有兴趣，可以查询在线的MySQL文档获得帮助。<br>关于触发器这部分，需要特别注意的是触发器是行触发的，每次增加、修改或者删除记录都会触发进行处理，编写过于复杂的触发器或者增加过多的触发器对记录的插人、更新、删除操作肯定会有比较严重的影响，因此在设计数据库的时候要有所考虑，不要将应用的处理逻辑过多地依赖于触发器来处理。</p>
<p>≦ 178 ≧<br>第11章 事务控制和锁定语句<br>MySQL支持对MyISAM和MEMORY存储引擎的表进行表级锁定，对BDB存储引擎的表进行页级锁定，对InnoDB存储引擎的表进行行级锁定。默认情况下，表锁和行锁都是自动获得的，不需要额外的命令。但是在有的情况下，用户需要明确地进行锁表或者进行事务的控制，以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。<br>有关锁机制、不同存储引擎对锁的处理、死锁等内容，将会在后面的优化篇中进行更详<br>细的介绍，有兴趣的读者可以参见相关的章节。 11.1 LOCK TABLES 和 UNLOCK TABLES<br>LOCKTABLES可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。<br>UNLOCKTABLES可以释放当前线程获得的任何锁定。当前线程执行另一个LOCK TABLES时，或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁，具体语法如下：<br>LOCK TABLES<br>tbl_name [AS aTias] {READ [LOCAL] I [LOW_PRIORITY] WRITE}<br>[,tbl_name [AS alias] {READ [LOCAL] I [LOW_PRIORITY] WRITE}] UNLOCK TABLES<br>表11-1给出了一个获得表锁和释放表锁的简单例子，其中film_text表获得read锁的情况，其他session更新该表记录会等待锁，film_text表释放锁以后，其他session可以进行更新操作。其中session1和 session2表示两个同时打开的 session，表格中的每一行表示同一时刻两个session 的运行状况，后面的例子也都是同样格式，这里不再赘述。<br>表11-1 一个获得表锁和释放表锁的简单例子<br>session_1 session_2<br>获得表film_text的READ锁定： mysql&gt; lock table film_text read; Query OK,0 rows affected (0.00 sec)</p>
<p>≦ 179 ≧<br>11.2事务控制 161<br>续表<br>session_1 session_2<br>当前session可以查询该表记录： 其他session也可以查询该表的记录：<br>mysql&gt; select film_id,title from film_text where film_id&#x3D; mysql&gt; select film_id,title from film_text where film_id&#x3D; 1001; 1001;<br>flm_id|title filmid |title<br>|1001 |ACADEMYDINOSAUR |1001 |ACADEMY DINOSAUR| 1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>其他session更新锁定表会等待获得锁：<br>mysql&gt;update film_text set title &#x3D;Test’where film_id&#x3D;1001; 等待<br>释放锁：<br>mysql&gt; unlock tables; 等待 Query OK, 0 rows affected (0.00 sec)<br>Session获得锁，更新操作完成：<br>mysql&gt;update film_text set title &#x3D;Testwhere film_id&#x3D; 1001;<br>Query OK, 1 row affected (1 min 0.71 sec) Rows matched:1 Changed:1 Warnings:0<br>有关表锁的使用，可以参见16.2节以获得更详细的信息。<br>注意：LOCKTABLES&#x2F;UNLOCKTABLES有时也写为LOCKTABLE&#x2F;UNLOCKTABLE，两种写法<br>含义一致。<br>11.2事务控制<br>MySQL通过SETAUTOCOMMIT、START TRANSACTION、COMMIT和ROLLBACK<br>等语句支持本地事务，具体语法如下： START TRANSACTIONI BEGIN WORKJ<br>COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] SET AUTOCOMMIT&#x3D;{O&#x2F;1}<br>默认情况下，MySQL是自动提交（Autocommit）的。如果需要通过明确的Commit和 Rollback来提交和回滚事务，那么就需要通过明确的事务控制命令来开始事务，这是和Oracle 的事务管理明显不同的地方。如果应用是从Oracle数据库迁移到MySQL数据库，则需要确保应用中是否对事务进行了明确的管理。<br>。 STARTTRANSACTION或BEGIN语句可以开始一项新的事务。 OCOMMIT和ROLLBACK用来提交或者回滚事务。<br>OCHAIN和RELEASE子句分别用来定义在事务提交或者回滚之后的操作，CHAIN会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE则会断开和客户端的连接。<br>OSETAUTOCOMMIT可以修改当前连接的提交方式，如果设置了SETAUTOC-OMMIT&#x3D;O，则设置之后的所有事务都需要通过明确的命令进行提交或者回滚。<br>如果只是对某些语句需要进行事务控制，则使用STARTTRANSACTION语句开始一个</p>
<p>≦ 180 ≧<br>162 第11章事务控制和锁定语句<br>事务比较方便，这样，事务结束之后可以自动回到自动提交的方式。如果希望所有的事务都不是自动提交的，那么通过修改AUTOCOMMIT来控制事务比较方便，这样不用在每个事务开始的时候再执行STARTTRANSACTION语句。<br>表11-2中的例子演示了使用STARTTRANSACTION开始的事务在提交后自动回到自动提交的方式；如果在提交时使用COMMITANDCHAIN，那么会在提交后立即开始一个新的事务。<br>表11-2 STARTTRANSACTION和COMMITANDCHAIN的使用例子<br>session_1 session_2<br>从表actor中查询actor_id&#x3D;201的记录，结果为空： 从表actor中查询actor_id&#x3D;201的记录，结果为空： mysql&gt; select * from actor where actor id&#x3D;201; mysql&gt;select *from actor where actor id &#x3D;201;<br>Empty set (0.00 sec) Empty set (0.00 sec) 用start transaction命令启动一个事务，往表actor中插入一条<br>记录，没有commit： mysql&gt; start transaction;<br>Query OK,0 rows affcted (0.00 sec)<br>mysq&gt;insert into actor(actor idfirst name,last name) values(201,Lisa’,Tom’);<br>Query OK,1 row affected (0.00 sec)<br>查询表actor，结果仍然为空：<br>mysql&gt; select *from actor where actor id&#x3D;201; Empty set (0.00 sec)<br>执行提交：<br>mysql&gt; commit;<br>Query OK,0rows affected(0.04 sec)<br>再次查询表actor，可以查询到结果：<br>mysql&gt; select actor_id,last_name from actor where actor id in (201,202);<br>actor id|last _name|<br>|201 |Tom 1 row in set (0.00 sec)<br>这个事务是按照自动提交执行的：<br>mysql&gt; nsert into actor(actor idfirstname,last_name)values202, Lisa’,Lan’);<br>QueryOK,1row affected(0.04 sec)<br>可以从actor表中查询到session1刚刚插入的数据：<br>mysql&gt;select actor_idlastname from actorwhere actorid in (201,202);<br>actor id |last _name<br>|201 Tom |202 Lan<br>2rows in set (0.00 sec)</p>
<p>≦ 181 ≧<br>11.2 事务控制 163<br>续表<br>session_1 session_2<br>重新用starttransaction启动一个事务： mysql&gt; start transaction;<br>QueryOK,0rows affected0.00 sec) 往表actor中插入一条记录：<br>mysql&gt;ert nto actr(actridfrstname,lastam) values(203,Lisa,TT);<br>Query OK,1row affected (0.00 sec)<br>用commitandchain命令提交： mysql&gt;commit and chain;<br>Query OK,0rows affcted (0.03 sec) 此时自动开始一个新的事务：<br>mysq&gt;insert into actor (actor_idfirst_name,lastname) values(204,Lisa,Mou);<br>Query OK, 1 row affected (0.00 sec)<br>session1刚插入的记录无法看到：<br>mysql&gt; select actor_id，last_name from actor where<br>first_name&#x3D;’Lisa’; actor_id|last_name<br>|178[MONROET 1201 Tom<br>1202 |Lan 1203 |TT<br>4rows in set (0.00 sec)<br>用commit命令提交： mysql&gt; commit;<br>Query OK,0rows affected (0.06 sec)<br>sessionl插入的新记录可以看到：<br>mysql&gt; select actor id，last_name from actor where<br>first_name&#x3D;’Lisa’; actor _id|last_name<br>|178 MONROET |201 |Tom<br>|202 |Lan |203 |TT<br>|204 |Mou 5 rows in set (0.00 sec)<br>如果在锁表期间，用starttransaction命令开始一个新事务，则会造成一个隐含的UNLOCK TABLES被执行，如表11-3所示。<br>表11-3 starttransaction导致的UNLOCKTABLES<br>session_1 session_2<br>从表actor中查询actor_id&#x3D;201的记录，结果为空：从表actor中查询actor_id&#x3D;201的记录，结果为空： mysql&gt;select <em>from actor where actor_id&#x3D;201; mysql&gt; select</em>from actor where actor_id&#x3D;201;<br>Empty set (0.00 sec) Empty set (0.00 sec) 对表actor加写锁：<br>mysql&gt;lock table actor write;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>≦ 182 ≧<br>164 第11章事务控制和锁定语句<br>续表<br>session_1 session_2<br>对表actor的读操作被阻塞：<br>mysql&gt; select actor_id,last_name from actor where actor_id&#x3D;<br>201; 等待<br>插入一条记录：<br>mysql&gt;insert into actor(actor id,first_name, 等待<br>last_name) values(201,Lisa,，Tom); Query OK, 1 row affected (0.04 sec) 回滚刚才的记录：<br>mysql&gt;rollback; 等待 Query OK, 0 rows affected (0.00 sec)<br>用starttransaction命令重新开始一个事务：<br>mysql&gt; start transaction; 等待 Query OK, 0 rows affected (0.00 sec)<br>session1开始一个事务时，表锁被释放，可以查询：<br>mysql&gt; select actor_id，last_name from actorwhere actor_id&#x3D; 201;<br>actor_id|last_name| |201 |Tom 1 row in set (17.78 sec)<br>对lock方式加的表锁，不能通过rollback进行回滚<br>因此，在同一个事务中，最好使用相同存储引引擎的表，否则ROLLBACK时需要对非事务类型的表进行特别的处理，因为COMMIT、ROLLBACK只能对事务类型的表进行提交和回滚。<br>通常情况下，只对提交的事务记录到二进制的日志中，但是如果一个事务中包含非事务类型的表，那么回滚操作也会被记录到二进制日志中，以确保非事务类型表的更新可以被复制到从数据库（Slave）中。<br>和Oracle的事务管理相同，所有的DDL语句是不能回滚的，并且部分的DDL语句会造成隐式的提交。<br>在事务中可以通过定义SAVEPOINT，指定回滚事务的一个部分，但是不能指定提交事务的一个部分。对于复杂的应用，可以定义多个不同的SAVEPOINT，满足不同的条件时，回滚不同的SAVEPOINT。需要注意的是，如果定义了相同名字的SAVEPOINT，则后面定义的 SAVEPOINT会覆盖之前的定义。对于不再需要使用的SAVEPOINT，可以通过RELEASE SAVEPOINT命令删除SAVEPOINT，删除后的SAVEPOINT不能再执行ROLLBACKTO SAVEPOINT命令。<br>表11-4中的例子就是模拟回滚事务的一个部分，通过定义SAVEPOINT来指定需要回滚的事务的位置。<br>表11-4 模拟回滚事务<br>session_1 session_2<br>从表actor中查询first_name&#x3D;Simon’的记录，结果为空：从表actor中查询first_name&#x3D;Simon’的记录，结果为空： mysql&gt; select *from actor where first _name &#x3D;’Simon’; mysql&gt; select *from actor where first _name &#x3D; ‘Simon’； Empty set (0.00 sec) Empty set (0.00 sec)</p>
<p>≦ 183 ≧<br>11.2 事务控制 165<br>续表<br>session_1<br>启动一个事务，往表actor中插入一条记录： mysql&gt; start transaction;<br>QueryOK,0rows affected(0.02 sec)<br>mysql&gt;insert into actor(actor id,firstname, last_name) values(301,Simon,Tom);<br>Query OK,1 row affected (0.00 sec) 可以查询到刚插入的记录：<br>mysql&gt; select actor id,last_name from actor where first_name 无法从actor表中查到session1刚插入的记录： &#x3D;’Simon’; mysql&gt; select * from actor where first name &#x3D; ‘Simon’;<br>Empty set (0.00 sec)<br>[actor id |last_name|<br>|301 Tom 1 row in set (0.00 sec)<br>定义savepoint，名称为 test： mysql&gt; savepoint test;<br>Query OK,Orows affected (0.00 sec) 继续插入一条记录：<br>mysql&gt; insert into actor (actor id,first_name,last name) values(302,Simon’,Cof);<br>Query OK,1 row affected (0.00 sec) 可以查询到两条记录：<br>mysql&gt;select actor_id,last_name from actor where firstname &#x3D;’Simon’;<br>仍然无法查询到结果：<br>|actor_id last _name|<br>mysql&gt; select *from actor where first_name &#x3D;Simon’;<br>|301 Tom Empty set (0.00 sec) |302 |Cof 2 rows in set (0.00 sec)<br>回滚到刚才定义的 savepoint： mysql&gt; rollback to savepoint test; Query OK, 0 rows affected (0.00 sec)<br>只能从表actor中查询到第一条记录，因为第二条已经被回滚： mysql&gt; select actorid,last_name from actor wherefirstname &#x3D;’Simon’;<br>仍然无法查询到结果：<br>|actor id |last_name| mysql&gt; select *from actor where first_name &#x3D;’Simon’;<br>Empty set (0.00 sec)<br>|301 1Tom<br>1 row in set (0.00 sec) 用commit命令提交： mysql&gt; commit;<br>Query OK, 0 rows affected (0.05 sec)<br>只能从actor表中查询到第一条记录：只能从actor表中查询到sessionl插入的第一条记录： mysql&gt; select actor_id,lastname from actor where firstname mysql&gt;select actor_id,last_name from actor where first_name &#x3D;’Simon’; &#x3D;’Simon’;<br>actor_id |last_name| |actor id |last_name|<br>|301[Tom 1301 Tom<br>1 row in set (0.00 sec) 1 row in set (0.00 sec)</p>
<p>≦ 184 ≧<br>166 第11章事务控制和锁定语句 11.3分布式事务的使用<br>MySQL从5.0.3版本起开始支持分布式事务，当前分布式事务只支持InnoDB存储引擎。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。<br>11.3.1分布式事务的原理<br>在MySQL中，使用分布式事务的应用程序涉及一个或多个资源管理器和一个事务管理器。 O资源管理器（RM）用于提供通向事务资源的途径。数据库服务器是一种资源管理器。<br>该管理器必须可以提交或回滚由RM管理的事务。例如，多台MySQL数据库作为多台资源管理器或者几台MySQL服务器和几台Oracle服务器作为资源管理器。<br>事务管理器（TM）用于协调作为一个分布式事务一部分的事务。TM与管理每个事务的RMs进行通信。在一个分布式事务中，各个单个事务均是分布式事务的“分支事务”。分布式事务和各分支通过一种命名方法进行标识。<br>MySQL执行XAMySQL时，MySQL服务器相当于一个用于管理分布式事务中的XA事务的资源管理器。与MySQL服务器连接的客户端相当于事务管理器。<br>要执行一个分布式事务，必须知道这个分布式事务涉及哪些资源管理器，并且把每个资源管理器的事务执行到事务可以被提交或回滚时。根据每个资源管理器报告的有关执行情况的内容，这些分支事务必须作为一个原子性操作全部提交或回滚。要管理一个分布式事务，必须要考虑任何组件或连接网络可能会出现故障。<br>用于执行分布式事务的过程使用两阶段提交，发生时间在由分布式事务的各个分支需要进行的行动已经被执行之后。<br>在第一阶段中，所有的分支被预备好。即它们被TM告知要准备提交。通常，这意味着用于管理分支的每个RM会记录对于被稳定保存的分支的行动。分支指示是否它们可以这么做。这些结果被用于第二阶段。<br>在第二阶段中，TM告知RMs是否要提交或回滚。如果在预备分支时，所有的分支指示它们将能够提交，则所有的分支被告知要提交。如果在预备时，有任何分支指示它将不能提交，则所有分支被告知回滚。<br>在有些情况下，一个分布式事务可能会使用一阶段提交。例如，当一个事务管理器发现，一个分布式事务只由一个事务资源组成（即单一分支），则该资源可以被告知同时进行预备和提交。 11.3.2分布式事务的语法<br>分布式事务（XA事务）的SQL语法如下： XA {START&#x2F;BEGIN} Xid [JOIN&#x2F;RESUME]<br>XASTARTxid用于启动一个带给定xid值的XA事务。每个XA事务必须有一个唯一的 xid值，因此该值当前不能被其他的XA事务使用。xid是一个XA事务标识符，用来唯一标识一个分布式事务。xid值由客户端提供，或由MySQL服务器生成。xid值包含1~3个部分：</p>
<p>≦ 185 ≧<br>11.3分布式事务的使用 167<br>xid: gtrid [, bqual [, formatID J]<br>gtrid是一个分布式事务标识符，相同的分布式事务应该使用相同的gtrid，这样可以明确知道XA事务属于哪个分布式事务。<br>bqual是一个分支限定符，默认值是空串。对于一个分布式事务中的每个分支事务， bqual值必须是唯一的。<br>formatID是一个数字，用于标识由gtrid和bqual值使用的格式，默认值是1。<br>下面其他XA语法中用到的xid值都必须和START操作使用的xid值相同，也就是表示对这个启动的XA事务进行操作。<br>XA END Xid [SUSPEND [FOR MIGRATE]] XA PREPARE Xid<br>使事务进人PREPARE状态，也就是两阶段提交的第一个提交阶段。<br>XA COMMIT Xid [ONE PHASE] XA ROLLBACK xid<br>这两个命令用来提交或者回滚具体的分支事务。也就是两阶段提交的第二个提交阶段：<br>分支事务被实际提交或者回滚。 XA RECOVER<br>XARECOVER返回当前数据库中处于PREPARE状态的分支事务的详细信息。<br>分布式的关键在于如何确保分布式事务的完整性，以及在某个分支出现问题时的故障解决。XA的相关命令就是提供给应用如何在多个独立的数据库之间进行分布式事务的管理，包括启动一个分支事务、使事务进入准备阶段以及事务的实际提交回滚操作等。表11-5中的例子演示了一个简单的分布式事务的执行，事务的内容是在DB1中插人一条记录，同时在DB2 中更新一条记录，两个操作作为同一事务提交或者回滚。<br>表11-5 分布式事务例子<br>session_1in DB1 session_2 in DB2<br>在数据库DB2中启动分布式事务“test”的另外一个分支<br>在数据库DB1中启动一个分布式事务的一个分支事务，xid 事务，xid的gtrid为“test”，bqual为“db2”：的gtrid为“test”，bqual为“db1”： mysql&gt;xa start‘test’,db2’;<br>mysql&gt; xa start ‘test’,db1’; Query OK, 0 rows affected (0.00 sec) Query OK,0 rows affected (0.00 sec) 分支事务2在表film_actor中更新了23条记录：<br>分支事务1在表actor中插入一条记录： mysql&gt;update film_actor set last_update-nowO where mysql&gt;insert intoactor(actorifrst_name,astnam) actor_id&#x3D;178;<br>values(301,Simon’,Tom); Query OK,23rows affected（0.04 sec) Query OK,1 row affected (0.00 sec) Rows matched:23Changed:23Warnings:0<br>对分支事务1进行第一阶段提交，进入prepare状态：对分支事务2进行第一阶段提交，进入prepare状态： mysql&gt; xa end’test’,db1’; mysql&gt; xa end ‘test’,’db2’;<br>Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affcted (0.00 sec) mysql&gt; xa prepare test’,’db1’;<br>Query OK,0rows affected(0.02 sec) mysql&gt;xa prepare test,db2;<br>Query OK, 0 rows affected (0.02 sec)<br>用xarecover命令查看当前分支事务状态：用xarecover命令查看当前分支事务状态： mysql&gt;xa recover \G mysql&gt; xa recover G<br>formatID: 1 formatID: 1 gtrid_length:4 gtrid_length:4<br>bqual_length: 3 bqual_length:3 data:testdb1 data: testdb2 1 row in set (0.00 sec) 1 row in set (0.00 sec)</p>
<p>≦ 186 ≧<br>168 第11章事务控制和锁定语句<br>续表<br>session_1 in DB1 session_2 in DB2<br>两个事务都进入准备提交阶段，如果之前遇到任何错误，都应该回滚所有的分支，以确保分布式事务的正确提交分支事务1：<br>mysql&gt; xa commit ‘test’,db1; 提交分支事务2：<br>QueryOK,0rows affected (0.03 sec) mysql&gt;xa commit ‘test,，db2;<br>两个事务都到达准备提交阶段后，一旦开始进行提交操作， Query OK, 0 rows affected (0.03 sec)<br>就需要确保全部的分支都提交成功 11.3.3存在的问题<br>虽然MySQL支持分布式事务，但是仍然存在一些问题。<br>在MySQL5.5之前的版本，如果分支事务在达到prepare状态时，数据库异常重新启动，服务器重新启动以后，可以选择对分支事务进行提交或者回滚操作，但是即使选择提交事务，该事务也不会被写人BINLOG。这就存在一定的隐患，可能导致使用BINLOG恢复时丢失部分数据。如果存在复制的从库，则有可能导致主从数据库的数据不一致。以下演示了这个过程。<br>（1）从表actor中查询first_name&#x3D;’Simon’的记录，显示有一条。 mysql&gt; select actor_id,last name from actor where first name &#x3D; ‘simon’; l actor_id l last name|<br>1301 1Tom 1 row in set (o.00 sec)<br>（2）启动分布式事务“test”，删除刚才查询的记录。 mysql&gt; xa start ‘test’;<br>Query ok,0 rows affected (o.o0 sec)<br>mysql&gt; delete from actor where actor id &#x3D; 301; Query Ok,1 row affected （0.00 sec)<br>mysql&gt; select actor_id,last name from actor where first name &#x3D; ‘simon’; Empty set (o.00 sec)<br>（3）完成第一阶段提交，进人prepare状态。 mysql&gt; xa end ‘test’;<br>Query ok,O rows affected (o.oo sec) mysql&gt; xa prepare ‘test’;<br>Query ok,0 rows affected (0.03 sec)<br>（4）此时，数据库异常终止，查询出错。<br>mysql&gt; select actor _id,last name from actor where first name &#x3D; ‘simon;<br>ERROR 2006 (HY000): MySQL server has gone away No connection. Trying to reconnect..<br>ERROR 2002 (HY000):Can’t connect to 1ocal MysQL server through socket&#x2F;mnt&#x2F;db&#x2F;mysqld.sock’(2) ERROR:<br>Can’t connect to the server<br>（5）启动数据库后，分支事务依然存在。 mysql&gt; xa recover \G<br>formatID: 1 gtrid 1ength:4 bqual_1ength:0</p>
<p>≦ 187 ≧<br>11.3分布式事务的使用 169<br>data: test<br>1row in set (0.00 sec)<br>（6）表中记录并没有被删除。<br>mysql&gt; select actor_id,last name from actor where first name &#x3D; *simon’;<br>Iactorid l last name 1301<br>1row in set (0.00 sec)<br>（7）可以在MySQL的数据库日志中看到分布式事务的处理情况，数据库启动的时候发现有一个prepare 状态的事务，提示需要进行处理：<br>InnoDB: Transaction 0 117471044 was in the XA prepared state. InnoDB: 1 transaction(s) which must be rolled back or cleaned up<br>InnoDB: in total o row operations to undo InnoDB:Trx id counter is 0 117471488<br>070710 16:55:41 InnoDB:Started:1og sequence number 29 2758352865 070710 16:55:41 InnoDB: Starting recovery for XA transactions..<br>070710 16:55:41 InnoDB:Transaction 0 117471044 in prepared state after recovery 070710 16:55:41 InnoDB:Transaction contains changes to 1 rows<br>070710 16:55:41 InnoDB:1 transactions in prepared state after recovery<br>070710 16:55:41 [Note] Found 1 prepared transaction(s) in InnoDB 070710 16:55:41 [warning] Found 1 prepared XA transactions<br>可以进行提交或者回滚。 mysql&gt;xa commit test’；<br>Query ok,0 rows affected (0.02 sec)<br>mysql&gt; select actor id,last name from actor where first name &#x3D; *simon’; Empty set (0.00 sec)<br>提交后，使用mysqlbinlog查看BINLOG，可以确认最后提交的这个分支事务并没有记录到BINLOG中，因为复制和灾难恢复都是依赖于BINLOG的，所以BINLOG的缺失会导致复制环境的不同步，以及使用BINLOG恢复丢失部分数据。由于这个BUG的存在，在 MySQL5.7之前，对于数据库实例死机，官方的建议是选择回滚prepare的事务。<br>此外，如果分支事务的客户端连接异常中止，例如执行prepare之后退出连接，那么数据库会自动回滚未完成的分支事务，但是这种做法实际上仍然存在问题，因为如果此时分支事务已经执行到prepare状态，那么这个分布式事务的其他分支可能已经成功提交，如果这个分支回滚，可能导致分布式事务的不完整，丢失部分分支事务的内容，如表11-6所示。<br>表11-6 客户端连接中止导致分布式事务失败例子<br>session_1 session_2<br>从表actor中查询first_name&#x3D;Simon的记录，结果为空：从表actor中查询first_name&#x3D;Simon的记录，结果为空： mysql&gt; select * from actor where first _name &#x3D;’Simon’; mysql&gt; select *from actor where first _name&#x3D;Simon’ Empty set (0.00 sec) Empty set (0.00 sec)<br>启动分布式事务test： mysql&gt; xa start ‘test;<br>Query OK, 0 rows affected (0.00 sec) 往actor表中插入一条记录：<br>mysql&gt; insert into actor (actor id,first name,last_name) values(301,Simon’Tom’);<br>Query OK,1 row affected (0.00 sec) 事务结束：<br>mysql&gt; xa end ‘test’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>≦ 188 ≧<br>170 第11章事务控制和锁定语句<br>续表<br>session_1 session_2<br>查询刚插入的记录，可以显示结果：<br>mysql&gt; select actor id,last_name from actor where firstname &#x3D;’Simon’;<br>查询刚插入的记录，显示结果为空：<br>|actor id|last_name| mysql&gt; select <em>from actor where first <em>name &#x3D;Simon’;<br>Empty set (0.00 sec)<br>|301 |Tom 1 row in set (0.00 sec)<br>完成第一阶段提交，进入prepare状态： mysql&gt;xa prepare’test’;<br>Query OK, 0 rows affected (0.02 sec)<br>查询分布式事务“test”的状态： mysql&gt; xa recover \G<br>formatID: 1 gtrid_length:4 bqual</em> length:3<br>data: test<br>1 row in set (0.00 sec)<br>session_1异常中止<br>sessionl异常中止后，分布式事务被回滚，session2中无法查询到sessionl插入的记录，如果此时session2存在分支<br>session_1被回滚 事务并且被成功提交，则会导致分布式事务的不完整<br>mysql&gt;select</em>from actor where first_name&#x3D;’Simon’; Empty set (0.00 sec)<br>而上面也已经提到，当发现部分分支已经提交成功，需要使用备份和BINLOG来恢复数据的时候，那些在prepare状态的分支事务因为并没有记录到BINLOG，所以不能通过BINLOG 进行恢复，在数据库恢复后，将丢失这部分的数据。<br>在MySQL5.7中，已经解决了XA事务的严格持久化问题，在session断开和实例崩溃的情况下，事务都不会自动回滚，同时在XAPREPARE时，之前的事务信息就会被写人BINLOG 并同步到备库。最终再由用户决定将悬挂事务回滚或者是提交。下面测试一下XA事务在 MySQL5.7中的改进。<br>首先，开启一个XA事务： mysql&gt;xa start’test’;<br>Query oK,0 rows affected (o.oo sec)<br>mysql&gt; insert into actor （actor_id,first name,last_ name) values（301,’simon’,Tom’);<br>Query ok, 1 row affected (0.o0 sec) mysql&gt; xa end test’;<br>Query ok,0 rows affected (o.o0 sec)<br>在MySQL5.7中，XA事务在结束之后，提交之前，不允许进行查询： mysql&gt; select * from actor;<br>ERROR 1399 (XAEO7): XAER_RMFAIL: The command cannot be executed when global transaction is in the IDLE state<br>mysql&gt; xa prepare ‘test’;<br>Query ok,0 rows affected (o.o0 sec) mysql&gt; select* from actor;<br>ERROR 1399 (XAE07): XAER RMFAIL:The command cannot be executed when global transaction is in the PREPARED state</p>
<p>≦ 189 ≧<br>11.4小结 171<br>此时查看BINLOG，可以看到执行XAPREPARE后，BINLOG已经有相应的记录： Query eVent :XA START x’74657374’,x,1<br>Table map event write_rows event<br>Query event:XA ENDx’74657374’，x，1<br>XA_prepare eVent:XA PREPARE X’74657374’,x,1<br>断开后重新连接MySQL，可以看到，事务没有被自动回滚，可以手动进行回滚或提交：<br>mysql&gt; exit Bye<br>[root~]#mysq]<br>welcome to the MysQL monitor. Commands end with ; or g. Your MysQL connection id is 17<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>Copyright (c) 2000, 2018, oracle and&#x2F;or its affiliates. All rights reserved. Oracle is a registered trademark of oracle Corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type help:or h’ for help. Type \c’ to clear the current input statement. mysql&gt; xa recover;<br>|formatID | gtrid length | bqual_length 丨 data |<br>11 41 oltestl<br>1row in set (0.00 sec) mysq1&gt;<br>mysql&gt; mysql&gt;xa commit ‘test’;<br>Query ok,O rows affected (o.oo sec)<br>总之，MySQL的分布式事务还存在一些问题，在数据库或者应用异常的情况下，可能会导致分布式事务的不完整或者需要人工介人处理。如果需要使用分布式事务，建议尽量采用<br>MySQL5.7或者更新的版本。 11.4小结<br>事务控制和锁定是MySQL的重要特点之一。本章介绍了MySQL提供的事务控制和锁定语法，并对分布式事务进行了简单的介绍。MySQL中锁的管理涉及的内容很广泛，在后面的优化篇中我们将会对锁机制、死锁和应用中需要注意的其他问题进行更深人的讨论。</p>
<p>≦ 190 ≧<br>第12章SQL中的安全问题<br>在日常开发过程中，程序员一般只关心SQL是否能实现预期的功能，而对于SQL的安全问题一般都不太重视。实际上，如果SQL语句写作不当，将会给应用系统造成很大的安全隐患，其中最重要的隐患就是SQL注人。本章以MySQL为例，将会对SQL注人以及相应的<br>防范措施进行详细的介绍。 12.1SQL注入简介<br>结构化查询语言（SQL）是一种用来和数据库交互的文本语言。SQL注人（SQLInjection）就是利用某些数据库的外部接口将用户数据插人到实际的数据库操作语言（SQL）当中，从而达到入侵数据库乃至操作系统的目的。它的产生主要是由于程序对用户输入的数据没有进行严格的过滤，导致非法数据库查询语句的执行。<br>SQL注人攻击具有很大的危害，攻击者可以利用它读取、修改或者删除数据库内的数据，获取数据库中的用户名和密码等敏感信息，甚至可以获得数据库管理员的权限，而且，SQL 注人也很难防范。网站管理员无法通过安装系统补丁或者进行简单的安全配置进行自我保护，一般的防火墙也无法拦截SQL注人攻击。<br>下面的用户登录验证程序就是SQL注入的一个例子（以PHP程序举例）。<br>（1）创建用户表user： CREATE TABLE uSer（<br>userid int(11) NOT NULL auto_increment, username varchar(20) NOT NULL default password varchar(20) NOT NULL default PRIMARY KEY (userid)<br>)TYPE&#x3D;MyISAM AUTO INCREMENT&#x3D;3<br>（2）给用户表user添加一条用户记录：<br>INSERT INTO ‘userVALUES （1,angel’,‘mypass’);<br>（3）验证用户root登录localhost服务器： &lt;？php<br>$servername &#x3D;”localhost”;<br>$dbusername &#x3D;”root”; $dbpassword &#x3D;<br>$dbname &#x3D;”injection”;<br>mysq1_connect（$servername，Sdbusername，$dbpassword）or die（”数据库连接失败”）;<br>SsqT&#x3D;”sELECT *FROM user WHERE username&#x3D;’Susername’AND password&#x3D;’$password; $result&#x3D; mysql db query(sdbname, $sq1);</p>
<p>≦ 191 ≧<br>12.2应用开发中可以采取的应对措施 173<br>suserinfo &#x3D;mysql fetch_array($result); if(empty(Suserinfo))<br>echo“登录失败”；}else<br>echo“登录成功”；<br>echo“<p>SQL Query:$sq1<p>“;?&gt;<br>（4）然后提交如下URL：<br><a target="_blank" rel="noopener" href="http://127.0.0.1/injection/user.php?username=angel%27or%271=1">http://127.0.0.1/injection/user.php?username=angel&#39;or&#39;1=1</a><br>结果发现，这个URL可以成功登录系统，但是很显然这并不是我们预期的结果。同样也可以利用SQL的注释语句实现SQL注人，如下面的例子：<br><a target="_blank" rel="noopener" href="http://127.0.0.1/injection/user.php?username=ange7%27/">http://127.0.0.1/injection/user.php?username=ange7&#39;/</a>* <a target="_blank" rel="noopener" href="http://127.0.0.1/injection/user.php?username=angel%27#">http://127.0.0.1/injection/user.php?username=angel&#39;#</a><br>因为在SQL语句中，“*”或者“#”都可以将后面的语句注释掉。这样上述语句就可以通过这两个注释符中任意一个将后面的语句给注释掉了，结果导致只根据用户名而没有密码的URL都成功进行了登录。利用“or”和注释符的不同之处在于，前者是利用逻辑运算，而后者则是根据MySQL的特性，这个比逻辑运算简单多了。虽然这两种情况实现的原理不同，<br>但是达到了同样的SQL注人效果，都是我们应该关注的。 12.2应用开发中可以采取的应对措施<br>对于上面提到的SQL注入隐患，后果可想而知是很严重的，轻则获得数据信息，重则可以将数据进行非法更改。那么对这种情况有没有防范措施呢？答案是肯定的。本节将介绍一些常用的防范方法。<br>12.2.1PrepareStatement+Bind-Variable<br>MySQL服务器端并不存在共享池的概念，所以在MySQL上使用绑定变量（BindVariable）最大的好处主要是为了避免SQL注人，增加安全性。下面以Java语言为例，同样是根据 username来访问user表：<br>Class.forName(“com.mysql.jdbc.Driver”).newInstanceO;<br>String connectionurl&#x3D;”jdbc:mysql:&#x2F;&#x2F;localhost:3331&#x2F;test”; string connectionuser &#x3D; test user”；<br>String connectionpassword &#x3D;”test passwd”;<br>conn &#x3D; DriverManager.getconnection(connectionurl,connectionuser, conne-ctionPassword); String sqlstmt &#x3D; select * from user where username &#x3D; ? and password &#x3D; ?”;<br>System.out.println(“source SQL Statement:+ sqstmt)； prepstmt &#x3D; conn.preparestatement(sqlstmt);<br>System.out.println(“Before Bind value:”+ prepstmt.toStringO);<br>prepstmt.setstring(1,“angel′or l&#x3D;1’”); prepstmt.setstring(2,”test”);<br>System.out.println(“After Bind value:”+ prepstmt.tostring();<br>rs&#x3D; prepstmt.executeQueryO； while （rs.nextO）{<br>String ename &#x3D; rs.getstring(“username”); String job &#x3D;rs.getstring(“password”);<br>System.out.println(“username:” +username+”,password:”+ password);</p>
<p>≦ 192 ≧<br>174 第12章SQL中的安全问题<br>输出日志如下：<br>Source sQL Statement: select * from user where username &#x3D; ? and password &#x3D;?<br>Before Bind value:com.mysql.jdbc.JDBc4Preparedstatement@6910fe28: select * from user where<br>*<em>NOT SPECIFIED ** and pasSword &#x3D;<br>username&#x3D; ** NOT SPECIFIED **<br>After Bind value:com.mysql.jdbc.jDBc4Preparedstatement@6910fe28:select * from user where username &#x3D;’angel’or 1&#x3D;1and password &#x3D;’test’<br>可以注意到，虽然传入的变量中带了“angelor1&#x3D;1”的条件，企图蒙混过关，但是由于使用了绑定变量（Java驱动中采用PreparedStatement语句来实现），输人的参数中的单引号被正常转义，导致后续的“or1&#x3D;1”作为username条件的内容出现，而不会被作为SQL的一个单独条件被解析，避免了SQL注人的风险。<br>同样的，在使用绑定变量的情况下，企图通过注释“</em>”或“#”让后续条件失效也是会失败的： prepstmt.setstring（1,”angel ‘&#x2F;*”)；<br>After Bind value:com.mysqi.jdbc.JDBc4Preparedstatement@6910fe28:  select * from user where<br>username &#x3D;’angel ‘&#x2F;*’and password &#x3D;’test prepstmt.setstring(1,”angel *#”);<br>After Bind value:com.mysql.jdbc.JDBC4Preparedstatement@5a9e29fb: select * from user where username &#x3D;’angel &#39;#′and password &#x3D;*test”<br>需要注意，PreparedStatement语句是由JDBC驱动来支持的，在使用PreparedStatement 语句的时候，仅仅做了简单的替换和转义，并不是MySQL提供了PreparedStatement的特性。<br>对Java、JSP开发的应用，可以使用PrepareStatement+Bind-variable来防止SQL注人，另外从PHP5开始，也在扩展的MySQLI中支持PrepareStatement，所以在使用这类语言作数据库开发时，强烈建议使用PrepareStatement+Bind-variable来实现。下面是PHP的例子：<br>$stmt &#x3D; $dbh-&gt;prepare(“SELECT *FROM users WHERE USERNAME &#x3D;? AND PASSWORD &#x3D; ?”); $stmt-&gt;execute(array($username, $password));<br>12.2.2使用应用程序提供的转换函数<br>很多应用程序接口都提供了对特殊字符进行转换的函数。恰当地使用这些函数，可以防止应用程序用户输入使应用程序生成不期望的语句。<br>OMySQLCAPI:使用mysql_real_escape_stringOAPI调用。 OMySQL++：使用escape和quote修饰符。<br>OPHP:使用mysql_real_escape_stringO函数（适用于PHP4.3.0版本）。从PHP5开始，可以使用扩展的MySQLI，这是对MySQL新特性的一个扩展支持，其中的一个优点就是支持 PrepareStatement.<br>PerlDBI:使用placeholders或者quoteO方法。<br>0 RubyDBI:使用placeholders或者quoteO方法。 12.2.3自已定义函数进行校验<br>如果现有的转换函数仍然不能满足要求，则需要自己编写函数进行输人校验。输人验证是一个很复杂的问题。输人验证的途径可以分为以下几种：<br>整理数据使之变得有效； ○拒绝已知的非法输入；</p>
<p>≦ 193 ≧<br>12.3小结 175<br>只接受已知的合法输入。<br>因此，如果想要获得最好的安全状态，目前最好的解决办法就是，对用户提交或者可能改变的数据进行简单分类，分别应用正则表达式来对用户提供的输入数据进行严格的检测和验证。<br>下面采用正则表达式的方法提供一个验证函数，以供读者参考。<br>已知非法符号有：“ 《”“&gt;”“”“_”“”和“]”。其实只需要过滤非法的符号组合就可以阻止已知形式的攻击，并且如果发现更新的攻击<br>符号组合，也可以将这些符号组合增添进来，继续防范新的攻击。特别是空格符号和与其产生相同作用的分隔关键字的符号，例如“*<em>”，如果能成功过滤这种符号，那么有很多注人攻击将不能发生，并且同时也要过滤它们的十六进制表示“%XX”。<br>由此，可以构造如下正则表达式：<br>（11（%27）:1（%3b)&#x3D;1（%3（1（28）(%29）1</em>1C%2%2a）1（<em>1（%2a2）+1（%2b) 1&lt;|（%3c）&gt;1(%3&#x2F;（-）1[%5b]%5d）<br>根据上述的正则表达式，可以提供一个函数（以PHP举例），可以防范大多数的SQL注人，具体函数如下：<br>function SafeRequest (SParaName, $ParaType)<br>&#x2F;—传入参数—</em>&#x2F;<br>&#x2F;<em>ParaName：参数名称-字符型</em>&#x2F;<br>&#x2F;<em>ParaType：参数类型-数字型（1表示参数是数字或字符，0表示参数为其他）</em>&#x2F; if ($paraType &#x3D;&#x3D;1)<br>$re&#x3D;”&#x2F;[^\w+$]&#x2F;“;<br>小 else 心<br>$re&#x3D;“&#x2F;（11（%27）1;1（%3b）&#x3D;1（%3）1（1(%28）11(%29）1（&#x2F;1C%2f%2a)<br>[（*1（%2a%2）+1（%2b)1&lt;1（%3&gt;1(%3）1(1[1%5b&#x2F;]15）&#x2F;；<br>if (preg_match($re,$ParaName)&gt;0)<br>echo（”参数不符合要求，请重新输入！”）； return 0;<br>else<br>return 1;<br>12.3小结<br>本章主要从SQL注人的角度讨论了SQL的安全问题，阐述了SQL注人的原理以及防范措施，最后通过一个PHP函数例子给出了类似问题解决方法的参考。<br>本章的内容不仅仅适用于MySQL数据库，一些原理以及解决方案同样适用于其他数据库系统，因为SQL注人问题是一个数据库应用普遍存在的安全问题。</p>
<p>≦ 194 ≧<br>第13章 SQLMode及相关问题与其他数据库不同，MySQL可以运行在不同的SQLMode（SQL模式）下。SQLMode<br>定义了MySQL应支持的SQL语法、数据校验等，这样可以更容易地在不同的环境中使用<br>MySQL。本章将详细介绍常用的SQLMode及其在实际中的应用。 13.1MySQL SQL Mode简介<br>在MySQL中，SQLMode常用来解决下面几类问题。<br>通过设置SQLMode，可以完成不同严格程度的数据校验，有效地保障数据准确性。通过设置SQLMode为ANSI模式，来保证大多数SQL符合标准的SQL语法，这样<br>应用在不同数据库之间进行迁移时，则不需要对业务SQL进行较大的修改。<br>O在不同数据库之间进行数据迁移之前，通过设置SQLMode可以使MySQL上的数据更方便地迁移到目标数据库中。<br>在MySQL5.7中，SQLMode有了较大的变化，查询默认的SQLMode（sql_mode参数）为ONLY_FULL_GROUP_BY、STRICT_TRANS_TABLES、NO_ZERO_IN_DATE、NO_ZERO DATE、ERROR_FOR_DIVISION_BY_ZERO、NO_AUTO_CREATE_USER 和NO_ENGINE SUBSTITUTION（不同的小版本可能略有区别）。这些SQLMODE的含义如表13-1所示。<br>表13-1 MySQL5.7中默认的SQLMode<br>sql_mode值描述<br>ONLY_FULL_GROUP_BY 在groupby子句中没有出现的列，出现在select列表、having条件、orderby条件<br>中时会被拒绝<br>STRICT_TRANS_TABLES 非法日期，超过字段长度的值插入时，直接报错，拒绝执行<br>日期中针对月份和日期部分，如果为0，比如2018-00-00，有不同的执行逻辑<br>NO_ZERO_IN_DATE Odisable：可以正常插入，实际插入值还是2018-00-00没有警告<br>Oenable：可以正常插入，有警告；如果mode中包含STRICT_TRANS_TABLES，则日期被拒绝写入，但可以通过加ignore关键字写入0000-00-00<br>针对日期0000-00-00，执行逻辑如下 disable：可以正常插入，没有警告<br>NO_ZERO_DATE<br>enable：可以正常插入，有警告；如果mode中包含STRICT_TRANS_TABLES，则日期被拒绝写入，但可以通过加ignore关键字写入0000-00-00，有警告</p>
<p>≦ 195 ≧<br>13.1MySQLSQLMode简介 177<br>续表<br>sql_mode值 描述<br>除数为0（包括MOD(N，0)），执行逻辑如下<br>ERROR_FOR_DIVISION_BY_ZERO disable：插入NULL，没有警告<br>enable：插入NULL，有警告；如果mode中包含STRICT_TRANS_TABLES，则数据被拒绝写入，但可以通过加ignore关键字写入NULL，有警告<br>NO_AUTO_CREATE_USER 防止使用不带密码子句的grant语句来创建一个用户<br>执行create table或者alter table语句时，如果指定了不支持（包括disable或未编<br>NOENGINE_SUBSTITUTION 译）的存储引擎，是否自动替换为默认的存储引擎<br>Odisabe：create table会自动替换后执行，altertable不会执行，两个命令都有警告 enable：两个命令直接报错<br>相比之前的版本，MySQL5.7.5之后的版本最大的区别是在SQLMode的默认设置中，增加了严格的事物表模式（STRICT_TRANS_TABLES），在这种模式不下允许插人字段类型不一致的值，不允许插人超过字段长度的值，这在绝大多数场景下都更加合理。如果不设置 STRICT_TRANS_TABLES，那么上述操作会被允许，只是在插人后，MySQL会返回一个 warning，从而导致表中写人异常数据。<br>NO_ZERO_DATE、NO_ZERO_DATE、ERROR_FOR_DIVISION_BY_ZERO这儿种SQL Mode很少单独使用，通常和STRICT_TRANS_TABLES一起来用，官网宣称这几种SQLMode 将来可能会合并。下面来看个具体的例子。<br>（1）查看默认SQLMode的命令如下：<br>mysql&gt; select @asql <em>mode; 1@@sql_mode<br>IONLYFU GOUPBY,STICTRANSTABLES,NOZERO INDAE 1row in set (0.00 sec)<br>（2）查看测试表t的表结构的命令如下： mysql&gt; desc t sql mode</em> strict;<br>|Field 丨.Type |Null |Key|Default| Extra|<br>Iid int（11) IYES 1NULL Iname varchar(10)|YEs INULL<br>2rows in set (o.o0 sec)<br>（3）首先取消SQLMode的严格模式： mysql&gt; set session sql mode&#x3D;’；<br>Query ok,0 rows affected,1 warning (O.o0 sec)<br>（4）在表中插入一条记录，其中name故意超出了实际的定义值varchar(10)：<br>mysql&gt; insert into t sql mode strict values(1,<a href="mailto:&#98;&#x65;&#x69;&#106;&#x69;&#x6e;&#x67;&#64;&#x31;&#50;&#54;&#x2e;&#99;&#x6f;&#x6d;">&#98;&#x65;&#x69;&#106;&#x69;&#x6e;&#x67;&#64;&#x31;&#50;&#54;&#x2e;&#99;&#x6f;&#x6d;</a>‘); Query oK,1 row affected,1 warning （0.02 sec)<br>（5）可以发现，记录可以插人，但是显示了一个warning，查看warning内容： mysql&gt; show warnings;<br>ILevel |Code 丨 Message<br>|warning | 1265 |Data truncated for columnnameat row 11 1row in set (0.00 sec)</p>
<p>≦ 196 ≧<br>178 第13章SQLMode及相关问题<br>（6）warning提示对插入的name值进行了截断，从表t_sql_mode_strict中查看实际插入值：<br>mysql&gt; select * from t_sql mode_strict; |id|name<br>1|beijing@121 1 row in set (0.00 sec)<br>果然，记录虽然插人进去，但是只截取了前10位字符。<br>（7）接下来设置SQLMode为STRICT_TRANS_TABLES（严格的事物表模式）：<br>mysql&gt; set session sqT _mode&#x3D;’STRICT_TRANS_TABLES’; Query ok,0 rows affected (0.01 sec)<br>mysql&gt; select @@sql mode; 1@@sql mode<br>ISTRICT TRANS TABLES 1row in set (0.01 sec)<br>（8）再次尝试插入上面的测试记录：<br>mysql&gt; insert into t sql mode strict values（1,‘<a href="mailto:&#98;&#101;&#105;&#106;&#x69;&#x6e;&#103;&#64;&#x31;&#x32;&#54;&#46;&#99;&#111;&#x6d;">&#98;&#101;&#105;&#106;&#x69;&#x6e;&#103;&#64;&#x31;&#x32;&#54;&#46;&#99;&#111;&#x6d;</a>‘）; ERRoR 1406 (22001): Data too 1ong for column ‘name at row 1<br>结果发现，这次记录没有插入成功，给出了一个ERROR，而不仅仅是warming。<br>上面的例子中，给出了sql_mode的一种修改方法，即SET[SESSIONIGLOBAL]sql_mode&#x3D; modes’，其中SESSION选项表示只在本次连接中生效；而GLOBAL选项表示在本次连接中并不生效，而对于新的连接则生效，这种方法在MySQL4.1开始有效。另外，也可以通过使<br>用“–sql-mode&#x3D;”modes””选项，在MySQL启动时设置sql_mode。 13.2SQLMode的常见功能<br>下面介绍一下SQLMode的常见功能。<br>（1）校验日期数据合法性，这是SQLMode的一项常见功能。<br>在下面的例子中，观察一下非法日期“2007-04-31”（因为4月没有31日）在不同SQLMode 下能否正确插人。<br>mysql&gt; set session sql mode&#x3D;’ANsI’; Query ok,0 rows affected (o.oo sec)<br>mysql&gt; create table t sql _mode_ansi (d datetime); Query ok,0 rows affected (0.03 sec)<br>mysql&gt; insert into t sql mode_ansi values(‘2007-04-31’); Query ok,1 row affected,1 warning (0.00 sec)<br>mysql&gt; select * from t; ld<br>10000-00-0000:00:001 1row in set (o.00 sec)<br>mysql&gt; set session sql _mode&#x3D;’TRADITIONAL’; Query Ok,O rows affected (0.o0 sec)</p>
<p>≦ 197 ≧<br>13.2SQLMode的常见功能 179<br>mysql&gt; insert into t sq1_mode_ansi values(‘2007-04-31’);<br>ERROR 1292 (22007):Incorrect datetime value:2007-04-31’for column’d’at row1<br>很显然，在ANSI模式下，非法日期可以插入，但是插入值却变为“0000-00-0000:00:00”，并且系统给出了warning；而在TRADITIONAL模式下，会直接提示日期非法，拒绝插入。<br>（2）启用NO_BACKSLASH_ESCAPES模式，使反斜线“\”成为普通字符。在导人数据时，如果数据中含有反斜线字符，那么启用NO_BACKSLASH_ESCAPES模式保证数据的正确性，是一个不错的选择。<br>以下示例说明了启用NO_BACKSLASH_ESCAPES模式前后对反斜线“”插入的变化。 mysql&gt; set sql mode&#x3D;′ansi’;<br>Query ok, 0 rows affected (o.o0 sec)<br>mysql&gt; select @@sql _mode; 1 @@sql_mode<br>REASTPSCONAT,NSUTE,RACENFUGUY, 1 row in set (o.00 sec)<br>mysql&gt; create table t sq1 mode bs (context varchar(20)); Query ok,0 rows affected (0.04 sec)<br>mysql&gt; insert into t sql mode bs values(‘\beijing’);<br>Query ok,1 row affected (0.o0 sec) mysql&gt; select * from t sql mode bs;<br>1context| leijing<br>1row in set (0.00 sec)<br>mysql&gt; insert into t sql mode bs values(‘\beijing’);<br>Query ok,1 row affected (0.00 sec) mysql&gt; select *from t sql_mode bs;<br>Icontext leijing<br>|\beijing丨<br>2 rows in set (o.00 sec)<br>mySql&gt; Set Sql _mOde &#x3D;REAL AS FLOAT,PIPES_AS CONCAT,ANSI QUOTES,IGNORE SPACE,ONLY_FULL_GROUP BY,ANSI,NO BACKSLASH ESCAPES<br>Query ok, 0 rows affected (o.oo sec)<br>mysql&gt; mysql&gt; select @@sq1 mode; 1 @@sql_mode<br>REAASFATIPESSCONCAT,ANSUTESGNOREPACENFUGROUPBYNSI,AKSASHEAPE 1row in set (0.00 sec)<br>mysql&gt; insert into t sql mode bs values(‘\beijing’);<br>Query OK,1 row affected (o.o0 sec) mysql&gt; select *from t sql_mode bs; 1context</p>
<p>≦ 198 ≧<br>180 第13章SQLMode及相关问题<br>leijing Abeijing\beijing<br>3rows in set (o.00 sec)<br>通过上面的示例可以看到，当在ANSI模式中增加了NO_BACKSLASH_ESCAPES模式后，反斜线变为了普通字符。如果导人的数据存在反斜线，可以设置此模式，保证导人数据的正确性。<br>（3）启用PIPES_AS_CONCAT模式。将“”视为字符串连接操作符，在Oracle等数据库中，“”被视为字符串的连接操作符，所以，在其他数据库中含有“I”操作符的SQL在 MySQL中将无法执行。为了解决这个问题，MySQL提供了PIPES_AS_CONCAT模式。<br>下面通过示例来介绍一下PIPES_AS_CONCAT模式的作用。 mysql&gt; set sql _mode&#x3D;’ansi’;<br>Query ok,O rows affected (o.oo sec)<br>mysql&gt; select @@sgl _mode; l @@sql_mode<br>IREALASFOAT,PIPESAS_CONCAT,ANSI QUOTES,IGNORESPACE,ONLY_FULGROUP BY,AN 1row in set (0.o0 sec)<br>mysql&gt; select ‘beijing’ll’2018’<br>1beijing’|l′2018 1beijing2018<br>1 row in set (0.01 sec)<br>通过上面的示例可以看到，ANSI模式中包含了PIPES_AS_CONCAT模式，所以默认情况下，MySQL版本支持将“I”视为字符串连接操作符。<br>需要注意的是，在分区表和主从复制环境中，要谨慎修改SQLMode。前者可能导致数据的写人逻辑发生变化，新的逻辑可能导致同一条数据在不同的SQLMode下写人不同的分区；如果主从服务器的SQLMode不同，后者会导致复制的数据在主从服务器上写人逻辑不同。<br>这两种情况都可能导致数据的混乱。 13.3常用的SQL Mode<br>熟悉并了解经常使用的SQLMode会帮助用户更好地使用它。表13-2总结了常用的 SQLMode值及其说明。<br>表13-2 MySQL中的SQLMode<br>sql_mode值描述<br>等同于REAL_AS_FLOAT、PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、<br>ANSI ONLY_FULL_GROUP_BY和ANSI组合模式，这种模式遇到异常时倾向于警告而不是立刻<br>返回错误<br>STRICT_TRANS_TABLES适用于事务表和非事务表，它是严格模式，不允许非法日期，也<br>STRICT_TRANS_TABLES 不允许超过字段长度的值插入字段中，对于插入不正确的值给出错误而不是警告。MySQL<br>5.7版本后添加到默认的SQLMode中</p>
<p>≦ 199 ≧<br>13.3常用的SQLMode 181<br>续表<br>sql_mode值 描述<br>TRADITIONAL模式等同于STRICT_TRANS_TABLES、STRICT_ALL_TABLES、 NO_ZERO_IN DATE、NO_ZERODATE、ERROR FOR DIVISION_BY_ZERO、NO_AUTO<br>TRADITIONAL CREATE_USER和NO_ENGINE_SUBSTITUTION的组合模式，所以它也是严格模式，对<br>于插入不正确的值会给出错误而不是警告。可以应用在事务表和非事务表，用在事务表时，只要出现错误就会立即回滚<br>可以发现，表格中第一列SQLMode的值大都是一些原子模式的组合，类似于角色和权限的关系。这样当实际应用时，只需要设置一个模式组合，就可以设置很多的原子模式，大大简化了用户的工作。<br>其中TRADITIONAL和MySQL5.7的默认模式很相似，都属于严格模式。两者的主要区别在于TRADITIONAL包含了原子模式STRICT_ALL_TABLES。STRICT_ALL_TABLES和 STRICT_TRANS_TABLES非常类似，对于事物表（比如InnoDB）的写入规则完全一致，但对于非事物表有细微的差别，如下例所示：<br>（1）创建非事物表tlmyisam，存储引擎设置为MyISAM。<br>mysql&gt; create table t1 myisam (id int,name varchar(4)) engine&#x3D;myisam; Query oK,O rows affected （o.o5 sec)<br>（2）设置SQLMode为STRICT_TRANS_TABLES。 mysql&gt; set sql _mode&#x3D;’STRICT_TRANS TABLES’;<br>Query ok,0 rows affected, 1 warning (0.00 sec)<br>（3）分别写入下面的数据，发现第一条正常，第二条有警告，第三条被拒绝。<br>mysql&gt; insert into tl myisam values(1,’z1’); Query ok,1 row affected (0.01 sec)<br>mysql&gt; insert into tlmyisam values（10,’z1′),(20,’z1’),(30,z111111111111′);<br>Query ok,3 rows affected,1 warning (0.o0 sec) Records:3 Duplicates:0 Warnings:1<br>mysql&gt; insert into tlmyisam values(10,z10000000000’),（20,’z1’),(30,’z111111111111’); ERROR 1406(22001):Data too long for columnnameat row 1<br>（4）查询表发现全部写人，但name为“z111111111111”的被截断为“z111”。 mysql&gt; select * from t1 myisam;<br>id InameI<br>101z1<br>301z111|<br>4 rows in set (0.00 sec)<br>（5）更改SQLMode为STRICT_ALL_TABLES。 mysql&gt; set sql_mode&#x3D;’STRICT ALL TABLES’;<br>Query ok,0 rows affected, 1 warning (0.00 sec)<br>（6）写入刚才同样的数据，发现第一条正常，第二条和第三条被拒绝。<br>mysql&gt; insert into t1 myisam values(1,’z1’); Query oK,1 row affected （0.00 sec)<br>mysql&gt; insert into t1myisam values（10,’z1’),（20,z1’),（30,z111111111111’); ERROR 1406 (22001):Data too long for column ‘name′ at row3</p>
<p>≦ 200 ≧<br>182 第13章SQLMode及相关问题<br>mysql&gt; insert into t1myisam values(10,z10000000000）,（20,z1),（30,z111111111111’); ERROR 1406 (22001): Data too long for column name′at row 1<br>从上例可以看出，对于非事物表，如果一次写入多行记录，在STRICT_TRANS_TABLES 模式下，只要多行中的第一条写入成功，那么后面的记录即使违反了严格模式的约束，也会自动转换为最接近的数据写人成功；而在STRICTALL_TABLES模式下则相反，只要多行记录中的任意一行违反严格模式的约束，本次的所有记录都会写入失败。显而易见，两者各有利弊，前者可能导致数据的异常，后者可能导致事物的不一致。避免这种问题的最好办法是<br>让数据逐条写人，读者在开发中一定要注意。 13.4SQLMode在迁移中如何使用<br>如果MySQL与其他异构数据库之间有数据迁移的需求，那么MySQL中提供的数据库组合模式就会对数据迁移过程有所帮助。<br>从表13-3中可以看出，MySQL提供了很多数据库的组合模式名称，例如“ORACLE”“DB2”等。这些模式组合是由很多小的sql_mode组合而成，在异构数据库之间迁移数据时可以尝试使用这些模式来导出适合于目标数据库格式的数据，这样就使得导出数据更容易导入目标数据库。<br>表13-3 MySQL中的常用数据库Mode<br>组合后的模式名称 组合模式中的各个sql_mode<br>PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE _SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、<br>DB2 NO_FIELD_OPTIONS<br>MAXDB PIPES_AS_CONCAT、ANSI QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、<br>NO_FIELD_OPTIONS、NO_AUTO_CREATE_USER<br>MSSQL PIPES_AS_CONCAT、ANSI QUOTES、IGNORE_SPACE、NOKEY_OPTIONS、NO_TABLE OPTIONS、<br>NO_FIELDOPTIONS<br>ORACLE PIPES_AS_CONCAT、ANSI QUOTES、IGNORE SPACE、NO_KEY_OPTIONS、NO_TABLEOPTIONS、<br>NO_FIELD_OPTIONS、NO_AUTO_CREATE USER<br>POSTGRESQL PIPES_AS_CONCAT、ANSI_QUOTES、IGNORE_SPACE、NO_KEY_OPTIONS、NO_TABLE_OPTIONS、<br>NO_FIELD OPTIONS<br>在数据迁移过程中，可以设置SQLMode为NO_TABLE_OPTIONS模式，这样将去掉show create table中的“engine”关键字，获得通用的建表脚本。<br>测试示例如下：<br>mysql&gt; show create table emp \G;<br>Table: emp<br>Create Table: CREATE TABLE emp（’ename′varchar(20) DEFAULT NULL,’hiredate’ date DEFAULT NULL,<br>saldecima1(10,2) DEFAULT NULL,’deptnoint(2) DEFAULT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 1row in set (o.00 sec)<br>mysql&gt; set session sql mode&#x3D;No TABLE OPTIONS’;<br>Query ok,0 rows affected (o.o0 sec) mysql&gt; show create table emp \G;</p>
<p>≦ 201 ≧<br>13.5小结 183<br>Table:emp<br>Create Table: CREATE TABLEemp（<br>‘ename’varchar(20) DEFAULT NULL,’hiredate’ date DEFAULT NULL,<br>sal′ decima1（10,2) DEFAULT NULL,<br>deptno′int(2） DEFAULT NULL 1 row in set (o.00 sec)<br>13.5 小结<br>本章介绍了SQLMode的含义以及实际用途，重点讨论了以下内容。<br>OSQLMode的“严格模式”为MySQL提供了很好的数据校验功能，保证了数据的准确性，TRADITIONAL和STRICT_TRANS_TABLES是常用的两种严格模式，要注意两者的区别。<br>OSQLMode的多种模式可以灵活组合，组合后的模式可以更好地满足应用程序的需求。尤其在数据迁移中，SQLMode的使用更为重要。</p>
<p>≦ 202 ≧<br>第14章 MySQL分区<br>MySQL从5.1版本起开始支持分区的功能。分区是指根据一定的规则，数据库把一个表分解成多个更小的、更容易管理的部分。就访问数据库的应用而言，逻辑上只有一个表或一个索引，但是实际上这个表可能由数十个物理分区对象组成，每个分区都是一个独立的对象，可以独自处理，可以作为表的一部分进行处理。分区对应用来说是完全透明的，不影响应用的业务逻辑。<br>14.1分区概述<br>分区有利于管理非常大的表，它采用了“分而治之”的逻辑。分区引入了分区键（Partition Key）的概念，分区键用于根据某个区间值（或者范围值）、特定值列表或者HASH函数值执行数据的聚集，让数据根据规则分布在不同的分区中，让一个大对象变成一些小对象。<br>MySQL分区的优点主要包括以下4个方面。<br>和单个磁盘或者文件系统分区相比，可以存储更多数据。<br>优化查询。在Where子句中包含分区条件时，可以只扫描必要的一个或多个分区来提高查询效率；同时在涉及SUMO和COUNTO这类聚合函数的查询时，可以容易地在每个分区上并行处理，最终只需要汇总所有分区得到的结果。在MySQL5.7中，还可以通过类似 SELECT*FROMtPARTITION（pO，p1)这样的方式来显式查询指定分区的数据。<br>对于已经过期或者不需要保存的数据，可以通过删除与这些数据有关的分区来快速删除数据。<br>跨多个磁盘来分散数据查询，以获得更大的查询吞吐量。<br>在MySQL5.7中，通过二进制安装会默认包含分区支持，如果通过源码编译安装，那么需要在编译时指定参数DWITH_PARTITION_STORAGE_ENGINE。<br>可以通过SHOWPLUGINS命令或者查询PLUGINS字典表来确定当前的MySQL是否支持分区，例如：<br>mysql&gt; select * from information schema.plugins where PLuGIN NAME&#x3D;partition’\G<br>1.row<br>PLUGIN NAME: partition<br>PLUGIN VERSION:1.0 PLUGIN STATUS:ACTIVE<br>PLUGIN TYPE: STORAGE ENGINE<br>PLUGIN TYPE VERSION: 50722.0<br>PLUGIN LIBRARYNULL</p>
<p>≦ 203 ≧<br>14.2分区类型 185<br>PLUGIN LIBRARY_VERSION: NULL<br>PLUGIN AUTHOR: Mikael Ronstrom, MySQL AB<br>PLUGIN DESCRIPTION: Partition Storage Engine Helper<br>PLUGIN_LICENSE:GPL<br>LOAD_OPTION:ON<br>1row in set(0.00 sec)<br>通过查到的partition插件信息，如果PLUGIN_STATUS列的状态是ACTIVE，说明MySQL 已经开启了分区功能。<br>MySQL支持大部分存储引擎（比如MyISAM、InnoDB、Memory等）来创建分区表；但不支持MERGE、CSV和FEDERATED这3类存储引擎。在MySQL5.7版本中，同一个分区表的所有分区必须使用同一个存储引擎，且分区数量不能超过8192（NDB存储引擎除外），即同一个表上，不能对一个分区使用MyISAM引擎，对另一个分区使用InnoDB。但是，可以在同一个MySQL服务器中，甚至同一个数据库中，对于不同的分区表使用不同的存储引擎。<br>和非分区表设置存储引擎一样，分区表设置存储引擎，只能用[STORAGEJENGINE子句。[STORAGE]ENGINE子句必须列在CREATETABLE语句中的其他任何分区选项之前。例如，下面的例子创建了一个使用InnoDB引擎并有6个HASH分区的表：<br>mysql&gt; CREATE TABLE emp （empid INT, salary DECIMAL(7,2）,birth date DATE)<br>ENGINE&#x3D;INNODB<br>PARTITION BY HASH( MONTH(birth date))<br>-&gt;<br>PARTITIONS 6;<br>Query ok,0 rows affected (0.11 sec)<br>注意：MySQL的分区适用于一个表的所有数据和索引，不能只对表数据分区而不对索引分区；反<br>过来也是一样的，不能只对索引分区而不对表分区，同时也不能只对表的一部分数据进行分区。MySQL的分区表上创建的索引一定是本地LOCAL索引。<br>14.2分区类型<br>本节主要讨论在MySQL5.7中可用的分区类型，主要有以下6种。<br>RANGE分区：基于一个给定连续区间范围，把数据分配到不同的分区。<br>OLIST分区：类似RANGE分区，区别在LIST分区是基于枚举出的值列表分区，RANGE 是基于给定的连续区间范围分区。<br>OCOLUMNS分区：类似于RANGE和LIST，区别在于分区键既可以是多列，又可以是非整数。<br>●HASH分区：基于给定的分区个数，把数据取模分配到不同的分区。 OKEY分区：类似于HASH分区，但使用MySQL提供的哈希函数。<br>子分区：也叫作复合分区或者组合分区，即在主分区下再做一层分区，将数据再次分割。在MySQL5.7中，RANGE分区、LIST分区、HASH分区都要求分区键必须是INT类型，<br>或者通过表达式返回INT类型，但KEY和COLUMNS分区例外，可以使用其他类型的列（BLOB或TEXT列类型除外）作为分区键。如果希望在RANGE和LIST类型的分区中使用非INT列作为分区键，可以选择COLUMNS分区。<br>无论是哪种MySQL分区类型，要么分区表上没有主键&#x2F;唯一键，要么分区表的主键&#x2F;唯一键都必须包含分区键，也就是说不能使用主键&#x2F;唯一键字段之外的其他字段分区，例如emp表的主键为id字段，在尝试通过store_id字段分区的时候，MySQL会提示返回失败：</p>
<p>≦ 204 ≧<br>186 第14章MySQL分区 mysqT&gt; CREATE TABLE emp C<br>-&gt; id INT NOT NULL,! ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT*1970-01-01’<br>separated DATE NOT NULL DEFAULT 9999-12-31’<br>-V job VARCHAR(30) NOT NULL,<br>store id INT NOT NULL,<br>A PRIMARY KEY (id)-&gt;<br>PARTITION BY RANGE (store_id) (<br>PARTITION PO VALUES LESS THAN (10), PARTITION P1 VALUES LESS THAN (20), PARTITION P2 VALUES LESS THAN (30)<br>ERROR 1503 (HYOoo): A PRIMARY KEY must include all columns in the table’s partitioning function<br>去掉主键约束后，创建表就会成功： mysql&gt; CREATE TABLE emp （<br>-&gt; id INT NOT NULL,-&gt; ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT1970-01-01′,<br>separated DATE NOT NULL DEFAULT 9999-12-31’<br>job vaRCHaR(30) NoT NULl, store id INT NOT NULL<br>-&gt; PARTITION BY RANGE (store_id) (<br>PARTITION pO VALUES LESS THAN (10),<br>-&gt; PARTITION pl VALUES LESS THAN (20),<br>PARTITION p2 VALUES LESS THAN (30)<br>-&gt;<br>;<br>Query ok, 0 rows affected (0.05 sec)<br>分区的名字基本上遵循MySQL标识符的原则。说到命名，顺便介绍一下MySQL命名中的大小写敏感：在MySQL中，对于库名和表名是否大小写敏感，可以通过下面的方法来查看：<br>mysql&gt; show variables like %lower _case%’;<br>| Variable name 1 value 1<br>I lower_case file system OFF<br>1lower case table names 1 2rows in set (0.00 sec)<br>这里lower_case_file_system是一个不可以修改的变量，代表了操作系统是否大小写敏感， OFF代表敏感，ON代表不敏感。lower_case_table_names代表数据库的库名和表名是否大小写敏感，1代表敏感，0代表不敏感。如果操作系统大小写敏感（例如Linux），那么库名和表名大小写是否敏感就由lower_case_table_names参数来决定，如果操作系统大小写不敏感（例如Windows），那么lower_case_table_names应该设置为1。否则可能会遇到数据库实例挂起、崩溃、启动报错等问题。<br>但是需要注意的是，列名、别名、分区名这些是不区分大小写的。例如，无论<br>lower_case_table_names的值如何设置，下面的CREATETABLE语句都将会产生错误： mysq7&gt; CREATE TABLE t2 (val INT)<br>PARTITION BY LIST(Val)(<br>PARTITION mypart VALUES IN (1,3,5), PARTITION MyPart VALUES IN (2,4,6)<br>ERROR 1517 (HY000): Duplicate partition name mypart<br>这是因为MySQL认为分区名字mypart和MyPart没有区别。</p>
<p>≦ 205 ≧<br>14.2分区类型 187<br>14.2.1RANGE分区<br>按照RANGE分区的表是利用取值范围将数据分成分区，区间要连续并且不能互相重叠，使用VALUESLESSTHAN操作符进行分区定义。<br>例如，雇员表emp中按商店IDstore_id进行RANGE分区： mysql&gt; CREATE TABLE emp （<br>id INT NOT NULL,</p>
<blockquote>
<p>ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT 1970-01-01’<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’,<br>job VARCHAR(30) NOT NULL, store id INT NOT NULL<br>PARTITION BY RANGE (store id)（<br>PARTITION PO VALUES LESS THAN (10), PARTITION p1 VALUES LESS THAN (20) PARTITION P2 VALUES LESS THAN (30)<br>Query ok,O rows affected (o.o5 sec)<br>按照这种分区方案，在商店1～9工作的雇员相对应的所有行被保存在分区P0中，商店 10～19的雇员保存在P1中，依次类推。注意，每个分区都是按顺序进行定义的，从最低到最高。这是PARTITIONBYRANGE语法的要求；类似Java或者C中的“switchcase”语句。<br>这时，如果增加了商店ID大于等于30的行，会出现错误，因为没有规则包含商店ID大于等于30的行，服务器不知道应该把记录保存在哪里。<br>mysql&gt; insert into emp（id, ename,hired,job,store id) values (‘7934，MILLER,1982-01-23′,CLERK50)；<br>ERROR 1526 (HY000): Table has no partition for value 50<br>可以在设置分区的时候使用VALUESLESSTHANMAXVALUE子句，该子句提供给所有大于明确指定的最高值的值，MAXVALUE表示最大的可能的整数值。例如，增加P3分区存储所有商店ID大于等于30的行之后再执行插人语句就没有问题了：<br>mysql&gt; alter table emp add partition (partition p3 VALUES LESs THAN MAXVALuE);<br>Query ok,0 rows affected (0.21 sec) Records:ODuplicates:0 warnings:0<br>mysql&gt; insert into emp（id, ename,hired, job, store id) values (‘7934’,MILLER′,1982-01-23′,CLERK,50);<br>Query ok, 1 row affected (0.04 sec)<br>MySQL支持在VALUESLESSTHAN子句中使用表达式，比如，以日期作为RANGE分区的分区列：<br>mysql&gt; CREATE TABLE emp_ date (<br>id INT NOT NULL, ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT 1970-01-01<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’,<br>job VARCHAR(3O) NOT NULL, store id INT NOT NULL<br>PARTITION BY RANGE (YEAR(separated))（<br>PARTITION p0 VALUES LESS THAN (1995), PARTITION P1 VALUES LESS THAN (2000), PARTITION P2 VALUES LESS THAN (2005)<br>-&gt;）;<br>Query ok, 0 rows affected (o.o8 sec)</p>
</blockquote>
<p>≦ 206 ≧<br>188 第14章MySQL分区<br>注意：在RANGE分区中，分区键如果是NULL值会被当作一个最小值来处理，在14.2.7节中有<br>详细的说明。<br>MySQL从5.5版本开始，改进了RANGE分区功能，提供了RANGECOLUMNS分区支持非整数分区，例如：<br>mysql&gt; CREATE TABLE emp date( 2538<br>id INT NOT NULL ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT 1970-01-01’，<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’,<br>job VARCHAR(30) NOT NULL, store id INT NOT NULL<br>PARTITION BY RANGE COLUMNS （Separated)（<br>PARTITION PO VALUES LESS THAN (‘1996-01-01’), PARTITION P1 VALUES LESS THAN (‘2001-01-01’), PARTITION P2VALUES LESS THAN (2006-01-01*)<br>)；<br>Query Ok,0 rows affected (0.07 sec)<br>RANGE分区功能特别适用于以下两种情况。<br>O当需要删除过期的数据时，只需要简单的ALTERTABLEempDROPPARTITIONpO 来删除pO分区中的数据。对于具有上百万条记录的表来说，删除分区要比运行一个DELETE 语句有效得多。<br>经常运行包含分区键的查询，MySQL可以很快地确定只有某一个或者某些分区需要扫描，因为其他分区不可能包含有符合该WHERE子句的任何记录。例如，检索商店ID大于等于25的记录数，MySQL只需要扫描p2分区即可。<br>mysql&gt; explain partitions select count(1) from emp where store id &gt;&#x3D; 25\G<br>*1.row<br>id:1<br>select type: SIMPLE<br>table:emp partitions:p2<br>type:ALL<br>possible keys:NULL<br>key: NULL key_len: NULL<br>ref:NULL rows:5<br>Extra: Using where<br>1 row in set (o.o0 sec) 14.2.2LIST分区<br>LIST分区是建立离散的值列表告诉数据库特定的值属于哪个分区，LIST分区在很多方面类似于RANGE分区，区别在于LIST分区是从属于一个枚举列表的值的集合，RANGE分区是从属于一个连续区间值的集合。<br>LIST分区通过使用PARTITIONBYLIST(expr)子句来实现，expr是某列值或一个基于某列值返回一个整数值的表达式，然后通过VALUESIN(value_list)的方式来定义分区，其中 valuelist是一个逗号分隔的整数列表。与RANGE分区不同，LIST分区不必声明任何特定的顺序，例如：<br>mysql&gt; CREATE TABLE expenses (<br>expense date DATE NOT NULL,</p>
<blockquote>
<p>category INT,</p>
</blockquote>
<p>≦ 207 ≧<br>14.2分区类型 189<br>amount DECIMAL （10,3)<br>)PARTITION BY LIST(category)（ PARTITION PO VALUES IN (3,5) PARTITION p1 VALUES IN (1, 10) PARTITION P2 VALUES IN (4, 9), PARTITION p3 VALUES IN (2), PARTITION p4 VALUES IN (6)<br>Query ok, 0 rows affected (o.o9 sec)<br>如果试图插入的列值（或者分区表达式的返回值）不包含分区值列表中时，那么INSERT 操作会失败并报错。要重点注意的是，LIST分区不存在类似VALUESLESSTHAN MAXVALUE这样包含其他值在内的定义方式。将要匹配的任何值都必须在值列表中找得到。<br>如果要使用非整数分区，则可以创建LISTCOLUMNS分区： mysql&gt; CREATE TABLE expenses (<br>expense date DATE NOT NULL,<br>category VARCHAR(30), amount DECIMAL (10,3)<br>)PARTITION BY LIST COLUMNS (category)（<br>PARTITION PO VALUES IN （’lodging’, food’),<br>PARTITION pl VALUES IN （flights’,ground transportation’), PARTITION p2 VALUES IN （leisure,customer entertainment’),<br>PARTITION p3 VALUES IN（communications’), PARTITION p4 VALUES IN (fees’)<br>-&gt;）；<br>Query ok, 0 rows affected (0.07 sec) 14.2.3COLUMNS分区<br>COLUMNS分区是在MySQL5.5引人的分区类型。在MySQL5.5版本之前，RANGE分区和LIST分区只支持整数分区，从而需要额外的函数计算来得到整数或者通过额外的转换表来转换为整数再分区。COLUMNS分区解决了这一问题。<br>COLUMNS分区可以细分为RANGECOLUMNS分区和LISTCOLUMNS分区，两者都支持整数、日期时间、字符串三大数据类型。<br>整数类型：tinyint、smallint、mediumint、int和bigint；其他数值类型都不支持，例如不支持Decimal和Float。<br>日期时间类型：date和datetime。<br>字符类型：char、varchar、binary和varbinary；不支持text和blob类型作为分区键。注意：在MySQL5.7中，COLUMNS分区仅支持一个或者多个字段名作为分区键，不支持表达式<br>作为分区键，区别于RANGE分区和LIST分区。<br>对比RANGE分区和LIST分区，COLUMNS分区的亮点除了支持数据类型增加之外，还<br>支持多列分区。例如，创建了一个根据字段a、b组合的RANGECOLUMNS分区： mysql&gt; CREATE TABLE rc3（<br>aINT, b INT</p>
<blockquote>
<p>)<br>PARTITION BY RANGE COLUMNS(a,b)（<br>PARTITION pO1 VALUES LESS THAN (O,10), PARTITION P02 VALUES LESS THAN (10,10), PARTITION P03 VALUES LESS THAN (10,20), PARTITION P04 VALUES LESS THAN (10,35),<br>PARTITION P05 VALUES LESS THAN (1O,MAXVALUE),<br>PARTITION PO6 VALUES LESS THAN (MAXVALUE, MAXVALUE)</p>
</blockquote>
<p>≦ 208 ≧<br>190 第14章MySQL分区<br>-&gt;;<br>Query ok, 0 rows affected (0.07 sec)<br>需要注意的是，RANGECOLUMNS分区键的比较是基于元组的比较，也就是基于字段组的比较，这和之前RANGE分区键的比较有些差异，我们写人几条测试数据并观察测试数据的分区分布情况来看一看。<br>O写入a&#x3D;l,b&#x3D;10的记录，从information_schema.partitions表发现数据实际上写入了p02 分区，也就是说元组（1，10）&lt;（10,10），如图14-1所示。<br>mysql&gt; insert into rc3 （a,b) values (1,10); Query ok,1 row affected (0.00 sec)<br>mysq1&gt; select (1,10) &lt;(10,10) from dual; 1(1,10)&lt;（10,10)1<br>1<br>1row in set (0.01 sec) mysql&gt; SELECT<br>partition_name part,<br>partition_expression expr, partition description descr, table_rows<br>-&gt;FROM<br>INFORMATION SCHEMA.partitions<br>-&gt;<br>-&gt;WHERE<br>TABLE SCHEMA &#x3D; schema AND TABLE NAME&#x3D;rc3’；<br>|part expr descr table rows<br>p01 0,10 0 pO2”b” 110,10 p03”b 10,20<br>p04”b” 10,35 p05”b 10,MAXVALUE o p06 MAXVALUE,MAXVALUE<br>O写入a&#x3D;10,b&#x3D;9的记录，从information_schema.partitions表能够发现数据实际上写入了p02分区，也就是说元组（10,9)&lt;(10,10)，元组（10,9)的大小判断不是简单地通过元组的首字段进行的，如图14-2所示。<br>根据range（ab）定义分区根据range（a,b）定义分区<br>加记录迎分区小于记录分区小于 ab p01 0 10 p01 0 10<br>10 p02 10 10 10 p02 10 10<br>109 p03 10 20 10 9 p03 10 20 10 p04 10 35 10 10 p04 10 35 1099 p05 10 MAXVALUE 1099 p05 10 MAXVALUE<br>06MAXVALUE MAXVALUE P06MAXVALUE MAXVALUE<br>(1,10)&lt;(10,10)?(1,10)&lt;(10,10)？<br>(a&lt;10)(a&lt;10) OR OR<br>(a&#x3D;10)AND(b&lt;10))(a&#x3D;10)AND(b&lt;10))<br>TRUE TRUE<br>(1&lt;10)(1&lt;10) OR OR<br>(1&#x3D;10)AND(10&lt;10)(1&#x3D;10)AND(10&lt;10))<br>图14-1写入RANGECOLUMNS分区测试一图14-2 2写入RANGECOLUMNS分区测试二</p>
<p>≦ 209 ≧<br>14.2分区类型 191<br>mysql&gt; insert into rc3(a, b) values(10,9); Query ok, 1 row affected (0.o0 sec)<br>mysq1&gt; se1ect (10,9)&lt;（10,10) from dual; 1（10,9)&lt;（10,10)1<br>1 row in set(0.00 sec) mysql&gt; SELECT<br>partition_name part,<br>-&gt; partition expression expr,-&gt; partition_description descr,<br>table_rows<br>-&gt;<br>-&gt;FROM<br>-&gt; INFORMATION SCHEMA.partitions-&gt;WHERE<br>TABLE SCHEMA &#x3D; SchemaO<br>-&gt;<br>-&gt; AND TABLE NAME&#x3D;’rc3’;<br>|part expr Idescr |table_rows<br>p01”a，b” 10,10 0 p02 a，b 10,10 p03”b” 10,20 p04”a” 10,35 o<br>b<br>p05 10,MAXVALUE p06 MAXVALUE,MAXVALUE 01<br>6 rows in set (0.01 sec)<br>写入a&#x3D;10,b&#x3D;10的记录，从information_schema.partitions表能够发现数据实际上写入<br>了p03分区，也就是说元组（10,10)&lt;&#x3D;（10,10)&lt;（10,20），如图14-3所示。<br>根据range（a,b）定义分区 根据range（a.b）定义分区<br>记录分区小于记录分区小于<br>b p01 0 10 ab p01 0 10 10 p02 10 p02 10 10 9 p03 10 20 10 9 p03 10<br>1010 p04 10 MAXVALUE 1010 p04 10 MAXVALUE<br>35<br>p05 10 1099 p05<br>MAXVALUE MAXVALUE p06MAXVALUE MAXVALUE<br>(1.10)&lt;(10,10)？(1,10)&lt;(10,10)？<br>(a&lt;10)(a&lt;10) OR OR<br>((a&#x3D;10)AND(b&lt;10)(a&#x3D;10)AND(b&lt;10)<br>FALSE TRUE<br>(1&lt;10)(1&lt;10) OR OR<br>(1&#x3D;10)AND（10&lt;10)（(1&#x3D;10)AND(10&lt;10)<br>图14-3写入RANGECOLUMNS分区测试三<br>mysql&gt; insert into rc3(a,b) values(10,10); Query ok,1 row affected (0.o0 sec)<br>mysql&gt; select（10,10)&lt;（10,10) from dual; 1（10,10)&lt;(10,10)I<br>0<br>1rowin set(0.00 sec)</p>
<p>≦ 210 ≧<br>192 第14章MySQL分区 mysql&gt; SELECT<br>partition name part,<br>partition expression expr, partition description descr, table_rows</p>
<blockquote>
<p>FROM<br>INFORMATION SCHEMA.partitions WHERE<br>TABLE SCHEMA &#x3D; schema) AND TABLE NAME&#x3D;rc3’;<br>Ipart expr |descr | table_rows pO1 10,10 0 p02 10,10 2 p03 10,20<br>p04 10,35 O p05 10,MAXVALUE 0 p06 MAXVALUE,MAXVALUE 01<br>6rows in set (0.00 sec)<br>其实，RANGECOLUMNS分区键的比较（元组的比较）其实就是多列排序，先根据a 字段排序再根据b字段排序，根据排序结果来分区存放数据。和RANGE单字段分区排序的规则实际上是一致的。<br>14.2.4HASH分区<br>HASH分区主要用来分散热点读，确保数据在预先确定个数的分区中尽可能平均分布。对一个表执行HASH分区时，MySQL会对分区键应用一个散列函数，以此确定数据应当放在 N个分区中的哪个分区中。<br>MySQL支持两种HASH分区，即常规HASH分区和线性HASH分区（LINEARHASH分区）。常规HASH使用的是取模算法，线性HASH分区使用的是一个线性的2的幂的运算法则。<br>在这里，我们将要创建一个常规HASH分区的散列表emp，使用PARTITIONBY HASH(expr)PARTITIONSnum子句对分区类型、分区键和分区个数进行定义，其中expr是某列值或一个基于某列值返回一个整数值的表达式；num是一个非负的整数，表示分割成分区的数量，默认num为1。下面的SQL语句创建了一个基于store_id列HASH分区的表，表被分成了4个分区。<br>mysqT&gt; CREATE TABLE emp（<br>id INT NOT NULL,<br>-&gt;<br>-&gt; ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT1970-01-01’,<br>Separated DATE NOT NULL DEFAULT’9999-12-31’,<br>job VARCHAR(30) NOT NULL, store_id INT NOT NULL<br>PARTITION BY HASH (store_id) PARTITIONS 4; Query Ok,0 rows affected (o.o5 sec)<br>其实对于一个表达式“expr”，我们是可以计算出它会被保存在哪个分区中。假设将要保存记录的分区编号为N，那么“N&#x3D;MOD(expr,num)”。例如，emp表有4个分区，插人一个store_id 列值为234的记录到emp表中：<br>mysql&gt; insert into emp values （1,’Tom,’2010-10-10,’9999-12-31′,’clerk’, 234）; Query ok,0 rows affected (0.05 sec)<br>如果插入一个col3列值为2005-09-15的记录到表t1中，那么保存该条记录的分区确定如下：</p>
</blockquote>
<p>≦ 211 ≧<br>14.2分区类型 193<br>OD（234，4)&#x3D;2 ISRLOIN<br>也就是store_id&#x3D;234这条记录将会被保存到第二个分区，图14-4显示了MySQL会检查 store_id中的值、计算散列、确定给定行会出现在哪个分区。<br>mysql&gt;linsert into emp</p>
<blockquote>
<p>（id,ename,hired,separated,job,storeid) &gt;values<br>（1tom2010-10-10，9999-12-31clerK，234);<br>Query ok,1 row affected(0.00 sec) mysql&gt;linsert into emp<br>（id,ename,hired,separated,job,store_id) value<br>1,SmitH2007-10-102012-11-30waiter 229);<br>Query ok,1 row affected(0.02 sec Partition P1<br>图14-4MySQL写入Hash分区<br>通过执行计划可以确定store_id&#x3D;234这条记录存储在第二个分区内： sql&gt; explain partitions select * from emp where store id &#x3D; 234\G<br>*1.row<br>id:1<br>select_type: SIMPLE<br>table: emp partitions:p2<br>type:ALL<br>possible keys: NULL<br>key: NULL key_len:NULL ref: NULL rows : 2<br>Extra: using where<br>1 row in set (0.00 sec)<br>表达式“expr”可以是MySQL中有效的任何函数或者其他表达式，只要它们返回一个既非常数也非随机数的整数。每当插入&#x2F;更新&#x2F;删除一行数据时，这个表达式都需要计算一次，这意味着非常复杂的表达式可能会引起性能问题，MySQL也不推荐使用涉及多列的哈希表达式。<br>常规HASH分区方式看上去挺不错的，通过取模的方式来使数据尽可能平均分布在每个分区中，让每个分区管理的数据都减少了，提高了查询的效率；可是当我们需要增加分区或者合并分区的时候，问题就出现了。假设原来是5个常规HASH分区，现在需要新增一个常规HASH分区，原来的取模算法是MOD(expr,5)，根据余数0～4分布在5个分区中，现在新增一个分区后，取模算法变成MOD(expr,6)，根据余数0～5分区在6个分区中，原来5个分区中的数据大部分都需要通过重新计算重新分区。常规HASH在分区管理上带来的代价太大了，不适合需要灵活变动分区的需求。为了降低分区管理上的代价，MySQL提供了线性HASH 分区，分区函数是一个线性的2的幂的运算法则。<br>线性HASH分区和常规HASH分区在语法上的唯一区别是在“PARTITIONBY”子句中<br>添加“LINEAR”关键字，例如： mysql&gt; CREATE TABLE emp (<br>id INT NOT NUL</p>
</blockquote>
<p>≦ 212 ≧<br>194 第14章MySQL分区<br>ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT‘1970-01-01’,<br>separated DATE NOT NULL DEFAULT 9999-12-31’,<br>job VARCHAR(3O) NOT NULL, store id INT NOT NULL<br>PARTITION BY LINEAR HASH (store id) PARTITIONS 4;<br>Query Ok,0 rows affected (0.02 sec)<br>同样的，使用线性HASH时，指定记录保存在哪个分区是可以计算出来的，假设将要保存记录的分区编号为N，num是一个非负的整数，表示分割成分区的数量，那么N可以通过以下算法得到。<br>（1）首先，找到下一个大于等于num的2的幂，这个值设为V，V可以通过下面的公式得到：<br>V &#x3D;Power (2, Ceiling (Log (2, num))<br>例如，刚才创建的emp表预先设定了4个分区，也就是num&#x3D;4。<br>V&#x3D;Power (2, Ceiling (Log (2, num)) &#x3D; Power (2, Ceiling (Log (2, 4)) &#x3D;Power (2, Ceiling (2))<br>&#x3D;Power(2,2) &#x3D;4<br>（2）其次，设置N&#x3D;F(column_list)&amp;（V-1)。<br>例如，我们刚才计算出V&#x3D;4，现在计算store_id&#x3D;234对应的N值。 N&#x3D;F(column_list)&amp;(V-1)<br>&#x3D;234&amp;（4-1) &#x3D;2<br>（3）当N&gt;&#x3D;num时，设置V&#x3D;Ceiling（V&#x2F;2)，设置N&#x3D;N&amp;（V-1)。<br>对于store_id&#x3D;234这条记录，由于N&#x3D;2&lt;4，所以直接就能够判断这条记录会被存储在第二个分区中。<br>有意思的是，当线性HASH的分区个数是2的N次幂时，线性HASH的分区结果和常规 HASH的分区结果是一致的。<br>注意：由于负数取模较复杂，仅以非负整数A举例，模数num为2幂次方，那么数值A对num<br>取模能够转换为位与运算：MOD(A,num）&#x3D;A&amp;（num-1)。<br>假设分区个数num为2的幂次方，数值A（A为非负整数）的所在分区为N（A)。<br>常规HASH分区时，保存数值A所在分区N(A)&#x3D;MOD(A,num)&#x3D;A&amp;（num-1)。<br>o! 线性HASH分区时，找到大于等于num的幂V&#x3D;Power（2，Ceiling（Log（2，<br>num))&#x3D;num（num本身就是2的幂次方）；其次，计算N&#x3D;A&amp;（num-1)，考虑到A为非负整数，N&#x3D;A&amp;（num-1)&#x3D;MOD（A,num)，也就是N为数值 A对分区个数num取模的结果，容易判定N&lt;num，最终数值A所在的分区 N(A)&#x3D;N&#x3D;A&amp;（num-1)。这与常规HASH分区计算得到结果一致。<br>线性HASH分区的优点是，在分区维护（包含增加、删除、合并、拆分分区）时，MySQL 能够处理得更加迅速；缺点是，对比常规HASH分区（取模）的时候，线性HASH各个分区之间数据的分布不太均衡。</p>
<p>≦ 213 ≧<br>14.2分区类型 195<br>14.2.5KEY分区<br>按照KEY进行分区非常类似于按照HASH进行分区，只不过HASH分区允许使用用户自定义的表达式，而KEY分区则不允许，需要使用MySQL服务器提供的HASH函数；同时 HASH分区只支持整数分区，而KEY分区支持使用除BLOB和Text外其他类型的列作为分区键。<br>我们同样可以用PARTITIONBYKEY（expr)子句来创建一个KEY分区表，expr是零个或者多个字段名名的列表。下面语句创建了一个基于job字段进行KEY分区的表，表被分成了4个分区： mysql&gt; CREATE TABLE emp （<br>-&gt; id INT NOT NULL,-&gt; ename VARCHAR(30),<br>-V hired DATE NOT NULL DEFAULT 1970-01-01’,<br>separated DATE NOT NULL DEFAULT9999-12-31’ job VARCHAR(30) NOT NULL,<br>-&gt; store id INT NOT NULL &gt;<br>PARTITION BY KEY (jOb) PARTITIONS 4；<br>Query Ok,0 rows affected (0.04 sec)<br>与HASH分区不同，创建Key分区表的时候，可以不指定分区键，默认会首先选择使用主键作为分区键，例如：<br>mysql&gt; CREATE TABLE emp（个个<br>id INT NOT NULL ename VARCHAR(30),<br>-&gt; hired DATE NOT NULL DEFAULT’1970-01-01’，<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’,<br>-&gt; job VARCHAR(30) NOT NULL,<br>store id INT NOT NULL, PRIMARY KEY (id)<br>PARTITION BY KEY（） PARTITIONS 4;<br>Query oK, 0 rows affected (0.02 sec)<br>在没有主键的情况，会选择非空唯一键作为分区键： mysql&gt; drop table emp;<br>Query ok, 0 rows affected (0.02 sec) mysql&gt; CREATE TABLE emp （<br>-&gt; id INT NOT NULL,-&gt; ename VARCHAR(30),-&gt; hired DATE NOT NULL DEFAULT’1970-01-01’,</p>
<blockquote>
<p>Separated DATE NOT NULL DEFAULT 9999-12-31-&gt; job VARCHAR(30) NOT NULL,<br>store id INT NOT NULL,<br>-&gt; UNIQUE KEY （id)-V<br>PARTITION BY KEY（）PARTITIONS 4;<br>Query ok, 0 rows affected (o.01 sec)<br>注意：作为分区键的唯一键必须是非空的，如果不是非空的，依然会报错。 mysql&gt; CREATE TABLE emp （<br>-&gt; id INT,-&gt; ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT <em>1970-01-01</em>,<br>-V separated DATE NOT NULL DEFAULT ‘9999-12-31,-&gt; job VARCHAR(30) NOT NULL,<br>store id INT NOT NULL,<br>-V UNIQUE KEY （id,ename)</p>
</blockquote>
<p>≦ 214 ≧<br>196 第14章MySQL分区<br>PARTITION BY KEY（）PARTITIONS 4;<br>ERROR 1488 (HY000): Field in list of fields for partition function not found in table<br>在没有主键，也没有唯一键的情况下，就不能不指定分区键了： mysql&gt; drop table emp;<br>Query ok,0 rows affected (0.o1 sec) mysql&gt; CREATE TABLE emp （<br>-&gt; id INT NOT NULL,-&gt; ename VARCHAR(30),<br>-&gt; hired DATE NOT NULL DEFAULT1970-01-01’,<br>-V separated DATE NOT NULL DEFAULT ‘9999-12-31’,-&gt; job VARCHAR(30) NOT NULL,<br>store id INT NOT NULL<br>-&gt;<br>PARTITION BY KEY（）PARTITIONS 4;<br>ERROR 1488 (HYoo0): Field in list of fields for partition function not found in table<br>注意：在按照KEY分区的分区表上，不能够执行“ALTERTABLEDROPPRIMARYKEY；”语句<br>来删除主键，MySQL会返回错误“Field inlist of fields for partitionfunctionnot found in table”。<br>和HASH分区类似，在KEY分区中使用关键字LINEAR具有同样的作用，也就是LINEAR KEY分区时，分区的编号是通过2的幂算法得到的，而不是通过取模得到的。<br>KEY分区和HASH分区类似，在处理大量数据记录时，能够有效地分散热点。 14.2.6子分区<br>子分区（Subpartitioning）是分区表中对每个分区的再次分割，又被称为复合分区（CompositePartitioning）。MySQL5.7支持对已经通过RANGE或者LIST分区了的表再进行<br>子分区。子分区既可以使用HASH分区，也可以使用KEY分区。例如： mysql&gt; CREATE TABLE ts (id INT, purchased DATE)<br>PARTITION BY RANGE(YEAR(purchased))<br>SUBPARTITION BY HASH(TO DAYS(purchased)) SUBPARTITIONS 2<br>!√<br>-&gt; PARTITION PO VALUES LESS THAN (1990),-V PARTITION P1 VALUES LESS THAN (2000) √ PARTITION P2 VALUES LESS THAN MAXVALUE<br>Query ok, 0 rows affected (0.11 sec)<br>表ts有3个RANGE分区，这3个分区中的每个分区（pO、pl、p2）又被进一步分成两个子分区，实际上，整个表被分成了3×2&#x3D;6个分区，由于PARTITIONBYRANGE子句的作用，第一和第二个分区只保存purchased列中值小于1990的记录。<br>复合分区适用于保存非常大量的数据记录。在实际使用中，要注意以下几点。每个分区必须具有相同数量的子分区。<br>如果要显式指定子分区，则每个分区都要显式指定，比如下面的语句中，p1没有显式指定子分区，执行会失败：<br>CREATE TABLE ts (id INT, purchased DATE)<br>PARTITION BY RANGE( YEAR(purchaSed)）<br>SUBPARTITION BY HASH（ TO DAYS(purchased) ）（<br>PARTITION PO VALUES LESS THAN (1990)（<br>SUBPARTITION SO, SUBPARTITION S1</p>
<p>≦ 215 ≧<br>14.2分区类型 197<br>PARTITION p1 VALUES LESS THAN (2000), PARTITION P2 VALUES LESS THAN MAXVALUE（<br>SUBPARTITION s2, SUBPARTITION s3<br>子分区的名称在整个表中是唯一的。下面的语句执行会报分区名重复错误： CREATE TABLE ts (id INT, purchased DATE)<br>PARTITION BY RANGE(YEAR(purchased))<br>SUBPARTITION BY HASH( TO DAYS(purchased) ）（<br>PARTITION pO VALUES LESS THAN (1990) (<br>SUBPARTITION SO, SUBPARTITION_S1<br>PARTITION P1 VALUES LESS THAN (2000)（<br>SUBPARTITION sO, SUBPARTITION s1<br>PARTITION P2 VALUES LESS THAN MAXVALUE （<br>SUBPARTITION SO, SUBPARTITION s1<br>ERROR 1517 (HY000): Duplicate partition name s0 将pl、p2中的子分区名改一下即执行正常： mysql&gt; CREATE TABLE ts （id INT, purchased DATE)<br>PARTITION BY RANGE( YEAR(purchased))<br>SUBPARTITION BY HASH( TO DAYS(purchased) )(<br>PARTITION PO VALUES LESS THAN (1990)（<br>SUBPARTITION sO, SUBPARTITION s1<br>PARTITION P1 VALUES LESS THAN (2000)（<br>SUBPARTITION s2, SUBPARTITION s3<br>PARTITION p2 VALUES LESS THAN MAXVALUE (<br>SUBPARTITION S4, SUBPARTITION s5<br>Query ok, 0 rows affected (0.04 sec)<br>14.2.7MySQL分区处理NULL值的方式<br>MySQL不禁止在分区键值上使用NULL，分区键可能是一个字段或者一个用户定义的表达式。一般情况下，MySQL的分区把NULL当作零值，或者一个最小值进行处理。<br>注意：RANGE分区中，NULL值会被当作最小值来处理；LIST分区中，NULL值必须出现在枚<br>举列表中，否则不被接受；HASH&#x2F;KEY分区中，NULL值会被当作零值来处理。<br>例如，创建tb_range表，按照id进行RANGE分区，在RANGE分区中写人NULL值： mysql&gt;CREATE TABLE tb_range (<br>-&gt;id INT,<br>-&gt;name VARCHAR(5)<br>-&gt; PARTITION BY RANGE(id) (<br>-&gt;PARTITION pO VALUES LESS THAN (-6),-&gt;PARTITION p1 VALUES LESS THAN (O),-&gt; PARTITION p2 VALUES LESS THAN (1),<br>-&gt; PARTITION p3 VALUEs LESs THAN MAXVALUE</p>
<p>≦ 216 ≧<br>198 第14章MySQL分区 Query ok, 0 rows affected (0.06 sec)<br>mysql&gt;insert into tb range values (null,NULL’); Query ok,1 row affected (0.00 sec)<br>查询INFORMATIONSCHEMA.PARTITIONS表确认写人的NULL值被当作最小值处理，<br>NULL值被分配在分区pO内： mysqT&gt;SELECT<br>partition_name part,</p>
<blockquote>
<p>partition expression expr, partition description descr, table_rows<br>-&gt;FROM<br>INFORMATION SCHEMA.partitions &gt;WHERE<br>TABLE SCHEMA &#x3D; schema() AND TABLE NAME&#x3D;’tb_range’;<br>1part expr descr 1tablerows<br>po id-6 11 p1 id oi 1p2 id 1 0<br>1p3 1 MaXVaLUE | 01 4rows in set (0.00 sec)<br>例如，在LIST分区中写入NULL值，分区定义不包含NULL值的时候，会返回一个错<br>误“ERROR 1526 (HY000): Table has no partition for value NULL”。 mysql&gt;CREATE TABLE tb list （<br>-&gt;id INT,<br>-&gt;name VARCHAR(5)-&gt;)<br>-&gt;PARTITION BY LIST(id)（<br>-&gt;PARTITION p1VALUES IN （O),-&gt;PARTITION p2 VALUES IN (1) &gt;&gt;；<br>Query ok, 0 rows affected (o.o1 sec)<br>mysql&gt;insert into tb_list values (null,’NULL’);<br>ERROR 1526 (HY000):Table has no partition for value NULL<br>在LIST分区中增加NULL的定义之后，就能够成功写人NULL值： mysql&gt;CREATE TABLE tb list（<br>-&gt; id INT,<br>-&gt;name VARCHAR(5)-&gt;)<br>PARTITION BYLIST(id)（<br>-&gt; PARTITION P1 VALUES IN (O,NULL)，<br>-&gt;PARTITION p2 VALUES IN(1) &gt;);<br>Query ok,0 rows affected (o.o1 sec)<br>root@localhost:test 16:43&gt;insert into tb list values (NULL,*NULL’);<br>Query ok,1 row affected (o.o0 sec) root@localhost:test 16:43&gt;SELECT<br>partition _name part,<br>partition expression expr, partition description descr,<br>table rows-&gt;FROM<br>INFORMATION SCHEMA.partitions-&gt;WHERE<br>TABLE SCHEMA &#x3D; schema（) AND TABLE NAME&#x3D;’tb list’;</p>
</blockquote>
<p>≦ 217 ≧<br>14.3分区管理 199<br>expr | descr I table_rows 1<br>pl id NULL,0 p2 id<br>2rows in set (0.00 sec)<br>例如，创建tb_hash表，按照id列HASH分区，在HASH分区中写人NULL值： mysql&gt;CREATE TABLE tb hash (<br>id INT,<br>name VARCHAR(5)</p>
<blockquote>
<p>-&gt;PARTITION BY HASH(id)-&gt; PARTITIONS 2;<br>Query ok,0 rows affected (0.04 sec)<br>mysql&gt;insert into tb hash values (null,NuLL’);<br>Query ok, 1 row affected (0.o0 sec) mysql&gt;SELECT<br>partition_name part,<br>partition_expression expr, partition_description descr<br>table_rows FROM<br>INFORMATION_SCHEMA.partitions &gt;WHERE<br>TABLE SCHEMA &#x3D; schema) AND TABLE NAME&#x3D;’tb _hash’;<br>part expr descr table rows|<br>po id NULL pl id NULL<br>2 rows in set (0.00 sec)<br>由于针对不同的分区类型，NULL值时而被当作零值处理，时而被当作最小值处理，为了避免在处理NULL值时出现误判，更推荐通过设置字段非空和默认值来绕开MySQL默认对NULL值的处理。<br>14.3 分区管理<br>MySQL提供了添加、删除、重定义、合并、拆分、交换分区的命令，这些操作都可以通过ALTERTABLE命令来进行实现。<br>14.3.1RANGE与LIST分区管理<br>在添加、删除、重新定义分区的处理上，RANGE分区和LIST分区非常相似，所以合并一起来说。<br>从一个RANGE或者LIST分区的表中删除一个分区，可以使用ALTERTABLEDROP PARTITION语句来实现，以之前创建的按照表达式YEAR(seperated)的值进行RANGE分区<br>的emp_date表为例，执行如下语句创建emp_date表： mysql&gt; CREATE TABLE emp date （<br>id INT NOT NULL, ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT 1970-01-01*,<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’, job VARCHAR(30) NOT NULL,</p>
</blockquote>
<p>≦ 218 ≧<br>200 第14章MySQL分区<br>store id INT NOT NULL<br>-V<br>PARTITION BY RANGE (YEAR(separated）)（<br>PARTITION PO VALUES LESS THAN (1995) PARTITION P1 VALUES LESS THAN (2000)，<br>-V PARTITION P2 VALUES LESS THAN (2005),-&gt; PARTITION p3 VALUES LESS THAN (2015)-&gt;）;<br>Query ok,0 rows affected (0.o8 sec) 写人测试数据：<br>mysql&gt;insert into emp_date（id, ename,hired, separated, job, store id) values -&gt;（7499，’ALLEN’, 1981-02-20’,2003-08-03,SALESMAN,30）,<br>(7521,WARD’， 1981-02-22,·1993-09-01,SALESMAN,30)，-&gt;<br>1981-04-022000-08-01,MANAGER′,20),</p>
<blockquote>
<p>(7566，”JONES’.（7654,<br>-&gt; MARTIN’,*1981-09-28’,2012-12-31 SALESMAN′，30),-&gt;(7698,*BLAKE′,’1981-05-01′,1998-09-08’,MANAGER’,30),(7782,’CLARK’， 1981-06-092007-08-01， ‘MANAGER’，10),（7788,’SCOTT’， 1987-04-19’,2012-05-01′,ANALYST’，20)，（7839,KING’,‘1981-11-17’,’2011-03-09′，’PRESIDENT′,10)，（7844,TURNER′,1981-09-08′,’2010-12-31’, SALESMAN’，30)，（7876,ADAMS′,1987-05-23，2000-01-01,CLERK′，20)，(7900,JAMES′,1981-12-03,2004-09-02,CLERK,30), V<br>（7902， FORD’ 1981-12-03,2010-12-31， ANALYST’，20)，(7934,MILLER’,1982-01-23,2011-12-31’CLERK’,10）;<br>Query ok, 13 rows affected (0.01 sec) Records:13 Duplicates:0 warnings:0<br>通过下面的查询语句查看哪些记录在分区p2中（LESSTHAN2005）：<br>mysql&gt;select * from emp_date where separated between ‘2000-01-01’and ‘2004-12-31’; id ename hired Iseparated |job Istore id1<br>7499 ALLEN 1981-02-20 |2003-08-03 SALESMAN 30 7566 JONES 1981-04-02 2000-08-01 MANAGER 20 7876 ADAMS 1987-05-23 2000-01-01 1CLERK 20<br>7900 JAMES 1981-12-03 2004-09-02 CLERK 30 4rows in set (o.00 sec)<br>执行下面的语句删除p2分区：<br>mysql&gt;alter table emp date drop partition p2;<br>Query ok,0 rows affected (o.01 sec) Records:O Duplicates:O warnings:0<br>注意：删除分区的命令执行之后，并不显示实际从表中删除的行数，并不是真的没有记录被删除。<br>从表结构定义上，可以观察到p2分区确实被删除了： mysql&gt;show create table emp_date\G<br>Table: emp date<br>Create Table: CREATE TABLE emp date（ idint(11) NOT NULL,<br>ename varchar(3O) DEFAULT NULL<br>hired date NOT NULL DEFAULT’1970-01-01’<br>separated date NOT NULL DEFAULT‘9999-12-31′,<br>jobvarchar(30) NOT NULL, store id int(11) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1<br>&#x2F;*150100 PARTITION BY RANGE (YEAR(separated))<br>(PARTITION pO VALUES LESS THAN (1995) ENGINE&#x3D; InnoDB, PARTITION p1 VALUES LESS THAN (200O) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES LESS THAN (2015) ENGINE&#x3D;InnoDB) *&#x2F; 1row in set(o.o0 sec)<br>删除了p2分区，那么也同时删除了该分区中所有数据，重新执行前面的查询来确认一下：</p>
</blockquote>
<p>≦ 219 ≧<br>14.3分区管理 201<br>mysql&gt;select * from emp date where separated between 2000-01-01’ and 2004-12-31’; Empty set (0.00 sec)<br>同时检查emp_date表的记录数，确认受影响的仅是原来在p2分区中的记录：<br>mysql&gt;select count(l) from emp_ date; |count（11)1<br>1row in set (0.00 sec)<br>再次写人separated日期在2000-01-01’和2004-12-31之间的新记录到emp_date表时，这些行会被保存在p3分区中，确认一下，首先检查emp_date表的记录分布，p3分区中仅有7 条记录：<br>mysql&gt;SELECT<br>partition_name part,<br>partition expression expr, partition description descr, table_rows<br>FROM<br>INFORMATIoN_SCHEMA.partitions WHERE<br>TABLE SCHEMA &#x3D; schemaO AND TABLE_NAME&#x3D;’emp_date’;<br>Ipart | expr I descr 1table rows<br>pO YEAR(separated) 1995 pl 1YEAR(separated) 2000<br>1p3 IYEAR(separated) 2015 3 rows in set (o.00 sec)<br>在emp_date表中写人一条separated日期在2000-01-01’和2004-12-31之间的新记录： mysql&gt;insert into emp date(id, ename,hired,separated, job, store id) values</p>
<blockquote>
<p>（7566,J0NES′，1981-04-02，2000-08-01′,MANAGER′,20); Query ok,1rowaffected o.o0sec）<br>再次检查emp_date表的记录分布，发现p3分区的记录数增加为8条，确认新写入的记<br>录写人p3分区： mysql&gt;SELEcT<br>partition name part,<br>partition expression expr, partition_description descr, table rows<br>FROM<br>INFORMATION SCHEMA.partitions WHERE<br>TABLE SCHEMA &#x3D; schema() AND TABLE NAME&#x3D;’emp_date’;<br>part |expr Idescr 1 table rows1<br>PO YEAR(separated) 11995 0 p1 YEAR(separated) 2000 o<br>p3 IYEAR(separated) 2015 81 3 rows in set (0.00 sec)<br>删除LIST分区和删除RANGE分区使用的语句完全相同，只不过删除LIST分区之后，由于在LIST分区的定义中不再包含已经被删除了的分区的值列表，所以后续无法写人包含有已经删除了的分区的值列表的数据。</p>
</blockquote>
<p>≦ 220 ≧<br>202 第14章MySQL分区<br>为一个RANGE或者LIST分区的表增加一个分区，可以使用ALTERTABLEADD PARTITION语句来实现。对于RANGE分区来说，只能通过ADDPARTITION方式添加新的分区到分区列表的最大一端，例如，给emp_date表增加p4分区，存放separated日期在 2015-01-01和2029-12-31之间的记录：<br>mysql&gt;alter table emp_date add partition (partition p4 values less than (2030));<br>Query ok,0 rows affected (o.o1 sec) Records:0Duplicates:0warnings:0<br>mysql&gt;show create table emp_date\G<br>Table:emp_date<br>Create TabTe: CREATE TABLE emp date（<br>idint(11) NOT NULL,<br>enameVarchar(30) DEFAULT NULL<br>hireddate NOT NULL DEFAULT’1970-01-01’<br>separateddate NOT NULL DEFAULT’9999-12-31’,<br>jobvarchar(30) NOT NULL, store_idint（11) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl<br>&#x2F;*150100 PARTITION BY RANGE (YEAR(separated))<br>(PARTITION PO VALUES LESS THAN (1995) ENGINE&#x3D; InnoDB, PARTITION p1 VALUES LESS THAN (200O) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES LESS THAN (2015) ENGINE&#x3D;InnoDB,<br>PARTITION p4 VALUES LESS THAN (2030) ENGINE &#x3D; InnoDB) *&#x2F; 1 row in set (0.01 sec)<br>只能从RANGE分区列表最大端增加分区的话，否则会出现如下错误：<br>mysql&gt;alter table emp date add partition (partition p5 values less than (2025));<br>ERROR 1493 (HYooo): VALuEs LESS THAN value must be strictly increasing for each partition 给LIST分区增加新分区的方式也类似，以之前创建的expenses表为例，当前的expenses<br>表结构如下：<br>mysql&gt;CREATE TABLE expenses （<br>expense date DATE NOT NULL,<br>-&gt; category INT,<br>amount DECIMAL (10,3)<br>)PARTITION BY LIST(category)（<br>PARTITION pO VALUES IN (3,5), PARTITION P1 VALUES IN (1,10), PARTITION p2 VALUES IN (4, 9),<br>PARTITION p3 VALUES IN (2) PARTITION p4 VALUES IN (6)<br>Query oK,0 rows affected (o.04 sec)<br>为expenses表新增p5分区存储category分类为7和8的记录：<br>mysql&gt;alter table expenses add partition (partition p5 values in (7,8));<br>Query ok,0 rows affected (o.01 sec) Records:ODuplicates:O Warnings:0<br>增加LIST分区时，不能添加一个包含现有分区值列表中的任意值的分区，也就是说对一<br>个固定的分区键值，必须指定并且只能指定一个唯一的分区，否则会出现错误： mysql&gt;alter table expenses add partition (partition p6 values in (6,11));<br>ERROR 1495 (HY000): Multiple definition of same constant in list partitioning<br>MySQL也提供了在不丢失数据的情况下，通过重新定义分区的语句ALTERTABLE REORGANIZEPARTITIONINTO重定义分区。仍以RANGE分区的emp_date表为例，当前 emp_date的表结构如下：<br>mysql&gt;show create table emp_date\G</p>
<p>≦ 221 ≧<br>14.3分区管理 203<br>Table:emp date<br>Create Table:CREATE TABLE emp date（<br>id int(ll) NOT NULL,<br>enamevarchar(30) DEFAULT NULL,<br>hireddate NOT NULL DEFAULT1970-01-01<br>separated date NOT NULL DEFAULT’9999-12-31<br>jobvarchar(30) NOT NULL, store id int(il) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl<br>&#x2F;<em>!50100 PARTITION BY RANGE (YEAR(separated))<br>(PARTITION pO VALUES LESS THAN (1995) ENGINE &#x3D; InnoDB, PARTITION p1 VALUES LESS THAN (200O) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES LESS THAN (2015) ENGINE &#x3D; InnoDB,<br>PARTITION p4 VALUES LESS THAN (2030) ENGINE &#x3D; InnoDB) <em>&#x2F; 1 row in set (0.00 sec)<br>计划拆分p3分区（2000～2015）为两个分区p2（2000～2005）和p3（2005～2015）： mysql&gt;alter table emp_date reorganize partition p3 into (<br>partition p2 values less than (2005), partition p3 values less than (2015)<br>Query ok, 8 rows affected (0.03 sec) Records:8Duplicates:O warnings:0<br>确认拆分之后emp_date表的表结构： mysql&gt;show create table emp_date\G<br>Table: emp date<br>Create Table: CREATE TABLE emp date（ id int(11) NOT NULL,<br>ename varchar(30) DEFAULT NULL,<br>hired date NOT NULL DEFAULT1970-01-01<br>separated date NOT NULL DEFAULT’9999-12-31’,<br>job varchar(30) NOT NULL, store id int(11) NOT NULL<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl<br>&#x2F;</em>!50100 PARTITION BY RANGE (YEAR(separated))<br>(PARTITION pO VALUES LESS THAN (1995) ENGINE &#x3D; InnoDB, PARTITION p1 VALUES LESS THAN (2O0O) ENGINE &#x3D; InnoDB, PARTITION p2 VALUES LESS THAN (2005) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES LESS THAN (2015) ENGINE &#x3D; InnoDB, PARTITION p4 VALUES LESS THAN (2030) ENGINE &#x3D; InnoDB)</em>&#x2F; 1 row in set (o.00 sec)<br>重新定义分区可以用来拆分一个RANGE分区为多个RANGE分区，也可以用来合并多<br>个相邻RANGE分区为一个RANGE分区或者多个RANGE分区： mysql&gt;alter table emp date reorganize partition pl,p2,p3 into (<br>partition pl values less than (2015)<br>-&gt;)；<br>Query ok, 9 rows affected (0.05 sec) Records:9Duplicates:0 warnings:0<br>mysql&gt;show create table emp_date\G<br>Table: emp date<br>Create Table: CREATE TABLE emp date（ idint(11) NOT NULL,<br>ename varchar(30) DEFAULT NULL,<br>hired date NOT NULL DEFAULT 1970-01-01’<br>separated date NOT NULL DEFAULT 9999-12-31’，<br>jobvarchar(30) NOT NULL, store_id int(11) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1<br>&#x2F;*!5O10O PARTITION BY RANGE (YEAR(separated))<br>(PARTITION pO VALUES LESS THAN (1995) ENGINE &#x3D; InnoDB, PARTITION p1 VALUES LESS THAN (2015) ENGINE &#x3D; InnoDB,</p>
<p>≦ 222 ≧<br>204 第14章MySQL分区<br>PARTITION p4 VALUES LESS THAN (2030) ENGINE &#x3D; InnoDB)<em>&#x2F; 1 row in set (0.00 sec)<br>注意：重新定义RANGE分区时，只能够重新定义相邻的分区，不能跳过某个RANGE分区进行<br>重新定义，同时重新定义的分区区间必须和原分区区间覆盖相同的区间；也不能使用重新定义分区来改变表分区的类型，例如，不能把RANGE分区变为HASH分区，也不能把HASH 分区变成RANGE分区。<br>同样的，对LIST分区，也可以使用ALTERTABLEREORGANIZEPARTITIONINTO语<br>句重定义分区，例如，当前expenses 表的分区如下： mysql&gt;show create table expenses\G<br>★★业青<br>Table:expenses<br>Create Table: CREATE TABLE expenses<br>expense date date NOT NULL, categoryint(i1) DEFAULT NULL, amountdecimal（10,3) DEFAULT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl&#x2F;</em>!50100 PARTITION BY LIST (Category)<br>(PARTITION pO VALUES IN (3,5) ENGINE &#x3D;InnoDB, PARTITION p1 VALUES IN (1,10) ENGINE &#x3D; InnoDB, PARTITION p2 VALUES IN (4,9) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES IN (2) ENGINE &#x3D; InnoDB, PARTITION p4 VALUES IN （6) ENGINE&#x3D; InnoDB,<br>PARTITION p5 VALUES IN (7,8) ENGINE &#x3D; InnoDB)* 1row in set (o.00 sec)<br>现在需要调整p4分区，使得p4分区包含值为6和11的记录，即p4分区的定义为<br>PARTITIONp4VALUESIN(6,11)，之前单纯通过ADDPARTITION的方式是不可以的： mysql&gt;alter table expenses add partition (partition p6 values in (6,11));<br>ERROR 1495 (HY0o0): Multiple definition of same constant in list partitioning<br>可以变通地通过增加分区和重定义分区来实现。首先，先增加不重复值列表的p6分区，包含值11：<br>mysql&gt;alter table expenses add partition (partition p6 values in (11));<br>Query oK,0 rows affected (o.02 sec) Records:ODuplicates:O Warnings:0<br>mysql&gt;show create table expenses\G;<br>Table: expenses<br>Create Table: CREATE TABLE expenses（<br>expense date date NOT NULL, category int（i1) DEFAULT NULL，<br>amountdecimal（10,3) DEFAULT NULL）ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl&#x2F;<em>150100 PARTITION BY LIST (category)<br>（PARTITION pO VALUES IN (3,5) ENGINE&#x3D; InnoDB, PARTITION p1 VALUES IN (1,10) ENGINE &#x3D; InnoDB, PARTITION P2 VALUES IN (4,9) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES IN (2) ENGINE &#x3D; InnoDB, PARTITION p4 VALUES IN (6) ENGINE &#x3D; InnoDB, PARTITION p5 VALUES IN （7,8) ENGINE &#x3D; InnoDB,<br>PARTITION p6 VALUES IN (11) ENGINE&#x3D; InnoDB)</em>&#x2F; 1 row in set (0.00 sec)<br>之后，通过REORGANIZEPARTITION方式重定义p4、p5、p6这3个分区，合并p4和 p6两个分区为新的p4分区，包含值6和11：<br>myql&gt;alter table expenses reorganize partition p4,p5,p6 into （<br>partition p4 values in (6,11), partition p5 values in (7,8)</p>
<p>≦ 223 ≧<br>14.3分区管理 205<br>-&gt;);<br>Query ok, 0 rows affected (0.05 sec) Records:0Duplicates:0warnings:0<br>mysql&gt;show create table expenses\G<br>Table: expenses<br>Create Table: CREATE TABLE expenses<br>expense date  date NOT NULL, category int(Il) DEFAULT NULL,<br>amountdecima1(10,3) DEFAULT NULL)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1&#x2F;*!50100 PARTITION BY LIST (category)<br>(PARTITION pO VALUES IN (3,5) ENGINE &#x3D; InnoDB, PARTITION p1 VALUES IN (1,10) ENGINE &#x3D; InnoDB, PARTITION p2 VALUES IN (4,9) ENGINE &#x3D; InnoDB, PARTITION p3 VALUES IN (2) ENGINE &#x3D; InnoDB, PARTITION p4 VALUES IN (6,11) ENGINE &#x3D; InnoDB, PARTITION p5 VALUES IN (7,8) ENGINE&#x3D; InnoDB) *&#x2F; 1 row in set (o.o0 sec)<br>通过重定义分区之后，p4分区的值包含了6和11。类似的重定义RANGE分区，重新定义LIST分区时，只能够重新定义相邻的分区，不能跳过LIST分区进行重新定义，否则提示以下信息：<br>mysql&gt;alter table expenses reorganize partition p4,p6 into （partition p4 values in (6,11）); ERRoR 1519 (Hyooo): when reorganizing a set of partitions they must be in consecutive order<br>注意：类似重新定义RANGE分区，重新定义LIST分区时，只能够重新定义相邻的分区，不能跳<br>过LIST分区进行重新定义，同时重新定义的分区区间必须和原分区区间覆盖相同的区间；也不能使用重新定义分区来改变表分区的类型，例如，不能把LIST分区变为RANGE分区，也不能把RANGE分区变成LIST分区。<br>14.3.2HASH与KEY分区管理<br>在改变分区设置方面，HASH分区和KEY分区的表非常类似，所以这两种分区的管理合并在一起讨论。<br>不能以RANGE或者LIST分区表中删除分区的相同方式，来从HASH或者KEY分区的表中删除分区，而可以通过ALTERTABLECOALESCEPARTITION语句来合并HASH分区<br>或者KEY分区。例如，emp表按照store_id分成了4个分区： mysqT&gt; CREATE TABLE emp（<br>id INT NOT NULL, ename VARCHAR(30),<br>hired DATE NOT NULL DEFAULT 1970-01-01<br>separated DATE NOT NULL DEFAULT ‘9999-12-31’，<br>job VARCHAR(30) NOT NULL, store id INT NOT NULL</p>
<blockquote>
<p>PARTITION BY HASH (stOre id) PARTITIONS 4; Query ok, 0 rows affected (o.05 sec)<br>要减少HASH分区的数量，从4个分区变为2个分区，可以执行下面的ALTERTABLE命令： mysql&gt;alter table emp coalesce partition 2;<br>Query ok,0 rows affected (0.o3 sec) Records:O Duplicates:Owarnings:0<br>mysql&gt;show create table emp\G<br>Table: emp<br>Create Table: CREATE TABLE emp（</p>
</blockquote>
<p>≦ 224 ≧<br>206 第14章MySQL分区<br>idint(11) NOT NULL,<br>enameVarchar(3O) DEFAULT NULL<br>hired date NOT NULL DEFAULT’1970-01-01’<br>separated date NOT NULL DEFAULT’9999-12-31’,<br>jobvarchar(30) NOT NULL, store idint(11) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1&#x2F;<em>!50100 PARTITION BY HASH (store_id) PARTITIONS 2</em>&#x2F;<br>1 row in set (0.o0 sec)<br>COALESCE不能用来增加分区的数量，否则会出现以下错误： mysql&gt;alter table emp coalesce partition 8;<br>ERROR 1508 (HY000): Cannot remove all partitions, use DROP TABLE instead<br>要增加分区，可以通过ALTERTABLEADD PARTITION语句来实现，例如，当前emp<br>表有两个HASH分区，现在增加8个分区，最终emp表一共有10个HASH分区： mysql&gt;alter table emp add partition partitions 8;<br>Query ok,0 rows affected (0.05 sec) Records: ODuplicates:Owarnings:0<br>root@localhost:test 22:34&gt;show create table emp\G<br>Table: emp<br>Create Table: CREATE TABLE emp（ id int(11) NOT NULL,<br>enamevarchar(30) DEFAULT NULL,<br>hired date NOT NULL DEFAULT1970-01-01′，<br>separated date NOT NULL DEFAULT’9999-12-31’,<br>jobvarchar(30) NOT NULL, store idint(11) NOT NULL<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl&#x2F;*!50100 PARTITION BY HASH (store_id) PARTITIONS 10 *&#x2F;<br>1row in set (0.01 sec)<br>注意：通过ALTERTABLEADDPARTITIONPARTITIONSn语句新增HASH分区或者KEY分区时，<br>其实是对原表新增n个分区，而不是增加到n个分区。<br>14.3.3交换分区<br>MySQL5.6增加了交换分区的功能，使用ALTERTABLEptEXCHANGEPARTITIONp WITHTABLEnt命令，可以实现将分区表pt中的一个分区或者子分区p中的数据和普通表 nt中的数据进行交换。交换分区需要满足下列条件。<br>表nt不能是分区表，由于交换分区不能通过分区对分区的方式进行，如果有这种需求，可以用一个普通表作为中间表，通过交换两次分区来实现。<br>表nt不能是临时表。<br>表pt和nt的结构，除了分区之外，应该完全一致，包括索引的名称和索引列都要一致。表nt上不能有外键，也不能有其他表的外键依赖nt。<br>Ont表的所有数据，应该都在分区p定义的范围内，在MySQL5.7中，如果确定表中数据都在界限内，可以通过增加WITHOUTVALIDATION来跳过这个逐行验证的过程。<br>下面对交换分区做一下测试。<br>（1）首先创建一个分区表，并插入几行测试数据： mysql&gt; CREATE TABLE e（<br>id INT NOT NULL, fname VARCHAR(30),</p>
<p>≦ 225 ≧<br>14.3分区管理 207<br>Tname VARCHAR(30)<br>-&gt;)<br>-&gt; PARTITION BY RANGE （id)（<br>IV PARTITION PO VALUES LESS THAN (5O),<br>PARTITION P1 VALUES LESS THAN (100),<br>-&gt; PARTITION P2 VALUES LESS THAN (150)<br>-&gt; PARTITION p3 VALUES LESS THAN (MAXVALUE)-&gt;）；<br>Query ok,0 rows affected (0.03 sec) mysql&gt; INSERT INTo e VALUES</p>
<blockquote>
<p>(1669,“jim”,”Smith”),-&gt;(337,“Mary”,”Jones”),<br>(16,“Frank”，“white”)，</p>
<p>(2005,”Linda”,”Black”）;<br>V<br>Query ok, 4 rows affected (0.00 sec) Records:4Duplicates:0warnings:0<br>（2）接下来创建一个普通表，表结构和上面的分区表一致： mysql&gt; CREATE TABLE e2 LIKE e;<br>Query ok,0 rows affected (0.01 sec)<br>（3）通过REMOVEPARTITIONING子句将分区表改为非分区表： mysql&gt; ALTER TABLE e2 REMOVE PARTITIONING;<br>Query ok,0 rows affected (0.02 sec) Records:O Duplicates:O warnings:0<br>（4）查看分区表e中的数据分布：<br>mySql&gt; SELECT PARTITION_NAME,TABLE ROWS FROM INFORMATION SCHEMA.PARTITIONS<br>-&gt;WHERE TABLE NAME&#x3D;’e’; PARTITION NAME|TABLE ROWS<br>po p1 p2<br>p3 31 4rows in set (0.00 sec)<br>（5）执行交换分区命令，并观察交换之后的数据分布： mysql&gt; ALTER TABLE e EXCHANGE PARTITION pO WITH TABLE e2; Query oK, 0 rows affected (o.oo sec)<br>mySql&gt; SELECT PARTITION _NAME,TABLE_ROWS FROM INFORMATION SCHEMA.PARTITIONS<br>-&gt;WHERE TABLE NAME&#x3D;’e’; IPARTITION NAME|TABLE ROWSI<br>pO o p1<br>P2 01 p3 31<br>4rows in set (o.00 sec) mysq1&gt;<br>mysq&gt; select * from e2; Iid |fname|1name| 116|Frank|white 1 row in set (0.00 sec)<br>可以看到，数据已经成功地从分区表e的分区p0交换到了表e2中。<br>（6）在e2的name字段上创建索引l，此时e和e2定义不一致，交换命令报错：</p>
</blockquote>
<p>≦ 226 ≧<br>208 第14章MySQL分区<br>mysql&gt; create index idx e2 on e2（fname); Query oK,0 rows affected (o.o0 sec) Records:ODuplicates:0warnings:0<br>mysql&gt; ALTER TABLE e EXCHANGE PARTITION pO WITH TABLE e2; ERROR 1736 (HY000):Tables have different definitions<br>此时e上name列创建索引，但索引名和e2的不同，依然报错：<br>mysql&gt; create index idx e on e(fname); Query ok,0 rows affected (0.02 sec) Records:oDuplicates:owarnings:0<br>mysql&gt; ALTER TABLE e EXCHANGE PARTITION pO WITH TABLE e2;<br>ERROR 1736 (HY000):Tables have different definitions 将索引名称改为和e2一致，再次执行交换命令成功： mysql&gt; alter table e rename index idx e to idx e2;<br>Query ok,O rows affected (o.oo sec) Records:ODuplicates:0 warnings:0<br>mysql&gt; ALTER TABLE e EXCHANGE PARTITION pO WITH TABLE e2; Query ok,0rows affected (0.15 sec)<br>使用交换分区，可以方便地完成对包含大量数据的分区、子分区的备份，迁移等工作。但要特别注意以下几点，交换前尽量提前最好备份，避免交换后可能带来的数据问题：<br>交换分区不会触发任何被交换的表或分区上的触发器； 0 表中自增列的值会被重置；<br>交换分区的命令中，IGNORE关键字不会产生影响。 14.4小结<br>本章重点介绍了MySQL的集中主要的分区类型、适用场景以及常规的管理维护命令，分区通过“分而治之”的方法管理数据库表，提高了数据处理的并行度，从而能够提升性能。</p>
<p>≦ 227 ≧<br>3<br>第三部分优化篇</p>
<p>≦ 228 ≧<br>第15章SQL优化<br>在应用的开发过程中，由于初期数据量小，开发人员写SQL语句时更重视功能上的实现，但是当应用系统正式上线后，随着生产数据量的急剧增长，很多SQL语句开始逐渐显露出性能问题，对生产的影响也越来越大，此时这些有问题的SQL语句就成为整个系统性能的瓶颈，<br>因此我们必须要对它们进行优化。本章将详细介绍在MySQL中优化SQL语句的方法。 15.1 优化SQL语句的一般步骤<br>当面对一个有SQL性能问题的数据库时，我们应该从何处人手来进行系统的分析，使得能够尽快定位问题SQL并尽快解决问题。本节将向读者介绍这个过程。<br>本章大部分涉及的案例表位于MySQL的案例库Sakila上。Sakila是一个MySQL官方提供的模拟电影出租厅信息管理系统的数据库，可在MySQL官网页面上搜索并下载。<br>压缩包包括3个文件：sakila-schema.sql、sakila-data.sql和sakila.mwb，分别是Sakila库的表结构创建、数据灌人、Sakila的MySQLWorkbench数据模型（可以在MySQL工作台打开查看数据库模型）。<br>15.1.1通过showstatus命令了解各种SQL的执行频率<br>MySQL客户端连接成功后，通过show[sessionlglobalstatus命令可以提供服务器状态信息，也可以在操作系统上使用mysqladminextended-status命令获得这些消息。show[sessionlglobal]status可以根据需要加上参数“session”或者“global”来显示session级（当前连接）的统计结果和global级（自数据库上次启动至今）的统计结果。如果不写，默认使用的参数是“session”。<br>下面的命令显示了当前session中部分统计参数的值： mysql&gt; show status 1ike ‘com %’;<br>I variable_name |value|<br>Icom admin_commands 0<br>1 Com assign to_keycache 1Comalter_db<br>Com_ alter db upgrade ICom alter_event</p>
<p>≦ 229 ≧<br>15.1优化SQL语句的一般步骤 211<br>1 Com alter_ function Com_alter_instance Com alter_procedure Com_alter_server Com alter table<br>Com alter tablespace<br>Com_xxx表示每个xxx语句执行的次数，我们通常比较关心的是以下几个统计参数。 OCom_select:执行SELECT操作的次数，一次查询只累加1。<br>OCom_insert：执行INSERT操作的次数，对于批量插入的INSERT操作，只累加一次。<br>OCom_update:执行UPDATE操作的次数。 OCom_delete:执行DELETE操作的次数。<br>上面这些参数对于所有存储引擎的表操作都会进行累计。下面这几个参数只是针对 InnoDB存储引|擎的，累加的算法也略有不同。<br>OInnodb_rows_read:SELECT查询返回的行数。<br>OInnodb_rows_inserted：执行INSERT操作插入的行数。 OInnodb_rows_updated：执行UPDATE操作更新的行数。 OInnodb_rows_deleted:执行DELETE操作删除的行数。<br>通过以上几个参数，可以很容易地了解当前数据库的应用是以插入更新为主还是以查询操作为主，以及各种类型的SQL大致的执行比例是多少。对于更新操作的计数，是对执行次数的计数，不论提交还是回滚都会进行累加。<br>对于事务型的应用，通过Com_commit和Com_rollback可以了解事务提交和回滚的情况，对于回滚操作非常频繁的数据库，可能意味着应用编写存在问题。<br>此外，以下几个参数便于用户了解数据库的基本情况。 Connections:试图连接MySQL服务器的次数。<br>Uptime：服务器工作时间。 OSlow_queries:慢查询的次数。<br>15.1.2定位执行效率较低的SQL语句<br>可以通过以下两种方式定位执行效率较低的SQL语句。<br>通过慢查询日志定位那些执行效率较低的SQL语句，将slow-query-log参数设置为 1之后，MySQL会将所有执行时间超过long_query_time 参数所设定阔值的SQL，写入 slow_query_log_file参数所指定的文件中。<br>●慢查询日志在查询结束以后才记录，所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题，可以使用showprocesslist命令查看当前MySQL在进行的线程，包括线程的状态、是否锁表等，可以实时地查看SQL的执行情况，同时对一些锁表操作进行优化。<br>15.1.3通过EXPLAIN分析低效SQL的执行计划<br>通过以上步骤查询到效率低的SQL语句后，可以通过EXPLAIN或者DESC命令获取 MySQL如何执行SELECT语句的信息，包括在SELECT语句执行过程中表如何连接和连接</p>
<p>≦ 230 ≧<br>212 第15章SQL优化<br>的顺序，比如想统计某个email为租赁电影拷贝所支付的总金额，需要关联客户表customer 和付款表payment，并且对付款金额amount字段做求和（sum）操作，相应SQL的执行计划如下：<br>mysql&gt; explain select sum(amount) from customer a,payment b where 1&#x3D;1 and a.customer id &#x3D; b.customer id and email &#x3D;‘<a href="mailto:&#74;&#65;&#x4e;&#69;&#x2e;&#x42;&#69;&#78;&#78;&#x45;&#x54;&#x54;&#x40;&#115;&#x61;&#x6b;&#x69;&#108;&#x61;&#99;&#117;&#115;&#116;&#111;&#109;&#x65;&#114;&#x2e;&#111;&#x72;&#x67;">&#74;&#65;&#x4e;&#69;&#x2e;&#x42;&#69;&#78;&#78;&#x45;&#x54;&#x54;&#x40;&#115;&#x61;&#x6b;&#x69;&#108;&#x61;&#99;&#117;&#115;&#116;&#111;&#109;&#x65;&#114;&#x2e;&#111;&#x72;&#x67;</a>‘\G<br>id:1<br>select type: SIMPLE<br>table:a type:ALL<br>possible keys: PRIMARY<br>key: NULL key_len: NULL<br>ref:NULL rows:583<br>Extra: Using where<br>id:1<br>select_type: SIMPLE<br>table:b type: ref<br>possible keys:idx fk customer_id<br>key:idx fk customer_id key len:2<br>ref: sakila.a.customer_id<br>rows:12 Extra:<br>2 rows in set (0.00 sec)<br>对每个列简单地进行一下说明。<br>select_type:表示SELECT的类型，常见的取值有SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION中的第二个或者后面的查询语句）、SUBQUERY（子查询中的第一个SELECT）等。<br>table：输出结果集的表。<br>）type：表示MySQL在表中找到所需行的方式，或者叫访问类型，常见的类型如图15-1 所示。<br>IALL index range ref eq_ref const,system INULLI<br>图15-1常见访问类型<br>从左至右，性能由最差到最好。<br>（1）type&#x3D;ALL，全表扫描，MySQL遍历全表来找到匹配的行： mysql&gt; explain select * from film where rating &gt;9\G<br>id:1<br>select type: SIMPLE<br>table: film type: ALL<br>possible keys: NULL<br>key:NULL key_len: NULL<br>ref: NULL rows:916<br>Extra:using where<br>1 row in set (o.00 sec)<br>（2）type&#x3D;index，索引全扫描，MySQL遍历整个索引来查询匹配的行：</p>
<p>≦ 231 ≧<br>15.1优化SQL语句的一般步骤 213<br>mysql&gt; explain select title from film\G<br>id：1<br>select_type: SIMPLE<br>table:film type: index<br>possible keys: NULL<br>key: idx title key_len:767<br>ref: NULL rows:916<br>Extra: Using index<br>1 row in set (o.o0 sec)<br>（3）type&#x3D;range，索引范围扫描，常见于&lt;、&lt;&#x3D;、&gt;、&gt;&#x3D;、between等操作符：<br>mysql&gt; explain select * from payment where customer id &gt;&#x3D; 300 and customer _id &lt;&#x3D; 350\G<br>id：1<br>select type: SIMPLE<br>table: payment type: range<br>possible _keys:idx fk customer_id<br>key:idx fk customer_id key_len:2<br>ref: NULL rows: 1349<br>Extra: using where<br>1 row in set (o.o0 sec)<br>（4）type-ref，使用非唯一索引扫描或唯一索引的前缀扫描，返回匹配某个单独值的记录行，例如：<br>mysql&gt; explain select * from payment where customer_id &#x3D;350\G<br>id：1<br>select type: SIMPLE<br>table:payment type:ref<br>possible keys:idx_fk customer_id<br>key:idx fk customer id key_len:2<br>ref:const rows:23 Extra:<br>1row in set (0.00 sec)<br>索引idx_fk_customer_id是非唯一索引l，查询条件为等值查询条件customer_id&#x3D;35，所以扫描索引的类型为ref。ref还经常出现在join操作中：<br>mysql&gt; explain select b.<em>,a.</em> from payment a, customer b where a.customer id &#x3D; b.customer_idG<br>id：1<br>select_type: SIMPLE<br>table:b type: ALL<br>possible keys : PRIMARY<br>key: NULL key_len: NULL ref: NULL rows:505 Extra:<br>id:1<br>select type: SIMPLE<br>table:a type: ref<br>possible_keys:idx fk customer_id<br>key:idx fk customer id key_1en:2</p>
<p>≦ 232 ≧<br>214 第15章SQL优化<br>ref: sakila.b.customer_id<br>rows: 12 Extra:<br>2 rows in set (o.00 sec)<br>（5）type&#x3D;eq_ref，类似ref，区别就在使用的索引是唯一索引l，对于每个索引键值，表中只有一条记录匹配；简单来说，就是多表连接中使用primarykey或者unique index作为关联条件。<br>mysql&gt; explain select * from film a,film text b where a.film id &#x3D; b.film id\G ★★★★★★★★<br>id:1<br>select type: SIMPLE<br>table:a type: ALL<br>possible keys: PRIMARY<br>key: NULL key_len: NULL<br>ref: NULL rows:916 Extra:<br>id：1<br>select type: SIMPLE<br>table:b<br>type: eq_ref<br>possible keys: PRIMARY<br>key:PRIMARY key_len:2<br>ref: sakila.a.film id rows:1<br>Extra: using where<br>2rows in set (o.00 sec)<br>（6）type&#x3D;const&#x2F;system，单表中最多有一个匹配行，查询起来非常迅速，所以这个匹配行中的其他列的值可以被优化器在当前查询中当作常量来处理，例如，根据主键primarykey或者唯一索引unique index进行的查询。<br>构造一个查询：<br>mysql&gt; alter table customer drop index idx email;<br>Query ok,0 rows affected (0.o8 sec) Records:0 Duplicates:O warnings:0<br>mysql&gt; alter table customer add unique index uk email (email);<br>Query ok, 0 rows affected (0.15 sec) Records:ODuplicates:Owarnings:0<br>mysql&gt; explain select *from (select * from customer where email &#x3D;<a href="mailto:&#x41;&#x41;&#x52;&#111;&#x4e;&#46;&#x73;&#x45;&#x4c;&#x42;&#x59;&#x40;&#x73;&#97;&#107;&#105;&#x6c;&#x61;&#99;&#117;&#115;&#116;&#x6f;&#109;&#x65;&#x72;&#x2e;&#111;&#114;&#x67;">&#x41;&#x41;&#x52;&#111;&#x4e;&#46;&#x73;&#x45;&#x4c;&#x42;&#x59;&#x40;&#x73;&#97;&#107;&#105;&#x6c;&#x61;&#99;&#117;&#115;&#116;&#x6f;&#109;&#x65;&#x72;&#x2e;&#111;&#114;&#x67;</a>‘）a\G<br><em><strong>1.row</strong></em><br>id:1<br>select type: PRIMARY<br>table:<derived2> type: system<br>possible keys : NULL<br>key: NULL key_len: NULL<br>ref:NULL<br>rows:1 Extra:<br>id:2<br>select type: DERIVED<br>table: customer type: const<br>possible keys:uk email<br>key:uk_email key_len:153</p>
<p>≦ 233 ≧<br>15.1优化SQL语句的一般步骤 215<br>ref: rows:1 Extra:<br>2rows in set (o.00 sec)<br>通过唯一索引uk_email访问的时候，类型type为const；而从我们构造的仅有一条记录的a表中检索时，类型type就为 system。<br>（7）type&#x3D;NULL，MySQL不用访问表或者索引l，直接就能够得到结果，例如： mysql&gt; explain select 1 from dual where 1\G ★★***********<br>id：1<br>select type:SIMPLE<br>table: NULL type: NULL<br>possible keys: NULL<br>key:NULL key_len: NULL<br>ref:NULL rows: NULL<br>Extra: No tables used<br>1 row in set(o.00 sec)<br>类型type还有其他值，如ref_or_null（与ref类似，区别在于条件中包含对NULL的查询）、index_merge（索引合并优化）、unique_subquery（in的后面是一个查询主键字段的子查询）、index_subquery（与unique_subquery类似，区别在于in的后面是查询非唯一索引字段的子查询）等。<br>Opossible_keys：表示查询时可能使用的索引。 Okey：表示实际使用的索引。<br>Okey_len：使用到索引字段的长度。 rows:扫描行的数量。<br>OExtra：执行情况的说明和描述，包含不适合在其他列中显示但是对执行计划非常重要的额外信息。<br>MySQL从5.1版本开始支持分区功能，同时explain命令也增加了对分区的支持。可以通过explainpartitions命令查看SQL所访问的分区。例如，创建一个Hash分区的customer_part 表，根据分区键查询的时候，能够看到explainpartitions的输出结果中有一列partitions，其中<br>显示了SQL所需要访问的分区名字p2： mysql&gt; create table customer part（<br>customer id smallint(5) unsigned NOT NULL AUTO INCREMENT, PRIMARY KEY(customer id’)<br>-&gt;）partition by hash(customer_id) partitions 8; Query ok,0 rows affected (0.56 sec)<br>mysql&gt; insert into customer_part select * from customer;<br>Query ok, 599 rows affected (0.08 sec) Records:599 Duplicates:0 warnings:0<br>mysql&gt; explain partitions select * from customer part where customer id&#x3D; 130\G<br>id:1<br>select type: SIMPLE<br>table: customer_part partitions:p2<br>type: const<br>possible_keys:PRIMARY<br>key:PRIMARY key_len:2</p>
<p>≦ 234 ≧<br>216 第15章SQL优化<br>ref:const<br>rows:1 Extra:<br>1 row in set (0.00 sec)<br>有时，仅仅通过explain分析执行计划并不能很快地定位SQL的问题，那么这时我们还可以选择profile联合分析。<br>15.1.4通过showprofile分析SQL<br>MySQL从5.0.37版本开始增加了对showprofiles和showprofile语句的支持。通过<br>have_profiling参数，能够看到当前MySQL是否支持profile： mysql&gt; select @@have_profiling;<br>I @@have profiling| IYES<br>1 row in set(0.00 sec)<br>默认profiling是关闭的，可以通过set语句在Session级别开启profiling：<br>mysql&gt; select @@profiling; |@@profiling<br>1 row in set (0.02 sec) mysql&gt; set profiling&#x3D;1;<br>Query ok, 0 rows affected (o.o0 sec)<br>通过profile，用户能够更清楚地了解SQL执行的过程。例如，我们知道MyISAM表有表元数据的缓存（例如行数，即COUNT(*)值），那么对一个MyISAM表的COUNT(<em>）是不需要消耗太多资源的，而对于InnoDB来说，就没有这种元数据缓存，COUNT（</em>执行得较慢。下面来做个实验验证一下。<br>首先，在一个innodb引擎的付款表payment上，执行一个COUNT(<em>）查询： mysql&gt; select count(</em>) from payment;<br>1count(<em>）1 16049<br>1 row in set (0.01 sec)<br>执行完毕后，通过showprofiles语句，看到当前SQL的QueryID为4： mysql&gt; show profiles;<br>|Query ID| Duration 1 Query<br>110.00019300 SELECT DATABASE) 10.00049000丨 show databases 0.00281600 1 show tables<br>10.00774175| select count(</em>) from payment<br>4rows in set (0.00 sec)<br>通过showprofileforquery语句能够看到执行过程中线程的每个状态和消耗的时间： mysql&gt; show profile for query 4;</p>
<p>≦ 235 ≧<br>15.1优化SQL语句的一般步骤 217<br>status 1 Duration 1 starting 10.0000261 Waiting for query cache lock 10.000006 checking query cache for query 10000057 checking permissions 1 0.000011 opening tables 0.000300 System lock 0.000016 waiting for query cache lock 0.000024 init 0.000018 optimizing 0.000009 |statistics 0.000016 1preparing 0.000014 I executing 0000009 ISending data 10.007143 lend 0.000011 query end 0.000012 closing tables 0.000015 freeing items 0.000012 waiting for query cache lock 0.000004 freeing items 10.000020 | waiting for query cache lock 10.000004 |freeing items 10.000004<br>storing result in query cache 10.000006 logging slow query 0.000004 1cleaning up 10.0000051<br>24 rows in set (0.00 sec)<br>注意：Sendingdata状态表示MySQL线程开始访问数据行并把结果返回给客户端，而不仅仅是返<br>回结果给客户端。由于在Sending data状态下，MySQL线程往往需要做大量的磁盘读取操作，所以经常是整个查询中耗时最长的状态。<br>通过仔细检查showprofile forquery的输出，能够发现在执行COUNT(<em>)的过程中，时间主要消耗在Sendingdata这个状态上。为了更清晰地看到排序结果，可以查询INFORMATION_<br>SCHEMA.PROFILING表并按照时间做个DESC排序： mysql&gt; SET @query_id :&#x3D; 4;<br>Query ok,o rows affected (o.o0 sec)<br>mysql&gt; SELECT STATE, SUM(DURATION) AS Total R,<br>-&gt; ROUND( 1 100 * SUM(DURATION) &#x2F;<br>(SELECT SUM(DURATION)<br>-&gt; FROM INFORMATION SCHEMA.PROFILING-&gt; WHERE QUERY ID &#x3D; @query_id<br>),2) As Pct R, COUNT(</em>) AS Calls,<br>-&gt;<br>SUM(DURATION）&#x2F; COUNT(*)AS”R&#x2F;Ca71<br>-&gt;<br>FROM INFORMATION SCHEMA.PROFILING<br>WHERE QUERY ID &#x3D; @query_id GROUP BY STATE<br>ORDER BY Total R DESC;<br>STATE Total R 1PctR|Calls|R&#x2F;Call<br>Sending data 10.007143192.22 110.0071430000 |opening tables 10.0003001 3.871 110.0003000000<br>1logging slow query 10.000004 0.051 1 1 0.0000040000 19 rows in set (0.04 sec)<br>在获取到最消耗时间的线程状态后，MySQL支持进一步选择all、cpu、blockio、context switch、pagefaults等明细类型来查看MySQL在使用什么资源上耗费了过高的时间，例如，选择查看CPU的耗费时间：</p>
<p>≦ 236 ≧<br>218 第15章SQL优化 mysql&gt; show profile cpu for query 4;<br>Istatus Duration CPU user CPU_system Istarting 10.000036 0.000000 0.000000 Iexecuting 10.000009|0.000000 0.000000 Sending data 10.0071431 0.006999 0.0000001 Iend 10.000011 0.000000 0.0000001 |1ogging slow query 0.0000001<br>0.000002 0.000000 0.000000<br>1cleaning up 10.000003 0.000000 24rows in set (o.00 sec)<br>能够发现Sendingdata状态下，时间主要消耗在CPU上了。<br>对比MyISAM表的COUNT(<em>）操作，也创建一个同样表结构的MyISAM表，数据量也完全一致：<br>mysql&gt; create table payment myisam like payment; Query ok, 0 rows affected (0.11 sec)<br>mysql&gt; alter table payment myisam engine&#x3D;myisam;<br>Query ok,0 rows affected (0.24 sec) Records:O Duplicates:Owarnings:0<br>mysql&gt; insert into payment myisam select * from payment;<br>Query 0K, 16049 rows affected (0.37 sec) Records: 16049 Duplicates:0 Warnings:0<br>同样执行COUNT（</em>）操作，检查profile： mysql&gt; select count(<em>) from payment myisam;<br>|count（</em>）1 16049<br>1row in set(0.00 sec) mysql&gt; show profiles;<br>mysql&gt; show profile for query 10;<br>IStatus |Duration|<br>|starting 10.0000291<br>lexecuting 10.000015 end 10.000007 I query end 10.0000091<br>|cleaning up 10.0000061 21 rows in set (0.00 sec)<br>从profile的结果能够看出，InnoDB引擎的表在COUNT(*)时经历了Sendingdata状态，存在访问数据的过程，而MyISAM引擎的表在executing之后直接就结束查询，完全不需要访问数据。<br>读者如果对MySQL源码感兴趣，还可以通过showprofile sourceforquery查看SQL解析<br>执行过程中每个步骤对应的源码的文件、函数名以及具体的源文件行数： mysql&gt; show profile source for query 4\G<br>Status: checking permissions</p>
<p>≦ 237 ≧<br>15.1优化SQL语句的一般步骤 219<br>Duration:0.000015<br>Source_function: check access<br>Source file: sql parse.cc Source_1ine:4627<br>showprofile能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。而MySQL5.6 之后则通过trace文件进一步向我们展示了优化器是如何选择执行计划的。<br>注意：在MySQL5.7中，profile已经不建议使用，而使用performance schema中的一系列性能视<br>图来替代，详细内容请参考第20章。<br>15.1.5通过trace分析优化器如何选择执行计划<br>MySQL从5.6版本开始提供了对SQL的跟踪trace，通过trace文件能够进一步了解为什么优化器选择A执行计划而不选择B执行计划，帮助我们更好地理解优化器的行为。<br>使用方式：首先打开trace，设置格式为JSON，设置trace最大能够使用的内存大小，避免解析过程中因为默认内存过小而不能够完整显示。<br>mysql&gt; SET OPTIMIZER TRACE&#x3D;”enabled&#x3D;on”,END MARKERS IN JSON&#x3D;on; Query ok, 0 rows affected (0.03 sec)<br>mysql&gt; SET OPTIMIZER TRACE MAX MEM SIZE&#x3D;1000000; Query ok,0 rows affected (o.oo sec)<br>接下来执行想做trace的SQL语句，例如，想了解租赁表rental中库存编号inventory_id 为4466的电影拷贝在出租日期rental_date为2005-05-254:00:00～5:00:00出租的记录：<br>mysql&gt; select rental id from rental where 1&#x3D;1 and rental date&gt;&#x3D;*2005-05-25 04:00:00and rental date&lt;&#x3D;’2005-05-25 05:00:00’and inventory_id&#x3D;4466;<br>|rental id|<br>1 row in set(0.00 sec)<br>然后，检查INFORMATION_SCHEMA.OPTIMIZER_TRACE就可以知道MySQL是如何执行SQL语句的：<br>mySql&gt; SELECT *FROM INFORMATION SCHEMA.OPTIMIZER TRACE\G<br>最后会输出一个格式如下的跟踪文件（截取部分内容）：<br>QUERY: select rental id from rental where 1&#x3D;1 and rental date &gt;<br>2005-05-25 04:00:00′and renta1 date&lt;&#x3D;2005-05-25 05:00:00′and inventory_id&#x3D;4466<br>TRACE:<br>‘steps”:<br>“join preparation”:<br>“select#”:1,”steps”:[<br>“expanded query”:”&#x2F;* select#1 *&#x2F; selectrental′.rental id As “rental id”<br>fromrentalwhere（（1&#x3D;1)and （rental.rental date&gt; &#x3D;’2005-05-25 04:00:00’)andCrental rental date′&lt;&#x3D;‘2005-05-25 05:00:00’)and（rental.inventory id&#x3D;4466))<br>]&#x2F;<em>steps</em>&#x2F;<br>&#x2F;*join preparation *&#x2F; 3,<br>MISSING BYTES BEYOND MAX MEM SIZE:0</p>
<p>≦ 238 ≧<br>220 第15章SQL优化<br>INSUFFICIENT PRIVILEGES:O<br>1row in set(o.00 sec)<br>文件里面记录了很多信息，包括访问表的路径、行数、成本等，来帮助读者对执行计划的选择过程进行分析，后面会有一些使用的例子。<br>15.1.6确定问题并采取相应的优化措施<br>经过以上步骤，基本就可以确认问题出现的原因。此时用户可以根据情况采取相应的措施，进行优化以提高执行的效率。<br>在15.1.3节的例子中，已经可以确认是由于对客户表customer的全表扫描导致效率不理<br>想，那么对客户表customer的email字段创建索引，具体如下： mysql&gt; create index idx email on customer（emai1);<br>Query ok,0 rows affected (0.37 sec) Records:oDuplicates:OWarnings:0<br>创建索引后，再看一下这条语句的执行计划，具体如下：<br>mysql&gt; expTain select sum(amount) from customer a, payment b where 1&#x3D;1 and a.customer_id &#x3D; b.customer_id and email &#x3D;<a href="mailto:&#74;&#x41;&#x4e;&#x45;&#x2e;&#x42;&#x45;&#x4e;&#78;&#69;&#84;&#84;&#64;&#115;&#x61;&#x6b;&#105;&#x6c;&#x61;&#99;&#x75;&#x73;&#116;&#x6f;&#109;&#101;&#114;&#x2e;&#111;&#114;&#103;">&#74;&#x41;&#x4e;&#x45;&#x2e;&#x42;&#x45;&#x4e;&#78;&#69;&#84;&#84;&#64;&#115;&#x61;&#x6b;&#105;&#x6c;&#x61;&#99;&#x75;&#x73;&#116;&#x6f;&#109;&#101;&#114;&#x2e;&#111;&#114;&#103;</a>‘\G<br>1.row<br>id：1<br>select type: SIMPLE<br>table:a type: ref<br>possible keys: PRIMARY,idx email<br>key:idx email key_len:153<br>ref: const rows:1<br>Extra: Using where; Using index id:1<br>select type: SIMPLE<br>table:b type:ref<br>possible keys:idx fk_customer_id<br>key:idx_fk customer_id key_len:2<br>ref: sakila.a.customer_id<br>rows:14 Extra:<br>2 rows in set (o.00 sec)<br>可以发现，建立索引后对客户表customer需要扫描的行数明显减少（从583行减少到1 行），可见索引的使用可以大大提高数据库的访问速度，尤其在表很庞大的时候这种优势更为明显。<br>15.2 索引问题<br>索引是数据库优化中最常用也是最重要的手段之一，通过索引通常可以帮助用户解决大<br>多数的SQL性能问题。本节将详细讨论MySQL中索引的分类、存储和使用方法。 15.2.1索引的存储分类<br>索引是在MySQL的存储引擎层中实现的，而不是在服务器层实现的。所以每种存储引</p>
<p>≦ 239 ≧<br>15.2索引问题 221<br>擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型。MySQL目前提供了以下4种索引引。<br>B-Tree索引：最常见的索引类型，大部分引擎都支持B树索引。 HASH索引：只有Memory&#x2F;NDB引擎支持，使用场景简单。<br>R-Tree索引（空间索引）：空间索引是MyISAM的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。<br>Full-text（全文索引l）：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从MySQL5.6版本开始提供对全文索引的支持。<br>MySQL目前版本（8.0.11）还不支持函数索引（本书截稿前官方发布的最新版本8.0.13 已经支持），但可以通过两种方式实现函数索引的功能。<br>（1）前缀索引，即对列的前面某一部分进行索引。例如标题title字段，可以只取title的前10个字符进行索引，这个特性可以大大缩小索引文件的大小，但前缀索引也有缺点，在排序OrderBy和分组GroupBy操作的时候无法使用。用户在设计表结构的时候也可以对文本列根据此特性进行灵活设计。<br>下面是创建前缀索引的一个例子：<br>mysql&gt; create index idx title on fi1m（title(10));<br>Query ok, 0 rows affected (0.06 sec) Records:ODuplicates:O warnings:0<br>（2）虚拟列索引。在Oracle等大多商业数据库中，早已支持函数索引l，但MySQL一直没有实现这个功能。在MySQL5.7之后，可以通过创建虚拟列索引的方式来实现函数索引的功能，如下例所示：<br>在表salaries中执行如下SQL：<br>selectfromalaieswereound（salary&#x2F;100010<br>表的定义如下： mysql&gt; desc salaries;<br>1Field 1Type |Null |Key |Default | Extra<br>I emp_no I int(11) NULL salary 1int(11) NO NULL from date date NO PRI I NULL<br>to_date date NO INULL 4 rows in set (o.00 sec)<br>此时，直接在salary上创建索引并不会被这个SQL所使用。这里创建一个虚拟列 salary_by_1k:<br>mysql&gt; alter table salaries add column salary by_1k int generated always as (round(salary&#x2F;1000));<br>Query ok,0 rows affected (0.06 sec) Records:O Duplicates:0warnings:0<br>然后在这个虚拟列上创建索引：<br>mysql&gt; alter table salaries add key idx salary by_1k(salary_by_1k);<br>Query ok, 0 rows affected (11.18 sec) Records:O Duplicates:OWarnings:0<br>此时观察执行计划，显示新创建的虚拟列索引已经被使用：<br>mysql&gt; desc Select count(1) from salaries where round(salary&#x2F;1000)&lt;10 G;<br>id:1</p>
<p>≦ 240 ≧<br>222 第15章SQL优化<br>select type: SIMPLE<br>table: salaries partitions: NULL<br>type:range<br>possible_keys: idx salary_by 1k<br>key:idx salary by 1k key_len:5<br>ref: NULL rows:1<br>filtered:100.00<br>Extra: using where<br>1 row in set,1 warning (0.o0 sec)<br>实际执行后，SQL的执行时间从8s降到了0.2s，性能大幅提升。<br>表15-1主要对比了MyISAM、InnoDB、Memory这3个常用引擎支持的索引类型。表15-1 MyISAM、InnoDB、Memory这3个常用引擎支持的索引类型比较<br>索引 MyISAM引擎 InnoDB引擎 Memory引擎 B-Tree 索引支持 支持 支持 HASH索引不支持 不支持 支持 R-Tree索引支持 不支持 不支持 Full-text索引支持 支持 不支持<br>比较常用到的索引引就是B-Tree索引和Hash索引。Hash索引相对简单，只有Memory&#x2F;NDB 引擎支持完全的Hash索引，InnoDB存储引擎在MySQL5.7中支持自适应的Hash索引。所谓自适应，就是MySQL根据数据的访问频率和模式为某些热点页自动创建Hash索引，索引由bufferpool中的B-tree来自动生成，效率很高，这个特性由参数innodb_adaptive_hash_index 来控制，默认是打开的。<br>Hash索引适用于Key-Value查询，通过Hash索引引要比通过B-Tree索引|查询更迅速；Hash 索引不适用范围查询，例如&lt;、&gt;、&lt;&#x3D;、&gt;&#x3D;这类操作。如果使用Memory&#x2F;NDB引擎并且where 条件中不使用“&#x3D;”进行索引列，那么不会用到索引。Memory&#x2F;Heap引擎只有在“&#x3D;”的条件下才会使用索引。<br>B-Tree索引比较复杂，下面将详细分析MySQL是如何利用B-Tree索引的。 15.2.2MySQL如何使用索引<br>B-Tree索引是最常见的索引，构造类似二叉树，能根据键值提供一行或者一个行集的快速访问，通常只需要很少的读操作就可以找到正确的行。不过，需要注意B-Tree索引中的B 不代表二叉树（binary），而是代表平衡树（balanced）。B-Tree索引并不是一棵二叉树。<br>图15-2展示了经典的B-Tree的结构：根节点root下面有多个分支（Branch节点），Branch 节点下面就是明细的叶子（Leaf节点）。<br>可以利用B-Tree索引进行全关键字、关键字范围和关键字前缀查询，以下例子如果没有特别说明都能够在MySQL5.7上执行通过。<br>为了避免混淆，重命名租赁表rental上的索引rental_date为idx_rental_date： mysql&gt; alter table rental rename index rental date to idx rental date;<br>Query ok,0 rows affected (0.25 sec) Records:O Duplicates:0 warnings:0</p>
<p>≦ 241 ≧<br>15.2索引问题 223<br>B-Tree结构<br>Branch<br>图15-2B-Tree索引l的结构<br>1.MySQL中能够使用索引的典型场景<br>（1）匹配全值（Matchthefullvalue），对索引中所有列都指定具体值，即是对索引中的所有列都有等值匹配的条件。例如，租赁表rental中通过指定出租日期rental_date+库存编号 inventory_id+客户编号customer_id的组合条件进行查询，从执行计划的key和extra两字段的值看到优化器选择了复合索引idx_rental_date：<br>mysql&gt; explain select * from rental where rental date&#x3D;’2005-05-25 17:22:10’and inventory_id &#x3D;373 and customer_id&#x3D;343\G<br>id:1<br>select_type: SIMPLE<br>table:rental partitions: NULL<br>type:const<br>possible keys: idx_rental_date,idx fk inventory_id,idx fk customer_id<br>key: idx rental date key 1en:10<br>ref: const,const,const rows:1<br>filtered:100.00 Extra: NULL<br>1 row in set, 1 warning (0.08 sec)<br>explain输出结果中字段type的值为const，表示是常量；字段key的值为idx_rental_date，表示优化器选择索引idx_rental_date进行扫描。<br>（2）匹配值的范围查询（Matcharange ofvalues），对索引的值能够进行范围查找。例如，检索租赁表rental中客户编号customer_id在指定范围内的记录：<br>mysql&gt; explain select *from rental where customer id &gt;&#x3D; 373 and customer_id&lt;400\G<br>id:1<br>select type:SIMPLE<br>table: rental partitions: NULL<br>type:range<br>possible keys:idx fk customer id<br>key:idx fk customer_id key_len:2<br>ref:NULL rows:718<br>filtered: 100.00</p>
<p>≦ 242 ≧<br>224 第15章SQL优化<br>Extra: using index condition<br>1row in set (0.00 sec)<br>类型type为range说明优化器选择范围查询，索引key为idx_fk_customer_id说明优化器选择索引idx_fk_customer_id来加速访问，注意到这个例子中Extra列为Usingwhere，表示优化器除了利用索引来加速访问之外，还需要根据索引回表查询数据。<br>（3）匹配最左前缀（Matchaleftmostprefix），仅仅使用索引中的最左边列进行查找，比如在col1+col2+col3字段上的联合索引l能够被包含coll、（col1+col2）、（col1+col2+col3）的等值查询利用到，可是不能够被col2、（col2+col3）的等值查询利用到；以支付表payment 为例，如果查询条件中仅包含索引的第一列支付日期payment_date和索引的第三列更新时间 last_update的时候，从执行计划的key和extra看到优化器仍然能够使用复合索引idx_payment date进行条件过滤：<br>mysql&gt; alter table payment add index idx payment date (payment date, amount,last update);<br>Query ok, 0 rows affected (0.21 sec) Records:0Duplicates:0warnings:0<br>mysql&gt; explain select * from payment where payment date &#x3D;’2006-02-14 15:16:03’and 1ast update &#x3D;’2006-02-1522:12:32’\G<br>id：1<br>select type: SIMPLE<br>table: payment partitions: NULL<br>type:ref<br>possible_keys:idx payment date<br>key:idx payment date key_len:5<br>ref:const rows:182 filtered:10.00<br>Extra:Using index condition<br>1 row in set (0.00 sec)<br>但是，如果仅仅选择复合索引idx_payment_date的第二列支付金额amount和第三列更新时间last_update进行查询时，那么执行计划显示并不会利用到索引idx_payment_date：<br>mysql&gt; exp1ain select * from payment where amount &#x3D; 3.98 and 1ast update&#x3D;’2006-02-15 22:12:32’\G<br>1.row<br>id:1<br>select type: SIMPLE<br>table:payment partitions: NULL<br>type: ALL<br>possible keys: NULL<br>key: NULL key_len: NULL<br>ref:NULL rows:16086<br>filtered: 1.00<br>Extra: using where<br>1row in set (0.01 sec)<br>最左匹配原则可以算是MySQL中B-Tree索引使用的首要原则。<br>（4）仅仅对索引进行查询（Index onlyquery），当查询的列都在索引的字段中时，查询的效率更高；对比上一个例子使用Select*，本次选择查询的字段都包含在索引idx_payment_date 中时，能够看到查询计划有了一点变动：<br>mysql&gt; explain select 1ast update from payment where payment date &#x3D;’2006-02-14 15:16:03’ and amount&#x3D; 3.98\G<br>***<strong><strong>1.w</strong></strong><br>贵会会专业<br>id1</p>
<p>≦ 243 ≧<br>15.2索引问题 225<br>select_type: SIMPLE<br>table:payment partitions: NULL<br>type:ref<br>possible keys: idx_payment date<br>key:idx payment date key_len:8<br>ref:const,const rows:8<br>filtered:100.00<br>Extra:Using index<br>1row in set (o.o0 sec)<br>Extra部分变成了Usingindex，也就意味着，现在直接访问索引就足够获取到所需要的数据，不需要通过索引回表，Using index也就是平常说的覆盖索引扫描。只访问必须访问的数据，在一般情况下，减少不必要的数据访问能够提升效率。<br>（5）匹配列前缀（matchacolumnprefix），仅仅使用索引中的第一列，并且只包含索引第一列的开头一部分进行查找。例如，现在需要查询出标题title是以AFRICAN开头的电影信息，从执行计划能够清楚看到，idx_title_desc_part索引被利用上了：<br>mysql&gt; create index idx title desc part on film text （title(10),description(20));<br>Query ok, 1000 rows affected (0.08 sec) Records: 1000 Duplicates: 0 warnings:0<br>mysql&gt; explain select title from film_text where title like ‘AFRIcAN%’\G<br>id:1<br>select type: SIMPLE<br>table: film text partitions: NULL<br>type: range<br>possible keys: idx title desc_part,idx title description<br>key:idx_title desc_part key_1en:32<br>ref:NULL rows:1<br>filtered:100.00<br>Extra: using where<br>1row in set (0.02 sec)<br>Extra值为Usingwhere表示优化器需要通过索引回表查询数据。<br>（6）能够实现索引匹配部分精确而其他部分进行范围匹配（matchonepartexactlyand matcharangeon anotherpart）。例如，需要查询出租日期rental_date为指定日期且客户编号 customer_id为指定范围的库存：<br>mysql&gt; explain select inventory_id from rental where rental date&#x3D;’2006-02-14 15:16:03′ and customer_id &gt;&#x3D; 300 and customer_id &lt;&#x3D; 400\G<br>id：1<br>select type: SIMPLE<br>table:rental partitions: NULL<br>type:ref<br>possible keys: idx rental date,idx_fk customer_id<br>key:idx_rental date key_len:5<br>ref:const rows:182<br>filtered:16.85<br>Extra: using where; Using index<br>1 row in set (0.o0 sec)<br>类型type为range说明优化器选择范围查询，索引key为idx_rental_date说明优化器选择索引idx_rental_date帮助加速查询，同时由于只查询索引引字段inventory_id的值，所以在Extra</p>
<p>≦ 244 ≧<br>226 第15章SQL优化部分能看到Usingindex，表示查询使用了覆盖索引扫描。<br>（7）如果列名是索引，那么使用column_nameis null就会使用索引（区别于Oracle）。例如，查询支付表payment的租赁编号rental_id字段为空的记录就用到了索引：<br>mysql&gt; explain select * from payment where rental id is null\G 北京文次业<br>id:1<br>select type: SIMPLE<br>table:payment partitions: NULL<br>type: ref<br>possible keys: fk payment rental<br>key:fk payment rental key_len:5<br>ref:const rows:5<br>filtered:100.00<br>Extra: using index condition<br>1 row in set (0.00 sec)<br>（8）MySQL5.6引人了IndexConditionPushdown（ICP）的特性，进一步优化了查询。 Pushdown表示操作下放，某些情况下的条件过滤操作下放到存储引擎。<br>例如，查询租赁表rental中租赁时间rental_date在某一指定时间点且客户编号customer_id 在指定范围内的数据，MySQL5.5&#x2F;5.1的执行计划显示：优化器首先使用复合索引idx_rental date的首字段rentaldate过滤出符合条件rentaldate&#x3D;2006-02-1415:16:03′的记录（执行计划中key字段值显示为idx_rental_date），然后根据复合索引idx_rental_date回表获取记录后，最终根据条件customer_id&gt;&#x3D;300andcustomer_id&lt;&#x3D;300来过滤出最后的查询结果（执行计划中<br>Extra字段值显示为Usingwhere）。 mysql&gt; select versionO;<br>1versionO 15.5.32-1og1<br>1row in set (0.00 sec)<br>mysq1&gt; explain select * from rental where rental date&#x3D;’2006-02-14 15:16:03’ and customer_id &gt;&#x3D;300 and customer id &lt;&#x3D; 400\G<br>id：1<br>select type: SIMPLE<br>table:rental type:ref<br>possible keys:idx fk customer_id,idx_rental_date<br>key:idx_rental_date key_len:8<br>ref:const rows:182<br>Extra: using where<br>1row in set (o.00 sec)<br>复合索引检索如图15-3所示。<br>在MySQL5.7上做同样的案例，能够发现Explain执行计划的Extra部分从Usingwhere<br>变成了Usingindexcondition的提示： mysql&gt; select versionO;<br>1versionO 15.7.22-1og</p>
<p>≦ 245 ≧<br>15.2索引问题 227<br>1 row in set (o.00 sec)<br>mysql&gt; explain select *fromrental whererental date&#x3D;’2006-02-14 15:16:03’and customer_id&gt; 300 and customer_id&lt;&#x3D; 400\G<br>id:1<br>select type: SIMPLE<br>table:rental partitions: NULL<br>type: ref<br>possible keys: idx_rental date,idx fk customer_id<br>key: idx rental date key_len:5<br>ref:const rows:182<br>filtered:16.85<br>Extra: using index condition<br>1 row in set (o.00 sec)<br>B-Tree索引 表记录<br>Phase1：存储引擎根据条件 Phase2：根据索引过滤结果回表，再根 rental date&#x3D;2006-02-1415:16:03 据条件customer id &#x3D;300 and 过滤索引 customer_id&lt;&#x3D;400过滤记录<br>图15-3复合索引|检索<br>Usingindexcondition就表示MySQL使用了ICP来进一步优化查询，在检索的时候，把条件customer_id的过滤操作下推到存储引擎层来完成，这样能够降低不必要的IO访问，如图15-4所示。<br>B-Tree索引表记录<br>push index<br>Phasel：存储引擎根据条件conditionchecks 根据索引过滤后的记录回答 rental date&#x3D;2006-02-14 在索引上过滤<br>300andcustomerid&lt;&#x3D;400 过滤索引<br>图15-4IndexConditionPushdown</p>
<p>≦ 246 ≧<br>228 第15章SQL优化<br>2.存在索引但不能使用索引的典型场景<br>有些时候虽然有索引，但是并不被优化器选择使用。下面列举几个不能使用索引的常见场景。<br>（1）以%开头的LIKE查询不能够利用B-Tree索引l，执行计划中key的值为NULL表示没有使用索引：<br>mysql&gt; explain select * from actor where last name 1ike %NI%’\G<br>id:1<br>select type: SIMPLE<br>table: actor partitions: NULL<br>type:ALL<br>possible keys: NULL<br>key： NULL key_len: NULL<br>ref:NULL rows:200<br>filtered:11.11<br>Extra: using where<br>1 row in set (0.00 sec)<br>因为B-Tree索引的结构，所以以%开头的查询很自然就没法利用索引了，一般都推荐使用全文索引（Fulltext）来解决类似的全文检索问题。或者考虑利用InnoDB的表都是聚簇表的特点，采取一种轻量级别的解决方式：一般情况下，索引都会比表小，扫描索引要比扫描表更快（某些特殊情况下，索引比表更大，不在本例讨论范围内），而InnoDB表上二级索引 idx_last_name实际上存储字段last_name还有主键actor_id，那么理想的访问方式应该是首先扫描二级索引idxlastname获得满足条件lastnamelike%NI%的主键actor_id列表，之后根据主键回表去检索记录，这样访问避开了全表扫描演员表actor产生的大量IO请求。验证一下： mysql&gt; explain select * from (select actor id from actor where last name 1ike %NI%’)a,actor b where a.actor_id &#x3D; b.actor_id\G<br>id:1<br>select type: SIMPLE<br>table: actor partitions: NULL<br>type:index<br>possible keys: PRIMARY<br>key: idx actor_last name key_len: 137<br>ref: NULL rows:200<br>filtered:11.11<br>Extra:using where;using index<br>id：1<br>select type: SIMPLE<br>table:b partitions: NULL<br>type:eqref<br>possible keys: PRIMARY<br>key:PRIMARY key_1en:2<br>ref: sakila.actor.actor_id rows:1<br>filtered:100.00 Extra: NULL<br>2rows in set (o.00 sec)<br>从执行计划中能够看到，内层查询的Usingindex代表索引覆盖扫描，之后通过主键join</p>
<p>≦ 247 ≧<br>15.2索引问题 229<br>操作去演员表actor中获取最终查询结果，理论上是能够比直接全表扫描更快一些。<br>（2）数据类型出现隐式转换的时候也不会使用索引，特别是当列类型是字符串，那么一定记得在where条件中把字符常量值用引号引引起来，否则即便这个列上有索引，MySQL也不会用到，因为MySQL默认把输人的常量值进行转换以后才进行检索。例如，演员表actor中的姓氏字段last_name是字符型的，但是SQL语句中的条件值1是一个数值型值，因此即便<br>存在索引idx_last_name，MySQL也不能正确地用上索引，而是继续进行全表扫描： mysql&gt; explain select * from actor where Tast name &#x3D; 1\G<br>id：1<br>select type: SIMPLE<br>table: actor partitions: NULL<br>type: ALL<br>possible keys:idx actor_last_name<br>key: NULL key_len: NULL<br>ref:NULL rows:200<br>filtered:10.00<br>Extra: using where<br>1 row in set (0.00 sec)<br>加上引号之后，再次检查执行计划，就发现使用上索引了： mysql&gt; explain select * from actor where last name &#x3D;1’\G<br>id:1<br>select type: SIMPLE<br>table:actor partitions: NULL<br>type:ref<br>possible keys: idx actor_last name<br>key:idx actor_last_name key_len:137<br>ref: const rows:1<br>filtered:100.00 Extra: NULL<br>1 row in set (0.00 sec)<br>（3）复合索引的情况下，假如查询条件不包含索引列最左边部分，即不满足最左原则 Leftmost，是不会使用复合索引的：<br>mysql&gt; explain select * from payment where amount &#x3D; 3.98 and 1ast update&#x3D;′2006-02-15 22:12:32’\G<br>id:1<br>select_type: SIMPLE<br>table:payment partitions: NULL<br>type:ALL<br>possible keys: NULL<br>key: NULL key_len: NULL<br>ref:NULL rows:16086<br>filtered:1.00<br>Extra: using where<br>1 row in set (0.01 sec)<br>（4）如果MySQL估计使用索引比全表扫描更慢，则不使用索引。例如，查询以“S”开头的电影标题，需要返回的记录比例较大，MySQL就预估索引扫描还不如全表扫描更快：<br>mysql&gt; update film text set title &#x3D; concat(‘s’, title); Query 0k, 1000 rows affected (0.19 sec)<br>Rows matched:1000 changed:1000 warnings:0</p>
<p>≦ 248 ≧<br>230 第15章SQL优化<br>mysql&gt; explain select* from film text where title like’s%’\G<br>id:1<br>select_type: SIMPLE<br>table:film text partitions: NULL<br>type:ALL<br>possible keys:idx title desc part,idx_title_description<br>key: NULL key_len: NULL<br>ref: NULL rows:1000<br>filtered:100.00<br>Extra: using where<br>1 row in set (o.00 sec)<br>在MySQL5.7版本中，能够通过Trace清晰地看到优化器选择的过程，全表扫描table scan 需要访问的记录rows为1000，代价cost计算为233.53：<br>“table scan”:[<br>“rows”: 1000,”cost”:233.53<br>3&#x2F;<em>table scan</em>&#x2F;,<br>而对应idx_title_desc_part索引过滤条件时，优化器预估需要返回998条记录，访问代价 cost为1198.6，远高于全表扫描的代价，索引优化器倾向于选择全表扫描：<br>“index”:”idx title desc part”,”ranges”:[<br>“s\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 &lt;&#x3D;tit1e&lt;&#x3D;s?????????]&#x2F;* ranges *&#x2F;，<br>“index dives for eq ranges”:true,”rowid ordered”: false,<br>“using mrr”: false,”index only”:false，”rows”: 998,<br>“cost”: 1198.6,”chosen”: false,”cause”:”cost”<br>更换查询的值为一个选择率更高的值，就能发现优化器更倾向于选择索引扫描： mysql&gt; explain select * from film text where title like ‘sw%’\G<br><em><strong><strong>1.row</strong></strong></em><br>id:1<br>select type: SIMPLE<br>table: film text type: range<br>possible_keys:idx title desc_part,idx title description<br>key:idx_title_desc_part key_1en:32<br>ref: NULL rows:66<br>filtered:100.00<br>Extra: using where<br>1 row in set (0.00 sec)<br>同样通过trace能够看到，titlelike’SW%优化器预估需要返回66条记录，代价cost为 80.21，远小于全表扫描的代价，所以优化器倾向于选择索引扫描：<br>“index”:”idx title desc_part”,”ranges”:[<br>“sw\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000 &lt;&#x3D;tit1e&lt;&#x3D;Sw????????]&#x2F;*ranges *&#x2F;,<br>“index dives_for_eq_ ranges”: true,</p>
<p>≦ 249 ≧<br>15.3两个简单实用的优化方法 231<br>“rowid ordered”: false,<br>“using mrr”: false,”index only”: false，<br>“rows”: 66,”cost”: 80.21,”chosen”: true<br>也就是在查询时，筛选性越高越容易使用到索引，筛选性越低越不容易使用索引。<br>（5）用or分割开的条件，如果or前的条件中的列有索引l，而后面的列中没有索引，那么涉及的索引都不会被用到，例如：<br>mysql&gt; explain select * from payment where customer id &#x3D; 203 or amount &#x3D; 3.96\G<br>id:1<br>select type: SIMPLE<br>table: payment type: ALL<br>possible keys: idx fk customer_id<br>key: NULL key_len: NULL<br>ref:NULL rows: 16451<br>filtered:10.15<br>Extra: using where<br>1 row in set (o.o0 sec)<br>因为or后面的条件列中没有索引，那么后面的查询肯定要走全表扫描，在存在全表扫描<br>的情况下，就没有必要多一次索引扫描增加I&#x2F;O访问，一次全表扫描过滤条件就足够了。 15.2.3 查看索引使用情况<br>如果索引正在工作，Handler_read_key的值将很高，这个值代表了一个行被索引值读的次数，很低的值表明增加索引得到的性能改善不高，因为索引并不经常使用。<br>Handler_read_rnd_next的值高则意味着查询运行低效，并且应该建立索引补救。这个值的含义是在数据文件中读下一行的请求数。如果正进行大量的表扫描，Handler_read_rnd_next<br>的值较高，则通常说明表索引不正确或写入的查询没有利用索引，具体如下： mysql&gt; show status like ‘Handler_read%’;<br>1 variable name value<br>|Handler_read first 10<br>Handler_read key | Handler_read next<br>10<br>1 Handler_read prev Handler_read rnd<br>|Handler_read rnd next i 2055 6 rows in set (o.00 sec)<br>从上面的例子中可以看出，目前使用的MySQL数据库的索引情况并不理想。 15.3两个简单实用的优化方法<br>对于大多数开发人员来说，可能只希望掌握一些简单实用的优化方法；对于更多、更复杂的优化，更倾向于交给专业DBA来做。本节将向读者介绍两个简单适用的优化方法。</p>
<p>≦ 250 ≧<br>232 第15章SQL优化 15.3.1定期分析表和检查表<br>分析表的语法如下：<br>ANALYZE [LOCAL &#x2F; NO_WRITE_ To_BINLOG] TABLE tbi_name [, tbi_name]<br>本语句用于分析和存储表的关键字分布，分析的结果将可以使得系统得到准确的统计信息，使得SQL能够生成正确的执行计划。如果用户感觉实际执行计划并不是预期的执行计划，执行一次分析表可能会解决问题。在分析期间，使用一个读取锁定对表进行锁定。这对于 MyISAM、BDB和InnoDB表有作用。对于MyISAM表，本语句与使用myisamchk-a相当，<br>下例中对表sales做了表分析： mysql&gt; analyze table payment;<br>1Table Iop IMsg_type | Msg text |sakila.payment | analyze | status 1OK<br>1 row in set (0.00 sec) 检查表的语法如下：<br>CHECK TABLE tbl_name [,tb1_name]…[option] .option&#x3D;{QUICK&#x2F; FAST&#x2F; MEDIUM&#x2F; EXTENDED CHANGED}<br>检查表的作用是检查一个或多个表是否有错误。CHECKTABLE对MyISAM和InnoDB<br>表有作用。对于MyISAM表，关键字统计数据被更新，例如： mysql&gt; check table payment myisam;<br>I Table 1op I Msg type | Msg text|<br>|sakila.payment myisam | check| status 1rowin set (0.03 sec)<br>CHECKTABLE也可以检查视图是否有错误，比如在视图定义中被引用的表已不存在，下面给出一个示例。<br>（1）首先创建一个视图：<br>mysql&gt; create view v_payment myisam as select * from payment myisam; Query ok,0 rows affected (o.05 sec)<br>（2）然后CHECK一下该视图，发现没有问题： mysql&gt; check table v_payment myisam;<br>1Table lop 1Msg type| Msg text<br>I sakila.V payment myisam | check I status 1 row in set (0.05 sec)<br>（3）现在删除掉视图依赖的表： mysql&gt; drop table payment myisam; Query ok, 0 rows affected (o.o0 sec)<br>（4）再来CHECK一下刚才的视图，发现报错了，并且提示出错的原因是Table sakila.payment myisam不存在了：<br>mysql&gt; check table v_payment myisam\G Table: sakila.V payment myisam</p>
<p>≦ 251 ≧<br>15.4常用SQL的优化 233<br>op：check Msg_type: Error<br>Msg_text: Table ‘sakila.paymentmyisam doesn’t exist<br>Table: sakila.v payment myisam Op:check<br>Msg_type: Error<br>Msg text: View sakila.v payment myisam’ references invalid table(s) or column(s) or function(s) or definer&#x2F;invoker of view lack rights to use them<br>Table: sakila.V payment myisam<br>op： check Msg_type: error Msg text: Corrupt<br>3rows in set (0.00 sec) 15.3.2定期优化表<br>优化表的语法如下：<br>OPTIMIZE [LOCAL NOWRITE TOBINLOG] TABLE tbname tbname】<br>如果已经删除了表的一大部分，或者如果已经对含有可变长度行的表（含有VARCHAR、 BLOB或TEXT列的表）进行了很多更改，则应使用OPTIMIZETABLE命令来进行表优化。这个命令可以将表中的空间碎片进行合并，并且可以消除由于删除或者更新造成的空间浪费，但OPTIMIZETABLE命令只对MyISAM、BDB和InnoDB表起作用。命令执行期间MyISAM 表会全程锁表，而InnoDB表则会将优化命令转换为重建表和分析表两个操作，加锁时间也仅仅在整个工作的prepare和commit期间做短暂的加锁工作，对于表的读写几乎没有影响。<br>以下例子显示了优化表payment_myisam的过程： mysql&gt; optimize table payment myisam;<br>1 Table lop 1Msg_type | Msg text1<br>| sakila.payment myisam | optimize | status OK 1row in set (0.02 sec)<br>对于InnoDB引擎的表来说，通过设置innodb_file_per_table参数，设置InnoDB为独立表空间模式，这样每个数据库的每个表都会生成一个独立的ibd文件，用于存储表的数据和索引，这样可以一定程度上减轻InnoDB表的空间回收问题。另外，在删除大量数据后，InnoDB 表可以通过altertable但是不修改引擎的方式来回收不用的空间：<br>mysql&gt; alter table payment engine&#x3D;innodb; Query 0k, 16049 rows affected (2.56 sec) Records: 16049 Duplicates:0 warnings:0<br>注意：ANALYZE、CHECK、OPTIMIZE、ALTERTABLE执行期间将对表进行锁定，因此一定注<br>意要在数据库不繁忙的时候执行相关的操作。<br>15.4常用SQL的优化<br>前面已经介绍了MySQL中是如何通过索引来优化查询的。在日常开发中，除了使用查询外，我们还会使用一些其他的常用SQL，比如INSERT、GROUPBY等。对于这些SQL语句，哪又该如何进行优化呢？本节将针对这些SQL语句介绍一些优化的方法。</p>
<p>≦ 252 ≧<br>234 第15章SQL优化 15.4.1大批量插入数据<br>当用load命令导入数据的时候，适当的设置可以提高导入的速度。<br>对于MyISAM存储引擎的表，可以通过以下方式快速地导人大量的数据。<br>ALTER TABLE tbl name DISABLE KEYS; loading the data<br>ALTER TABLE tbl name ENABLE KEYS;<br>DISABLEKEYS和ENABLEKEYS用来打开或者关闭MyISAM表非唯一索引I的更新。在导人大量的数据到一个非空的MyISAM表时，通过设置这两个命令，可以提高导入的效率。对于导人大量数据到一个空的MyISAM表，默认就是先导人数据然后才创建索引的，所以不用进行设置。<br>以下示例用LOAD语句导人数据耗时115.12s：<br>mysql&gt; load data infile’&#x2F;home&#x2F;mysql&#x2F;film test.txt’ into table film test2; Query Ok, 529056 rows affected (1 min 55.12 sec)<br>Records:529056 Deleted:0 skipped:0warnings:0<br>而用altertabletbl_name disablekeys方式总耗时6.34+12.25&#x3D;18.59s，提高了6倍多。<br>mysql&gt; alter table film_test2 disable keys; Query oK,Orows affected (o.o0 sec)<br>mysql&gt; load data infile&#x2F;home&#x2F;mysql&#x2F;filmtest.txt’ into table filmtest2; Query oK,529056 rows affected (6.34 sec)<br>Records:529056 Deleted:0skipped:0warnings:0<br>mysql&gt; alter table film test2 enable keys; Query ok,0 rows affected (12.25 sec)<br>上面是对MyISAM表进行数据导人时的优化措施，对于InnoDB类型的表，这种方式并不能提高导人数据的效率，可以有以下几种方式提高InnoDB表的导人效率。<br>（1）因为InnoDB类型的表是按照主键的顺序保存的，所以将导人的数据按照主键的顺序排列，可以有效地提高导人数据的效率。<br>例如，下面的文本film_test3.txt是按表film_test4的主键存储的，那么导人时共耗时27.92s。<br>mysql&gt; load data infile &#x2F;home&#x2F;mysql&#x2F;film test3.txt into table film test4; Query ok,1587168 rows affected (22.92 sec)<br>Records:1587168 Deleted:0Skipped:0Warnings:0<br>而下面的film_test4.txt是没有任何顺序的文本，那么导人时共耗时31.16s。 mysql&gt; load data infile&#x2F;home&#x2F;mysql&#x2F;film test4.txt’into table filmtest4; Query 0k,1587168 rows affected (31.16 sec)<br>Records:1587168 Deleted:0 skipped:0Warnings:0<br>从上面的例子可以看出，当被导人的文件按表主键顺序存储时比不按主键顺序存储时快 1.12倍。<br>（2）在导人数据前执行SETUNIQUE_CHECKS&#x3D;O，关闭唯一性校验；在导人结束后执行 SETUNIQUE_CHECKS&#x3D;1，恢复唯一性校验，可以提高导人的效率。<br>例如，当UNIQUE_CHECKS&#x3D;1时：<br>mysql&gt; load data infile&#x2F;home&#x2F;mysql&#x2F;film test3.txt into table film test4; Query ok,1587168 rows affected (22.92 sec)<br>Records:1587168 Deleted:0 skipped:0warnings:0 当SETUNIQUE_CHECKS&#x3D;O时：</p>
<p>≦ 253 ≧<br>15.4常用SQL的优化 235<br>mysql&gt; 1oad data infile &#x2F;home&#x2F;mysql&#x2F;film test3.txt’ into table fi1m test4; Query 0k, 1587168 rows affected (19.92 sec)<br>Records:1587168 Deleted:0skipped:0warnings:0<br>可见UNIQUE_CHECKS&#x3D;O时比SETUNIQUE_CHECKS&#x3D;1时要快一些。<br>（3）如果应用使用自动提交的方式，建议在导入前执行SETAUTOCOMMIT&#x3D;O，关闭自动提交，导人结束后再执行SETAUTOCOMMIT&#x3D;1，打开自动提交，也可以提高导入的效率。<br>例如，当AUTOCOMMIT&#x3D;1时：<br>mysql&gt; load data infile&#x2F;home&#x2F;mysql&#x2F;film test3.txt into table film test4; Query 0k,1587168 rows affected (22.92 sec)<br>Records:1587168Deleted:0skipped:0 warnings:0 当AUTOCOMMIT&#x3D;O时：<br>mysql&gt; load data infile &#x2F;home&#x2F;mysql&#x2F;film_test3.txt’ into table film test4; Query 0k, 1587168 rows affected (20.87 sec)<br>Records:1587168 Deleted:0skipped:0Warnings:<br>对比一下可以知道，当AUTOCOMMIT&#x3D;O时比AUTOCOMMIT&#x3D;1时导人数据要快一些。 15.4.2优化INSERT语句<br>当进行数据INSERT的时候，可以考虑采用以下几种优化方式。<br>O如果同时从同一客户插入很多行，应尽量使用多个值表的INSERT语句，这种方式将大大缩减客户端与数据库之间的连接、关闭等消耗，使得效率比分开执行的单个INSERT 语句快（在大部分情况下，使用多个值表的INSERT语句能比单个INSERT语句快上好几倍）。下面是一次插入多值的一个例子：<br>insert into testvalues（1,2）,(1,3),(1,4)<br>O如果从不同客户插入很多行，可以通过使用INSERTDELAYED语句得到更高的速度。DELAYED的含义是让INSERT语句马上执行，其实数据都被放在内存的队列中，并没有真正写入磁盘，这比每条语句分别插入要快得多；LOW_PRIORITY刚好相反，在所有其他用户对表的读写完成后才进行插入。<br>将索引文件和数据文件分在不同的磁盘上存放（利用建表中的选项）。<br>如果进行批量插入，可以通过增加bulk_insert_buffer_size变量值的方法来提高速度，但是，这只能对MyISAM表使用。<br>O当从一个文本文件装载一个表时，使用LOADDATAINFILE。这通常比使用很多 INSERT语句快20倍。<br>15.4.3优化ORDERBY语句<br>优化ORDERBY语句之前，首先来了解一下MySQL中的排序方式。先看customer表上的索引情况：<br>mysql&gt; show index from customer\G<br>Table: customer Non_unique :0<br>Key_name : PRIMARY Seq_in index:1<br>column_name:customer_id Collation: A</p>
<p>≦ 254 ≧<br>236 第15章SQL优化<br>Cardinality: 541 Sub_part:NULL<br>Packed: NULL Nu11:<br>Index type: BTREE<br>Comment:<br>贵贵吉★★★★业业★业会<br>Table: customer Non_unique:1<br>Key name:idx fk store id Seq_in_index:1<br>Column name: store_id<br>Collation:A Cardinality:3<br>Sub part: NULL Packed: NULL Nu11:<br>Index type: BTREE Comment:<br>Table: customer<br>Non unique:1<br>Key name:idx fk address id Seq_in_index:1<br>Column _name:address id<br>Collation:A Cardinality: 541 Sub part: NULL<br>Packed:NULL Nu71:<br>Index type: BTREE Comment:<br>Table: customer Non unique:1<br>Key_name: idx last_name Seq_in_index:1<br>Column name:last name<br>Collation:A Cardinality:541 Sub part:NULL<br>Packed: NULL Nu7l:<br>Index type: BTREE Comment:<br>4rows in set (1.05 sec)<br>1.MySQL中有两种排序方式<br>第一种通过有序索引顺序扫描直接返回有序数据，这种方式在使用explain分析查询的时<br>候显示为UsingIndex，不需要额外的排序，操作效率较高，例如： mysql&gt; explain select customer_id from customer order by store_id\G<br>id:1<br>select type: SIMPLE<br>table: customer type: index<br>possible keys: NULL<br>key:idx_fk_store_id key_len:1<br>ref: NULL rows:541<br>Extra:using index<br>1 row in set (0.41 sec)<br>第二种是通过对返回数据进行排序，也就是通常说的Filesort排序，所有不是通过索引直接返回排序结果的排序都叫Filesort排序。Filesort并不代表通过磁盘文件进行排序，而只是</p>
<p>≦ 255 ≧<br>15.4常用SQL的优化 237<br>说明进行了一个排序操作，至于排序操作是否使用了磁盘文件或临时表等，则取决于MySQL 服务器对排序参数的设置和需要排序数据的大小。例如，按照商店store_id排序返回所有客户记录时，出现了对全表扫描的结果的排序：<br>mysql&gt; explain select * from customer order by store_id\G<br>id：1<br>select type: SIMPLE<br>table: customer type: ALL<br>possible keys : NULL<br>key: NULL key_len: NULL<br>ref: NULL rows:541<br>Extra: using filesort<br>1 row in set (0.68 sec)<br>又如，只需要获取商店store_id和顾客email信息时，对表customer的扫描就被对覆盖索引idx_storeid_email扫描替代，此时虽然只访问了索引就足够，但是在索引idx_storeid_email 上发生了一次排序操作，所以执行计划中仍然有UsingFilesort。<br>mysql&gt; alter table customer add index idx storeid email (store id,email);<br>Query 0k, 599 rows affected (1.17 sec) Records:599 Duplicates:0warnings:0<br>mysql&gt; explain select store id, email, customer_id from customer order by email\G<br>1.row<br>id:1<br>select_type: SIMPLE<br>table: customer type:index<br>possible keys: NULL<br>key:idx_storeid_email key_len:154<br>ref:NULL rows:590<br>Extra: using index; using filesort<br>1 row in set (0.10 sec)<br>Filesort是通过相应的排序算法，将取得的数据在sort_buffer_size系统变量设置的内存排序区中进行排序，如果内存装载不下，它就会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集。sort_buffer_size设置的排序区是每个线程独占的，所以同一个时刻，MySQL中存在多个sortbuffer排序区。<br>了解了MySQL排序的方式，优化目标就清晰了：尽量减少额外的排序，通过索引直接返回有序数据。WHERE条件和ORDERBY使用相同的索引I，并且ORDERBY的顺序和索引顺序相同，并且ORDERBY的字段都是升序或者都是降序，否则肯定需要额外的排序操作，这样就会出现Filesort。<br>例如，查询商店编号store_id为1，按照email逆序排序的记录主键customer_id时，优化器使用扫描索引idx_storeid_email直接返回排序完毕的记录：<br>mysql&gt; explain select store_id, email, customer_id from customer where store id &#x3D; 1 order by email desc \G<br>id:1<br>select type: SIMPLE<br>table: customer type: ref<br>possible keys: idx fk store id,idx storeid email<br>key: idx_storeid_email key len1</p>
<p>≦ 256 ≧<br>238 第15章SQL优化<br>ref:const rows:295<br>Extra: Using where; using index<br>1row in set (1.93 sec)<br>而查询商店编号store_id大于等于1小于等于3，按照email排序的记录主键customer_id 的时候，由于优化器评估使用索引idx_storeid_email进行范围扫描代价cost最低，所以最终是对索引扫描的结果，进行了额外的按照ename逆序排序操作：<br>mysql&gt; explain select store id, email,customer id from customer where store id &gt;&#x3D; 1 and store id&lt;&#x3D; 3 order by emai1 desc\G<br>id:1<br>select type: SIMPLE<br>table: customer type: range<br>possible keys:idx fk store id,idx storeid email<br>key: idx_storeid_email key_len:1<br>ref:NULL rows:295<br>Extra: Using where; Using index; using filesort<br>1row in set(1.53 sec)<br>总结，下列SQL可以使用索引：<br>SELECT * FROM tabname ORDER BY key_partl,key_part2,…;<br>SELECT * FROM tabname WHERE key part1&#x3D;1 ORDER BY key part1 DESC,key part2 DESC;<br>SELECT * FROM tabname ORDER BY key part1 DESC,key part2 DESC; 但是在以下几种情况下则不使用索引：<br>SELECT * FROM tabname ORDER BY key_part1 DESC, key_part2 ASC;-order by的字段混合Asc和DESC<br>SELECT * FROM tabname WHERE key2&#x3D;constant ORDER BY keyl:<br>一-用于查询行的关键字与ORDERBY中所使用的不相同 SELECT * FROM tabname ORDER BY key1, key2；<br>–对不同的关键字使用ORDERBY： 2.Filesort的优化<br>通过创建合适的索引l能够减少Filesort出现，但是在某些情况下，条件限制不能让Filesort 消失，那就需要想办法加快Filesort的操作。对于Filesort，MySQL有两种排序算法。<br>两次扫描算法（TwoPasses）：首先根据条件取出排序字段和行指针信息，之后在排序区sort buffer中排序。如果排序区sort buffer不够，则在临时表TemporaryTable中存储排序结果。完成排序后根据行指针回表读取记录。该算法是MySQL4.1之前采用的算法，需要两次访问数据，第一次获取排序字段和行指针信息，第二次根据行指针获取记录，尤其是第二次读取操作可能导致大量随机I&#x2F;O操作；优点是排序的时候内存开销较少。<br>一次扫描算法（SinglePass）：一次性取出满足条件的行的所有字段，然后在排序区sort buffer中排序后直接输出结果集。排序的时候内存开销比较大，但是排序效率比两次扫描算法要高。<br>MySQL通过比较系统变量max_length_for_sort_data的大小和Query语句取出的字段总大小来判断使用哪种排序算法。如果max_length_for_sort_data更大，那么使用第二种优化之后的算法；否则使用第一种算法。<br>适当加大系统变量max_length_for_sort_data的值，能够让MySQL选择更优化的Filesort 排序算法。当然，假如max_length_for_sort_data设置过大，会造成CPU利用率过低和磁盘I&#x2F;O 过高，CPU和IO利用平衡就足够了。</p>
<p>≦ 257 ≧<br>15.4常用SQL的优化 239<br>适当加大sort_buffer_size排序区，尽量让排序在内存中完成，而不是通过创建临时表放在文件中进行；当然也不能无限制加大sort_buffer_size排序区，因为 sort_buffer_size参数是每个线程独占的，设置过大，会导致服务器SWAP严重，要考虑数据库活动连接数和服务器内存的大小来适当设置排序区。<br>尽量只使用必要的字段，SELECT具体的字段名称，而不是SELECT*选择所有字段，<br>这样可以减少排序区的使用，提高SQL性能。 15.4.4优化GROUPBY语句<br>默认情况下，MySQL对所有GROUPBYcoll,col2.·的字段进行排序。这与在查询中指定ORDERBYcoll,col2.类似。因此，如果显式包括一个包含相同列的ORDERBY子句，则对MySQL的实际执行性能没有什么影响。<br>如果查询包括GROUPBY但用户想要避免排序结果的消耗，则可以指定ORDERBY NULL禁止排序，如下面的例子：<br>mysql&gt; explain select payment date, sum(amount) from payment group by payment date\G<br>id：1<br>select type: SIMPLE<br>table:payment type:ALL<br>possible_keys: NULL<br>key: NULL key_len: NULL<br>ref: NULL rows:16310<br>Extra: Using temporary; using filesort<br>1 row in set (0.01 sec)<br>mysql&gt; explain select payment date, sum（amount) from payment group by payment date order by nul7\G<br>id：1<br>select type: SIMPLE<br>table:payment type: ALL<br>possible keys: NULL<br>key: NULL key Ten: NULL<br>ref: NULL rows:16310<br>Extra: Using temporary<br>1 row in set (0.06 sec)<br>从上面的例子可以看出，第一个SQL语句需要进行“Filesort”，而第二个SQL由于ORDER BYNULL不需要进行“Filesort”，而上文提过Filesort往往非常耗费时间。<br>15.4.5 优化JOIN操作<br>MySQL对于多表JOIN在目前只支持一种算法—Nested-LoopJoin（NLJ）。NLJ的原理非常简单，就是内外两层循环，对于外循环中的每条记录，都要在内循环中做一次检索，如下面的伪代码所示：<br>for each row in tl matching range {<br>for each row in t2 matching reference key<br>if row satisfies join conditions, send to client</p>
<p>≦ 258 ≧<br>240 第15章SQL优化<br>其中t1和t2表进行join，t1通过范围扫描取每条记录作为外循环，t2通过关联字段在表中做扫描，满足条件则返回客户端；不断重复这个过程直到外循环结束。外循环的表通常也称为驱动表。<br>从这个流程来看，NL』的性能高低主要取决于两方面：一是外循环的结果集大小，二是内循环扫描数据的效率。常见的优化方案是在驱动表上加上尽可能的where条件并创建合适索引，使得外循环的结果集更小，读取效率更高；内循环为了提高扫描效率，通常需要在关联字段上加索引。<br>通过上面的优化，在大多数情况下，NL』的性能是可以满足需求的，尤其是关联字段在内循环是主键或者唯一索引时效率尤其高。但有两种情况，NLJ的性能会有比较明显地下降。<br>外循环结果集大，导致访问内循环表的io次数非常多。<br>内循环的关联字段并不是唯一索引，而是普通的辅助索引。如果访问的数据列不在辅助索引上，此时通常需要再次回表，通过辅助索引的主键找到聚集索引的实际数据，而回表会导致大量的随机io产生，导致性能下降明显。<br>为了优化这两个问题，MySQL先后推出了NLJ的变种BNL（BlockNested-LoopJoin）和BKA（BatchedKey Access）。<br>1.BNL<br>BNL在MySQL较早版本就引I人，算法伪代码如下： for each row in tl matching range<br>for each row in t2 matching reference key  store used columns from tl, t2 in join buffer<br>if buffer is full  for each row in t3<br>for each tl,t2 combination in join buffer<br>if row satisfies join conditions, send to client empty join buffer<br>if buffer is not empty  for each row in t3<br>for each tl,t2 combination in join buffer<br>if row satisfies join conditions, send to client<br>通过缓存外层循环读的行，来降低内层表的读取次数。例如，10行数据读人到buffer中，然后buffer被传递到内层循环，内层表读出的每一行都要跟这个缓存的10行依次做对比，这样就降低了内层表数据的读取次数。<br>在MySQL5.7中，BNL优化器特性默认是打开的，以下示例将customer和payment表进行join，关联字段上均无索引：<br>mysql&gt; show variables like optimizer switch AG; Variable name: optimizer switch<br>value: index merge&#x3D;on,index merge union&#x3D;on,index merge sort union&#x3D;on,index merge</p>
<p>≦ 259 ≧<br>15.4常用SQL的优化 241<br>intersection&#x3D;on,engine condition pushdown&#x3D;on,index condition_pushdown&#x3D;on,mrr&#x3D;on,mrr_cost based&#x3D; on,block_nested_loop&#x3D;on,batched key access&#x3D;off,materialization&#x3D;on,semijoin&#x3D;on,loosescan&#x3D;on, firstmatch&#x3D;on,duplicateweedout&#x3D;on,subquery_materialization_cost_based&#x3D;on,use_index extensions&#x3D;<br>on,condition_fanout filter&#x3D;on,derived merge&#x3D;on 1row in set (0.00 sec)<br>mysql&gt; desc select count(1) from customer a,payment b where a.create date&#x3D;b.payment date;<br>id l select type l table l partitions l type l possible keys key Ikey len l ref rows Ifiltered l Extra<br>SIMPLE a INULL IALL NULL NULLINULL |NULL<br>599 100.00INULL<br>SIMPLE NULL ALL NUL |NULL NULL<br>6<br>16086 10.00 I using where; using join buffer (Block Nested Loop)1 2 rows in set,1 warning (0.01 sec)<br>如执行计划的Extra部分显示，连接使用了BNL。实际执行上面的SQL，完成时间为1.54s：<br>mysql&gt; select count(1) from customer a,payment b where a.create date&#x3D;b.payment date; |count(1)1<br>01<br>1row in set(1.54 sec)<br>关闭BNL特性，再次观察一下：<br>mysql&gt;set optimizer_switch&#x3D;’block_nested_loop&#x3D;off; Query oK,0 rows affected (0.01 sec)<br>mysql&gt; desc select count(1) from customer a,payment b where a.create date&#x3D;b.payment date;<br>id | select type | table l partitions | type | possible keys | key | key len |ref rows filtered | Extra<br>|SIMPLE la NULL IALLINULL 1NULL NULL INULL<br>599 100.00NULL<br>SIMPLE NULL ALL NULL |NULLINULL INULL<br>160861 10.00 | using wherel<br>2 rows in set,1 warning (0.00 sec)<br>执行计划中的BNL部分消失，再次执行SQL：<br>mysql&gt;select count(1) from customer a,payment b where a.create date&#x3D;b.payment date; count（1)1<br>1row in set （4.25 sec)<br>完成时间为4.25s，比使用BNL特性慢了近两倍。<br>BNL性能虽然大幅提高，但使用条件较为苛刻，只有当join类型是all&#x2F;index&#x2F;range时才可以，也就是内表不使用索引或者索引效率很低时才不得已使用。buffer的大小由参数 join_buffer_size进行设置，buffer中保存参与连接的所有列信息，join完成后buffer释放。对于使用到BNL特性且性能较差的SQL，建议在session级别将join_buffer_size临时增大来提高性能。</p>
<p>≦ 260 ≧<br>242 第15章SQL优化<br>2.MRR&amp;BKA<br>从上面的介绍知道，BNL的使用场景较为苛刻，最重要的条件是内表关联字段没有索引或者索引效率很低，此时使用BNL可以较明显的降低访问内表的次数，同时降低回表的IO 次数，以此来达到优化的目的。但在大多数情况下，表的join操作通常是通过效率较高的索引来做ref或者eq_ref方式进行连接，这种情况下，BNL是无法使用的。为了优化这种更常见的join，MySQL引I人了MRR和BKA。<br>MRR（MultiRangeRead）是MySQL5.6引入的特性。MRR优化的目的就是为了减少磁盘的随机访问，InnoDB由于聚集索引的特性，如果查询使用辅助索引，并且用到表中非索引列，那么需要回表读取数据做后续处理，过于随机的回表会伴随着大量的随机IO。而 MRR的优化并不是每次通过辅助索引读取到数据就回表，而是通过范围扫描将数据存人 read_rnd_buffer_size，然后对其按照PrimaryKey（RowID）排序，最后使用排序好的数据进行顺序回表，因为InnoDB中叶子节点数据是按照PrimaryKey（RowID）进行排列的，这样就转换随机IO为顺序IO了，对于瓶颈为IO的SQL<br>Possible ways to use MRR<br>查询语句将带来极大的性能提升。<br>range access<br>MRR特性在单表和多表join查询中都可以使用。 ref,eq_ref access<br>其中，单表通常通过范围查询（range access）；多表join<br>BatchedKey<br>方式如果是ref&#x2F;eq_ref，则先通过BKA算法（后面介绍） Access<br>批量提取key到joinbuffer，然后将buffer中的key作 Multi Range Read 为参数传入MRR的调用接口，MRR高效读取需要的 Storage Engine 数据返回，过程如图15-5所示。<br>如果要打开MRR特性，则需要设置以下两个优图15-5MRR的使用方式化器参数：<br>set optimizer switch&#x3D;mrr&#x3D;on,mrr cost based&#x3D;off’;<br>其中mrr参数控制MRR特性是否打开，默认为on；mrr_cost_based控制是否根据优化器的计算成本来决定使用MRR特性，默认是on；如果希望尽可能使用MRR，可以将此参数设置为off。<br>要查看是否使用了MRR特性，需要观察在执行计划的Extra部分是否存在“UsingMRR” 字符串，下例SQL就使用了MRR特性：<br>mysql&gt; desc select * from payment where customer id between 1 and 200 \G;<br>id1<br>select type: SIMPLE<br>table:payment partitions: NULL<br>type: range<br>possible keys: idx fk customer_id<br>key:idx_fk_customer _id key_len:2<br>ref: NULL rows:5444<br>filtered:100.00<br>Extra: using index condition;Using MRR<br>1 row in set, 1 warning (0.o0 sec)<br>BKA（BatchedKeyAccess）是MySQL5.6引I人的新算法，结合MRR特性进行高效JOIN</p>
<p>≦ 261 ≧<br>15.4常用SQL的优化 243<br>操作，算法具体工作步骤如下。<br>将外循环表中相关的列放入JoinBuffer中。<br>批量的将Key（索引键值）发送到MRR接口。<br>OMRR通过收到的Key，根据其对应的PrimaryKey(RowID)进行排序，然后再根据排序后的PrimaryKey(RowID)顺序的读取聚集索引，得到需要的列数据。<br>返回结果集给客户端。<br>MySQL5.7以后，BKA默认是打开的，由优化器中的参数batched_key_access来控制。如果要使用BKA，则先需打开MRR特性，通常一起设置如下参数：<br>mysql&gt; SET optimizer_switch&#x3D;’mrr&#x3D;on,mrr_cost based&#x3D;off,batched key_access&#x3D;on’;<br>Query ok,0 rows affected (o.oo sec)<br>判断是否使用了BKA算法，需要查看执行计划中extra部分是否含有“Usingjoinbuffer(BatchedKeyAccess)”字符串，如下例中倒数第2行所示：<br>mysql&gt; desc  select count(*) from employees a,salaries b where a.hire date&#x3D;b.to date and b.salary&gt;5000 and a.gender&#x3D;1 \G;<br>id:1<br>select type: SIMPLE<br>table:b partitions: NULL<br>type: ALL<br>possible keys: test salaries<br>key: NULL key_len: NULL ref:NULL rows:2790144 filtered:33.33<br>Extra:using where id:1<br>select_type: SIMPLE<br>table:a partitions: NULL<br>type:ref<br>possible keys: emp hiredate<br>key:emp_hiredate key_len:3<br>ref:employees.b.to date rows:53<br>filtered:50.00<br>Extra: Using where; Using join buffer (Batched Key Access)<br>2rows in set,1 warning (0.o0 sec)<br>通过BKA来做JOIN，很多情况下可以提高连接的效率，但对JOIN也有一定的条件限制，一个条件是连接的列要求是唯一索引或者普通索引，但不能是主键；另一个是要有对非主键列的查询操作，否则优化器就可以通过覆盖索引等方式直接得到需要的数据，不需要回表，<br>也就不需要用到MRR接口。 15.4.6优化嵌套查询<br>MySQL4.1开始支持SQL的子查询。这个技术可以使用SELECT语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性地完成很多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接（JOIN）替代。</p>
<p>≦ 262 ≧<br>244 第15章SQL优化<br>在下面的例子中，要从客户表customer中找到不在支付表payment中的所有客户信息： mysql&gt; explain select *from customer where customer id not in (select customer id from payment )\G<br>id:1<br>select type:PRIMARY<br>table: customer partitions: NULL<br>type: ALL<br>possible keys: NULL<br>key:NULL key_len:NULL<br>ref: NULL rows:599<br>filtered:100.00<br>Extra: Using where<br>id：2<br>select_type: DEPENDENT SUBQUERY<br>table: payment partitions: NULL<br>type: index subquery<br>possible keys: idx fk customer_id<br>key: idx fk customer_id key_1en:2<br>ref: func rows:26<br>filtered:100.00<br>Extra:Using index<br>2rows in set (o.00 sec)<br>如果使用连接（JOIN）来完成这个查询工作，速度将会快很多。尤其是当payment表中对customer id建有索引l，性能将会更好，具体查询如下：<br>mysql&gt; explain select * from customer a left join payment b on a.customer_id &#x3D; b.customer_id where b.customer id is nu7l\G<br>id:1<br>select_type: SIMPLE<br>table:a partitions: NULL<br>type:ALL<br>possible keys: NULL<br>key： NULL key len: NULL<br>ref: NULL rows:599<br>filtered:100.00 Extra: NULL ★★★<br>id:1<br>select type: SIMPLE<br>table:b partitions: NULL<br>type: ref<br>possible keys: idx_ fk customer_id<br>key:idx fk customer id key_len:2<br>ref: sakila.a.customer_id rows:26<br>filtered:100.00<br>Extra: Using where; Not exists<br>2rows in set (o.00 sec)<br>从执行计划中可以看出查询关联的类型从index_subquery调整为了ref，在MySQL5.5以下版本（包括MySQL5.5），子查询的效率还是不如关联查询（JOIN）。<br>连接（JOIN）之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成</p>
<p>≦ 263 ≧<br>15.4常用SQL的优化 245<br>这个逻辑上需要两个步骤的查询工作。<br>15.4.7MySQL如何优化OR条件<br>对于含有OR的查询子句，如果要利用索引I，则OR之间的每个条件列都必须用到索引；如果没有索引，则应该考虑增加索引。<br>例如，首先使用showindex命令查看表sales2的索引，可知它有3个索引，在id和year 两个字段上分别有1个独立的索引，在company_id和year字段上有1个复合索引。<br>mysql&gt; show index from sales2\G；<br>Table:sales2 Non unique :1<br>Key_name:ind sales2 id<br>Seq_in index :1 Column_name : id collationA Cardinality:1000 Sub part:NULL<br>Packed: NULL Nu1l:YES<br>Index type: BTREE Comment:<br>★**业★★★业业★<br>Table: sales2 Non unique:1<br>Key name:ind sales2 year<br>Seq_in index:1 Column_name : year Collation:A Cardinality:250 Sub part: NULL<br>Packed: NULL Null: YES<br>Index type: BTREE Comment :<br>Table:sales2 Non_unique : 1<br>Key name: ind sales2 companyid moneys Seq in index:1<br>column_name : company_id<br>Collation:A Cardinality: 1000 Sub part: NULL Packed : NULL Null:YES Index type: BTREE<br>Comment:<br>青★业会会专业会会会会<br>Table:sales2 Non unique :1<br>key_name:ind sales2 companyid moneys<br>Seq_in_index:2 Column name:year collation:A Cardinality:1000 Sub part: NULL<br>Packed: NULL Null: YES<br>Index_type: BTREE Comment :<br>4 rows in set (o.00 sec)<br>然后在两个独立索引上面做OR操作，具体如下：</p>
<p>≦ 264 ≧<br>246 第15章SQL优化<br>mysql&gt; explain select *from sales2 where id &#x3D; 2or year &#x3D; 1998\G;<br>id:1<br>select_type: SIMPLE<br>table:sales2<br>type:index merge<br>possible keys:ind sales2 id,ind sales2 year<br>key:ind sales2 id,ind sales2_year key_1en:5,2<br>ref: NULL rows:2<br>Extra:Using union(ind sales2 id,ind sales2 year);Using where<br>1 row in set(0.00 sec)<br>可以发现查询正确地用到了索引，并且从执行计划的描述中，发现MySQL在处理含有 OR字句的查询时，实际是对OR的各个字段分别查询后的结果进行了UNION操作。<br>但是当在建有复合索引的列company_id和moneys上面做OR操作时，却不能用到索引，具体结果如下：<br>mysql&gt; explain select * from sales2 where company_id &#x3D; 3 or moneys &#x3D; 100\G;<br>***1.row#<br>id:1<br>select type: SIMPLE<br>table: sales2 type: ALL<br>possible_keys: ind sales2_companyid moneys<br>key: NULL key_len:NULL<br>ref: NULL rows:1000<br>Extra: Using where<br>1 row in set (o.00 sec)<br>15.4.8优化分页查询<br>一般分页查询时，通过创建覆盖索引能够比较好地提高性能。一个常见又非常头痛的分页场景是“limit1000,20”，此时MySQL排序出前1020条记录后仅仅需要返回第1001到1020 条记录，前1000条记录都会被抛弃，查询和排序的代价非常高。<br>1.第一种优化思路<br>在索引上完成排序分页的操作，最后根据主键关联回原表查询所需要的其他列内容。例如，对电影表film根据标题title排序后取某一页数据，直接查询的时候，能够从explain的输出结果中看到优化器实际上做了全表扫描，处理效率不高：<br>mysql&gt; explain select film id, description from film order by title limit 50,5\G<br>id:1<br>select type: SIMPLE<br>table: fi1m type: ALL<br>possible keys: NULL<br>key: NULL key_len: NULL ref:NULL rows:919<br>Extra: using filesort<br>1 row in set (o.00 sec)<br>而按照索引分页后回表方式改写SQL后，从explain的输出结果中已经看不到全表扫描了：</p>
<p>≦ 265 ≧<br>15.4常用SQL的优化 247<br>mysql&gt; explain select a.film id,a.description from film a inner join (select film id from film order by title 1imit 50,5)b on a.film id &#x3D;b.fi1m id\G<br>id：1<br>select type:PRIMARY<br>table:<derived2> type:ALL<br>possible keys:NULL<br>key:NULL key_len:NULL<br>ref:NULL<br>rows:5 Extra:<br>id:1<br>select type:PRIMARY<br>table:a<br>type:eq_ref<br>possible keys: PRIMARY<br>key:PRIMARY key_len:2<br>ref: b.film id<br>rows:1 Extra:<br>id：2<br>select type:DERIVED<br>table:film type: index<br>possible keys: NULL<br>key:idx title key_len:767<br>ref: NULL rows:55<br>Extra:using index<br>3rows din set (o.o0 sec)<br>这种方式让MySQL扫描尽可能少的页面来提高分页效率。 2.第二种优化思路<br>把LIMIIT查询转换成某个位置的查询，例如，假设每页10条记录，查询支付表payment<br>中按照租赁编号rental_id逆序排序的第42页记录，能够看到执行计划走了全表扫描： mysql&gt; explain select * from payment order by rental id desc 1imit 410,10\G<br>id:1<br>select type: SIMPLE<br>table:payment type:ALL<br>possible keys: NULL<br>key: NULL key Ten:NULL<br>ref: NULL rows:16451<br>Extra: Using filesort<br>1row in set(o.o0 sec)<br>和开发人员协商一下，翻页的过程中通过增加一个参数last_page_record，用来记录上一<br>页最后一行的租赁编号rental_id，例如第41页最后一行的租赁编号rental_id&#x3D;15640： mysql&gt; select payment id,rental id from payment order by rental id desc 1imit 400,10; I payment id l rental id|<br>1669 15649 2193 15648 67851 15647</p>
<p>≦ 266 ≧<br>248 第15章SQL优化<br>30881 156461 5831 15645 1201 15644 8105 15643 4369 15642 6499 15641 7095 15640<br>10 rows in set (0.00 sec)<br>那么在翻页到第42页时，可以根据第41页最后一条记录向后追溯，相应的SQL可以改写为： mysql&gt; explain select * from payment where rental id&lt; 15640 order by rental id desc limit 10\G<br>id:1<br>select type: SIMPLE<br>table:payment type: range<br>possible keys:fk payment _rental<br>key:fk_payment_rental key_1en:5<br>ref: NULL rows:8225<br>Extra: Using where<br>1 row in set(o.o0 sec)<br>注意：这样把LIMITm,n转换成LIMITn的查询，只适合在排序字段不会出现重复值的特定环境，<br>能够减轻分页翻页的压力；如果排序字段出现大量重复值，而仍进行这种优化，那么分页结果可能会丢失部分记录，不适用这种方式进行优化。<br>15.4.9使用SQL提示<br>SQL提示（SQLHINT）是优化数据库的一个重要手段，简单来说就是在SQL语句中加<br>人一些人为的提示来达到优化操作的目的。下面是一个使用SQL提示的示例： SELECT SQL BUFFER RESULTSFROM<br>这个语句将强制MySQL生成一个临时结果集。只要临时结果集生成后，所有表上的锁定均被释放。这能在遇到表锁定问题时或要花很长时间将结果传给客户端时有所帮助，因为可以尽快释放锁资源。<br>下面是一些在MySQL中常用的SQL提示。 1.USE INDEX<br>在查询语句中表名的后面，添加USEINDEX来提供希望MySQL去参考的索引I列表，就可以让MySQL不再考虑其他可用的索引。<br>mysql&gt; explain select count(*) from rental use index (idx rental _date)\G<br>id:1<br>select type: SIMPLE<br>table:rental type:index<br>possible keys: NULL<br>key:idx_rental_date key_len:13<br>ref: NULL rows:16291<br>Extra: using index<br>1 row in set (o.o0 sec)</p>
<p>≦ 267 ≧<br>15.4常用SQL的优化 249<br>2.IGNORE INDEX<br>如果用户只是单纯地想让MySQL忽略一个或者多个索引，则可以使用IGNOREINDEX<br>作为HINT。同样是上面的例子，这次来看一下查询过程忽略索引ind_sales2_id的情况： mysql&gt; explain select count(<em>) from rental ignore index (idx rental date)\G<br>☆</em>★<br>id:1<br>select type: SIMPLE<br>table: rental type: index<br>possible keys : NULL<br>key: idx_fk staff_id key_len:1<br>ref: NULL rows:16291<br>Extra:using index<br>1 row in set (o.00 sec)<br>从执行计划可以看出，系统忽略了指定的索引，使用索引idx_fk_staffid。 3.FORCE INDEX<br>为强制MySQL使用一个特定的索引，可在查询中使用FORCEINDEX作为HINT。例如，当不强制使用索引的时候，因为大部分库存inventory_id的值都是大于1的，因此MySQL会默认进行全表扫描，而不使用索引，如下所示：<br>mysql&gt; explain select * from rental where inventory_id &gt; 1\G<br>**<em><strong>1.W#</strong></em><br>id:1<br>select type: SIMPLE<br>table: rental type: ALL<br>possible keys:idx fk inventory_id<br>key: NULL key_len: NULL ref:NULL rows:16291<br>Extra: using where<br>row in set (o.00 sec)<br>尝试使用use index的hint看看：<br>mysql&gt; explain select * from rental use index (idx fk inventory_id) where inventory_id &gt; 1\G<br>id：1<br>select type: SIMPLE<br>table: rental type : ALL<br>possible keys : idx fk inventory_id<br>key: NULL key_len: NULL ref:NULL rows:16291<br>Extra: Using where<br>1 row in set (o.o0 sec)<br>发现仍然不行，MySQL还是选择走全表扫描。但是，当使用FORCEINDEX进行提示时，即便使用索引的效率不是最高，MySQL还是选择使用了索引I，这是MySQL留给用户的一个自行选择执行计划的权力。加人FORCEINDEX提示后再次执行以上SQL语句：<br>mysql&gt; explain select * from rental force index (idx fk inventory_id) where inventory_id &gt; 1\G<br>id：1<br>select type : SIMPLE</p>
<p>≦ 268 ≧<br>250 第15章SQL优化<br>table :rental type:range<br>possible keys:idx fk inventory _id<br>key : idx_fk_inventory_id key_len:3<br>ref:NULL rows:8145<br>Extra : using where<br>row in set (0.o1 sec)<br>果然，执行计划中使用了FORCEINDEX后的索引。 15.5直方图<br>直方图是MySQL8.0引人的新功能。利用直方图，用户可以对一张表的一列做数据分布的统计，特别是针对没有索引的字段。这可以帮助优化器找到更优的执行计划。统计直方图<br>的主要使用场景是用来计算字段选择性，即过滤效率。 15.5.1什么是直方图<br>在数据库中，查询优化器负责将SQL转换成最有效的执行计划。但有时，由于一些字段的数据分布不均衡，导致优化器针对某些值不会选择最优的执行计划，从而使得执行效率降低。为了能做出更准确的选择，优化器需要了解条件列中具体的数据分布情况，而直方图的引人就是为了统计这些信息。<br>直方图的主要操作命令有以下两个。生成直方图：<br>ANALYZE TABLE tbl name UPDATE HISTOGRAM ON col name col name] WITH N BUCKETS;<br>删除直方图：<br>ANALYZE TABLE tbl name DROP HISTOGRAM ON col name [ col name];<br>其中，BUCKETS表示生成桶的个数，桶用来存放列中不同值的分布情况，默认值为100，最大到1024。<br>举一个简单的例子，员工表empl的性别字段gender数据分布如下：<br>mysql&gt; select gender,count(1) from emp1 group by gender; |gender | count(1)|<br>299025<br>999<br>如果没有直方图，查询gender为“M”或者“F”，执行计划如下： mysql&gt; desc select count(1) from emp1 where gender&#x3D;’F’ \G;<br>1.row<br>★★<br>id：1<br>select type: SIMPLE<br>table:emp1 partitions: NULL<br>type: ALL<br>possible keys: NULL<br>key: NULL key_len: NULL ref: NULL rows:299556</p>
<p>≦ 269 ≧<br>15.5直方图 251<br>filtered:50.00<br>Extra: using where<br>1 row in set, 1 warning (0.00 sec)<br>可以发现，执行计划中的filtered值都是50%，即优化器不知道数据实际分布情况，只是按照值的个数进行平均分配。如果在gender上创建了直方图，则执行计划会按照实际的数据分布进行过滤，如下所示：<br>mysql&gt; analyze table empl update histogram on gender AG; Table:employees.emp1<br>Op: histogram Msg type: status<br>Msg text: Histogram statistics created for column ‘gender 1 row in set (0.32 sec)<br>mysql&gt; desc select count(1) from emp1 where gender&#x3D;’F’ G;<br>id:1<br>select type: SIMPLE<br>table: empl partitions: NULL<br>type: ALL<br>possible keys: NULL<br>key： NULL key_len: NULL ref: NULL rows:299556<br>filtered:0.33<br>Extra: Using where<br>1 row in set,1 warning (0.00 sec)<br>上面的analyze命令在emp1的gender字段上创建了直方图，后面的执行计划显示filtered 属性已经从50%改为0.33%，符合实际分布情况。这个信息使得优化器对gender字段查询的<br>代价计算更为精确，从而在某些gender查询相关的SQL中生成更为高效的执行计划。 15.5.2直方图的分类<br>MySQL目前支持两种直方图类型：等宽直方图（singleton）和等高直方图（equi-height）。！它们的共同点是，都将数据分到了一系列的buckets中；区别在于如果列中不同值的个数小于等于bucket数，则为等宽直方图；反之则为等高直方图。MySQL会自动将数据划到不同的 bucket中，也会自动决定创建哪种类型的直方图。<br>直方图的统计信息存放在information_schema库的column_statistics视图中，以json格式保存。上例中gender列的直方图信息内容如下：<br>mysql&gt; select * from information schema.column statistics \G;<br>1.row *<br>SCHEMA NAME:employees<br>TABLE NAME: emp1 COLUMN _NAME: gender<br>HIST0GRAM:{“buckets”:[1, 0.9966702663786897],[2,1.0]],“data-type”:“enum”,“null-values”:0.0,”co1lation-id”:192,1ast-updated”:”2018-10-22 02:58:20.035927”,”sampling-rate”:1.0,<br>“histogram-type”:”singleton”,”number-of-buckets-specified”:100} 1 row in set (o.00 sec)<br>其中，HISTOGRAM列记录了gender字段的直方图信息，内容包括如下几项：<br>buckets:[[1,0.9966702663786897]，[2,1.0]]表示gender上创建了两个bucket，bucket 为1的值包含了99.67%的数据；bucket为2的值包含了1-99.67%&#x3D;0.33%的数据，即2后面的1.0是个累积的数据分布。由于enum保存的并不是字面值，这里的1和2是enum类型的</p>
<p>≦ 270 ≧<br>252 第15章SQL优化“M”和“F”实际保存的值。<br>data-type:“enum”表示gender字段是枚举类型。 null-values:0.0表示gender列中没有空值。<br>Ocollation-id:192表示排序方式，对应information_schema下collations中的id字段。 last-updated:表示直方图的最后更新日期。直方图只能手工update，而不会随着数据<br>的更新而更新；当数据量发生大的变更时，要重新手工生成新的直方图。<br>Osampling-rate：1.0，表示数据的采样率。对于数据量巨大的表，MySQL出于性能考虑，不会全部扫描，只会采样部分数据来生成直方图。采样大小由参数histogram_generation_ max_mem_size进行控制，这个值是控制最大多少内存能允许被使用。<br>histogram-type：生成的直方图类型，singleton表示等宽直方图，equi-height表示等高直方图。<br>Onumber-of-buckets-specified：表示指定了多少个bucket。对于等宽直方图来说，如果创建直方图时指定的buckets的个数大于列中唯一值的个数，则实际只需要创建唯一值的个数的buckets就可以了。本例中的值为100，而实际创建的bucket是两个。<br>对于等高直方图，bucket的显示内容有所不同，由于列中不同值的个数大于bucket的数量，因此每个bucket上对应的不是一个值，而是一个具有上下限的列值范围。下例是一个具有8个buckets的等高直方图：<br>{“buckets”:[[“1952-02-01”,”1953-09-17”,0.12507666053382396,595],[“1953-09-18”,”1955-04-30”,0.24993667173292802, 590],[“1955-05-01”,“1956-12-16”,0.375, 596],[“1956-12-17”,“1958-08-01”,0.5001199904007679,593],[“1958-08-02”,“1960-03-12”,0.625059995200384,589],[“1960-03-13”,“1961-10-27”,0.749953337066368,594],[“1961-10-28”,“1963-06-16”,0.87506666133376, 597],[“1963-06-17”,”1965-02-01”,1.0, 596],”data-type”:“date”,“nul1-values”:0.0,“co1lation-id”:8,”1ast-updated”:”2018-10-22 14:36:53.303565”,”sampling-rate”:1.0,”histogram-type”:”equi-height”,”number-of-buckets-specified”:8}<br>可以看出，每个bucket由4个值组成，第一、二个值表示列值上下限范围，第三个值表示列值在此范围内的记录数占总记录的百分比，第四个值表示bucket内列上唯一值的估算数量，通常也称为Cardinality。通常来说，对于等高直方图，bucket的个数越多，统计的分布越精确，但很多情况下，单纯提高bucket数量对数据分布的准确性不会有明显提高，建议初始时先设置较小的值，如果达不到效果再逐渐增加，重新设置bucket的命令和创建命令一样。<br>15.5.3直方图实例应用<br>上面简单介绍了直方图的概念和分类，本节给出一个示例来验证一下直方图在SQL优化中的作用。<br>两个表emp1和titles1进行join，SQL如下：<br>select count(1) from empl a,titles1 b where a.emp no&#x3D;b.emp no and a.gender&#x3D;’m’;<br>两表的定义和数据量分别如下： mysql&gt; desc emp1<br>-&gt;<br>|Field 1Type |Null |Key | Default丨Extra|<br>emp_no int(11) INO |PRI丨NULL birth date l date INO NULL</p>
<p>≦ 271 ≧<br>15.5直方图 253<br>1 first_name &#x2F; varchar(14) 1NO NULL last_name 1varchar(16) INO NULL 1gender enum(‘M’,’F’) NO NULL Ihire date | date NULL 1genderl 1varchar(10) IYES 1NULL<br>7 rows in set (0.01 sec)<br>mysql&gt; select count(1) from empl; count(1)<br>3000241<br>mysql&gt; desc titles1;<br>Field 1 Type | Null |Key | Default l Extral<br>emp_no int(11) NO PRI1 NULL title 1varchar(50) NO PRII NULL<br>I from date I date NO PRI NULL I to date | date YES NULL<br>4 rows in set (0.00 sec)<br>mysql&gt; select count(1) from titles1; 1 count(1)1<br>262408 1<br>gender字段的数据分布不均衡，如下所示：<br>mysql&gt; select gender,count(1) from empl group by gender; gender 1 count(1)1<br>F 999<br>299025<br>2rows in set (0.41 sec)<br>gender字段创建直方图之前，执行计划如下：<br>mysql&gt; desc select count(1) from empl a,titles1 b where a.emp no&#x3D;b.emp no and a.gender&#x3D;M G;<br>id:1<br>select type: SIMPLE<br>table:a partitions: NULL<br>type: ALL<br>possible _keys: PRIMARY<br>key: NULL key_len: NULL<br>ref: NULL rows:299550 filtered:50.00<br>Extra: using where</p>
<hr>
<p>id:1<br>select type: SIMPLE<br>table:b partitions: NULL<br>type: ref<br>possible keys: PRIMARY<br>key: PRIMARY key_len:4<br>ref: employees.a.emp_no</p>
<p>≦ 272 ≧<br>254 第15章SQL优化<br>rows:1<br>filtered:100.00<br>Extra:using index<br>2 rows in set, 1 warning (0.01 sec) SQL实际执行时间为1.54s：<br>mysql&gt; select count(1) from empl a,titles1 b where a.emp no&#x3D;b.emp_no and a.gender&#x3D;’M’; 1count(1)1<br>2609391<br>1row in set (1.42 sec)<br>现在在gender字段上创建直方图：<br>mysql&gt; analyze table emp1 update histogram on gender; ITable 1op Imsg type I Msg text<br>lemployees.empll histogram| status IHistogram statistics created for column ‘gender’. 1 row in set(0.34 sec)<br>再次观察执行计划，连接顺序发生了变化，titles1成为新的驱动表：<br>mysql&gt; desc select count(1) from emp1 a,titles1 b where a.emp_no&#x3D;b.emp_no and a.gender&#x3D;’M’\G;<br>Cow<br>id：1<br>select type: SIMPLE<br>table:b partitions: NULL<br>type: index<br>possible keys: PRIMARY<br>key: PRIMARY key_1en:159<br>ref:NULL rows:261872<br>filtered:100.00<br>Extra: Using index<br>id:1<br>select type: SIMPLE<br>table:a partitions: NULL<br>type: eq_ref<br>possible keys: PRIMARY<br>key:PRIMARY key_len:4<br>ref: employees.b.emp _no rows:1<br>filtered:99.67<br>Extra: Using where<br>2 rows in set,1 warning (0.o0 sec)<br>执行时间也大大缩短，仅仅用了0.46s，降了近3倍：<br>mysql&gt; select count(1) from emp1 a,titles1 b where a.emp no&#x3D;b.emp_no and a.gender&#x3D;’m’; 1count(1)1<br>2609391<br>1 row in set (0.17 sec)<br>此时，利用前面介绍的trace来分析一下执行计划的差异，如表15-2所示。</p>
<p>≦ 273 ≧<br>15.5直方图 255<br>表15-2 直方图使用前后trace对比<br>直方图创建前 直方图创建后<br>“rest _of plan”: [<br>“plan _prefix”:[ “rest of plan”: [<br>“titleslb” t<br>]&#x2F;<em>plan_prefix</em>&#x2F;, “plan_prefix”:[<br>“table”:”′empl””a””, “titleslb”<br>“filtering_effect”: [ ]&#x2F;<em>plan_prefix</em>&#x2F;,<br>“table”:”empl”‘a”,<br>“filtering_effect”: [<br>执行计<br>划1，选 “condition”:<br>择驱动 “(‘a”gender’&#x3D;’M)”, 表为<br>titlesl, “histogram_selectivity”:0.9967 cost二者<br>都为 1&#x2F;*filtering_effect <em>&#x2F;, 118027<br>“final_filtering_effect”: 0.9967,<br>]&#x2F;</em> filtering_effect *&#x2F;,<br>“final _filtering_effect”: 0.5,”rows_for_plan”:261872,<br>“cost for_plan”:118027,<br>“rows_for_plan”:261872, “chosen”: true<br>“cost for_plan”:118027,<br>“chosen”:true]&#x2F;<em>rest of plan</em>&#x2F;<br>]&#x2F;<em>rest_of plan</em>&#x2F;<br>“rest of plan”:[ “rest _of plan”; [<br>“plan _prefix”[ “plan _prefix”:[“empl”a”” “empl”a”<br>]<em>plan_prefix</em>&#x2F;,]<em>plan_prefix</em>,”table”：”titleslb””,”table”:”titles1b”,<br>“best_access_path”:{“best_access_path”:{“considered_access_paths”:[“considered access_paths”: [<br>执行计划<br>2，选择驱”access_type”:”ref”,”access_type”:”ref”, 动表为”index”:”PRIMARY”,”index””PRIMARY”, empl, cost”rows”:1.4682,”rows”:1.4682,<br>分别为”cost”:60108,”cost”: 119815, 90311和”chosen”: true”chosen” true 150018<br>! b,<br>“rows_for_plan”:219897,”rows_for_plan”:438329,”cost_for_plan”: 90311,”cost_for_plan”:150018,<br>“chosen”: true”pruned_by_cost”: true 1<br>&#x2F;<em>rest_ofplan</em>&#x2F;&#x2F;<em>rest ofplan</em>&#x2F;<br>选择由于90311&lt;118027，选择执行计划2，即连接顺序为由于150018&gt;118027，选择执行计划1，即连接顺结果 empl,titlesl 序为titlesl、empl<br>可以看出，由于直方图生成前后，过滤因子发生了变化，导致优化器在选择执行计划时的cost随着发生了改变，从而选择了更优的执行计划，达到了优化目的。</p>
<p>≦ 274 ≧<br>256 第15章SQL优化 15.5.4直方图小结<br>直方图的引人给SQL优化提供了一个新的思路，但并不是所有大表的字段都需要创建直方图。通常在一些唯一值较少、数据分布不均衡、查询较为频繁、没有创建索引的字段上考虑创建直方图。虽然在创建索引有时也可以达到优化效果，但由于这类字段索引使用率低、索引维护成本高，因此通常不会在这些字段上单独创建索引。而直方图只需要创建一次，对<br>数据的变更不需要实时进行维护，代价较小，更适合于此类条件的查询。 15.6使用查询重写<br>使用过Oracle数据库的同学可能知道，如果某个SQL的执行计划出了问题，可以使用 sql_profile，在不修改SQL本身的情况下，为SQL绑定更好的执行计划，这样做的好处是可以不依赖于代码的调整，第一时间解决因为执行计划选择错误而带来的问题。<br>而MySQL一直以来，都缺少能够便捷地干预执行计划的方式，经常需要通过修改SQL 的写法或者调整索引的方式来达到改变执行计划的目的，而修改SQL写法依赖于应用程序的修改和发布，不一定能够及时作出调整；通过修改索引的方式，代价往往也比较大，而且无法保证修改索引I后执行计划就能够符合预期，这是DBA在面对MySQL中的SQL优化时经常会遇到的一个问题。<br>在MySQL5.7中，提供了QueryRewritePlugin，可以通过规则匹配的方式，将符合条件的 SQL进行重写，从而达到调整执行计划或者其他的目标。下面来测试一下这个插件的安装和使用方法。<br>在Smysqlhome&#x2F;share目录下执行安装脚本，创建query_rewrite数据库和rewrite_rules 规则表：<br>mysql -uroot -p &lt; install_rewriter.sql mysql&gt; show databases like query%’;<br>|Database (query%) I query_rewrite<br>1row in set (o.00 sec) mysql&gt; use query_rewrite<br>Database changed mysql&gt; show tables;<br>I Tables_in query_rewrite rewrite rules<br>1 row in set (o.o0 sec)<br>VARIABLES LIKE ‘rewriter_enabled’;<br>I variable name Value</p>
<p>≦ 275 ≧<br>15.6使用查询重写 257<br>通过上面的查询，可以看到SQL重写插件已经打开。需要注意的是，SQL重写插件安装之后，即使关闭插件，仍然会有一定的额外开销，考虑到SQL重写插件可以动态安装和打开，因此，如果不是确定要使用这一插件，没有必要提前安装。<br>下面通过一个示例来演示一下查询重写是如何发挥作用的。<br>（1）增加匹配规则，将“SELECT？”全部重写为“SELECT？+1”，其中“？”是通配符，用来匹配数据值：<br>mysql&gt;INSERT INTo query_rewrite.rewrite _rules (pattern,replacement)</p>
<blockquote>
<p>VALUES(‘SELECT,SELECT?+1′）;<br>Query ok, 1 row affected (0.00 sec)（2）刷新使规则生效：<br>mysql&gt; CALL query_rewrite.flush_rewrite_rulesO； Query ok, 0 rows affected,1 warning (0.01 sec)<br>（3）看一下重新的效果： mysql&gt; select 1;<br>1row in set,1 warning (0.00 sec)<br>mysql&gt; show warnings; |Level | code | Message<br>I Note  1105 IQuery select 1’rewritten tosELECT 1+ 1’by a query rewrite plugin | 1 row in set (0.00 sec)<br>可以看到select1被重写为selectl+1，同时MySQL也返回一个warming，提示原SQL被重写了：<br>mysql&gt; show warnings;<br>| Level I code Message<br>Note 1105 Query’select 1’ rewritten to’sELECT 1 + 1’ by a query rewrite plugin1 1 row in set (o.o0 sec)<br>需要注意的是，改写对函数无效：<br>mysql&gt; select PIO; IPIO<br>13.1415931<br>1 row in set (0.00 sec)<br>这里PIO就没有没改写为PIO+1。<br>接下来，再给出一个示例，来说明如何通过查询重写来优化执行计划： mysql&gt; create table tab_test rewrite(<br>-&gt;order_idvarchar(20) not null, &gt;user_idvarchar(40) not null, &gt;status smallint(5) not null, &gt;primary key （order_id）,<br>-&gt;keyidx user_id(user id）, &gt;keyidx status(status））;<br>Query Ok, 0 rows affected (o.o1 sec)</p>
</blockquote>
<p>≦ 276 ≧<br>258 第15章SQL优化<br>假设这是一个订单表，其中保存了订单id、用户id和订单状态，导人数据后，总共有100 个用户，每个用户有1000个订单，并且这些订单的状态都是正常，用status&#x3D;1来表示，最后再加人1条状态为0的数据，表示异常。<br>mysqT&gt; DELIMITER&#x2F;&#x2F; mysq1&gt;<br>mysql&gt; CREATE PROCEDURE p_test1)<br>-&gt;BEGIN<br>-&gt; declare v user int; &gt;declare v order int;</p>
<blockquote>
<p>set @v_user&#x3D;l;-&gt;while @v_user&lt;101-&gt; do<br>set @v order&#x3D;1;<br>while @v_order&lt;1001 do<br>insert into tab_test rewrite(order_id,user_id,status)<br>values （concat(order_,@v user,,@v order）,concat（user,@v user）,1）;<br>set @v order&#x3D;@v order+1; END while;<br>set @v user&#x3D;@v user+l;<br>END while; &gt;<br>insert into tab test rewrite(order_id,user_id,status) values （’order 1 1001’,user 1,0);-&gt;END&#x2F;&#x2F;<br>Query ok,O rows affected (o.oo sec) mysq1&gt;<br>mysql&gt; DELIMITER；<br>mysql&gt; call p_test1(;<br>Query 0k,1 row affected (1 min 30.17 sec)<br>现在要查询某个用户的状态为1的数据，首先来看一下默认的执行计划：<br>mysql&gt; explain select * from tab_test _rewrite where user_id &#x3D; user 1 and status &#x3D; 1\G<br>id:1<br>select_type: SIMPLE<br>table: tab_test_rewrite partitions: NULL<br>type: index merge<br>possible _keys: idx user _id,idx status<br>key: idx user_id,idx status<br>key_1en:122,2 ref: NULL rows:500 filtered:100.00<br>Extra: using intersect(idx user _id,idx status):using where; using index<br>1 row in set,1 warning (o.o0 sec)<br>可以看到，默认的执行计划是扫描了idx_user_id和idx_status两个索引，并做了index_merge，而实际上，绝大多数记录的status都等于1，所以idxstatus对于状态是1的数据的选择度很差，一般没有必要去扫描这个索引l，再来看一下如果使用forceindex之后的执行计划：<br>mysql&gt; explain select * from tab_test rewrite force index (idx user id) where user_id &#x3D;user 1 and status &#x3D; 1G<br>#会<br>id:1<br>select type: SIMPLE<br>table: tab_test_rewrite partitions: NULL<br>type: ref<br>possible keys: idx user_id<br>key:idx user_id key_1en:122<br>ref: const rows: 1001<br>iltered:100.00</p>
</blockquote>
<p>≦ 277 ≧<br>15.7常用SQL技巧 259<br>Extra: using where<br>1 row in set, 1 warning (0.o0 sec)<br>这个执行计划更加符合我们的预期，为了优化这个查询，下面对这个查询进行改写： mysql&gt; INSERT INTo query_rewrite.rewrite_rules</p>
<blockquote>
<p>（pattern_database,pattern,replacement)-&gt;VALUESC’employees’,<br>‘select * from tab test rewrite where user_id &#x3D; ? and status &#x3D; 1’<br>-&gt;’select * from tab test rewrite force index (idx user id where user id &#x3D;? and status &#x3D; 1’); Query ok, 1 row affected (0.o0 sec)<br>mysql&gt; CALL query_rewrite.flush rewrite rulesO;<br>Query ok, 0 rows affected (0.01 sec) 重新执行以下查询：<br>mysql&gt; select * from tab test rewrite where user _id &#x3D; user 1’ and status &#x3D; 1; mysql&gt; show warnings \G;<br>Level: Note Code: 1105<br>Message: Query ‘select * from tab test rewrite where user id &#x3D; user 1’ and status &#x3D; 1’ rewritten to’select * from tab_test rewrite force index (idx user_id) where user id &#x3D;user 1’ and status<br>1’by a query rewrite plugin 1 row in set(o.00 sec)<br>可以看到，查询已经正确被改写。<br>当然，MySQL对于查询改写的处理相比Oracle来说仍然比较简单，而这种通过字符串匹配和替换的方式来做的改写，也存在一些问题，例如，可能造成一些查询被错误的修改。因<br>此在使用这一特性时，需要做好充分的测试。 15.7常用SQL技巧<br>15.7.1·正则表达式的使用<br>正则表达式（regularexpression）是指一个用来描述或者匹配一系列符合某个句法规则的字符串的单个字符串。在很多文本编辑器或其他工具里，正则表达式通常被用来检索和&#x2F;或替换那些符合某个模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。例如，在Perl中就内建了一个功能强大的正则表达式引擎。正则表达式这个概念最初是由UNIX中的工具软件（例如 SED和GREP）普及开的，通常缩写成“RegEx”或者“RegExp”。<br>MySQL利用RegExp命令提供给用户扩展的正则表达式功能，RegExp实现的功能类似 UNIX上GREP和SED的功能，并且RegExp在进行模式匹配时是区分大小写的。熟悉并掌握RegExp的功能可以使模式匹配工作事半功倍。<br>MySQL5.7中可以使用的模式序列如表15-3所示。<br>表15-3 正则表达式中的模式<br>序列序列说明<br>在字符串的开始处进行匹配<br>$ 在字符串的末尾处进行匹配<br>匹配任意单个字符，包括换行符<br>[..] 匹配出括号内的任意字符</p>
</blockquote>
<p>≦ 278 ≧<br>260 第15章SQL优化<br>续表<br>列 序列说明<br>[.] 匹配不出括号内的任意字符 a* 匹配零个或多个a（包括空串） a+ 匹配1个或多个a（不包括空串） a? 匹配1个或零个a<br>alla2 匹配al或a2 a(m) 匹配m个a<br>a(m,) 匹配m个或更多个a<br>a(m,n) 匹配m到n个a a(,n) 匹配0到n个a<br>(…) 将模式元素组成单一元素<br>下面举一些例子来介绍常用正则表达式的使用方法。<br>“入”在字符串的开始处进行匹配，返回结果为1表示匹配，返回结果为0表示不匹配。下例中尝试匹配字符串“abcdefg”是否以字符“a”开始。<br>mysql&gt; select ‘abcdefg REGExP a’; |’abcdefgREGEXPAa’1<br>11<br>1 row in set (0.39 sec)<br>“$”在字符串的末尾处进行匹配。下例中尝试匹配字符串“abcdefg”是否以字符“g”结束。 mysql&gt; select ‘abcdefg’REGExP’gs”;<br>I’abcdefg’REGEXP’gs 1row in set (0.01 sec)<br>“”匹配任意单个字符，包括换行符。下例中字符串“abcdefg”尝试匹配单字符“h” 和“f”。<br>mysql&gt; select’abcdefg′REGExP.h’,’abcdefg’REGExP.f’;<br>‘abcdefg′REGEXP.h’’abcdefg’REGEXP’.f’<br>11<br>1 row in set (0.00 sec)<br>“[..”匹配出括号内的任意字符。下例中字符串“abcdefg”尝试匹配“fhk”中的任意一个字符，如果有一个字符能匹配上，则返回1。<br>mysql&gt; select ‘abcdefg′REGExP “[fhk]”; I’abcdefg′REGExP”[fhk]”1<br>11<br>1 row in set (0.01 sec)<br>“[^…”匹配不出括号内的任意字符，和“[….”刚好相反。下例中字符串“efg”和“X”中如果有任何一个字符匹配不上“[XYZ]”中的任意一个字符，则返回O；如果全部都能匹配上，则返回1。</p>
<p>≦ 279 ≧<br>15.7常用SQL技巧 261<br>mysql&gt; select.’efg′REGEXP “[AXYZ]”,’X’REGEXP “[AxYZ]”;<br>I’efg’REGEXP “[AXYZ]”I’X′REGEXP “[△XYZ]” 1 row in set (o.00 sec)<br>上文介绍了正则表达式的常见使用方法。但是，在实际工作中，正则表达式到底会在什么地方用到呢？下面给出一个实例，使用正则表达式查询出使用163.com邮箱的用户和邮箱。（1）创建测试数据：<br>mysql&gt; insert into customer (store id, first name,last name,address_id,email) values<br>(1,188mail,beijing，605,<a href="mailto:&#x62;&#x65;&#105;&#x6a;&#105;&#110;&#x67;&#64;&#49;&#x38;&#x38;&#x2e;&#99;&#111;&#109;">&#x62;&#x65;&#105;&#x6a;&#105;&#110;&#x67;&#64;&#49;&#x38;&#x38;&#x2e;&#99;&#111;&#109;</a>）; Query ok, 1 row affected, 1 warning (0.06 sec)<br>mysql&gt; insert into customer (store id, first name,last name,address id, email) values(1,126mail,‘beijing’,605,<a href="mailto:&#x62;&#x65;&#x69;&#106;&#x69;&#110;&#103;&#x40;&#x31;&#x32;&#54;&#x2e;&#x63;&#111;&#109;">&#x62;&#x65;&#x69;&#106;&#x69;&#110;&#103;&#x40;&#x31;&#x32;&#54;&#x2e;&#x63;&#111;&#109;</a>‘）;<br>Query ok,1 row affected, 1 warning (0.05 sec)<br>mysql&gt; insert into customer (store id, first name, last name,address id, email) values<br>(1,163mail,beijing′，605,‘<a href="mailto:&#x62;&#x65;&#105;&#x6a;&#105;&#x6e;&#x67;&#64;&#49;&#54;&#51;&#x2e;&#x63;&#111;&#x6d;">&#x62;&#x65;&#105;&#x6a;&#105;&#x6e;&#x67;&#64;&#49;&#54;&#51;&#x2e;&#x63;&#111;&#x6d;</a>‘）; Query ok, 1 row affected, 1 warning (0.03 sec)<br>（2）使用正则表达式“$”和“[.”进行匹配：<br>mysql&gt; select first name, email from customer where email regexp @163,.]coms”; I first name I email<br>1163mail 1 <a href="mailto:&#98;&#101;&#x69;&#x6a;&#x69;&#x6e;&#103;&#x40;&#x31;&#x36;&#51;&#x2e;&#x63;&#111;&#109;">&#98;&#101;&#x69;&#x6a;&#x69;&#x6e;&#103;&#x40;&#x31;&#x36;&#51;&#x2e;&#x63;&#111;&#109;</a> 1 row in set (0.00 sec)<br>从以上可以看出，如果不使用正则表达式而使用普通的LIKE语句，则WHERE条件需要写成如下格式：<br>emailike@163%.comoremaiike@163%com<br>显然，采用正则表达式可以使得代码更加简单易读。 15.7.2巧用RANDO提取随机行<br>大多数数据库都会提供产生随机数的包或者函数，通过这些包或者函数可以产生用户需要的随机数，也可以用来从数据表中抽取随机产生的记录，这对一些抽样分析统计是非常有用的。例如ORACLE中用DBMS_RANDOM包产生随机数，而在MySQL中，产生随机数的方法是RANDO函数。可以利用这个函数与ORDERBY子句一起完成随机抽取某些行的功能。它的原理其实就是ORDERBYRANDO能够把数据随机排序。<br>例如，可按照随机顺序检索数据行：<br>mysqT&gt; select * from category order by randO;<br>I category_id l name 1last update<br>12 Music 2006-02-1504:46:27<br>Foreign 2006-02-1504:46:27 13 New 2006-02-15 04:46:27<br>Drama 12006-02-15 04:46:27 Action 12006-02-1504:46:27 31children 12006-02-1504:46:27<br>这样，如果想随机抽取一部分样本的时候，把数据随机排序后再抽取前n条记录就可以</p>
<p>≦ 280 ≧<br>262 第15章SQL优化了，比如：<br>mysql&gt; select * from category order by rand) limit 5; I category_id | name |last update<br>2006-02-1504:46:27<br>4 Classics Foreign<br>9 2006-02-1504:46:27 2 Animation 2006-02-1504:46:27 Trave] 2006-02-15 04:46:27 7 Drama 2006-02-1504:46:27<br>5rows in set (o.00 sec)<br>上面的例子从类别表category中随机抽取了5个样本，随机抽取样本对总体的统计具有十分重要的意义，因此这个函数非常有用。<br>15.7.3利用GROUPBY的WITHROLLUP子句<br>在SQL语句中，使用GROUPBY的WITHROLLUP字句可以检索出更多的分组聚合信息，它不仅仅能像一般的GROUPBY语句那样检索出各组的聚合信息，还能检索出本组类的整体聚合信息，具体如下例所示。<br>在支付表payment中，按照支付时间payment_date的年月、经手员工编号staff_id列分组对支付金额amount列进行聚合计算如下：<br>mysql&gt; select date format(payment date,%Y-%m’),staff id, sum(amount) from payment group by date format（payment_date,%Y-%m’),staff_id;<br>1date format(payment date,%Y-%m’)| staff id| sum(amount)1<br>12005-05 2621.83 2005-05 2202.60 2005-06 4776.36<br>1<br>2005-06 4855.52 2005-07 14003.54<br>2005-07 14370.35 2005-08 11853.65<br>2005-08 12218.48 2006-02 234.09<br>12006-02 280.09 10 rows in set (0.06 sec)<br>mysql&gt; select date format(payment date,%Y-%m’),IFNULL(staff id,), sum（amount) from payment group by date_format(payment date,%y-%m’), staff _id with rollup;<br>Idate format(payment date,%Y-%m’)I IFNULL(staff id,)I sum(amount)<br>12005-05 1 2621.83 2005-05 2 2202.60<br>2005-05 4824.43 2005-06<br>2005-06 4776.36 2005-06 4855.52<br>9631.88<br>2005-07 V 14003.54 2005-07 14370.35 2005-07 28373.89<br>2005-08 11853.65 2005-08 2 12218.48<br>2005-08 24072.13 2006-02 1 234.09<br>2006-02 12 280.09 2006-02 514.18 |NULL 67416.51<br>16 rows in set (0.05 sec)</p>
<p>≦ 281 ≧<br>15.7常用SQL技巧 263<br>从上面的例子中可以看到，第二个SQL语句的结果比第一个SQL语句的结果多出了很多行，而这些行反映出了更多的信息。例如，第二个SQL语句的结果的前两行表示2005-05 月份各个员工（1、2）的经手的支付金额，而第三行表示2005-05月份总支付金额为4824.43，这个信息在第一个SQL语句中是不能反映出来的，第16行表示总支付金额为67416.51，这个信息在第一个SQL语句中是没有的。<br>其实WITHROLLUP反映的是一种OLAP思想，也就是说这一个GROUPBY语句执行完成后可以满足用户想要得到的任何一个分组以及分组组合的聚合信息值。<br>注意：当使用ROLLUP时，不能同时使用ORDERBY子句进行结果排序。换言之，ROLLUP和<br>ORDERBY是互相排斥的。此外，LIMIT用在ROLLUP后面。<br>15.7.4用BITGROUPFUNCTIONS做统计<br>本节主要介绍如何共同使用GROUPBY语句和BIT_AND、BIT_OR函数完成统计工作。这两个函数的一般用途就是做数值之间的逻辑位运算，但是，当把它们与GROUPBY子句联合使用的时候就可以做一些其他的任务。<br>假设现在有这样一个任务：一个超市需要记录每个用户每次来超市都购买了哪些商品。为了将问题简单化，假设该超市只有面包、牛奶、饼干、啤酒4种商品。那么通常该怎么做呢？一般先建立一个购物单表，里面记录购物发生的时间、顾客信息等；然后再建立一个购物单明细表，里面记录该顾客所购买的商品。这样设计表结构的优点是顾客所购买的商品的详细信息可以记录下来，比如数量、单价等，但是如果目前的这个任务只需要知道用户购买商品的种类和每次购物总价等信息，那么这种数据库结构的设计就显得太复杂了。一般还可能会想到用一个表实现这个功能，并且用一个字段以字符串的形式记录顾客所购买的所有商品的商品号，这也是一种方法，但是如果顾客一次购买商品比较多，需要很大的存储空间，而且将来做各种统计的时候也会捉襟见肘。<br>下面给出一种新的解决办法，类似于上面讲到的第二种方案，仍然用一个字段表示顾客购<br>买商品的信息，但是这个字段是数值型的而不是字符型的，该字段存储一个十进制数字，当它转换成二进制的时候，那么每一位代表一种商品，而且如果所在位是“1”那么表示顾客购买了该种商品，“0”表示没有购买该种商品。比如数值的第一位代表面包（规定从右向左开始计算）第二位代表牛奶、第三位代表饼干、第4位代表啤酒，这样如果一个用户购物单的商品列的数值为5，那么二进制表示为0101，这样从右向左第一位和第三位是1，那么就可以知道这个用户购买了面包和饼干，而如果这个客户有多个这样的购物单（在数据库中就是有多条记录），把这些购物单按用户分组做BIT_ORO操作就可以知道这个用户都购买过什么商品。<br>下面举例说明一下这个操作，首先初始化一组数据：<br>mysql&gt; create table order_rab (id int,customer _id int,kind int); Query ok, 0 rows affected (o.o5 sec)<br>mysql&gt; insert into order _rab values (1,1,5）,(2,1,4); Query ok, 2 rows affected (o.o0 sec)<br>mysq1&gt; insert into order_rab values (3,2,3),(4,2,4); Query ok, 2 rows affected (o.00 sec)<br>mysql&gt; select * from order_rab; 1 id l customer_id | kind 1<br>15</p>
<p>≦ 282 ≧<br>264 第15章SQL优化 4rows in set(0.00 sec)<br>其中customerid是顾客编号，kind是所购买的商品，初始化了两个顾客1和2的数据，他们每人购物两次，前者购买的商品数值是5和4，转化为二进制分别为0101、0100，表示这个顾客第一次购买了牛奶和啤酒，第二次购买了牛奶；后者购买的商品数值是3和4，转化为二进制分别为0011、0100，表示这个顾客第一次购买了饼干和啤酒，第二次购买了牛奶。<br>下面用BIT_ORO函数与GROUPBY子句联合起来，统计一下这两个顾客在这个超市一共都购买过什么商品，如下例：<br>mysql&gt; select customer id,bit or(kind) from order _rab group by customer_id;<br>I customer id I bit or(kind) 11<br>2rows in set (o.00 sec)<br>可以看到顾客1的BITOR0结果是5，即0101，表示这个顾客在本超市购买过牛奶和啤酒；顾客2的BITORO结果是7，即0111，表示这个顾客在本超市购买过牛奶、饼干、啤酒。<br>下面解释一下数据库在处理这个逻辑时的计算过程，以第一个顾客举例，BIT_OR(kind) 就相当于把kind的各个值做了一个“或”操作，最终结果是十进制的5。逻辑计算公式如下：<br>.0101.0100<br>OR..0000<br>0101<br>同理，可以用BIT_ANDO统计每个顾客每次来本超市都会购买的商品，具体如下：<br>mysql&gt; select customer_id,bit and(kind) from order_rab group by customer _id; I customer_id I bit and（kind)<br>10<br>2 rows in set (0.01 sec)<br>顾客1的BIT_ANDO结果是4，即0100，表示顾客1每次来本超市都会购买牛奶；顾客 2的BIT_ANDO结果是0，即0000，表示顾客2不是每次来本超市都会购买的商品。<br>数据库在处理BITANDO的时候就是把kind的各个值做了一个“与”操作，拿顾客1举例说明一下，逻辑计算公式如下：<br>0101.0100<br>#AND..1111<br>从上面的例子可以看出，这种数据库结构设计的好处就是能用很简洁的数据表示很丰富的信息，这种方法能够大大地节省存储空间，而且能够提高部分统计计算的速度。不过需要注意的是，这种设计其实损失了顾客购买商品的详细信息，比如购买商品的数量、当时单价、是否有折扣、是否有促销等，因此还要根据应用的实际情况有选择地考虑数据库的结构设计。</p>
<p>≦ 283 ≧<br>15.7常用SQL技巧 265<br>15.7.5数据库名、表名大小写问题<br>在MySQL中，数据库对应操作系统下的数据目录。数据库中的每个表至少对应数据库目录中的一个文件（也可能是多个，这取决于存储引擎）。因此，所使用操作系统的大小写敏感性决定了数据库名和表名的大小写敏感性。在大多数UNIX环境中，由于操作系统对大小写的敏感性导致了数据库名和表名对大小写敏感性，而在Windows中，由于操作系统本身对大小写不敏感，因此在Windows下的MySQL数据库名和表名对大小写也不敏感。<br>列、索引、存储子程序和触发器名在任何平台上对大小写不敏感。默认情况下，表别名在UNIX中对大小写敏感，但在Windows或macOSX中对大小写不敏感。下面的查询在UNIX 中会报错，因为它同时引用了别名a和A：<br>mysql&gt; select id from order_rab a where A.id &#x3D; 1;<br>ERRoR 1054 (42s22):unknown column A.idin where clause<br>然而，该查询在Windows中是可以的。要想避免出现差别，最好采用一致的转换，例如，总是用小写创建并引用数据库名和表名。<br>在MySQL中，如何在硬盘上保存、使用表名和数据库名是由lower_case_tables_name系统变量决定的，用户可以在启动MySQL服务时设置这个系统变量。lower_case_tables_name 可以采用如表15-4所示的任一值。<br>表15-4 lower_case_tables_name的取值范围<br>使用CREATETABLE或CREATEDATABASE语句指定的大写和小写在硬盘上保存表名和数据库名。名称对大小写敏感。在UNIX系统中的默认设置就是这个值<br>表名在硬盘上以小写保存，名称对大小写敏感。MySQL将所有表名转换为小写以便存储和查找。该值为Windows 和macOSX系统中的默认值<br>表名和数据库名在硬盘上使用CREATETABLE或CREATEDATABASE语句指定的大小写进行保存，但MySQL 将它们转换为小写以便查找。此值只在对大小写不敏感的文件系统上适用<br>如果只在一个平台上使用MySQL，通常不需要更改lower_case_tables_name变量。然而，！如果用户想要在对大小写敏感性不同的文件系统的平台之间转移表，就会遇到困难。例如，在UNIX中，my_tables和MY_tables是两个不同的表，但在Windows中，这两个表名相同。<br>在UNIX中使用lower_case_tables_name&#x3D;O，而在Windows中使用lower_case_tables_ name&#x3D;2，这样可以保留数据库名和表名的大小写。不利之处是必须确保在Windows中的所有 SQL语句总是正确地使用大小写来引I用数据库名和表名，如果SQL语句中没有正确引I用数据库名和表名的大小写，那么虽然在Windows中能正确执行，但是如果将查询转移到UNIX中，大小写不正确，将会导致查询失败。<br>注意：在UNIX中将lower_case_tables_name设置为1并且重启mysqld之前，必须先将旧的数据<br>库名和表名转换为小写。尽管在某些平台中数据库名和表名对大小写不敏感，但是最好养成在同一查询中使用相同的大小写来引用给定的数据库名或表名的习惯。<br>15.7.6使用外键需要注意的问题<br>在MySQL中，InnoDB存储引擎支持对外部关键字约束条件的检查。而对于其他类型存储引擎的表，当使用REFERENCEStbl_name(col_name)子句定义列时可以使用外部关键字，但是该子</p>
<p>≦ 284 ≧<br>266 第15章SQL优化<br>句没有实际的效果，只作为备忘录或注释来提醒用户目前正定义的列指向另一个表中的一个列。<br>例如，下面的myisam表外键就没有起作用：<br>mysql&gt; create table users(id int,name varchar(10),primary key（id)) engine&#x3D;myisam; Query ok,0 rows affected (0.03 sec)<br>mysql&gt; create table books（id int,bookname varchar（10),userid int ,primary key（id),constraint<br>fk userid id foreign key(userid) references users(id)) engine&#x3D;myisam; Query ok,0 rows affected (0.03 sec)<br>mysql&gt; insert into books values(1,book1′,1); Query ok,1 row affected (0.00 sec)<br>如果用InnoDB存储引擎建表的话，外键就会起作用，具体如下：<br>mysql&gt; create table users2(id int,name varchar(10),primary key(id)) engine&#x3D;innodb; Query ok,0 rows affected (0.14 sec)<br>mysql&gt; create table books2(id int,bookname varchar(10),userid int ,primary key（id),constraint<br>fk userid id foreign key（userid) references users2(id)) engine&#x3D;innodb; Query ok,0 rows affected (0.18 sec)<br>mysql&gt; insert into books2 values(1,’book1’,1);<br>ERROR 1452 (23000): Cannot add or update a child row:a foreign key constraint fails (‘sakila&#x2F; books2’CONSTRAINTfk userid id’FOREIGN KEY Cuserid’) REFERENCES‘users2C’id’))<br>而且，用showcreatetable命令查看建表语句的时候，发现MyISAM存储引擎并不显示<br>外键的语句，而InnoDB存储引擎就会显示外键语句，具体如下： mysql&gt; show create table books\G;<br>Table:books<br>Create Table: CREATE TABLE‘books′（ id’int(11) NOT NULL DEFAULTO’，‘bookname* varchar(10) DEFAULT NULL,<br>‘userid’ int(i1) DEFAULT NULL, PRIMARY KEY（id’),<br>KEYfk userid id’（’userid’)<br>)ENGINE&#x3D;MyISAM DEFAULT CHARSET&#x3D;gbk 1row in set (o.00 sec)<br>mysql&gt; show create table books2\G;<br>Table: books2<br>Create Table: CREATE TABLE books2’（’idint(11) NOT NULL DEFAULT’O’,’bookname varchar(10) DEFAULT NULL,<br>userid’ int(i1) DEFAULT NULL, PRIMARY KEY (‘id’),<br>KEY’fk userid id’ (‘userid’),<br>CONSTRAINT’fk userid id’FOREIGN KEY (‘userid’) REFERENCEs’users2’(‘id’)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gbk 1 row in set (o.00 sec)<br>15.8小结<br>SQL优化问题是数据库性能优化最基础也是最重要的一个问题，实践表明很多数据库性能问题都是由不合适的SQL语句造成。本章通过实例描述了SQL优化的一般过程，从定位一个有性能问题的SQL语句到分析产生性能问题的原因，最后到采取什么措施优化SQL语句的性能。另外，针对特定的SQL（比如排序、join等）和MySQL8.0引入的一些新功能（比如直方图）也做了一些介绍，希望能帮助读者拓宽优化的思路。</p>
<p>≦ 285 ≧<br>第16章 锁问题<br>锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的计算资源（如CPU、RAM、I&#x2F;O等）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题。锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。本章我们着重讨论MySQL锁机制的特点、常见的锁问题，以及解决MySQL锁问题的一些方法或建议。<br>16.1MySQL锁概述<br>相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引引擎采用的是表级锁（table-level locking）;； BDB存储引擎采用的是页面锁（page-levellocking），但也支持表级锁；InnoDB存储引擎既支持行级锁（row-levellocking），也支持表级锁，但默认情况下是采用行级锁。<br>MySQL这3种锁的特性可大致归纳如下。<br>●表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。<br>●行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。<br>●页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。<br>从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如 Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。这一点在本书的“开发篇”介绍表类型的选择时，也曾提到过。下面重点介绍MySQL表锁和InnoDB行锁的问题。由于BDB已经被 InnoDB取代，即将成为历史，这里就不进一步讨论了。</p>
<p>≦ 286 ≧<br>268 第16章锁问题 16.2MyISAM表锁<br>MyISAM存储引擎只支持表锁，这也是MySQL开始几个版本中唯一支持的锁类型。随着应用对事务完整性和并发性要求的不断提高，MySQL才开始开发基于事务的存储引擎，后来慢慢出现了支持页锁的BDB存储引擎和支持行锁的InnoDB存储引擎。但是，MyISAM的<br>表锁依然是使用最为广泛的锁类型。本节将详细介绍MyISAM表锁的使用。 16.2.1查询表级锁争用情况<br>可以通过检查table_locks_waited和table_locks_immediate状态变量来分析系统上的表锁定争用情况：<br>mysql&gt; show status like table%’;<br>I Variable name |value1 I Table locks immediate<br>ITable_locks_waited 10 2 rows in set (0.00 sec))<br>如果Table_locks_waited的值比较高，则说明存在着较严重的表级锁争用情况。 16.2.2MySQL表级锁的锁模式<br>MySQL的表级锁有两种模式：表共享读锁（TableReadLock）和表独占写锁（TableWrite Lock）。锁模式的兼容性如表16-1所示。<br>表16-1 MySQL中的表锁兼容性<br>是否兼容请求锁模式<br>None 读锁 写锁<br>当前锁模式<br>读锁是是否写锁是否否<br>可见，对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；MyISAM 表的读操作与写操作之间，以及写操作之间是串行的！根据如表16-2所示的示例可以知道，当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。<br>表16-2 MyISAM存储引擎的写阻塞读示例<br>session_1 session_2<br>获得表film_text的WRITE锁定： mysql&gt; lock table film_text write; Query OK, 0 rows affected (0.00 sec)</p>
<p>≦ 287 ≧<br>16.2MyISAM表锁 269<br>续表<br>session_1 session_2<br>当前session对锁定表的查询、更新、插入操作都可以执行： mysql&gt; select film_id,title from film_text where film_id&#x3D;1001;<br>film_id |title<br>其他session对锁定表的查询被阻塞，需要等待锁被<br>|1001|UpdateTest] 释放：<br>1 row in set (0.00 sec) mysql&gt; select film_id.title from film_text where<br>film_id&#x3D;1001;<br>mysql&gt;insert into film_text (film_id,title)values(1003, 等待 &#96;Test);<br>Query OK,1 row affected (0.00 sec)<br>mysql&gt;update film_text set title&#x3D;Test’where film_id&#x3D;1001; Query OK,1rowaffected(0.00 sec)<br>Rows matched: 1Changed: 1Warnings: 0 释放锁：<br>mysql&gt; unlock tables; 等待 Query OK,0rows affected (0.00 sec)<br>Session2获得锁，查询返回：<br>mysql&gt; select film_id,title from film_text where<br>film_id&#x3D;1001; |film id|title<br>|1001[Test 1 row in set(57.59 sec)<br>16.2.3如何加表锁<br>MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁；在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用LOCKTABLE命令给MyISAM表显式加锁。在本书的示例中，显式加锁基本上都是为了方便说明问题，并非必须如此。<br>给MyISAM表显式加锁，一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。例如，有一个订单表orders，其中记录有各订单的总金额total，同时还有一个订单明细表order_detail，其中记录有各订单每一产品的金额小计subtotal，假设我们需要<br>检查这两个表的金额合计是否相符，可能就需要执行如下两条SQL语句： Select sum(total) from orders;<br>Select sum(subtotal) from order detail;<br>这时，如果不先给两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中， order_detail表可能已经发生了改变。因此，正确的方法应该是：<br>Lock tables orders read local, order_detail read local; Select sum(total) from orders;<br>Select sum(subtotal) from order_detail; Unlock tables;<br>要特别说明以下两点内容。<br>O上面的示例在LOCKTABLES时加了“local”选项，其作用就是在满足MyISAM表并发插入条件的情况下，允许其他用户在表尾并发插入记录，有关MyISAM表的并发插入问</p>
<p>≦ 288 ≧<br>270 第16章锁问题题，在后面的章节中还会进一步介绍。<br>在用LOCKTABLES给表显式加表锁时，必须同时取得所有涉及表的锁，并且MySQL 不支持锁升级。也就是说，在执行LOCKTABLES后，只能访问显式加锁的这些表，不能访问未加锁的表；同时，如果加的是读锁，那么只能执行查询操作，而不能执行更新操作。在自动加锁的情况下也是如此，MyISAM总是一次获得SQL语句所需要的全部锁。这也正是 MyISAM表不会出现死锁（DeadlockFree）的原因。<br>在如表16-3所示的示例中，一个session使用LOCKTABLE命令给表film_text加了读锁，这个session可以查询锁定表中的记录，但更新或访问其他表都会提示错误；同时，另外一个 session可以查询表中的记录，但更新就会出现锁等待。<br>表16-3 MyISAM存储引擎的读阻塞写示例<br>session_1 session_2<br>获得表film_text的READ锁定： mysql&gt; lock table film_text read; Query OK, 0 rows affected (0.00 sec)<br>当前session可以查询该表记录： 其他session也可以查询该表的记录：<br>mysql&gt; select film_id,title from film_text where film_id mysql&gt; select film_id.title from film_text where film_id 1001; 1001;<br>|filmid |title [film id[title<br>|1001[ACADEMYDINOSAUR| |1001[ACADEMYDINOSAUR] 1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>其他session可以查询或者更新未锁定的表：<br>mysql&gt; select film_id,title from film where film_id &#x3D; 1001;<br>当前session不能查询没有锁定的表： film id|title mysql&gt; select film_id,title from film where film_id&#x3D;1001;<br>ERROR 1100 (HY000):Table film’was not locked with |1001 updaterecord| LOCK TABLES<br>1 row in set (0.00 sec)<br>mysql&gt;update film set title&#x3D;Test’where film id&#x3D; 1001; QueryOK,1row affected (0.04 sec)<br>Rows matched:1 Changed:1Warnings: 0<br>当前session中插入或者更新锁定的表都会提示错误：<br>mysql&gt; insert intofilm_text （film id,title)values<br>(1002,Test’); 其他session更新锁定表会等待获得锁： ERROR1099 (HY000):Tablefilm_ text’was locked with a mysql&gt;updatefilm_text set title&#x3D;Test’wherefilm READ lock and can’t be updated id&#x3D;1001; mysql&gt;update film text set title &#x3D;Test’ where film_id&#x3D;<br>等待<br>1001;<br>ERROR1099 (HY000):Tablefilm_text’was locked with a<br>READ lock and can’t be updated 释放锁：<br>mysql&gt; unlock tables; 等待 QueryOK,0rows affected (0.00 sec)<br>session获得锁，更新操作完成：<br>mysql&gt;update film_text set title&#x3D;Test’where film id&#x3D;1001;<br>Query OK,1 row affected (1 min0.71 sec) Rows matched:1Changed:1 Warnings:0</p>
<p>≦ 289 ≧<br>16.2MyISAM表锁 271<br>当使用LOCKTABLES时，不仅需要一次锁定用到的所有表，而且，同一个表在SQL语句中出现多少次，就要通过与SQL语句中相同的别名锁定多少次，否则也会出错！举例说明如下。<br>（1）对actor表获得读锁： mysql&gt; lock table actor read;<br>Query oK, O rows affected (o.o0 sec)（2）但是通过别名访问会提示错误：<br>mysql&gt; select a.first name,a.last name,b.first name,b.last name from actor a,actor b where a.first name &#x3D; b.first name and a.first name &#x3D; Lisa’ and a.last name &#x3D; Tom’ and a.last name  b.last name; ERROR1100HYO）Tableawasotocked withLoCKTABES<br>（3）需要对别名分别锁定：<br>mysql&gt; lock table actor as a read,actor as b read;<br>Query ok,O rows affected (o.o0 sec)（4）按照别名的查询可以正确执行：<br>mysql&gt; select a.first name,a.last name,b.first name,b.last name from actor a,actor b where a.first name &#x3D; b.first name and a.first name &#x3D;Lisa and a.last name &#x3D;’Tom’ and a.last name b.last name;<br>first name I last name I first name | last name |<br>Lisa Tom I LISA I MONROE 1 row in set (0.00 sec)<br>16.2.4并发插入（ConcurrentInserts）<br>上文提到过MyISAM表的读和写是串行的，但这是就总体而言的。在一定条件下， MyISAM表也支持查询和插入操作的并发进行。<br>MyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入的行为，其值分别可以为0、1或2。<br>当concurrent_insert设置为O时，不允许并发插入。<br>当concurrent_insert设置为1时，如果MyISAM表中没有空洞（表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是MySQL 的默认设置。<br>当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录。<br>在如表16-4所示的示例中，session_1获得了一个表的READLOCAL锁，该线程可以对表进行查询操作，但不能对表进行更新操作；其他的线程（session_2），虽然不能对表进行删除和更新操作，但却可以对该表进行并发插入操作，这里假设该表中间不存在空洞。<br>表16-4 MyISAM存储引擎的读写（INSERT）并发示例<br>session_1 session_2<br>获得表film_text的READLOCAL锁定： mysql&gt; lock table film_text read local; Query OK, 0 rows affected (0.00 sec)</p>
<p>≦ 290 ≧<br>272 第16章锁问题<br>续表<br>session_2<br>当前session不能对锁定表进行更新或者插入操作： 其他session可以进行插入操作，但是更新会等待：<br>mysql&gt;insert into film_text (film_id,title)values (1002,Test’); mysql&gt; insert into film_text (film_id,title) values ERROR 1099 (HY000):Table’film_textwas locked with a (1002,Test);<br>READ lock and can’t be updated Query OK,1 row affected (0.00 sec)<br>mysql&gt;update film_text set title&#x3D;Test’where film_id&#x3D;1001; mysql&gt;update film_text set title&#x3D;Update Test where ERROR 1099 (HY000):Table film_text was locked with a film_id&#x3D;1001;<br>READ lock and can’t be updated 等待当前session不能访问其他session插入的记录：<br>mysql&gt;select flmid,title from film_text where film_id&#x3D;1002; Empty set (0.00 sec)<br>释放锁： 等待 mysql&gt; unlock tables;<br>Query OK, 0 rows affected (0.00 sec)<br>当前session解锁后可以获得其他session插入的记录： session2获得锁，更新操作完成：<br>mysql&gt; select film id,title from film_text where film id&#x3D;1002; mysql&gt; update film text set title &#x3D; Update Test’ where<br>film_id&#x3D;1001;<br>flmid|title Query OK,1row affected (1min17.75 sec)<br>Rows matched: 1 Changed:1Warnings:0<br>|1002 |Test 1 row in set (0.00 sec)<br>可以利用MyISAM存储引擎的并发插人特性来解决应用中对同一表查询和插入的锁争用。例如，将concurrent_insert系统变量设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIMIZETABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞。<br>有关OPTIMIZETABLE语句的详细介绍，可以参见15.3节的内容。 16.2.5MyISAM的锁调度<br>前面讲过，MyISAM存储引擎的读锁和写锁是互斥的，读写操作是串行的。那么，一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？答案是写进程先获得锁。不仅如此，即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前！这是因为MySQL认为写请求一般比读请求要重要。这也正是MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。这种情况有时可能会变得非常糟糕！幸好我们可以通过一些设置来调节MyISAM的调度行为。<br>通过指定启动参数low-priority-updates，使MyISAM引擎默认给予读请求以优先的权利。 O通过执行命令SETLOW_PRIORITY_UPDATES&#x3D;1，使该连接发出的更新请求优先级降低。 O通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句<br>的优先级。<br>虽然上面3种方法都是要么更新优先，要么查询优先的方法，但还是可以用其来解决查询相对重要的应用（如用户登录系统）中读锁等待严重的问题。<br>另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数 max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一些获得锁的机会。</p>
<p>≦ 291 ≧<br>16.3InnoDB锁问题 273<br>上面已经讨论了写优先调度机制带来的问题和解决办法。这里还要强调一点：一些需要长时间运行的查询操作，也会使写进程“饿死”！因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应<br>尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。 16.3InnoDB锁问题<br>InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）；二是采用了行级锁。行级锁与表级锁本来就有许多不同之处，另外，事务的引人也带来了一些新问题。<br>下面我们先介绍一点背景知识，然后详细讨论InnoDB的锁问题。 16.3.1背景知识<br>1.事务（Transaction）及其ACID属性<br>事务是由一组SQL语句组成的逻辑处理单元，具有以下4个属性，通常简称为事务的 ACID属性。<br>原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。<br>一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。<br>隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。<br>持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。<br>银行转账就是事务的一个典型示例。 2.并发事务处理带来的问题<br>相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持更多的用户。但并发事务处理也会带来一些问题，主要包括以下几种情况。<br>更新丢失（LostUpdate）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题一最后的更新覆盖了由其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改副本的编辑人员覆盖另一个编辑人员所做的更改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题。<br>脏读（DirtyRead）：一个事务正在对一条记录做修改，在这个事务完成并提交前，</p>
<p>≦ 292 ≧<br>274 第16章锁问题<br>这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。<br>不可重复读（Non-RepeatableRead）：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变或某些记录已经被删除了！这种现象就叫做“不可重复读”。<br>幻读（PhantomRead）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。<br>3.事务隔离级别<br>在上面讲到的并发事务处理带来的问题中，“更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。<br>“脏读”“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。数据库实现事务隔离的方式，基本上可分为以下两种。<br>一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。<br>另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（MultiVersionConcurrencyControl，MVCC或MCC），也经常称为多版本数据库。<br>数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。<br>为了解决“隔离”与“并发”的矛盾，ISO&#x2F;ANSISQL92定义了4个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己的业务逻辑要求，通过选择不同的隔离级别来平衡“隔离”与“并发”的矛盾。表16-5很好地概括了这4个隔离级别的特性。<br>表16-5 4种隔离级别比较<br>读数据一致性及允许的<br>不可重<br>并发副作用读数据一致性脏读幻读<br>复读<br>隔离级别<br>最低级别，只能保证不读取物理<br>未提交读（Readuncommitted）是是是<br>上损坏的数据<br>已提交读（Readcommitted）语句级否是是可重复读（Repeatableread）事务级否否是可序列化（Serializable）最高级别，事务级否否否<br>最后要说明的是：各具体数据库并不一定完全实现了上述4个隔离级别，例如，Oracle 只提供Readcommitted和Serializable两个标准隔离级别，另外还提供自己定义的Readonly 隔离级别；SQLServer除支持上述ISO&#x2F;ANSISQL92定义的4个隔离级别外，还支持一个叫做“快照”的隔离级别，但严格来说，它是一个用MVCC实现的Serializable隔离级别。MySQL</p>
<p>≦ 293 ≧<br>16.3InnoDB锁问题 275<br>支持全部4个隔离级别，但在具体实现时，有一些MySQL自有的特点（区别于其他数据库的实现），比如在一些隔离级别下是采用MVCC一致性读，但某些情况下又不是，在后面的章节中将会对这些内容做进一步介绍。<br>16.3.2获取InnoDB行锁争用情况<br>可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：<br>mysql&gt; show status like innodb_row lock%’; 1Variable name Value<br>I InnoDB_row_ lock current waits InnoDB_row_lock_time<br>InnoDB_row_lock time_avg 0 InnoDB_row_lock time_max o<br>I InnoDB_row_lock waits i0 5 rows in set (0.01 sec)<br>如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，可以通过设置InnoDBMonitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。<br>通过设置下面两个参数可以来设置监视器，MySQL定期将包含锁冲突信息的日志写人 error log:<br>SET GLoBAL innodb status output&#x3D;ON;<br>SET GLOBAL innodb status output locks&#x3D;ON;<br>也可以用以下语句来查看最新的状态信息（粗体部分显示为锁冲突信息）：<br>mysql&gt; Show engine innodb status\G; |InnoDB<br>2018-11-05 17:55:31 0x7f3b909a7700 INNODB MONITOR OUTPUT Per second averages calculated from the last 20 seconds LATEST FOREIGN KEY ERROR<br>2018-11-02 15:59:59 0x7f3b90966700 Transaction:<br>TRANSACTION 2285382, ACTIVE 0 sec inserting mysql tables in use 1,locked 1<br>2lock struct(s),heap size 1136, 0 row lock(s)<br>MySQL thread id 10,os thread handle 139893805573888,query id 1081ocalhost root update insert into titles values(11111li11,1,nowO,now)<br>Foreign key constraint fails for table employees titles:<br>CONSTRAINT titles ibfk 1FOREIGN KEY (emp no) REFERENCES employees( emp_no*) ON DELETE CASCADE<br>Trying to add in child table, in index PRIMARY tuple:<br>MysQL thread id 8124,os thread handle 139893341038336,query id 2451665 1oca1host root TABLE Lock tablesakila.customer trx id 3811967 lock mode Ix<br>RECoRD LocKS space id 72 page no 7n bits 256 index PRIMARY of tablesakila.customer trx id 3811967 1ockm<br>ode x locks rec but not gap<br>Record lock, heap no 2 PHYSICAL REcoRD: n fields 11; compact format; info bits 0<br>可以在MySQL命令行中通过发出下列语句来停止监视器： SET GLOBAL innodb status output&#x3D;OFF<br>SET GLOBAL innodb status output locks&#x3D;OFF;</p>
<p>≦ 294 ≧<br>276 第16章锁问题<br>设置监视器后，在SHOWINNODBSTATUS的显示内容中，会有当前锁等待的详细信息，包括表名、锁类型、锁定记录的情况等，以便进一步分析和确定问题。<br>打开监视器以后，默认情况下每15s会向日志中记录监控的内容，如果长时间打开会导致errorlog文件变得非常巨大，所以用户在确认问题原因之后，要记得关闭监视器。用户也可以在启动选项中加人–innodb-status-file选项使得监控信息写入指定的innodb_status.pid文件，以便和error日志进行隔离。<br>16.3.3InnoDB的行锁模式及加锁方法<br>InnoDB实现了以下两种类型的行锁。<br>共享锁（S）：允许一个事务读一行，阻止其他事务获得相同数据集的排他锁。<br>○排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。<br>另外，为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（IntentionLock），这两种意向锁都是表锁。<br>意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。<br>意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。<br>上述锁模式的兼容情况具体如表16-6所示。<br>表16-6 InnoDB行锁模式兼容性列表<br>请求锁模式<br>是否兼容 x 1X s IS 当前锁模式<br>X 冲突冲突冲突 冲突 IX 冲突兼容冲突兼容<br>S 冲突冲突兼容兼容 IS 冲突兼容兼容兼容<br>如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。<br>意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句， InnoDB会自动给涉及数据集加排他锁（X）；对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显式给记录集加共享锁或排他锁。<br>（1）在MYSQL5.7中。<br>O共享锁（S）:SELECT <em>FROM table_name WHERE…LOCK IN SHARE MODE。<br>O排他锁（X）:SELECT</em>FROM table_nameWHERE…FORUPDATE。（2）在MySQL8.0中。<br>O共享锁（S）:SELECT<em>FROMtable_name WHERE..FOR SHARE<br>O排他锁（X）:SELECT</em>FROM table_nameWHERE..FORUPDATE[NOWAITISKIP</p>
<p>≦ 295 ≧<br>16.3InnoDB锁问题 277<br>LOCKED]<br>在MySQL5.7及之前的版本，用SELECT..INSHAREMODE获得共享锁，MySQL8.0 后改为了SELECT..FORSHARE语句，为了向下兼容，INSHAREMODE命令仍然可以在 MySQL8.0中使用。共享锁主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用 SELECT…FORUPDATE方式获得排他锁。<br>在MySQL5.7中，SELECT.FORUPDATE语句用来显式加排他锁。如果遇到锁等待，那么session默认会等待50s，这在高并发的应用系统中，一旦出现对于热点行的争用，将会造成连接数的快速增加，甚至超过最大连接数。为了解决并发问题，在MySQL8.0中，FOR UPDATE后增加了两个选项：SKIPLOCKED和NOWAIT，使用这两个选项在一定程度上会避免这种情况。其中，NOWAIT选项发现有锁等待后会立即返回错误，不用等到锁超时后报错；某些特殊场景下，也可以使用SKIPLOCKED来跳过被锁定的行，直接更新其他行，但这样要注意是否会造成更新结果不符合预期。<br>在如表16-7所示的示例中，使用了SELECT.INSHAREMODE加锁后再更新记录，看看会出现什么情况，其中actor表的actor id字段为主键。<br>表16-7 InnoDB存储引擎的共享锁示例<br>session_1 session_2<br>mysql&gt; set autocommit &#x3D; 0; mysql&gt; set autocommit &#x3D; 0; Query OK,0rows affected(0.00 sec) QueryOK,0rows affected (0.0 sec)<br>mysql&gt; select actor id,first_name,last name from actor mysql&gt; select actor id,first_name,last_name from actor where where actor_id&#x3D;178; actor_id&#x3D; 178;<br>[actor_id|first_name|last_name actor id|first name|last_name<br>|178[LISA |MONROE |178 |LISA |MONROE|<br>1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>当前session对actor_id&#x3D;178的记录加 sharemode的共享锁：<br>mysql&gt; select actor_id,first_name,last_name from actor<br>where actor id&#x3D; 178 lock in share mode; actor_id|first_name|last_name<br>|178 |LISA |MONROE 1 row in set (0.01 sec)<br>其他session仍然可以查询记录，并也可以对该记录加share mode的共享锁：<br>mysql&gt; select actor_id,first name,lastname from actor where<br>actor_id&#x3D;178 lock in share mode; actor id|first name |last _name<br>|178 |LISA[MONROE| 1 row in set (0.01 sec)</p>
<p>≦ 296 ≧<br>278 第16章 锁问题<br>续表<br>session_1 session_2<br>当前session对锁定的记录进行更新操作，等待锁： mysql&gt;update actor set last_name &#x3D;MONROE T’where<br>actor_id&#x3D;178; 等待<br>其他session也对该记录进行更新操作，则会导致死锁退出： mysql&gt;update actor set last _name&#x3D;MONROE T where actor id&#x3D;178;<br>ERROR1213(40001):Deadlock found when trying to get lock;try restarting transaction<br>获得锁后，可以成功更新：<br>mysql&gt;update actor set last_name&#x3D;MONROE T’where actor_id&#x3D;178;<br>QueryOK,1row affected(17.67 sec)<br>Rows matched:1Changed:1Warnings:0<br>当使用SELECT..FORUPDATE加锁后再更新记录，出现如表16-8所示的情况。表16-8 InnoDB存储引擎的排他锁示例<br>session_1 session_2<br>mysql&gt; set autocommit&#x3D;0; mysql&gt; set autocommit &#x3D;0;<br>Query OK, 0 rows affcted (0.00 sec) QueryK,0owsaffcted（0.0se)<br>mysql&gt; select actor_id,firstname,lastname from actor where mysql&gt;select actoridfirstname,lastnamefrom actorwhre actor_id&#x3D;178; actor_id&#x3D;178;<br>|actor_id|first_name|last_name |actor id|first_name |last_name<br>|178 |LISA |MONROE |178 LISA |MONROE<br>1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>当前session对actor_id&#x3D;178的记录加forupdate的共享锁： mysql&gt;select actor id,firstname,lastname from actorwhere actor_id&#x3D;178 for update;<br>|actor id |first_name |last_name<br>|178 |LISA |MONROE 1 row in set (0.00 sec)<br>其他session可以查询该记录，但是不能对该记录加共享锁，会等待获得锁：<br>mysql&gt;select actoridfirstname,lastnamefromactorwhre actor_id&#x3D;178;<br>|actor_id |first_name last name<br>|178 LISA |MONROE 1 row in set (0.00 sec)<br>mysq&gt;selectactoridfirstname,astname from actorwhere<br>actor id&#x3D;178 for update; 等待</p>
<p>≦ 297 ≧<br>16.3InnoDB锁问题 279<br>续表<br>session_1 session_2<br>当前session可以对锁定的记录进行更新操作，更新后释放锁： mysql&gt;update actor set last_name &#x3D;‘MONROE T where actor_id&#x3D;178;<br>Query OK, 1 row affected (0.00 sec)<br>Rows matched:1Changed:1Warnings: 0 mysql&gt; commit;<br>Query OK, 0rows affected (0.01 sec)<br>其他session获得锁，得到其他session提交的记录：<br>mysql&gt;selectactor_id,first_name,lastname from actor where actor_id&#x3D;178 for update;<br>actorid|first_name|last name |178 [LISA |MONROET 1 row in set (9.59 sec)<br>16.3.4InnoDB行锁实现方式<br>InnoDB行锁是通过给索引上的索引项加锁来实现的，如果没有索引，InnoDB将通过隐藏的聚簇索引来对记录加锁。InnoDB行锁分为3种情形。<br>Recordlock：对索引项加锁。<br>Gaplock：对索引项之间的“间隙”、第一条记录前的“间隙”或最后一条记录后的“间隙”加锁。<br>ONext-keylock：前两种的组合，对记录及其前面的间隙加锁。<br>InnoDB这种行锁实现特点意味着：如果不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，实际效果跟表锁一样！<br>在实际应用中，要特别注意InnoDB行锁的这一特性，否则可能导致大量的锁冲突，从而影响并发性能。下面通过一些实际示例来加以说明。<br>（1）在不通过索引条件查询时，InnoDB会锁定表中的所有记录。在表16-9中的示例中，tab_no_index表开始没有索引l：<br>mysql&gt; create table tab_no_index(id int,name varchar（10)) engine&#x3D;innodb; Query ok,0 rows affected (0.15 sec)<br>mysq1&gt;insert into tabno index values（1,’1’),(2,2′),(3,3′),(4,’4’）;<br>Query ok, 4 rows affected (0.00 sec) Records:4Duplicates:0warnings:0<br>表16-9 InnoDB存储引擎的表在不使用索引时对全部记录加锁的示例<br>session_1 session_2<br>mysql&gt;set autocommit&#x3D;0; mysql&gt; set autocommit&#x3D;0; Query OK,0rows affected (0.00 sec) QueryOK,0rows affected(0.00 sec) mysql&gt; select *from tab_no_index where id&#x3D; 1; mysql&gt;select *from tab_no_index where id&#x3D;2;<br>id |name| |id|name|<br>11 1<br>1 row in set (0.00 sec) 1 rowin set(0.00 sec)</p>
<p>≦ 298 ≧<br>280 第16章 锁问题<br>续表<br>session_1 session_2<br>mysql&gt; select *from tab_no_index where id&#x3D;1 for update; id|name|<br>11 11 1 row in set (0.00 sec)<br>mysql&gt; select *from tab_no_index where id&#x3D;2 forupdate; 等待<br>在表16-9中，看起来session_1只给一行加了排他锁，但session_2在请求其他行的排他锁时，却出现了锁等待！原因是在没有索引的情况下，InnoDB会对所有记录都加锁。当给其增加一个索引后，InnoDB就只锁定了符合条件的行，如表16-10所示。<br>表16-10 InnoDB存储引擎的表在使用索引时使用行锁的示例<br>session_1 session_2<br>mysql&gt; set autocommit&#x3D;0; mysql&gt;set autocommit&#x3D;0;<br>Query OK,0rows affected (0.00 sec) Query OK,0rows affected (0.00 sec)<br>mysql&gt; select *from tab_with_index where id&#x3D; 1; mysql&gt; select *from tab_with_index where id&#x3D;2; id[name| [id|name|<br>11 11 12 12<br>1 row in set (0.00 sec) 1 row in set (0.00 sec) mysql&gt;select *from tab_with_index where id&#x3D;1 for update;<br>|id |name|<br>|1 | 1 row in set (0.00 sec)<br>mysql&gt; select *from tab_with index where id&#x3D;2 for update;<br>id name|<br>12 |2 1 row in set (0.00 sec)<br>创建tab_with_index表，id字段有普通索引l：<br>mysq1&gt; create table tab with_index(id int,name varchar(10)) engine&#x3D;innodb; Query ok,0 rows affected (0.15 sec)<br>mysq1&gt;insert into tab with_indexvalues(1,’1’),(2,’2’),(3,’3’),（4,’4’）;<br>Query ok, 4 rows affected (0.00 sec) Records:4Duplicates:0warnings:0<br>mysql&gt; alter table tab with index add index id(id);<br>Query ok,4rows affected (0.24 sec) Records:4 Duplicates:0 warnings:0<br>（2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不</p>
<p>≦ 299 ≧<br>16.3InnoDB锁问题 281<br>同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。应用设计的时候要注意这一点。<br>在如表16-11所示的示例中，表tab_with_index的id字段有索引l，name字段没有索引l：<br>mysql&gt; insert into tab with_index values(1,’4’); Query ok,1 row affected (0.o0 sec)<br>mysql&gt; select * from tab with_index where id &#x3D;1; |id |name|<br>11 11<br>14<br>2rows in set (0.00 sec)<br>表16-11 InnoDB存储引擎使用相同索引键的阻塞示例<br>session_1 session_2<br>mysql&gt; set autocommit&#x3D;0; mysql&gt; set autocommit&#x3D;0;<br>Query OK,0rows affected (0.00 sc) Query OK,Orows affected (0.00 sec) mysql&gt; select * from tab_with_index where id&#x3D;1 and name&#x3D;<br>‘1’for update:[id[name|<br>I1 |1 1 row in set (0.00 sec)<br>虽然session_2访问的是和session_1不同的记录，但是因为使用了相同的索引，所以需要等待锁：<br>mysql&gt;select *from tab_with_index where id&#x3D;1 and name<br>4for update; 等待<br>（3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。<br>在如表16-12所示的示例中，表tab_with_index的id字段有主键索引l，name字段有普通索引l： mysql&gt; alter table tab with index add index name(name);<br>Query ok,5rows affected (0.23 sec) Records:5 Duplicates:0 Warnings:0<br>表16-12 InnoDB存储引擎的表使用不同索引的阻塞示例<br>session_1 session_2<br>mysql&gt; set autocommit&#x3D;0; mysql&gt;set autocommit&#x3D;0; QueryK,0rowsafcted(0.00sec) QueryOK,0rowsaffected(0.00 sec)<br>mysql&gt; select *from tab_with_index where id&#x3D;1 for update;<br>|id name<br>|1 |1<br>[4<br>2 rows in set (0.00 sec)</p>
<p>≦ 300 ≧<br>282 第16章锁问题<br>续表<br>session_1 session_2<br>session_2使用name的索引访问记录，因为记录没有被加锁，所以可以获得锁：<br>mysql&gt; select *from tab_with_index where name &#x3D;2’for update;<br>id name[2 |2<br>1row in set (0.00 sec)<br>由于访问的记录已经被session_1锁定，所以等待获得锁： mysql&gt; select <em>from tab_with_index where name &#x3D;’4 for update;<br>（4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB也会对所有记录加锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。关于MySQL在什么情况下不使用索引的详细讨论，可以参考15.2节。<br>在下面的示例中，检索值的数据类型与索引字段不同，虽然MySQL能够进行数据类型转换，却不会使用索引，从而导致InnoDB对所有记录加锁。通过用explain检查两条SQL的执行计划，读者可以清楚地看到这一点。<br>在示例中，tab_with_index表的name字段有索引l，但是name字段是varchar类型的，如果where条件中不是和varchar类型进行比较，则会对name进行隐式的数据类型转换，从而导致索引无法使用，走了全表扫描。<br>mysql&gt; alter table tab with index add index name(name);<br>Query 0k,4 rows affected (8.06 sec) Records:4Duplicates:0warnings:0<br>mysql&gt; explain select * from tab with index where name &#x3D;1\G<br>id:1<br>select type: SIMPLE<br>table: tab with index type: ALL<br>possible keys: name<br>key: NULL key len: NULL<br>ref: NULL rows:4<br>Extra: Using where<br>1 row in set (0.00 sec)<br>mysql&gt; explain select <em>from tab with_index where name &#x3D;’1’\G<br>1.row</em><br>★★★★★业</em>★★业★★★业业★<br>id:1<br>select type: SIMPLE<br>table:tab with index type:ref<br>possible keys: name<br>key:name key_1en:23<br>ref:const rows:1<br>Extra:Using where<br>1 row in set (0.00 sec)</p>
<p>≦ 301 ≧<br>16.3InnoDB锁问题 283<br>16.3.5Next-Key锁<br>当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做间隙（GAP），InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的Next-Key锁。<br>举例来说，假如emp表中只有101条记录，其empid的值分别是1、2、、100、101， SQL语句如下：<br>Select * from emp where empid&gt; 100 for update;<br>这是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。<br>InnoDB使用Next-Key锁的目的，一方面是为了防止幻读，以满足相关隔离级别的要求，对于上面的示例，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对锁机制的影响，以及不同隔离级别下InnoDB使用Next-Key锁的情况，在后续的章节中会做进一步介绍。<br>很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。<br>还要特别说明的是，InnoDB除了通过范围条件加锁时使用Next-Key锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用Next-Key锁！<br>在如表16-13所示的示例中，假如emp表中只有101条记录，其empid的值分别是1、2、”、 100、101。<br>表16-13 InnoDB存储引l擎的Next-Key锁阻塞示例<br>session_1 session_2<br>mysql&gt; select @@tx_isolation; mysql&gt; select @@tx_isolation;<br>@@tx_isolation@@tx_isolation<br>[REPEATABLE-READ[REPEATABLE-READ<br>1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>mysql&gt;set autocommit &#x3D;0; mysql&gt;set autocommit &#x3D;0: Query OK, 0 rows affected (0.00 sec) Query OK,0 rows affected (0.00 sec) 当前session对不存在的记录加forupdate的锁：<br>mysql&gt;select *from emp where empid &#x3D;102 for update; Empty set (0.00 sec)<br>这时，如果其他session插入empid为201的记录（注意：这条记录并不存在），也会出现锁等待：<br>mysql&gt;insert into emp(empid…) values(20…); 阻塞等待<br>Session_I 执行rollback： mysql&gt;rollback;<br>Query OK,0rows affcted (13.04 sec)</p>
<p>≦ 302 ≧<br>284 第16章锁问题<br>续表<br>session_1 session_2<br>由于其他 session_1回退后释放了Next-Key 锁，当前 session可以获得锁并成功插入记录：<br>mysql&gt;insert into emp（empid…)values(201..) Query OK,1row affected（13.35sec)<br>16.3.6恢复和复制的需要，对InnoDB锁机制的影响<br>MySQL通过BINLOG记录执行成功的INSERT、UPDATE、DELETE等更新数据的SQL 语句，并由此实现MySQL数据库的恢复和主从复制（参见本书的“管理维护篇”）。MySQL5.7 支持3种日志格式，即基于语句的日志格式SBL、基于行的日志格式RBL和混合格式。它还支持4种复制模式。<br>O基于SQL语句的复制SBR：这也是MySQL最早支持的复制模式。<br>O基于行数据的复制RBR：这是MySQL5.1以后开始支持的复制模式，主要优点是支持对非安全SQL的复制。<br>混合复制模式：对安全的SQL语句采用基于SQL语句的复制模式，对于非安全的 SQL语句采用居于行的复制模式。<br>使用全局事务ID（GTIDs）的复制：主要是解决主从自动同步一致问题。<br>对基于语句日志格式（SBL）的恢复和复制而言，由于MySQL的BINLOG是按照事务提交的先后顺序记录的，因此要正确恢复或复制数据，就必须满足：在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。这已经超过了 ISO&#x2F;ANSISQL92“可重复读”隔离级别的要求，实际上是要求事务要串行化。这也是许多情况下，InnoDB要用到Next-Key锁的原因，比如在用范围条件更新记录时，无论在Read Committed或是RepeatableRead隔离级别下，InnoDB都要使用Next-Key锁，但这并不是隔离级别要求的，有关InnoDB在不同隔离级别下加锁的差异在16.3.7节还会介绍。<br>对于“insert into target <em>tab select *from source_tab where .”和“create table new_tab…select…From source_tabwhere…（CTAS）这种SQL语句，用户并没有对source</em>.tab 做任何更新操作，但MySQL对这种SQL语句做了特别处理。先来看表16-14中的示例。<br>表16-14 CTAS操作给原表加锁的示例<br>session_1 session_2<br>mysql&gt; set autocommit &#x3D;0: mysql&gt; set autocommit&#x3D;0; Query OK, 0 rows affected (0.00 sec) Query OK,0 rows affected (0.00 sec)<br>mysql→&gt; select *from target_tab; mysql&gt;select *from target_tab; Empty set (0.00 sec) Empty set (0.00 sec)<br>mysql&gt; select *from source _tab where name &#x3D;’1’; mysql&gt;select *from source tab where name&#x3D;’1’;<br>|d1|name|d2|[d1|name|d2|<br>4|1 4|1 511 511<br>6|1 6|1 711 711 811 8|1<br>5rows in set (0.00 sec) 5 rows in set (0.00 sec)</p>
<p>≦ 303 ≧<br>16.3InnoDB锁问题 285<br>续表<br>session_1 session_2<br>mysql&gt; insert into target tab select dl,name from source_tab where name&#x3D;’1’;<br>Query OK,5rows affected (0.00 sec) Records:5Duplicates:OWarnings:0<br>mysql&gt;update source _tab set name &#x3D;1′where name &#x3D;’8’; 等待<br>commit;<br>返回结果 commit;<br>在上面的示例中，只是简单地读source_tab表的数据，相当于执行一个普通的SELECT 语句，用一致性读就可以了。Oracle正是这么做的，它通过MVCC技术实现的多版本数据来实现一致性读，不需要给source_tab加任何锁。我们知道InnoDB也实现了多版本数据，对普通的SELECT一致性读，也不需要加任何锁；但这里InnoDB却给source_tab加了共享锁，并没有使用多版本数据一致性读技术！<br>MySQL为什么要这么做呢？其原因还是为了保证恢复和复制的正确性。因为在不加锁的情况下，如果在上述语句执行过程中，其他事务对source_tab做了更新操作，就可能导致数据恢复的结果错误。为了演示这一点，我们再重复一下前面的示例，不同的是在session_1执行事务前，先将系统变量innodb_locks_unsafe_for_binlog的值设置为“on”（其默认值为off），具体结果如表16-15所示。<br>表16-15 CTAS操作不给原表加锁带来的安全问题示例<br>session_1 session_2<br>mysql&gt; set autocommit &#x3D;0;<br>Query OK,0 rows affected (0.00 sec) mysql&gt; set autocommit &#x3D;0;<br>Query OK, 0 rows affected (0.00 sec)<br>mysql&gt;set innodb_locks_unsafe_for_binlog&#x3D;on’<br>Query OK, 0 rows affected (0.00 sec) mysql&gt; select *from target _tab; mysql&gt;select *from target_tab; Empty set (0.00 sec) Empty set (0.00 sec)<br>mysql&gt; select *from source _tab where name &#x3D;’1’:<br>mysql&gt;select *from source tab where name &#x3D;’1’;<br>dl |name|d2<br>dl |name|d2<br>1<br>5 rows in set (0.00 sec)<br>5 rows in set (0.00 sec)<br>mysql&gt; insert into target tab select dl,name from source _tab where name &#x3D;’1’;<br>Query OK,5rows affected(0.00 sec) Records:5Duplicates:0Warnings:0</p>
<p>≦ 304 ≧<br>286 第16章 锁问题<br>续表<br>session_1 session_2<br>session_1未提交，可以对session_1的select的记录进行更新操作：<br>mysql&gt;update source_tab set name&#x3D;8′where name&#x3D;1’; QueryOK,5rows affected (0.00 sec)<br>Rowsmatched:5Changed:5Warnings:0<br>mysql&gt; select *from source_tab where name&#x3D;8’; |d1|name|d2<br>4|8 518 618 718 818<br>5 rows in set(0.00 sec)<br>更新操作先提交 mysql&gt; commit;<br>Query OK,0rows affcted (0.05 se)<br>插入操作后提交： mysql&gt; commit;<br>Query OK,0 rows affected (0.07 sec)<br>mysql&gt; select *from t1 where name &#x3D;’1’;<br>此时查看数据，target_tab中可以插入source_tab更新前 Empty set (0.00 sec) 的结果，这符合应用逻辑：<br>mysql&gt; select *from source_tab where name&#x3D;8”; mysql&gt; select *from source_tab where name &#x3D;”8”; |d1|name|d2| |d1|name|d2|<br>418 11 11<br>418<br>518 11 11<br>518<br>618 11<br>618<br>718 11 11 818 11 718 1|<br>818<br>5 rows in set (0.00 sec) 5 rows in set (0.00 sec) mysql&gt; select *from target_tab;<br>mysql&gt; select * from target _tab;<br>lid |name| |id |name|<br>14 |1.00<br>[1.00<br>15 |1.00 14<br>15[1.00<br>16 11.00<br>16 |1.00<br>17 11.00<br>17[1.001<br>18 |1.00 18[1.00|<br>5 rows in set (0.00 sec) 5rows in set (0.00 sec) 从上可见，设置系统变量innodb_locks_unsafe_for_binlog的值为“on”后，InnoDB不再<br>对source_tab加锁，结果也符合应用逻辑，但是如果分析BINLOG的内容： SET TIMESTAMP&#x3D;1169175130;<br>BEGIN;#at274</p>
<p>≦ 305 ≧<br>16.3InnoDB锁问题 287<br>#070119 10:51:57 server id 1 end log pos 105 Query  thread id&#x3D;1 execI time&#x3D;0 error_code&#x3D;0<br>SET TIMESTAMP&#x3D;1169175117；<br>update source tab set name &#x3D; ‘8’ where name &#x3D; ‘1’;#at379<br>#070119 10:52:10 server id 1end 1og pos 406 xid&#x3D;5<br>COMMIT;#at406<br>#070119 10:52:14 server id 1 end 1og pos 474 Query thread id&#x3D;2 exec_time&#x3D;0 error code&#x3D;0<br>SET TIMESTAMP&#x3D;1169175134;<br>BEGIN;#at474<br>#070119 10:51:29 server id 1 end log pos 119 Query thread id&#x3D;2 exec time&#x3D;0 error code&#x3D;0<br>SET TIMESTAMP&#x3D;1169175089;<br>insert into target tab select dl,name from source tab where name &#x3D; ‘1’;#at593<br>#070119 10:52:14 server id 1 end 1og pos 620 COMMIT ;<br>可以发现，在BINLOG中，更新操作的位置在INSERT..SELECT之前，如果使用这个 BINLOG进行数据库恢复，恢复的结果与实际的应用逻辑不符；如果进行复制，就会导致主从数据库不一致！<br>通过上面的示例，读者就不难理解为什么MySQL在处理“Insertinto target_tab select* from source_tab where..”和“createtable new_tab…select…Fromsource_tabwhere ..”时要给source_tab加锁，而不是使用对并发影响最小的多版本数据来实现一致性读。还要特别说明的是，如果上述语句的SELECT是范围条件，InnoDB还会给源表加Next-Key锁。<br>因此，INSERT…SELECT..和CREATETABLE…SELECT…语句，可能会阻止对源表的并发更新。如果查询比较复杂，会造成严重的性能问题，读者在应用中应尽量避免使用。实际上，MySQL将这种SQL称为不确定（non-deterministic）的SQL，属于“UnsafeSQL”，不推荐使用。<br>如果应用中一定要用这种SQL来实现业务逻辑，又不希望对源表的并发更新产生影响，可以采取以下3种措施。<br>O采取上面示例中的做法，将innodb_locks_unsafe_for_binlog的值设置为“on”，强制 MySQL使用多版本数据一致性读。但付出的代价是可能无法用BINLOG正确地恢复或复制数据，因此，不推荐使用这种方式。<br>O通过使用“select*from source_tab…Into outfile”和“load datainfile..”语句组合来间接实现，采用这种方式MySQL不会给source_tab加锁。<br>O使用基于行的BINLOG格式和基于行数据的复制。<br>16.3.7InnoDB在不同隔离级别下的一致性读及锁的差异<br>前面讲过，锁和多版本数据是InnoDB实现一致性读和ISO&#x2F;ANSISQL92隔离级别的手段，因此，在不同的隔离级别下，InnoDB处理SQL时采用的一致性读策略和需要的锁是不同的。同时，数据恢复和复制机制的特点，也对一些SQL的一致性读策略和锁策略有很大影响。将这些特性归纳成如表16-16所示的内容，以便读者查阅。</p>
<p>≦ 306 ≧<br>288 第16章锁问题<br>表16-16 InnoDB存储引擎中不同SQL在不同隔离级别下锁的比较一致性 隔离级别<br>读和锁 Read<br>Read Commited Repeatable Read Serializable<br>Uncommited<br>SQL<br>SQL 条件<br>相等 none locks consisten read&#x2F;none lock consisten read&#x2F;none lock share locks<br>select<br>范围 none locks consistenread&#x2F;none lock consistenread&#x2F;none lock share next-key<br>exclusive locks exclusive locks exclusive locks<br>update 相等 exclusivenext-key exclusive next-key exclusive locks exclusive next-key<br>范围 exclusive next-key<br>Insert N&#x2F;A exclusive locks exclusive locks exclusive locks exclusive locks<br>无键冲突 exclusive locks exclusive locks exclusive locks exclusive locks<br>replace exclusive next-key<br>键冲突 exclusivenext-key exclusive next-key exclusive next-key 相等 exclusive locks exclusive locks<br>delete exclusive locks exclusive locks<br>范围 exclusivenext-keyexclusivenext-key exclusive next-key exclusivenext-key<br>Select…from 相等 share locks share locks share locks share locks..Lock in<br>share mode 范围 share locks share locks share next-key sharenext-key Select*from 相等 exclusive locks exclusive locks exclusive locks exclusive locks…For update 范围 exclusive locks share locks exclusive next-key exclusive next-key<br>innodb locks unsafe<br>Insert into.. share next-key share next-key share next-key share next-key Select.. for binlog-off<br>(指源表锁） innodb locks unsafe none locks consisten read&#x2F;none lock consistenread&#x2F;none lock share next-key<br>for binlog-on<br>create table…_for_binlog&#x3D;off sharenext-key share next-key share next-key Select..<br>（指源表锁） innodb locksunsafe none locks consistenread&#x2F;none lock consistenread&#x2F;none lock share next-key<br>for binlog-on<br>从表16-16中可以看出，对于许多SQL，隔离级别越高，InnoDB给记录集加的锁就越严格（尤其是使用范围条件的时候），产生锁冲突的可能性也就越高，从而对并发性事务处理性能的影响也就越大。因此，在应用中，应该尽量使用较低的隔离级别，以减少锁争用的机率。实际上，通过优化事务逻辑，大部分应用使用ReadCommitted隔离级别就足够了。对于一些确实需要更高隔离级别的事务，可以通过在程序中执行SETSESSIONTRANSACTION ISOLATIONLEVELREPEATABLEREAD或SETSESSIONTRANSACTIONISOLATION<br>LEVELSERIALIZABLE动态改变隔离级别的方式来满足需求。 16.3.8什么时候使用表锁<br>对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们选择 InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁。<br>第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。<br>第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这</p>
<p>≦ 307 ≧<br>16.3InnoDB锁问题 289<br>种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁，减少数据库因事务回滚带来的开销。<br>当然，应用中这两种事务不能太多，否则，就应该考虑使用MyISAM表了。在InnoDB 下，使用表锁要注意以下两点。<br>（1）使用LOCKTABLES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由 InnoDB存储引擎层管理的，而是由其上一层一MySQL Server负责的，仅当autocommit&#x3D;0、 innodb_table_locks&#x3D;1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL Server 也才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则， InnoDB将无法自动检测并处理这种死锁。有关死锁，16.3.9节还会继续讨论。<br>（2）在用LOCKTABLES对InnoDB表加锁时要注意，要将AUTOCOMMIT设为O，否则MySQL不会给表加锁；事务结束前，不要用UNLOCKTABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCKTABLES加的表级锁，必须用UNLOCKTABLES释放表锁。正确的方式如下所示。<br>例如，如果需要写表t1并从表t读，可以按如下做： SET AUTOCOMMIT&#x3D;O;<br>LOCK TABLES t1 WRITE, t2 READ,<br>[do something with tables tl and t2 here]; COMMIT;<br>UNLOCK TABLES;<br>16.3.9关于死锁<br>上文讲过，MyISAM表锁是deadlockfree的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了在InnoDB中发生死锁是可能的。表16-17就是一个发生死锁的示例。<br>表16-17 InnoDB存储引擎中的死锁示例<br>session_1 session_2<br>mysql&gt; set autocommit &#x3D; 0; mysql&gt; set autocommit &#x3D;0; Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec)<br>mysql&gt;select *from table_1 where where id&#x3D;1 forupdate; mysql&gt; select * from table_2 where id&#x3D;1 for update; 做一些其他处理<br>select *from table_2where id&#x3D;1 for update; 做一些其他处理因session_2已取得排他锁，等待<br>mysql&gt; select *from table_1 where where id&#x3D;1 forupdate; 死锁<br>在上面的示例中，两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。<br>发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodblockwaittimeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。通过</p>
<p>≦ 308 ≧<br>290 第16章锁问题设置合适的锁等待超时阈值，可以避免这种情况发生。<br>通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的SQL语句，绝大部分死锁都可以避免。下面通过几个实例来介绍几种避免死锁的常用方法。<br>（1）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。在表16-18所示的示例中，由于两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可以避免。<br>表16-18 InnoDB存储引擎中表顺序造成的死锁示例<br>session_1 session_2<br>mysql&gt; set autocommit&#x3D;0; mysql&gt; set autocommit&#x3D;0;<br>Query OK,0rowsaffcted (0.00 se) Query OK,0rows affected (0.00 sec)<br>mysql&gt; select first name,last _name from actor where actor id &#x3D;1 for update;<br>first_name last_name<br>[PENELOPE|GUINESS 1 row in set(0.00 sec)<br>mysql&gt; insert into country (country_id,country) values(110,Test’);<br>Query K,1 row affcted (0.00 sec)<br>mysql&gt;insert into country (country _id,country) values（110,Test’); 等待<br>mysql&gt; select first name,last_name from actor where actor_id&#x3D; 1 for update;<br>|first_name last_name<br>|PENELOPE|GUINESS 1 row in set (0.00 sec)<br>mysql&gt; insert into country (country_id,country) values(110,Test’);<br>ERROR1213(40001):Deadlock found when trying to get lock; try restarting transaction<br>（2）在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。表16-19是一个数据操作顺序不一致而造成死锁的示例。<br>表16-19 InnoDB存储引擎中表数据操作顺序不一致造成的死锁示例<br>session_1 session_2<br>mysql&gt;set autocommit&#x3D;0; mysql&gt; set autocommit&#x3D;0; Query OK, 0 rows affected (0.00 sec) Query OK,0 rows affected (0.00 sec)<br>mysql&gt; select first_name,last name from actor where actor id &#x3D; 1 for update;<br>|first_name last name<br>|PENELOPE|GUINESS 1 row in set (0.00 sec)</p>
<p>≦ 309 ≧<br>16.3InnoDB锁问题 291<br>续表<br>session_1 session 2<br>mysql&gt; select first name,last_name from actor where<br>“actor_id&#x3D;3 for update; first name|last name| |ED CHASE 1 row in set (0.00 sec)<br>mysql&gt;select first_name,last name from actor where actor_id&#x3D;<br>3 for update; 等待<br>mysql&gt; select first_name,last_name from actor where actor id&#x3D; 1 for update;<br>ERROR 1213(40001):Deadlock found when trying to get lock;try restarting transaction<br>mysql&gt; select firstname,lastname from actor where actor id&#x3D; 3for update;<br>|first_name|last name<br>|ED |CHASE I row in set (4.71 sec)<br>（3）在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。具体演示可参见16.3.3节中的示例。<br>（4）前面讲过，在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT..FORUPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插人一条新记录，如果两个线程都这么做，就会出，现死锁。这种情况下，将隔离级别改成READCOMMITTED，就可避免问题，如表16-20 所示。<br>表16-20 InnoDB存储引擎中隔离级别引起的死锁示例1<br>session_1 session_2<br>mysql&gt; select @@tx_isolation; mysql&gt; select @@tx_isolation;<br>@@tx_isolation@@tx_isolation<br>|REPEATABLE-READ |REPEATABLE-READ<br>1 row in set(0.00 sec) 1 row in set (0.00 sec)<br>mysql&gt; set autocommit&#x3D; 0: mysql&gt; set autocommit &#x3D; 0; Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) 当前session对不存在的记录加forupdate的锁：<br>mysql&gt; select actor id,firstname,last_name from actor where<br>actor_id &#x3D;201 for update; Empty set (0.00 sec)</p>
<p>≦ 310 ≧<br>292 第16章锁问题<br>续表<br>session_1 session_2<br>其他session也可以对不存在的记录加forupdate的锁： mysql&gt; select actor id,first_name,last_name from actor<br>where actor id&#x3D;201 forupdate; Empty set (0.00 sec)<br>因为其他session也对该记录加了锁，所以当前的插入会等待： mysql&gt; insert into actor （actor id,first name，last _name)<br>values(201,Lisa’,Tom); 等待<br>因为其他session已经对记录进行了更新，这时候再插入记录就会提示死锁并退出：<br>mysql&gt;insert into actor (actor id,first name,last_name)values(201,Lisa’,Tom):<br>ERROR 1213（40001):Deadlock found when trying to get lock;try restarting transaction<br>由于其他session已经退出，当前 session可以获得锁并成功插入记录：<br>mysql&gt;insert into actor (actor id,first name,last_name) values(201,LisaTom); Query OK,1 row affected(13.35 sec)<br>（5）当隔离级别为READCOMMITTED时，如果两个线程都先执行SELECT.FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插人记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第一个线程提交后，第二个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第三个线程又来申请排他锁，也会出现死锁。<br>对于这种情况，可以直接做插人操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁，如表16-21所示。<br>表16-21 InnoDB存储引擎中隔离级别引起的死锁示例2<br>session_1 session_2 session_3<br>mysql&gt;select @@tx_isolation; mysql&gt; select @@tx_isolation; mysql&gt; select @@tx_isolation;<br>@@tx_isolation@@tx_isolation@@tx_isolation<br>[READ-COMMITTED READ-COMMITTED[READ-COMMITTED<br>1 row in set (0.00 sec) 1 row in set (0.00 sec) 1 row in set (0.00 sec)<br>mysql&gt; set autocommit&#x3D;0; mysql&gt; set autocommit&#x3D;0: mysql&gt;set autocommit&#x3D;0; QueryOK,0rows affected（0.01 sec) Query OK,0rows affected(0.01 sec) Query OK,0rowsaffected (0.01 sec)<br>由于记录不存在，session_2也可以获得<br>session_1获得forupdate的共享锁： for update的共享锁： mysql&gt; select actor_id,frst<br>name,lastname from actor where actor_id mysql&gt; select aetor_id,first<br>name, last name from actor where<br>&#x3D;201 for update; actor_id&#x3D;201 for update; Empty set(0.00 sec)<br>Empty set (0.00 sec)</p>
<p>≦ 311 ≧<br>16.3InnoDB锁问题 293<br>续表<br>session_1 session_2 session_3<br>session_1可以成功插入记录： mysql&gt; insert into actor (actor<br>idfirst name,last name) values(201,Lisa’,Tom);<br>Query OK,1row affected(0.00 sec)<br>session_2插入申请等待获得锁： mysql&gt;insert into actor (actor id,firstame,astameal<br>(201,Lisa’,Tom’); 等待<br>session_1成功提交： mysql&gt;commit;<br>Query OK,0rows affected (0.04 sec)<br>session_2获得锁，发现插入记录主键重，这个时候抛出了异常，但是并没有释放共享锁：<br>mysql&gt;insert into actor (actor id,irstamelastnamevals(201,Lisa’,Tom’);<br>ERROR 1062 (23000):Duplicate entry 201′forkey’PRIMARY”<br>session_3申请获得共享锁，因为 session2已经锁定该记录，所以 session_3需要等待：<br>mysqselect actorid,firstname,<br>last name from actor where actor_id&#x3D;201<br>for update; 等待<br>这个时候，如果session_2直接对记录进行更新操作，则会抛出死锁的异常： mysql&gt; update actor set last_name&#x3D;Lan’ where actor _id&#x3D;201;<br>ERROR 1213(40001):Deadlock found when trying to get lock; try restarting transaction<br>session_2释放锁后，session_3获得锁： mysql&gt; select first_name,last name from actor where actor id &#x3D; 201 for update;<br>first_name |last_name|<br>Lisa[Tom 1 row in set (31.12 sec)<br>尽管通过上面介绍的设计和SQL优化等措施，可以大大减少死锁，但死锁很难完全避免。因此，在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯。<br>如果出现死锁，可以用SHOWINNODBSTATUS命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引引发死锁的SQL语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。下面是一</p>
<p>≦ 312 ≧<br>294 第16章锁问题<br>段SHOWINNODBSTATUS输出的示例： mysql&gt; show innodb status \G<br>LATEST DETECTED DEADLOCK 070710 14:05:16<br><em><strong>(1) TRANSACTION：<br>TRANSACTION 0 117470078, ACTIVE 117 sec, process no 1468, oS thread id 1197328736 inserting mysql tables in use 1, locked 1<br>LOCK WAIT 5 1ock struct(s),heap size 1216<br>MySQL thread id 7521657,query id 673468054 1ocalhost root update<br>insert into country (country id,country) values(110,Test’)</strong></em>(2)TRANSACTION:<br>TRANSACTION 0 117470079, ACTIVE 39 sec, process no 1468,Os thread id 1164048736 starting index read, thread declared inside InnoDB 500<br>mysql tables in use 1, 1ocked 1<br>4 lock struct(s), heap size 1216,undo log entries 1<br>MySQL thread id 7521664, query id 673468058 1oca1host root statistics select first name,last name from actor where actor id &#x3D; 1 for update**(2)HOLDS THE LOCK(S）:<br>#**(2) WAITING FOR THIS LOCK TO BE GRANTED:**WE ROLL BACK TRANSACTION (1)<br>16.4小结<br>本章重点介绍了MySQL中MyISAM表级锁和InnoDB行级锁的实现特点，并讨论了两种存储引擎经常遇到的锁问题和解决办法。<br>对于MyISAM的表锁，主要讨论了以下几点。<br>（1）共享读锁（S）之间是兼容的，但共享读锁（S）与排他写锁（X）之间，以及排他写锁（X）之间是互斥的，也就是说读和写是串行的。<br>（2）在一定条件下，MyISAM允许查询和插入并发执行，可以利用这一点来解决应用中对同一表查询和插人的锁争用问题。<br>（3）MyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定 LOW_PRIORITY选项来调节读写锁的争用。<br>（4）由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，MyISAM 表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。<br>对于InnoDB表，本章主要讨论了以下几个内容。<br>OInnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会对所有数据加锁。<br>O介绍了InnoDBNext-Key锁机制，以及InnoDB使用Next-Key锁的原因。在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。<br>MySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。</p>
<p>≦ 313 ≧<br>16.4小结 295<br>锁冲突甚至死锁很难完全避免。<br>在了解InnoDB锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括以下几项：<br>尽量使用较低的隔离级别；<br>精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会；选择合理的事务大小，小事务发生锁冲突的概率也更小；<br>给记录集显式加锁时，最好一次性请求足够级别的锁。比如要修改数据，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁；<br>不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会；<br>○尽量用相等的条件访问数据，这样可以避免Next-Key锁对并发插入的影响；不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁；<br>○对于一些特定的事务，可以使用表锁来提高处理速度或减少发生死锁的概率。</p>
<p>≦ 314 ≧<br>第17章 优化MySQLServer<br>MySQL是一个可高度定制化的数据库系统，提供了很多可配置的参数。除非是做简单测试，我们一般都需要根据应用特性和硬件情况对MySQL做配置优化。本章在简单说明<br>MySQL体系结构和内部机制的基础上，着重介绍MySQLServer的性能优化和调整。 17.1MySQL体系结构概览<br>MySQL实例由一组后台线程、一些内存块和若干服务线程组成，如图17-1所示。<br>Thread cache 单个线程占用的buffer<br>Query cache read buffer size MySQL Server Layer<br>sort buffer size<br>primary Second key &amp;data index&amp;data ib logfileo testl.ibd test2.ibd ib_logfilel<br>rollback segment<br>innodbdictionary ib logfile3<br>System Tablespace User Tablespace Innodblog file<br>图17-1MySQL系统结构<br>在默认情况下，MySQL有7组后台线程，分别是1个主线程、4组IO线程、1个锁线程和1个错误监控线程。MySQL5.5和MySQL5.6之后又分别新增了一个purge线程和一个page cleaner线程。这些后台线程的主要功能如下。</p>
<p>≦ 315 ≧<br>17.1MySQL体系结构概览 297<br>master thread:主要负责将脏缓存页刷新到数据文件，执行purge操作，触发检查点，合并插入缓冲区等。<br>Oinsertbufferthread：主要负责插入缓冲区的合并操作。 Oread thread：负责数据库读取操作，可配置多个读线程。 Owritethread：负责数据库写操作，可配置多个写线程。 Olog thread：用于将重做日志刷新到logfile中。<br>Opurge thread:MySQL5.5之后用单独的purge thread执行purge操作。<br>Opage cleaner thread:MySQL5.6之后，用来执行bufferpool中脏页的flush操作。 Olockthread：负责锁控制和死锁检测等。<br>错误监控线程：主要负责错误监控和错误处理。<br>我们可以通过showengineinnodb status命令来查看这些线程的状态： show engine innodb status\G;<br>2018-10-10 16:22:39 0X7f6f18355700 INNODB MONITOR OUTPUT Per second averages calculated from the last 3 seconds BACKGROUND THREAD<br>srv_master_thread 1oops: 3424 srv_active,0 srv_shutdown,6297767 srv_id1e<br>srv_master_thread 1og flush and writes: 5955867 SEMAPHORES<br>OS WAIT ARRAY INFo: reservation count 806944 OS WAIT ARRAY INFO: signal count 844536<br>RW-shared spins 0, rounds 338076,0s waits 14683 RW-excl spins 0, rounds 1522728, 0s waits 7608 RW-sx spins 26111, rounds 672324,0s waits 4511<br>Spin rounds per wait: 338076.00 RW-shared, 1522728.00 RW-exc1,25.75 RW-sx LATEST FOREIGN KEY ERROR<br>2018-09-29 16:56:21 0x7f6f20135700 Error in foreign key constraint of table sakila&#x2F;#sql-6efd 2d3: foreign key fk payment_customer(customer_id) references customer(id):<br>Cannot resolve column name close to: LATEST DETECTED DEADLOCK<br>2018-10-09 11:39:36 0x7f6f20072700***(1) TRANSACTION:<br>TRANSACTIoN 2110061, ACTIVE 0 sec starting index read<br>##*WE ROLL BACK TRANSACTION (1) TRANSACTIONS<br>Trx id counter 2255786<br>Purge done for trx’s n:o&lt;2255762 undo n:o&lt;0 state: running but idle History list length 75<br>LIST OF TRANSACTIONS FOR EACH SESSION:<br>–TRANSACTION 421596340903536,not started<br>0lock struct(s),heap size 1136,0 row lock(s)-TRANSACTI0N 421596340901712, not started<br>0lock struct(s）,heap size 1136,0 row lock(s)<br>—TRANSACTIoN 421596340902624, not started 0lock struct(s）,heap size 1136,0 row lock（s) FILE I&#x2F;O</p>
<p>≦ 316 ≧<br>298 第17章优化MySQLServer<br>1&#x2F;o thread o state: waiting for completed aio requests (insert buffer thread)<br>I&#x2F;o thread 1 state: waiting for completed aio requests (log thread) I&#x2F;o thread 2 state:waiting for completed aio requests (read thread)<br>I&#x2F;o thread 9 state: waiting for completed aio requests (read thread) I&#x2F;o thread 10 state: waiting for completed aio requests (write thread)<br>1&#x2F;o thread 17 state:waiting for completed aio requests (write thread)<br>Pending normal aio reads:[0,0,0,0,0,0,0,o],aiowrites:[0,0,0,0,0,0,0, 0] ibuf aio reads:,log i&#x2F;o’s:, sync i&#x2F;o’s:<br>Pending flushes （fsync) 1og:O;buffer pool:0<br>25172 0s file reads,734032 os file writes, 522428 0s fsyncs 0.00 reads&#x2F;s, 0 avg bytes&#x2F;read, 0.00 writes&#x2F;s, 0.00 fsyncs&#x2F;s<br>END OF INNODB MONITOR OUTPUT<br>17.2MySQL内存管理及优化<br>内存是影响数据库性能的重要资源，也是MySQL性能优化的一个重要方面。本节主要<br>介绍MyISAM和InnoDB的内存管理及优化。 17.2.1内存优化原则<br>在调整MySQL内存分配时，要注意以下3点。<br>O将尽量多的内存分配给MySQL做缓存，但要给操作系统和其他程序的运行预留足够的内存，否则如果产生SWAP页交换，将严重影响系统性能。<br>OMyISAM的数据文件读取依赖于操作系统自身的IO缓存，因此，如果有MyISAM 表，就要预留更多的内存给操作系统做IO缓存。<br>排序区、连接区等缓存是分配给每个数据库会话（session）专用的，其默认值的设置要根据最大连接数合理分配，如果设置太大，不但浪费内存资源，而且在并发连接较高时会导致物理内存耗尽。<br>17.2.2MyISAM内存优化<br>MyISAM存储引擎使用keybuffer缓存索引块，以加速MyISAM索引的读写速度。对于 MyISAM表的数据块，MySQL没有特别的缓存机制，完全依赖于操作系统的IO缓存。<br>1.key_buffer_size设置<br>key_buffer_size决定MyISAM索引块缓存区的大小，它直接影响MyISAM表的存取效率。可以在MySQL的参数文件中设置key_buffer_size的值，对于一般MyISAM数据库，建议至<br>少将1&#x2F;4可用内存分配给key_buffer_size： Key_buffer_size &#x3D;4G<br>可以通过检查key_read_requests、key_reads、key_write_requests和key_writes等MySQL 状态变量来评估索引缓存的效率。一般来说，索引块物理读比率key_reads&#x2F;key_read_requests 应小于0.01。索引块写比率key_writes&#x2F;key_write_requests也应尽可能小，但这与应用特点有</p>
<p>≦ 317 ≧<br>17.2MySQL内存管理及优化 299<br>关，对于更新和删除操作特别多的应用，key_writes／key_write_requests可能会接近1，而对于每次更新很多行记录的应用，key_writes&#x2F;key_write_requests就会比较小。<br>除通过索引块的物理读写比率衡量keybuffer的效率外，我们也可以通过评估keybuffer 的使用率来判断索引缓存设置是否合理。keybuffer使用率计算公式如下：<br>1 -((key_blocks_unused xkey_cache_block_size)&#x2F;key_buffer_size)<br>一般来说，使用率在80%左右比较合适，大于80%，可能因索引缓存不足而导致性能下降；小于80%，会导致内存浪费。<br>2.使用多个索引缓存<br>MySQL通过各session共享的keybuffer提高了MyISAM索引存取的性能，但它并不能消除session间对keybuffer的竞争。比如，一个 session如果对某个很大的索引进行扫描，就可能将其他的索引数据块挤出索引缓存区，而这些索引块可能是其他session要用的热数据。为减少session间对keybuffer的竞争，MySQL从5.1版本开始引入了多索引缓存的机制，从而可以将不同表的索引缓存到不同的keybuffer中。<br>可以通过下述命令创建新的keybuffer：<br>mysql&gt; set global hot cache.key_buffer_size&#x3D;128*1024; Query ok,0 rows affected (o.o1 sec)<br>其中，hot_cache是新建索引缓存的名称，global关键字表示新建的缓存对每一个新的连接都有效。<br>创建的索引缓存可以使用以下命令删除：<br>mysql&gt; set global hot_ cache.key buffer_size&#x3D;0;<br>Query ok,O rows affected (o.oo sec) 但我们不能删除默认的key_buffer：<br>mysql&gt; show variables like ‘key buffer_size’;<br>Variablename 1 value |key _buffer_size | 8388600 1 row in set (o.o0 sec)<br>mysql&gt; set global key buffer_size&#x3D;0;<br>Query ok,0rows affected, 1 warning (0.o0 sec) mysql&gt; show warnings;<br>I Level Icode l Message<br>I warning | 1438 | cannot drop default keycache 1row in set (0.01 sec)<br>在默认情况下，MySQL将使用默认keybuffer缓存MyISAM表的索引I，我们可以用cache index命令指定表的索引缓存：<br>mysql&gt; cache index sales,sales2 in hot_cache;<br>Table Msg.type Msg_text1<br>sakila.salesl assign to _keycache status OK sakila.sales2 I assign_to keycache status<br>2rows in set (0.04 sec)</p>
<p>≦ 318 ≧<br>300 第17章优化MySQLServer<br>除上述通过命令动态创建并分配辅助索引缓存外，更常见的做法是通过配置文件在<br>MySQL启动时自动创建并加载索引缓存： key_buffer size &#x3D; 4G<br>hot cache.key buffer_size &#x3D;2G cold cache.key buffer size &#x3D; 1G<br>init_file&#x3D;&#x2F;path&#x2F;to&#x2F;data-directory&#x2F;mysqld init.sql<br>在mysqld_init.sql中，可以通过cacheindex命令分配索引缓存，并用loadindexintocache 命令来进行索引预加载：<br>cache index sales in hot cache; cache index sales2 in cold cache; load index into cache sales, sales2;<br>3.调整“中点插入策略”<br>在默认情况下，MySQL使用简单的LRU（LeastRecentlyUsed）策略来选择要淘汰的索引数据块。但这种算法不是很精细，在某些情况下会导致真正的热块被淘汰。<br>如果出现这种情况，除了使用上面介绍的多个索引缓存机制外，还可以利用中点插入策略（MidpointInsertionStrategy）来优化索引引块淘汰算法。所谓“中点插入策略”，是对简单 LRU淘汰算法的改进，它将LRU链分成两部分：hot子表和warm子表，当一个索引块读人内存时，先被放到LRU链表的“中点”，即warm子表的尾部，当达到一定的命中次数后，该索引块会被晋升到hot子表的尾部；此后，该数据块在hot子表流转，如果其到达hot子表的头部并超过一定时间，它将由hot子表的头部降级到warm子表的头部；当需要淘汰索引块时，缓存管理程序会选择优先淘汰warm表头部的内存块。不难理解，这种算法能够避免偶尔被访问的索引块将访问频繁的热块淘汰。<br>可以通过调节key_cache_division_limit来控制多大比例的缓存用做warm子表， key_cache_division_limit的默认值是100，意思是全部缓存块都放在warm子表，其实也就是不启用“中点插入策略”。如果希望将大致30%的缓存用来cache最热的索引块，可以对 key_cache_division_limit做如下设置：<br>Set global key_cache _division_limit &#x3D; 70<br>Set global hot cache. key cache division_limit &#x3D; 70;<br>除调节warm子表的比例外，还可以通过key_cache_age_threshold控制数据块由hot子表向warm子表降级的时间，值越小，数据块将越快被降级。对于有N个块的索引缓存来说，如果一个在hot子表头部的索引引块，在最后Nxkey_cache_age_threshold&#x2F;100次缓存命准内未被访问过，就会被降级到warm子表。<br>4.调整read_buffer_size和read_rnd_buffer_size<br>如果需要经常顺序扫描MyISAM表，可以通过增大read_buffer_size的值来改善性能。但需要注意的是，read_buffer_size是每个session独占的，如果默认值太大，就会造成内存浪费，甚至导致物理内存耗尽。<br>对于需要做排序的MyISAM表查询，如带有orderby子句的SQL，适当增大read_rmd buffer_size的值，也可以改善此类SQL的性能。但同样要注意的是，read_rnd_buffer_size也是按session分配的，默认值不能设置得太大。</p>
<p>≦ 319 ≧<br>17.2MySQL内存管理及优化 301<br>17.2.3InnoDB内存优化<br>InnoDB的缓存机制与MyISAM不尽相同，本节重点介绍其缓存内部机制和优化方法。 1.InnoDB缓存机制<br>InnoDB用一块内存区做IO缓存池，该缓存池不仅用来缓存InnoDB的索引块，而且也用来缓存InnoDB的数据块，这一点与MyISAM不同。<br>在内部，InnoDB缓存池逻辑上由free list、flush list和LRU list组成。顾名思义，free list 是空闲缓存块列表，flushlist是需要刷新到磁盘的缓存块列表，而LRUlist是InnoDB正在使用的缓存块，它是InnoDBbufferpool的核心。<br>InnoDB使用的LRU算法与MyISAM的“中点插入策略”LRU算法很类似，大致原理是：将LRUlist分为youngsublist和oldsublist，数据从磁盘读入时，会将该缓存块插人到LRUlist 的“中点”，即oldsublist的头部；经过一定时间的访问（由innodb_old_blocks_time系统参数决定），该数据块将会由old sublist转移到young sublist的头部，也就是整个LRU list的头部；随着时间的推移，young sublist和oldsublist中较少被访问的缓存块将从各自链表的头部逐渐向尾部移动；需要淘汰数据块时，优先从链表尾部淘汰。这种设计同样是为了防止偶尔被访问的索引块将访问频繁的热块淘汰。<br>脏页的刷新存在于FLUSHlist和LRUlist这两个链表，LRU上也存在可以刷新的脏页，这里是直接可以刷新的，默认BP（INNODB_BUFFER_POOL）中不存在可用的数据页的时候，会扫描LRUlist尾部的innodb_Iru_scan_depth个数据页（默认是1024个数据页），进行相关刷新操作。从LRUlist 淘汰的数据页会立刻放人到freelist中去。<br>可以通过调整InnoDBbuffer pool的大小、改变young sublist和old sublist的分配比例、控制脏缓存的刷新活动、使用多个InnoDB缓存池等方法来优化InnoDB的性能。<br>2.innodb_buffer_pool_size的设置<br>innodb_buffer_pool_size决定InnoDB存储引擎表数据和索引数据的最大缓存区大小。和 MyISAM存储引擎不同，Innodbufferpool同时为数据块和索引块提供数据缓存，这与Oracle 的缓存机制很相似。在保证操作系统及其他程序有足够内存可用的情况下，innodb_buffer_ pool_size的值越大，缓存命中率越高，访问InnoDB表需要的磁盘IO就越少，性能也就越高。在一个专用的数据库服务器上，可以将80%的物理内存分配给InnoDBbufferpool，但一定要注意避免设置过大而导致页交换。<br>通过以下命令查看bufferpool的使用情况：<br>mysqladmin –socket&#x3D;&#x2F;tmp&#x2F;mysql_3307.sock extlgrep -i innodb buffer_pool<br>|Innodb buffer_pool dump_status |Dumping of buffer pool not started Innodb buffer pool _load status 1Buffer pool(s) load completed at 180729 17:44:29 Innodb_buffer_pool_resize_status<br>Innodb buffer pool pages data 119623 Innodb buffer_pool bytes data 1959903232 Innodb buffer pool pages dirty<br>Innodb buffer_pool bytes dirty 0 Innodb buffer_pool pages _flushed 205650<br>Innodb buffer_pool pages_free 206703 Innodb buffer _pool_pages_misc 1334 Innodb buffer_pool_pages_total 327660 |Innodb buffer pool read ahead rnd</p>
<p>≦ 320 ≧<br>302 第17章优化MySQLServer<br>IInnodb buffer pool read ahead 548 Innodb buffer _pool read ahead_evicted<br>Innodb buffer _pool_read_requests 627668161<br>Innodb buffer pool reads 17113 Innodb buffer_pool wait_free<br>Innodb_buffer_pool write_requests<br>可用以下公式计算InnoDB缓存池的命中率：<br>（1-innodb_buffer_pool_reads&#x2F;innodb_buffer_pool_read_request）x100 如果命中率太低，则应考虑扩充内存、增加innodb_buffer_pool_size的值。<br>在MySQL8.0中，增加了一个自动分配内存的参数——innodb_dedicated_server，如果一台服务器上面只运行了一个MySQL实例，那么将这个参数设置为1之后， innodb_buffer_pool_size、innodb_log_file_size和innodb_flush_method这3个参数会根据物理内存的大小自动分配，具体规则如下。<br>物理内存小于1GB:<br>innodb_buffer_pool_size&#x3D;128MB innodb_log_file_size&#x3D;48MB<br>innodb_flush_method&#x3D;O_DIRECT_NO_FSYNC（如果系统允许） O物理内存为1GB~4GB:<br>innodb_buffer_pool_size&#x3D;物理内存<em>0.5 innodb_log_file_size&#x3D;128MB<br>innodb_flush_method&#x3D;O_DIRECT_NO_FSYNC（如果系统允许）物理内存大于4GB：<br>innodb_buffer_pool_size&#x3D;物理内存</em>0.75 innodb_log_file_size&#x3D;1024MB<br>innodb_flush_method&#x3D;O_DIRECT_NO_FSYNC（如果系统允许）<br>其实，即使使用的是MySQL5.6或MySQL5.7，也可以参考上面的规则，来分配实例的这几个内存参数。<br>3.调整old sublist大小<br>在LRU list中，old sublist的比例由系统参数innodb_old_blocks_pct决定，其取值范围是<br>5～95，默认值是75（约等于3&#x2F;4）。通过以下命令可以查看其当前设置： mysql&gt; show global variables 1ike%innodb old blocks pct%’;<br>I variable_name | value | 1 innodb old blocks pct 1 75<br>可以根据InnoDBMonitor的输出信息来调整innodb_old_blocks_pct的值。例如，在没有较大表扫描或索引扫描的情况下，如果young&#x2F;s的值很低，可能就需要适当增大 innodb_old_blocks_pct的值或减小innodb_old_blocks_time的值。<br>4.调整innodb_old_blocks_time的设置<br>innodb_old_blocks_time参数决定了缓存数据块由old sublist转移到young sublist的快慢，当一个缓存数据块被插人到midpoint（oldsublist）后，至少要在oldsublist停留超过</p>
<p>≦ 321 ≧<br>17.2MySQL内存管理及优化 303<br>innodb_old_blocks_time（ms）后，才有可能被转移到new sublist。例如，将innodb_old_blocks_time 设置为1000（即1s），当出现tablescan时，InnoDB先将数据块载入到midpoint（oldsublist）上，程序读取数据块，因为这时，数据块在old sublist中的停留时间还不到innodb_old_blocks_time，所以不会被转移到有young sublist中，这样就避免了表扫描污染bufferpool的情况。<br>可以根据InnoDBMonitor的输出信息来调整innodb_old_blocks_time的值。在进行表扫描时，如果non-youngs&#x2F;s很低，young&#x2F;s很高，就应考虑将innodb_old_blocks_time适当调大，以防止表扫描将真正的热数据淘汰。更酷的是，这个值可以动态设置，如果要进行大的表扫描操作，可以很方便地临时做调整。<br>5.调整缓存池数量，减少内部对缓存池数据结构的争用<br>MySQL内部不同线程对InnoDB缓存池的访问在某些阶段是互斥的，这种内部竞争也会产生性能问题，尤其在高并发和bufferpool较大的情况下。为解决这个问题，InnoDB的缓存系统引「人了innodb_buffer_pool_instances配置参数，默认为8个，对于较大的缓存池，适当增大此参数的值，可以降低并发导致的内部缓存访问冲突，改善性能。InnoDB缓存系统会将参数innodb_buffer_pool_size指定大小的缓存平分为innodb_buffer_pool_instances个bufferpool。<br>6.控制innodbbuffer刷新，延长数据缓存时间，减缓磁盘I&#x2F;O<br>在InnoDB找不到干净的可用缓存页或检查点被触发等情况下，InnoDB的后台线程就会开始把“脏的缓存页”回写到磁盘文件中，这个过程叫缓存刷新。<br>我们通常都希望bufferpool中的数据在缓存中停留的时间尽可能长，以备重用，从而减少磁盘IO的次数。同时，磁盘IO较慢，是数据库系统最主要的性能瓶颈，我们往往也希望通过延迟缓存刷新来减轻IO系统的压力。InnoDBbufferpool的刷新快慢主要取决于两个参数。<br>O一个是innodb_max_dirty_pages_pct，它控制缓存池中脏页的最大比例，默认值是 50%，如果脏页的数量达到或超过该值，InnoDB的后台线程将开始缓存刷新。<br>O另一个是innodb_io_capacity，它代表磁盘系统的IO能力，其值在一定程度上代表磁盘每秒可完成IO的次数。innodb_io_capacity的默认值是200，对于转速较低的磁盘，如7200RPM 的磁盘，可将innodb_io_capacity的值降低到100，而对于固态硬盘和由多个磁盘组成的盘阵， innodb_io_capacity的值可以适当增大，尤其是对于固态硬盘来说，建议设置为2000或者更高。<br>innodb_io_capacity决定一批刷新脏页的数量，当缓存池脏页的比例达到 innodb_max_dirty_pages_pct时，InnoDB大约将innodb_io_capacity个已改变的缓存页刷新到磁盘；当脏页比例小于innodb_max_dirty_pages_pct时，如果innodb_adaptive_flushing的设置为 true，InnoDB将根据函数buf_flush_get_desired_flush_rate返回的重做日志产生速度来确定要刷新的脏页数。在合并插入缓存时，InnoDB每次合并的页数是0.05xinnodb_io_capacity。<br>可以根据一些InnoDBMonitor的值来调整innodb_max_dirty_pages_pct和innodb_io_capacity。例如，若innodb_buffer_pool_wait_free的值增长较快，则说明InnoDB经常在等待空闲缓存页，如果无法增大缓存池，那么应将innodb_max_dirty_pages_pct的值调小，或将innodb_io_capacity 的值提高，以加快脏页的刷新。<br>7.InnoDB doublewrite<br>在进行脏页刷新时，InnoDB采用了双写（doublewrite）策略，这么做的原因是：MySQL</p>
<p>≦ 322 ≧<br>304 第17章优化MySQLServer<br>的数据页大小（一般是16KB）与操作系统的IO数据页大小（一般是4KB）不一致，无法保证InnoDB缓存页被完整、一致地刷新到磁盘，而InnoDB的redo日志只记录了数据页改变的部分，并未记录数据页的完整前像，当发生部分写或断裂写时（比如将缓存页的第一个4KB 写入磁盘后，服务器突然断电），就会出现页面无法恢复的问题。为解决这个问题，InnoDB 引人了doublewrite技术。<br>InnoDBdoublewrite机制的实现原理是：用系统表空间中的一块连续磁盘空间（100个连续数据页，大小为2MB）作为doublewritebuffer，当进行脏页刷新时，首先将脏页的副本写到系统表空间的doublewritebuffer中，然后调用fsyncO刷新操作系统IO缓存，确保副本被真正写入磁盘，最后InnoDB后台IO线程将脏页刷新到磁盘数据文件。其原理示意图如图17-2所示。<br>innodbbufferpool<br>同步到doublewriter buffer，调用fsync 写入redo<br>logfileo logfilel<br>double writer buffer<br>system table spa logfile2 tablespace(ibdata)<br>图17-2InnoDBdoublewrite原理示意图<br>在做恢复时，如果发现不一致的页，InnoDB会用系统表空间doublewritebuffer区的相应副本来恢复数据页。<br>默认情况下，InnoDBdoublewrite是开启的，可以用以下命令查看： mysql&gt; show global variables like%doublewrite%’;<br>Variable name 1 Value |<br>I innodb doublewrite I oN 1 row in set (0.01 sec)<br>由于同步到doublewritebuffer是对连续磁盘空间的顺序写，因此开启双写对性能的影响并不太大。对于要求超高性能，又能容忍极端情况下少量数据丢失的应用，可以通过在配置文件中增加innodb_doublewrite&#x3D;0参数设置来关闭doublewrite，以尽量满足性能方面的要求。</p>
<p>≦ 323 ≧<br>17.3InnoDBlog机制及优化 305<br>17.2.4调整用户服务线程排序缓存区<br>如果通过showglobal status看到sort_merge_passes的值很大，可以考虑通过调整参数 sort_buffer_size的值来增大排序缓存区，以改善带有orderby子句或group子句SQL的性能。<br>对于无法通过索引进行连接操作的查询，可以尝试通过增大，join_buffer_size的值来改善性能。<br>不过需要注意的是，sortbuffer和joinbuffer都是面向客户服务线程分配的，如果设置过大可能造成内存浪费，甚至导致内存交换。尤其是joinbuffer，如果是多表关联的复杂查询，还可能会分配多个joinbuffer，因此，最好的策略是设置较小的全局join_buffer_size，而对需<br>要做复杂连接操作的session单独设置较大的join_buffer_size。 17.3 InnoDBlog机制及优化<br>支持事务的数据库系统都需要有一套机制来保证事务更新的一致性和持久性，InnoDB与 Oracle等支持事务的关系数据库一样，也采用redolog机制来保证事务更新的一致性和持久<br>性。本节将介绍InnoDB重做日志的内部机制，并讨论相关的性能优化问题。 17.3.1InnoDB重做日志<br>redolog是InnoDB保证事务ACID属性的重要机制，其工作原理图如图17-3所示。<br>innodbbuffer pool nodblogbuffe innodbflush log at trx commit-0<br>innodb_flush log at trx commit2 ib logfileo innodb_flush_log at trx_commit1<br>ib_logfilel ib_logfile2<br>图17-3redo日志回写磁盘示意图</p>
<p>≦ 324 ≧<br>306 第17章优化MySQLServer<br>当更新数据时，InnoDB内部的操作流程大致如下。<br>（1）将数据读入InnoDBbufferpool，并对相关记录加独占锁。（2）将UNDO信息写人undo表空间的回滚段中。<br>（3）更改缓存页中的数据，并将更新记录写人redobuffer中。<br>（4）提交时，根据innodb_flush_log_at_trx_commit 的设置，用不同的方式将redobuffer 中的更新记录刷新到InnoDBredo logfile中，然后释放独占锁。<br>（5）最后，后台IO线程根据需要择机将缓存中更新过的数据刷新到磁盘文件中。可以通过showengineinnodb status命令查看当前日志的写人情况，如图17-4所示。<br>上次数据页的修改<br>myspl &gt;show engine innodb status\G; 还没有刷新到日志文件的lsn号<br>LOG 上次成功操作，<br>已经刷新到日志文件中的Iisn号<br>Log sequence number 86269503508 Log lu shed up to 86269503506<br>Last checkpoint at86269495545 上次检查点成功完成时的lsn号<br>意味着恢复的起点<br>图17-4查看当前日志的写入情况<br>其中，LSN（LogSequenceNumber）称为日志序列号，它实际上对应日志文件的偏移量，其生成公式是：<br>新的LSN&#x3D;I旧的LSN+写人的日志大小<br>例如，日志文件大小为600MB，目前的LSN是1GB，现在要将512字节的更新记录写人redolog，则实际写人过程如下。<br>●求出偏移量：由于LSN数值远大于日志文件大小，因此通过取余方式，得到偏移量为400MB。<br>O写入日志：找到偏移400MB的位置，写入512字节日志内容，下一个事务的LSN就是1000000512。<br>由以上介绍可知，除InnoDBbufferpool外，InnoDBlogbuffer的大小、redo日志文件的大小以及innodb_flush_log_at_trx_commit参数的设置等，都会影响InnoDB的性能。下面我们介绍这几个参数的优化调整。<br>17.3.2innodb_flush_log_at_trx_commit的设置<br>innodb_flush_log_at_trx_commit参数可以控制将redobuffer中的更新记录写入到日志文件以及将日志文件数据刷新到磁盘的操作时机。通过调整这个参数，可以在性能和数据安全之间做取舍。<br>O如果这个参数设置为0，在事务提交时，InnoDB不会立即触发将缓存日志写到磁盘文件的操作，而是每秒触发一次缓存日志回写磁盘操作，并调用操作系统fsync刷新IO缓存。<br>如果这个参数设置为1，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，并调用操作系统fsync刷新IO缓存。</p>
<p>≦ 325 ≧<br>17.3InnoDBlog机制及优化 307<br>如果这个参数设置为2，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，但并不马上调用fsync来刷新IO缓存，而是每秒只做一次磁盘IO缓存刷新操作。 innodb_flush_log_at_trx_commit参数的默认值是1，即每个事务提交时都会从logbuffer 写更新记录到日志文件，而且会实际刷新磁盘缓存，显然，这完全能满足事务的持久化要求，是最安全的，但这样会有较大的性能损失。<br>在某些情况下，我们需要尽量提高性能，并且可以容忍在数据库崩溃时丢失小部分数据，那么通过将参数innodb_flush_log_at_trx_commit设置成0或2都能明显减少日志同步IO，加快事务提交，从而改善性能。<br>将此参数设置成0，如果数据库崩溃，最后1秒钟的事务重做日志可能会由于未及写人磁盘文件而丢失，这种方式是效率最高的，但也是最不安全的。<br>将此参数设置成2，如果数据库崩溃，由于已执行重做日志写人磁盘操作，只是没有做磁盘IO刷新操作，因此，只要不发生操作系统崩溃，数据就不会丢失，这种方式是对性能和数<br>据安全的折中，其性能和数据安全性介于其他两种方式之间。 17.3.3设置logfilesize，控制检查点<br>当一个日志文件写满后，InnoDB会自动切换到另一个日志文件，但切换时会触发数据库检查点（checkpoint），这将导致InnoDB缓存脏页的小批量刷新，会明显降低InnoDB的性能。<br>那是不是将innodb_log_file_size设得越大越好呢？理论上是，但如果日志文件设置得太大，恢复时将需要更长时间，同时也不便于管理。一般来说，平均每半小时写满1个日志文件比较合适。我们可以通过下面的方法来计算InnoDB每小时产生的日志量并估算合适的 innodb_log_file_size值。<br>首先，计算InnoDB每分钟产生的日志量： mysql&gt; pager grep -i “Log sequence number” PAGER set to ‘grep -i “Log sequence number<br>mySql&gt; SHOW ENGINE INNODB STATUS\G SELECT SLEEP(6O); SHOW ENGINE INNODB STATUS\G Log sequence number 90176272406<br>1 row in set (o.00 sec) 1row in set (59.99 sec)<br>Log sequence number 90196407469<br>1row in set (0.00 sec) mysql&gt; nopager<br>PAGER set to stdout<br>mysql&gt; select ROUND((90196407469 - 90176272406)&#x2F; 1024 &#x2F; 1024) as MB;<br>1MB |191<br>1row in set (o.00 sec)<br>这一步也可以通过查询INFORMATION_SCHEMA.GLOBAL_STATUS表来计算：<br>SELECT @a1:&#x3D; variable valueAS al FROM information_schema.global_status<br>WHERE variable name &#x3D;’innodb os_log written UNION ALL<br>SELECT S1eep(60) UNION ALL<br>SELECT @a2 :&#x3D;variable valueAS a2</p>
<p>≦ 326 ≧<br>308 第17章优化MySQLServer<br>FROM information schema.global status<br>WHERE variable name &#x3D;’innodb os log written’; lal<br>90176272406 90196407469<br>1row in set (0.01 sec)<br>SELECT RoUND((@a2-@a1)&#x2F; 1024 &#x2F; 1024 &#x2F; @@innodb_ 1og_files_in group) as MB;<br>191<br>1 row in set (0.01 sec)<br>通过上述操作得到InnoDB每分钟产生的日志量是19MB。然后，计算每半小时的日志量：<br>半小时日志量&#x3D;30×19MB&#x3D;570MB<br>这样，就可以得出innodb_log_file_size的大小至少应该是512MB。 17.3.4调整innodb_log_buffer_size<br>innodb_log_buffer_size决定InnoDB重做日志缓存池的大小，默认值是16MB。对于可能产生大量更新记录的大事务，增加innodb_log_buffer_size的大小，可以避免InnoDB在事务提交前就执行不必要的日志写人磁盘操作。因此，对于会在一个事务中更新、插入或删除大量记录的应用，我们可以通过增大innodb_log_buffer_size来减少日志写磁盘操作，从而提高事务处理的性能。<br>17.4调整MySQL并发相关的参数<br>从实现上来说，MySQLServer是多线程结构，包括后台线程和客户服务线程。多线程可以有效利用服务器资源，提高数据库的并发性能。在MySQL中，控制并发连接和线程的主<br>要参数包括max_connections、back_log、thread_cache_size以及table_open_cache 等。 17.4.1调整max_connections，提高并发连接<br>参数max_connections控制允许连接到MySQL数据库的最大数量，默认值是151。如果状态变量connection_errors_max_connections不为零，并且一直在增长，就说明不断有连接请求因数据库连接数已达到最大允许的值而失败，应考虑增大max_connections的值。<br>MySQL最大可支持的数据库连接取决于很多因素，包括给定操作系统平台线程库的质量、内存大小、每个连接的负荷以及期望的响应时间等。在Linux平台下，MySQL支持5000～ 10000个连接不是难事，如果内存足够、不考虑响应时间，甚至能达到上万个连接。而在 Windows平台下，受其所用线程库的影响，最大连接数有以下限制：<br>(open tables×2+open connections)&lt;2048<br>每一个session操作MySQL数据库表都需要占用文件描述符，数据库连接本身也要占用文件描述符，因此，在增大max_connections时，也要注意评估open-files-limit的设置是否够用。</p>
<p>≦ 327 ≧<br>17.5持久化全局变量 309<br>17.4.2调整back_log<br>back_log参数控制MySQL监听TCP端口时设置的积压请求栈大小，5.6.6版本以前的默认值是50，5.6.6版本以后的默认值是50+（max_connections&#x2F;5），但最大不能超过900。<br>如果需要数据库在较短时间内处理大量连接请求，可以考虑适当增大back_log的值。 17.4.3调整table_open_cache<br>每一个SQL执行线程至少都要打开1个表缓存，参数table_open_cache控制所有SQL执行线程可打开表缓存的数量。这个参数的值应根据最大连接数max_connections以及每个连接执行关联查询中所涉及表的最大个数（用N表示）来设定：<br>max_connectionsxN<br>在未执行flushtables命令的情况下，如果MySQL状态变量opened_tables的值较大，就说明table_open_cache设置得太小，应适当增大。增大table_open_cache的值，会增加MySQL<br>对文件描述符的使用量，因此，也要注意评估open-files-limit的设置是否够用。 17.4.4调整thread_cache_size<br>为加快连接数据库的速度，MySQL会缓存一定数量的客户服务线程以备重用，通过参数 thread_cache_size可控制MySQL缓存客户服务线程的数量。<br>可以通过计算线程cache的失效率threads_created&#x2F;connections来衡量thread_cache_size的设置是否合适。该值越接近1，说明线程cache命中率越低，应考虑适当增加thread_cache_size的值。 17.4.5innodb_lock_wait_timeout的设置<br>参数innodb_lock_wait_timeout可以控制InnoDB事务等待行锁的时间，默认值是50ms，可以根据需要动态设置。对于需要快速反馈的交互式OLTP应用，可以将行锁等待超时时间调小，以避免事务长时间挂起；对于后台运行的批处理操作，可以将行锁等待超时时间调大，以避免发生大的回滚操作。<br>17.5持久化全局变量<br>前面几节介绍了通过设置MySQL参数来优化数据库实例的方法，在MySQL8.0之前，一般都是通过setglobal命令来设置MySQL参数，一旦数据库实例重启，那么实例会从配置文件中重新加载旧的参数配置，之前做过的修改就会失效。因此，在使用setglobal命令修改了实例参数后，还要记得去修改配置文件中的配置。操作需要两步完成，因此容易产生遗漏，从而带来潜在的问题。<br>在MySQL8.0中，提供了全新的setpersist&#x2F;setpersist only命令，可以对数据库参数做持久化的修改，通过setpersist方式做过的修改，数据库实例在重启后，就能够正确加载修改后的参数。其中，setpersist命令会同时修改当前环境并持久化参数修改，setpersistonly命令则不修改当前环境，仅仅对修改做持久化，当下次实例启动时，参数修改才会生效。setpersist 命令的实现原理如下：</p>
<p>≦ 328 ≧<br>310 第17章优化MySQLServer<br>当使用setpersist命令来修改MySQL参数时，会在datadir中创建一个名为mysqld-auto.cnf 的文件，并在文件中以json的格式，保存被修改的参数的值。<br>数据库实例启动时，在加载了默认的my.cnf配置文件之后，会再读取mysqld-auto.cnf文件中的配置。如果发现文件中有修改的参数值，那么会使用后读到的mysqld-auto.cnf文件中的参数值来启动数据库。<br>下面来测试一下这个过程，将参数max_connections从10050持久化修改为11000： root@localhost:mysql 3488.sock [(none)]&gt;show variables 1ike ‘max connections’;<br>IVariable name 丨value Imax connections | 10050| 1row in set (0.00 sec)<br>root@localhost:mysq1 3488.sock [(none)]&gt;set persist max connections &#x3D; 11000; Query ok,0 rows affected (0.09 sec)<br>此时，发现datadir下生成了新文件mysqld-auto.cnf:<br>[mysq13488@hz 10 120 240 251mysq1home]s11 &#x2F;data2&#x2F;mysq13488&#x2F;data&#x2F;mysqld-auto.cnf<br>-1mysq73488 mysq13488 173 Sep 23 11:15&#x2F;data2&#x2F;mysq13488&#x2F;data&#x2F;mysqld-auto.cnf<br>文件内容如下：<br>[mysq13488@hz 10_120 240 251 mysq1home]$ more&#x2F;data2&#x2F;mysq13488&#x2F;data&#x2F;mysqld-auto.cnf<br>“version”:1,”mysql server”:{“max connections”:f”value”:”11000”,“Metadata”<br>[“Timestamp”:1537672549953953，”User”:”root”，”H ost”:“1ocalhost”}}}}<br>可以使用resetpersist命令来清除mysqld-auto.cnf文件中的所有配置，也可以通过reset persist+参数名的方式，来清除某个制定的配置。下面命令完全清除了刚才的配置：<br>root@localhost:mysql_3488.sock [(none)]&gt;reset persist max connections; Query oK,0 rows affected (0.07 sec)<br>root@localhost:mysql 3488.sock[(none)]&gt;exit Bye<br>[mysq13488@hz 10 120240 251 mysq1home]s more&#x2F;data2&#x2F;mysq13488&#x2F;data&#x2F;mysqld-auto.cnf{“version”:1，“mysql server”：{}}<br>通过增加持久化参数修改命令，MySQL8.0在一定程度上降低了DBA的维护复杂度，减少了因为忘记修改配置文件从而引l发问题的可能，但是对比Oracle使用pfile+spfile的方式来实现参数持久化的方案，MySQL8.0版本的参数持久化方式还存在一些不足，比如不能很方便的合并参数，需要查看两个文件，才能确定参数的实际值。希望未来MySQL可以继续改<br>进，提供更加方便的参数管理方案。 17.6使用资源组<br>在MySQL8.0中，新增了资源组（ResourceGroup）特性。通过资源组，可以限制某个任务或者查询对于系统资源的使用。目前MySQL8.0中，能够调整的是对CPU资源的使用限制和线程的优先级。<br>设置资源组可以使数据库更加有针对性地应对一些业务场景，例如数据库在执行一些批量任务的时候，如果希望能够控制对数据库产生的压力，从而减小对其他更重要服务的影响。我们就可以选择使用资源组，将批量任务能够使用的CPU减少，线程优先级降低。</p>
<p>≦ 329 ≧<br>17.6使用资源组 311<br>在CPU层面，MySQL控制的粒度为vCPU，也就是逻辑CPU的个数，逻辑CPU包括了超线程技术虚拟出来的CPU，可以通过命令more&#x2F;proc&#x2F;cpuinfo|grepprocessor|wc-1来查看服务器总共的vCPU数量。<br>在线程优先级层面，默认的线程优先级都是0，数字越小，线程优先级越高。对于系统资源组，线程优先级可以直接设置在-20～0之间；对于用户资源组，线程优先级可以设置在0 到19之间。<br>可以通过INFORMATION_SCHEMA.RESOURCE_GROUPS来查看资源组的设置。 root@localhost&gt; select * from INFORMATION SCHEMA.RESOURCE GROUPS;<br>|RESOURCE GROUP NAME|RESOURCE GROUP TYPE|RESOURCE GROUP ENABLED|VCPU IDS |THREAD PRIORITY| IUSR default USER 110-7<br>SYs default SYSTEM 2rows in set (0.38 sec)<br>可以看到，MySQL默认创建了两个资源组，都可以使用全部的vCPU，线程优先级都是0，这两个资源组的属性是不可修改的。新创建的线程默认都会被分配到这两个资源组中的一个。<br>接下来，创建一个用于执行批量任务的资源组： root@localhost&gt;CREATE RESOURCE GROUP Batch<br>-&gt;TYPE&#x3D;USER-&gt;VCPU&#x3D;2-3</p>
<blockquote>
<p>THREAD PRIORITY &#x3D; 10;<br>Query ok, 0 rows affected,1 warning (0.13 sec) root@localhost&gt;show warnings;<br>ILevel 1code | Message I warning l 3659 | Attribute thread priority is ignored (using default value). 1 row in set(0.00 sec)<br>root@locaThost&gt;Select * from INFORMATION SCHEMA.RESOURCE GROUPS;<br>|RESOURCE GROUP NAME|RESOURCE GROUP_TYPE|RESOURCE GROUP ENABLED|VCPU IDS|THREAD PRIORITY|<br>IUSR default IUSER 110-7 0 SYS_default SYSTEM 10-7 0 1Batch IUSER 112-3 0<br>3rows in set (o.00 sec)<br>可以看到，Batch资源组创建成功，可以使用vCPU2和3，但是对于资源组的线程优先级设置并没有成功，显示依然为0。对于Linux系统，需要首先用root用户或者sudo权限执行下面的操作并重启数据库实例：<br>[root@hz 10 120 240 251 mysq1home]#pwd&#x2F;home&#x2F;mysq13488&#x2F;mysq1home<br>[root@hz 10 120 240 251 mysq1home]# setcap cap sys nice+ep.&#x2F;bin&#x2F;mysqld<br>[root@hz 10 120 240251 mysq1home]# getcap.&#x2F;bin&#x2F;mysqld.&#x2F;bin&#x2F;mysqld&#x3D; cap_sys nice+ep<br>重启实例后，我们重新设置一下资源组的线程优先级：<br>root@localhost&gt;alter resource group Batch thread priority &#x3D; 19;<br>Query ok,0 rows affected (0.08 sec) 这次设置成功：<br>root@localhost&gt;select * from INFORMATIoN SCHEMA.RESOURCE_GROUPs;</p>
</blockquote>
<p>≦ 330 ≧<br>312 第17章优化MySQLServer<br>|RESOURCE GROUP NAME| RESOURCE GROUP_TYPE|RESOURCE GROUP ENABLED|VCPU IDS|THREAD PRIORITYI IUSR default IUSER 0-7<br>ISYs default ISYSTEM 110-7 0<br>I Batch |USER 2-3 3rows in set (o.00 sec)<br>对于正常执行的线程，可以使用以下几种方法来设置资源组。（1）第一种方法是通过线程id来设置：<br>首先使用showporcesslist或者information_schema.processlist获得session的id，再通过 performance_schema.threads获得session对应的线程id。<br>例如，获得的线程id为62，那么接下来执行。 root@localhost&gt;set resource group Batch for 62; Query ok,Orowsaffected (o.oo sec)<br>（2）第二种方法是在任务开始之前，设置session的资源组。在session中直接执行：<br>root@localhost&gt;set resource group Batch; Query ok,O rows affected (o.oo sec)<br>这样，当前 session的所有操作都会被放到Batch资源组中。<br>（3）第三种方法是通过注释的方式，将某个具体的SQL，放到Batch资源组中进行：<br>INSERT&#x2F;<em>+RESOURCE GROUP(Batch)</em>&#x2F;INTO tVALUES(2); DNS  S 17.7小结<br>本章在简要说明MySQL系统架构、缓存体系和redolog机制的基础上，介绍了影响 MySQL数据库性能的一些的重要配置参数，讨论了缓存、InnoDB日志和并发相关的性能优化问题。最后还介绍了MySQL5.7和8.0中新增的一些实例优化方法。</p>
<p>≦ 331 ≧<br>第18章 磁盘I&#x2F;O问题<br>作为应用系统的持久化层，不管数据库采取了什么样的Cache机制，但数据库最终总是要将数据储存到可以长久保存的I&#x2F;O设备一一磁盘上，但磁盘的存取速度显然要比CPU、 RAM的速度慢很多，因此，对于比较大的数据库，磁盘IO一般总会成为数据库的一个性能瓶颈！<br>实际上，前面提到的SQL优化、数据库对象优化、数据库参数优化以及应用程序优化等，大部分都是想通过减少或延缓磁盘读写来减轻磁盘I&#x2F;O的压力及其对性能的影响。解决磁盘 IO问题，减少或延缓磁盘操作肯定是一个重要方面，但磁盘I&#x2F;O是不可避免的，因此，增强磁盘I&#x2F;O本身的性能和吞吐量也是一个重要方面。本章将从磁盘类型、磁盘阵列、符号链接、<br>裸设备等更底层的方面来介绍提高磁盘I&#x2F;O能力的一些技术和方法。 18.1使用固态硬盘<br>固态硬盘（SolidStateDisk，SSD）是近年来提升数据库IO性能最常见、性价比最高的手段之一，如果存在IO瓶颈的数据库仍然使用的是SAS甚至SATA硬盘，那么应该优先考虑将硬盘升级为SSD固态硬盘。<br>传统机械硬盘的原理是依靠磁头来读写高速旋转的盘片，一般来说，性能受到以下3个方面的影响。<br>盘片转速：相对来说，转速越高的磁盘读写速度也越快，但是受到机械性能和发热的限制，机械硬盘的转速为4200~15000RPM。<br>●存储密度：同样面积大小的盘片，如果容量更大，那么存储密度也更大，同样转速下，磁头每秒钟能够读写的数据量也更大。<br>O接口类型：服务器上使用的机械硬盘常用的接口一般有SATA2、SATA3、SAS等类型，带宽从3Gbit&#x2F;s到12Gbit&#x2F;s不等，硬盘的性能自然会受到接口速度的限制。<br>对于机械硬盘来说，性能上最大的瓶颈来自于随机I&#x2F;O。发生随机I&#x2F;O时，硬盘需要不断地通过转动盘片加移动磁头这种机械操作，来定位到需要读写的数据块，效率比较低。<br>固态硬盘由主控芯片加闪存芯片组成，不存在机械操作过程，对比机械硬盘，固态硬盘的优点主要有以下3点。<br>O读写速度快：普通SATA接口的SSD，连续I&#x2F;O能力一般是机械硬盘的数倍，随机IO</p>
<p>≦ 332 ≧<br>314 第18章磁盘1&#x2F;0问题<br>能力更是可以达到机械硬盘的几十倍以上，采用了PCI-E接口的SSD，I&#x2F;O能力还会更高。<br>O可靠性高：早期的SSD闪存颗粒的擦写次数比较低，因此当时SSD的寿命也比较短，但是现在企业级SSD的擦写次数已经比较高，寿命对于大多数应用场景来说已经不成问题，反而由于不存在易损坏的机械结构，相对来说更加稳定可靠。<br>功耗低、体积小、重量轻、无噪音。<br>在使用固态硬盘的过程中，也有一些需要注意的方面。<br>O合理规划成本：虽然现在SSD的价格已经比较低，但是相比SAS硬盘仍然贵不少，因此，对于某些对I&#x2F;O资源需求不大，数据量又非常大的场景，例如日志类型的数据，也需要认真评估是否需要使用SSD。<br>O选择适合的SSD型号：不同型号的SSD，由于采用了不同的芯片和接口类型，相互之间I&#x2F;O能力差距很大，尤其是写入的IOPS，差距更加明显。在实际使用SSD的时候，需要根据业务的类型，来选择适合当前业务的SSD型号。<br>合理预留空间：目前企业级SSD的寿命（一般通过PE来计算）已经比较大，但是如果是针对写密集型应用，可以按SSD的PE计算一下预期的寿命，如果希望加大SSD的寿<br>命，在SSD型号不变的情况下，可以通过配置预留空间来解决。 18.2 使用磁盘阵列<br>RAID是RedundantArrayof IndependentDisks的缩写，翻译成中文就是“独立磁盘余阵列”，通常就叫做磁盘阵列。RAID就是按照一定策略将数据分布到若干物理磁盘上，这样不仅增强了数据存储的可靠性，而且可以提高数据读写的整体性能，因为通过分布实现了数据的“并行”读写。<br>RAID最早是用来取代大型计算机上高档存储设备的，相对于那些高档存储设备而言， RAID的价格很便宜，这也是曾经其名称中带有“廉价”（Inexpensive）一词的原因。但其实很长时间，对于PC而言，其价格远远谈不上“廉价”！近几年，随着存储技术的发展，RAID 开始变得真正的物美价廉了。<br>18.2.1常见RAID级别及其特性<br>根据数据分布和余方式，RAID分为许多级别，不同存储厂商提供的RAID卡或设备支持的RAID级别也不尽相同，这里只介绍最常见也是最基本的几种，如表18-1所示，其他RAID 级别基本上都是在这几种基础上的改进。<br>表18-1 常见的RAID级别的比较 RAID级别特性优缺点<br>也称之为条带化（Stripe），按一定的<br>RAID 0 条带大小（ChunkSize）将数据依次分数据并发读写速度快，无额外数据无余保护，可靠性差<br>布到各个磁盘，没有数据余磁盘空间开销，投资省<br>也称之为磁盘镜像（Mirror），两个磁数据有完全余保护，只要不<br>RAID1 盘一组，所有数据都同时写入两个磁出现两块镜像磁盘同时损坏，在容量一定的情况下，需要2倍<br>不会影响使用：可以提高并发的磁盘，投资比较大<br>盘，但读时从任一磁盘读都可以<br>读性能</p>
<p>≦ 333 ≧<br>18.4使用SymbolicLinks分布1&#x2F;O 315<br>续表<br>RAID级别 优 点<br>特<br>是RAID1和RAID0的结合，也称之<br>在容量一定的情况下，需要2倍<br>RAID10 为RAID1+0。先对磁盘做镜像，再条 可靠性高，并发读写性能优良 的磁盘，投资比较大<br>带化，使其兼具RAID1的可靠性和 RAID0的优良并发读写性能<br>每个Stripe上数据的修改都要写<br>像RAID0一样对磁盘组条带化，不同 RAID中的一个磁盘损坏，其 校验纠错块，写性能受影响：所<br>RAID4 的是：需要额外增加一个磁盘，用来 数据可以通过校验纠错数据 有纠错数据都在同一磁盘上，风<br>计算出来，具有一定容错保护<br>写各Stripe的校验纠错数据 能力；读数据速度快 险大，也会形成一个性能瓶颈；<br>在出现坏盘时，读性能会下降<br>是对RAID4的改进：将每一个条带<br>写性能不及RAID0、RAID1和<br>（Stripe）的校验纠错数据块也分别写基本同RAID4，只是其写性能<br>RAID5 到各个磁盘，而不是写到一个特定的和数据保护能力要更强一点 RAID10，容错能力也不及RAID<br>1；在出现坏盘时，读性能会下降<br>磁盘<br>在RAID5基础上，为了进一步加强数<br>每个数据块有了两个校验保护<br>据保护而设计的一种RAID方式，实屏障（一个分层校验，一个是总 写性能相比RAID5更差：需要际上是一种扩展RAID5等级。与<br>RAID6 RAID5的不同之处于除了每个硬盘体校验），因此RAID6的数据 消耗两块硬盘的容量作为数据<br>上都有同级数据XOR校验区外，还有余性能更好，每组RAID允许 校验盘一个针对每个数据块的XOR校验区两块磁盘同时出现故障<br>18.2.2-如何选择RAID级别<br>了解各种RAID级别的特性后，就可以根据数据读写的特点、可靠性要求以及投资预算等来选择合适的RAID级别，比如：<br>O数据读写都很频繁，可靠性要求也很高，最好选择RAID10；<br>○数据读很频繁，写相对较少，对可靠性有一定要求，可以选择RAID5或者RAID6; 数据读写都很频繁，但可以接受全部数据丢失，可以选择RAID0。<br>18.3虚拟文件卷或软RAID<br>最初，RAID都是由硬件实现的，要使用RAID，至少需要有一个RAID卡。但现在，一些操作系统中提供的软件包，也模拟实现了一些RAID的特性。虽然性能上不如硬RAID，但相比单个磁盘，性能和可靠性都有所改善。比如，Linux下的逻辑卷（LogicalVolume）系统 lvm2，支持条带化（Stripe）；Linux下的MD（MultipleDevice）驱动，支持RAID0、RAID1、 RAID4、RAID5、RAID6等。在不具备硬件条件的情况下，可以考虑使用上述虚拟文件卷<br>或软RAID技术，具体配置方法可参见Linux帮助文档。 18.4使用SymbolicLinks分布I&#x2F;0<br>MySQL的数据库名和表名是与文件系统的目录名和文件名对应的，在默认情况下，创建的数据库和表都存放在参数datadir定义的目录下。这样如果不使用RAID或逻辑卷，所有的表都存放在一个磁盘设备上，无法发挥多磁盘并行读写的优势！在这种情况下，就可以利用操作系统的符号连接（SymbolicLinks）将不同的数据库、表或索引指向不同的物理磁盘，从而达到分布磁盘I&#x2F;O的目的。</p>
<p>≦ 334 ≧<br>316 第18章磁盘1&#x2F;0问题<br>（1）将一个数据库指向其他物理磁盘。<br>其方法是先在目标磁盘上创建目录，然后再创建从MySQL数据目录（&#x2F;path&#x2F;to&#x2F;datadir）到目标目录的符号连接：<br>shell&gt; mkdir &#x2F;otherdisk&#x2F;databases&#x2F;test<br> shell&gt; 1n -s &#x2F;otherdisk&#x2F;databases&#x2F;test &#x2F;path&#x2F;to&#x2F;datadir<br>（2）将MyISAM（其他存储引擎的表不支持）表的数据文件或索引文件指向其他物理磁盘。 O对于新建的表，可以通过在CREATETABLE语句中增加DATADIRECTORY选项来<br>完成，例如：<br>Create table testCid int primary key,<br>Name varchar(20)) ENGINE &#x3D; innodb<br>DATA DIRECTORY &#x3D;&#x2F;datal&#x2F;data；<br>对于已有的表，可以先将其数据文件（ibd）转移到目标磁盘，然后再建立符号连接即可。需要说明的是，表定义文件（.frm）必须位于MySQL数据文件目录下，不能用符号连接。<br>（3）在Windows下使用符号连接。<br>以上介绍的是Linux&#x2F;UNIX下符号连接的使用方法，在Windows下，是通过在MySQL 数据文件目录下创建包含目标路径并以“.sym”结尾的文本文件来实现的。例如，假设MySQL 的数据文件目录是C：mysqldata，要把数据库foo存放到D：\data\foo，可以执行以下步骤。<br>创建目录D:\data\foo。<br>创建文件C：\mysql\data\foo.sym，在其中输入D:\data\foo。这样在数据库foo创建的表都会存储到D：\data\foo目录下。<br>注意：使用SymbolicLinks存在一定的安全风险，如果不使用SymbolicLinks，应通过启动参数<br>skip-symbolic-links禁用这一功能。<br>18.5禁止操作系统更新文件的atime属性<br>atime是Linux&#x2F;UNIX系统下的一个文件属性，每当读取文件时，操作系统都会将读操作发生的时间回写到磁盘上。对于读写频繁的数据库文件来说，记录文件的访问时间一般没有任何用处，还会增加磁盘系统的负担，影响IO的性能！因此，可以通过设置文件系统的mount 属性，阻止操作系统写atime信息，以减轻磁盘I&#x2F;O的负担。在Linux下的具体做法如下。<br>（1）修改文件系统配置文件&#x2F;etc&#x2F;fstab，指定noatime选项：<br>xa12<br>（2）重新mount文件系统：<br>#<br>完成上述操作，以后读&#x2F;home下文件就不会再写磁盘了。 18.6调整&#x2F;0调度算法<br>目前来说，传统的磁盘仍然是主流的存储设备，从传统的硬盘上读取数据分为以下3个步骤。（1）将磁头移动到磁盘表面的正确位置，花费的时间称为寻道时间。<br>（2）等待磁盘旋转，需要的数据会移动到磁头下面，花费的时间取决于磁盘的转速，转</p>
<p>≦ 335 ≧<br>18.6调整1&#x2F;O调度算法 317<br>速越高的磁盘需要的时间越短。<br>（3）磁盘继续旋转，直到所有需要的数据都经过磁头。<br>磁盘在做这样动作时的快慢可以归结为两个因素：访问时间（步骤1和步骤2）和传输速度，这两个因素也叫作延迟和吞吐量。 磁道<br>传统的磁盘结构如图18-1所示。 扇区 I&#x2F;O请求处理的快慢有很大程度上取决于<br>磁盘的寻道时间。为了减少寻道时间，操作系<br>统不对每次IO请求都直接寻道处理，而是将 磁头<br>I&#x2F;O请求放人队列，对请求进行合并和排序，来减少磁盘寻道操作次数。<br>IO 请求合并是指将两个或者多个 IO 请机械摇臂求合并成一个新请求，例如，当新来的请求和<br>当前请求队列中的某个请求需要访问的是相 图18-1传统磁盘结构<br>同或者相邻扇区时，那么就可以把两个请求合并为对同一个或者多个相邻扇区的请求，这样只需要一次寻道就足够。通过合并，多个IO请求被压缩为一次I&#x2F;O，最后只需要一次寻址就可以完成多次寻址的效果。<br>对于相邻扇区的访问通过合并处理，对于非相邻扇区的访问则通过排序处理。机械臂的转动是朝着扇区增长方向的，如果把IO请求按照扇区增长排序，一次旋转就可以访问更多的扇区，能够缩短所有请求的实际寻道时间。<br>为此Linux实现了4种I&#x2F;O调度算法，分别是NOOP算法（NoOperation）、最后期限算法（Deadline）、预期算法（Anticipatory）和完全公平队列算法（CFQ）。用户既可以在内核引导时指定一种I&#x2F;O调度算法，也可以在系统运行时动态修改I&#x2F;O调度算法。从内核2.5开始，默认的IO调度算法是Deadline，之后默认IO调度算法为Anticipatory，直到内核2.6.17为止，从内核2.6.18开始，CFQ成为默认的I&#x2F;O调度算法。4种算法详细介绍如下：<br>NOOP算法（NoOperation）不对IO请求排序，除了合并请求也不会进行其他任何优<br>化，用最简单的先进先出（FIFO）队列顺序提交I&#x2F;O请求。NOOP算法面向的主要是随机访问设备，例如SSD等。NOOP算法更适合随机访问设备的原因主要是，随机访问设备不存在传统机械磁盘的机械臂移动（也就是磁头移动）造成的寻道时间，那么就没有必要做多余的事情。<br>最后期限算法（Deadline）除了维护一个拥有合并和排序功能的请求队列之外，还额外维护了两个队列，分别是读请求队列和写请求队列，它们都是带有超时的FIFO队列。当新来一个I&#x2F;O请求时，会被同时插入普通队列和读&#x2F;写队列，然后I&#x2F;O调度器正常处理普通队列中的请求。当调度器发现读&#x2F;写请求队列中的请求超时的时候，会优先处理这些请求，保证尽可能不产生饥饿请求。Deadline在全局吞吐量和延迟方面做了权衡，牺牲一定的全局吞吐量来避免出现饥饿请求的可能。当系统存在大量顺序请求的时候，Deadline可能导致请求无法被很好地排序，引发频繁寻道。<br>O预期算法（Anticipatory）是基于预测的IO算法，它和Deadline很类似，也维护了3 个请求队列。两者的区别在于，Anticipatory处理完一个I&#x2F;O请求之后并不会直接返回处理下一个请求，而是等待片刻（默认6ms），等待期间如果有新来的相邻扇区的请求，会直接处理新来的请求，当等待时间结束后，调度才返回处理下一个队列请求。Anticipatory适合写入较</p>
<p>≦ 336 ≧<br>318 第18章磁盘1&#x2F;0问题<br>多的环境，例如文件服务器等，不适合MySQL等随机读取较多的数据库环境。<br>O完全公平队列（CompleteFairQueuing，CFQ）把I&#x2F;O请求按照进程分别放入进程对应的队列中。CFQ的公平是针对进程而言的，每一个提交I&#x2F;O请求的进程都会有自己的I&#x2F;O 队列，CFQ以时间片算法为前提，轮转调动队列，默认从当前队列中取出4个请求处理，然后处理下一个队列的4个请求，确保每个进程享有的I&#x2F;O资源是均衡的。<br>从上面的算法中可以看到，在不同的场景下选择不同的IO调度器是十分必要的。在完全随机的访问环境下，CFQ和Deadline性能差异很小，但是在有大的连续IO出现的情况下， CFQ可能会造成小I&#x2F;O的响应延时增加，所以建议MySQL数据库环境设置为Deadine算法，这样更稳定。对于SSD等设备，采用NOOP或者Deadline通常也可以获取比默认调度器更好的性能。<br>查看当前系统支持的IO调度算法： shell&gt; dmesg l grep -i scheduler<br>查看当前设备（&#x2F;dev&#x2F;sda）使用的I&#x2F;O调度算法：<br>shell&gt; more &#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;scheduler noop anticipatory deadline [cfa]<br>修改当前块设备（&#x2F;dev&#x2F;sda）使用的I&#x2F;O调度算法，修改I&#x2F;O调度算法后直接生效： shel1&gt; echo “deadline”&gt;&#x2F;sys&#x2F;block&#x2F;sda&#x2F;queue&#x2F;scheduler<br>永久地修改IO调度算法，可以通过修改内核引导参数，增加elevator&#x3D;调度程序名： shell&gt; vi &#x2F;boot&#x2F;grub&#x2F;menu.lst<br>更改内容：<br>kernel&#x2F;boot&#x2F;vmlinuz-2.6.18-308.e15roroot&#x3D;LABEL&#x3D;&#x2F;elevator&#x3D;deadline 18.7RAID卡电池充放电问题<br>RAID卡的写缓存设置对于系统的I&#x2F;O性能影响极大，而影响写缓存的最重要因素是RAID<br>卡电池的充放电问题。本节将详细介绍RAID卡充放电的原理和可能导致的各种问题。 18.7.1：什么是RAID卡电池充放电<br>RAID卡都有写缓存（BatteryBackedWriteCache），写缓存对I&#x2F;O性能的提升非常明显，为了避免掉电丢失写缓存中的数据，所以RAID卡都有电池（BatteryBackupUnit，BBU）来提供掉电后将写缓存中的数据写入磁盘。<br>为了记录RAID卡电池的放电曲线，便于RAID卡控制器了解电池的状态，同时为了延长电池的使用寿命，默认会定期启动自动校准模式（AutoLearnMode），在LearnCycle期间， RAID卡控制器不会启用BBU直到完成校准。通俗地说，RAID卡电池会定期充放电，定期充放电的操作叫作电池Relearn或者电池校准。<br>查看RAID卡BBU的状态：<br>shel1&gt; Megacli64 -AdpBbuCmd -GetBbustatus -aALL<br>BBU status for Adapter:0 BatteryType: BBU</p>
<p>≦ 337 ≧<br>18.7RAID卡电池充放电问题 319<br>voltage: 3945 mV Current: O mA<br>Temperature:47C<br>Battery State: optimal BBU Firmware Status:<br>Charging status None voltage OK Temperature ：OK Learn Cycle Requested -No Learn Cycle Active NO Learn Cycle Status OK Learn Cycle Timeout NO I2c Errors Detected No Battery Pack Missing No Battery Replacement required<br>Remaining Capacity Low No Periodic Learn Required No Transparent Learn No No space to cache offload No Pack is about to fail &amp; should be replaced NO Cache offload premium feature required No<br>Module microcode update required BBU GasGauge Status: 0x0228<br>Relative State of charge: 100%<br>Charger Status: Complete Remaining Capacity:442 mAh Full charge Capacity: 446 mAh<br>isSOHGood: Yes Exit Code:0x00<br>其中，粗体显示的几个主要属性含义如下。<br>OCharging Status:None、Charging、Discharging分别代表BBU处于不充放电状态、充电状态和放电状态。<br>OLearn CycleRequested:Yes代表当前有LearnCycle请求，正在处于校准中。 LearnCycleActive:Yes代表处于Learn Cycle校准阶段，控制器开始校准。 BatteryReplacementRequired:Yes代表电池需要更换。<br>RemainingCapacityLow：Yes代表电池容量过低，需要更换电池。<br>电池校准一般会经历3个阶段：首先RAID卡控制器会将BBU充满到最大程度，然后开始放电，放电完毕后重新将BBU充满到最大程度，一次BBU校准完成。整个过程一般为3 个小时或者更长，期间RAID卡会自动禁用WriteBack策略，以保证数据完整性，而系统I&#x2F;O 性能会出现较大的波动。<br>默认DELL服务器90天执行一次校准，而IBM服务器是30天。DELL和IBM都不推荐关闭BBU电池的AutoLearn模式，不做校准的RAID卡电池寿命会从正常的两年降低到正常寿命的1&#x2F;3，也就是8个月。<br>18.7.2RAID卡缓存策略<br>可以通过MegaCli64-LDInfo-Lall-aALL命令来查看当前RAID卡设置的缓存策略。<br>shell&gt; Megacli64 -LDInfo -Lall -aALL Adapter O – virtual Drive Information:<br>Virtual Drive: 0(Target Id:0) Name<br>:Primary-1, Secondary-0, RAID Level Qualifier-0<br>RAID Level:1.089TB</p>
<p>≦ 338 ≧<br>320 第18章磁盘1V&#x2F;O问题<br>Mirror Data ：1.089 TB state optimal strip size ：64KB Number of Drives per span:2 Span Depth<br>:2<br>Default Cache Policy :WriteBack, Readadaptive, Direct, No write Cache if Bad BBU Current Cache Policy : WriteBack, ReadAdaptive, Direct,No Write Cache if Bad BBU<br>Default Access Policy : Read&#x2F;write Current Access Policy : Read&#x2F;write<br>Disk Cache Policy:Disk’s Default Encryption Type None<br>01 Default CachePolicy：默认的缓存策略。<br>CurrentCachePolicy：当前生效的缓存策略。<br>下面对缓存策略进行详细的说明。 1.缓存策略第1段<br>写缓存策略，包括WriteBack和WriteThrough。<br>OWriteBack：进行写入操作的时候，将数据写入RAID卡缓存后直接返回，RAID卡控制器将在系统负载低或者RAID缓存满的情况下把数据写入磁盘，减少了磁盘操作的频次，大大提升了RAID卡写入性能，在大多数情况下能够有效降低系统I&#x2F;O负载。写入RAID卡缓存的数据的可靠性由RAID卡的BBU（BatteryBackupUnit）保证。<br>OWriteThrough：进行写入操作的时候，不使用RAID卡缓存，数据直接写入磁盘才返回。也就是RAID卡写缓存被穿透，每次写入都直接写入磁盘。大多数情况下，WriteThrough 的策略设置会造成系统I&#x2F;O负载上升。和WriteBack策略相比，WriteThrough策略则不需要 BBU电池来保证数据的完整性，但会造成传统机械硬盘写性能的大幅下降，但是对于SSD来说，使用WriteThrough反而是更好的选择。<br>2.缓存策略第2段<br>是否开启预读，包括ReadAheadNone、ReadAhead和ReadAdaptive。 OReadAheadNone：不开启预读。<br>ReadAhead：开启预读，在读操作的时候，预先把后面顺序的数据加载入缓存，在顺序读取的时候，能提供性能，但是在随机读的时候，开启预读做了不必要的操作，会降低随机读的性能。<br>○ReadAdaptive：自适应预读，在缓存和I&#x2F;O空闲的时候，选择顺序预读，需要消耗一些计算能力，是默认的策略。<br>3.缓存策略第3段<br>读操作是否缓存到RAID卡缓存中，包括Direct和Cached。<br>Direct:读操作不缓存到RAID卡缓存中。 OCached:读操作缓存到RAID卡缓存中。 4.缓存策略第4段<br>如果BBU出问题，是否启用WriteCache，包括WriteCache OKifBadBBU和NoWrite Cache if Bad BBU。<br>ONoWriteCacheifBadBBU：如果BBU出问题，则不再使用WriteCache，从WriteBack</p>
<p>≦ 339 ≧<br>18.7RAID卡电池充放电问题 321<br>策略自动切换到WriteThrough模式。这是默认配置，确保在没有BBU电池支持的情况，直接写入磁盘而不是RAID卡缓存，以确保数据安全。<br>OWriteCacheOKifBadBBU：如果BBU出问题，仍然启用WriteCache。通常不推荐这么配置，因为如果BBU出问题，将无法保证意外断电后数据能够完整写回磁盘。除非有 UPS后备电源或者其他类似方案做电源方面额外的保证。<br>RAID卡缓存策略可以通过MegaCli64-LDSetProp命令进行修改。常用的策略主要有下面4种：WriteBack、WriteThrough、Write Cache OKif BadBBU和NoWrite Cacheif Bad BBU。<br>shell&gt; MegaCli64 -LDSetProp -WB -La11 -aALL she1l&gt; MegaCli64 -LDSetProp -WT -Lall -aALL<br>she1l&gt; MegaCli64 -LDSetProp -CachedBadBBU -Lall -aALL she1l&gt; MegaCli64 -LDSetProp -NoCachedBadBBU -La1l -aALL<br>在RAID卡电池校准期间（RAID卡电池电量在降低到特定國值之后）或者电池故障期间，默认的RAID卡写缓存策略会自动发生变动，从WriteBack变为WriteThrough，造成系统写人性能下降，此时如果正好是业务高峰时间，会引起系统负载大幅度上升、响应时间变长。<br>此时，可以通过临时修改RAID卡缓存策略为WriteCacheOKifBadBBU来解决，修改后立即生效，无须重启系统等额外的配置：<br>shell&gt; MegaCli64 -LDSetProp CachedBadBBu -Lall -aALL<br>Set write Cache ok if bad BBu on Adapter O,vD o (target id: O) success Exit Code:0x00<br>#Megacli64 -LDInfo-Lall -aALL<br>Default Cache Policy: writeBack,ReadAdaptive, Direct, write Cache Ok if Bad BBU Current Cache Policy: WriteBack, ReadAdaptive, Direct,Write Cache OK if Bad BBU<br>Current Access Policy: Read&#x2F;write<br>注意，临时修改RAID卡缓存策略度过业务高峰期之后，仍然应该及时恢复缓存策略为<br>NoWriteCacheifBadBBU，避免断电可能导致的数据损失： shell&gt; MegaCli64–LDSetProp NoCachedBadBBU -Lall -aALL<br>Set No write Cache if bad BBu on Adapter O,VD O (target id:O) success Exit Code: 0x00<br>she1l&gt; Megacli64 -LDInfo -La1l -aALL<br>Default Cache Policy: writeBack,Readadaptive, Direct, No write Cache if Bad BBU Current cache Policy: writeBack, ReadAdaptive, Direct, No write Cache if Bad BBU<br>对于RAID卡缓存策略的自动变动带来的IO性能波动，一般解决方案有两种。 18.7.3如何应对RAID卡电池充放电带来的I&#x2F;O性能波动<br>1.解决方案1<br>根据RAID卡电池（BBU电池）下次充放电的时间，定期在业务量较低的时候，提前进行充放电，避免在业务高峰时发生RAID卡写人策略从WriteBack到WriteThrough的更改。在手工触发电池充放电之后，下一次充放电的时间会往后顺延。例如，DELL服务器电池Relearm周期一般为90天，在手工触发DELL服务器BBU电池校准之后，下一次电池Relearn的时间会往后顺延</p>
<p>≦ 340 ≧<br>322 第18章磁盘1&#x2F;O问题<br>90天；而IBM服务器电池Relearn的周期一般为30天，手工触发IBM服务器BBU电池校准之后，下一次电池Relearmn的时间就会往后顺延30天。具体时间周期可以在系统中查看。<br>可以从BBU电池的日志中获取到下次电池Relearn时间： she11&gt; Megacli64 -fwtermlog -dsply -a0 -nolog<br>11&#x2F;02&#x2F;12 21:18:33: Next Learn wi11 start on 01 31 2013 11&#x2F;02&#x2F;1221:18:33: **BATTERY FEATURE PROPERTIES 11&#x2F;02&#x2F;1221:18:33:<br>11&#x2F;02&#x2F;1221:18:33: Auto Learn Period :90days 11&#x2F;02&#x2F;1221:18:33: Next Learn Time ：412982313<br>11&#x2F;02&#x2F;1221:18:33: Delayed Learn Interval :o hours from scheduled time<br>11&#x2F;02&#x2F;1221:18:33: Next Learn scheduled on:01 31 2013 21:18:33 11&#x2F;02&#x2F;1221:18:33:<br>或者通过命令直接得到下一次电池Relearn的时间： shell&gt; Megacli -AdpBbucmd -GetBbuProperties -aall<br>BBU Properties for Adapter:0 Auto Learn Period: 90 Days<br>Next Learn time:Thu Jan 31 21:18:33 2013<br>Learn Delay Interval:O Hours Auto-Learn Mode: Transparent<br>Exit Code: 0x00<br>手工触发电池Relearn（电池校准）的操作：<br>shell&gt;Megacli64-AdpBbuCmd-BbuLearn-aALL<br>2.解决方案2<br>设置ForcedWriteBack写策略，也就是说即使在电池电量低于警戒值甚至电池放电完毕的情况下，强制使用WriteBack写缓存策略，避免写入性能波动，此时一定要有UPS之类的后备<br>电源，否则当电池放电完毕时服务器恰好断电，就会导致写入RAID卡缓存中的数据丢失。 18.8 N NUMA架构优化<br>从系统架构来看，目前的商用服务器大体可以分为3类：对称多处理器结构（Symmetric Multi-Processor，SMP）、非一致存储访问结构（Non-UniformMemoryAccess，NUMA）和海量并行处理结构（MassiveParallelProcessing，MPP）。一般服务器是SMP或者NUMA架构的较多。<br>SMP架构是指在一台计算机上汇集了一组处理器（多CPU），各个CPU之间共享内存子系统和总线结构，如图18-2所示。SMP架构同时使用多个CPU，系统将任务队列对称地分布于多个CPU上，从而极大地提高了整个系统的数据处理能力。所有的CPU都可以平等地访问内存、IO和外设。架构中多个CPU没有区别，共享相同的物理内存，每个CPU访问内存中的任何地址所需时间是相同的，因此SMP也被称为一致存储器访问结果（Uniform MemoryAccess，UMA）。对SMP服务器进行扩展的方式有增加内存、使用更快的CPU、增加CPU、扩充IO，以及增加更多的磁盘等。<br>SMP服务器的主要特征是共享，系统中所有的资源（CPU、内存、I&#x2F;O等）都是共享的。正是由于共享，导致了SMP服务器的扩展能力非常有限。对SMP服务器来说，扩展最受限制的是内存，由于每个CPU都必须通过相同的总线访问相同的内存资源，如果两个CPU同</p>
<p>≦ 341 ≧<br>18.8NUMA架构优化 323<br>时请求防问一个内存资源（例如同一段内存地址），由硬件、软件的锁机制来解决资源争用的问题。所以随着CPU数量的增加，CPU之间内存访问冲突加剧，最终造成CPU资源的浪费，使得CPU性能的有效性大幅度降低。<br>Symmetricarchitecturewithacenteredcrossbarenables uniform access from any CPU to anymemory unit<br>CPU Memory<br>图18-2SMP架构<br>SMP架构ShareEverything导致在扩展能力上被限制，NUMA架构出现了。NUMA把一台计算机分成多个节点（Node），每个节点内部拥有多个CPU，节点内部使用共有的内存控制器，节点之间是通过互联模块进行连接和信息交互，如图18-3所示。因此节点的所有内存对于本节点所有的CPU都是等同的，而对于其他节点中的所有CPU都是不同的。因此每个 CPU可以访问整个系统内存，但是访问本地节点的内存速度最快（不需要经过互联模块），访问非本地节点的内存的速度较慢（需要经过互联模块），即CPU访问内存的速度与节点的距离有关，距离称为NodeDistance。<br>Intersocket<br>Node0  connection Node<br>Local<br>图18-3NUMA架构</p>
<p>≦ 342 ≧<br>324 第18章磁盘1&#x2F;0问题<br>当前NUMA的节点情况如下所示：<br>shell&gt; numactl –hardware available:2 nodes (0-1)<br>node 0 size:24194 MB node 0 free:117 MB node 1size:24240 MB node 1 free:17 MB<br>node distances: nodeo1 0:1021<br>1: 2110 shell&gt; free -m<br>total used free shared buffers cached<br>Mem: 48273 48138 135 343 14891-&#x2F;+ buffers&#x2F;cache:32903 15369 Swap:2047 22 2025<br>当前服务器上有两个节点Node0和Node1，Node0的本地内存约为24GB，Node1的本地内存约为24GB。系统一共有48GB内存。<br>节点之间距离（NodeDistance）是指从节点1上访问节点0上的内存需要付出的代价的一种表现形式。例子中，Linux为节点本地内存声明距离为10，非本地内存声明距离为21。<br>NUMA的内存分配策略有以下4种。<br>缺省default:：总是在本地节点上分配（分配在当前进程运行的节点上）。<br>绑定bind：强制分配到指定节点上。<br>交叉interleave：在所有节点或者指定节点上交叉分配内存。<br>0<br>优先preferred：在指定节点上分配，失败则在其他节点上分配。显示当前系统NUMA策略：<br>shell&gt; numact1 –show policy: default<br>preferred node: current<br>physcpubind:0123456789101112131415<br>cpubind:01 nodebind:01 membind:01<br>因为NUMA默认的内存分配策略是优先在进程所在CPU的本地内存中分配，会导致CPU 节点之间内存分配不均衡，当某个CPU节点内存不足时，会导致Swap产生，而不是从远程节点分配内存，这就是SwapInsanity现象。<br>MySQL是单进程多线程架构的数据库，当NUMA采用默认内存分配策略时，MySQL进程会被并且仅仅会被分配到NUMA的一个节点上去。假设这个节点的本地内存为8GB，而 MySQL配置了14GB内存，MySQL分配的14GB内存中，超过节点本地内存部分（14GB-8GB &#x3D;6GB内存）。Linux宁愿使用Swap也不会使用其他节点的物理内存。在这种情况下，能观察到虽然系统总共可用物理内存还未使用完，但是MySQL进程已经开始在使用Swap了。<br>MySQL对NUMA特性支持不好，如果单机只运行一个MySQL实例，可以选择关闭 NUMA。关闭的方式有两种：<br>硬件层，在BIOS中设置关闭； OS内核，启动时设置numa&#x3D;off。<br>修改&#x2F;etc&#x2F;grub.conf文件，在kernel行追加numa&#x3D;off： shell&gt; vi &#x2F;etc&#x2F;grub.conf<br>title Red Hat Enterprise Linux (2.6.32-279.e16.x86_64)<br>root （hdo,0)</p>
<p>≦ 343 ≧<br>18.9小结 325<br>kernel &#x2F;boot&#x2F;vm1inuz-2.6.32-279.e16.x86_64 r0 r00t&#x3D;UUID&#x3D;7971e5ab-ee55-4848-80f6-33<br>f811702a51 rd NO LUKS rd NO LVM LANG&#x3D;en US.UTF-8 rd NO MD SYSFONT&#x3D;latarcyrheb-sun16 crashke<br>rnel&#x3D;auto KEYBOARDTYPE&#x3D;pc KEYTABLE&#x3D;us rd No DM rhgb quiet numa&#x3D;off 保存后重启服务器，再次检查NUMA只剩下一个节点就成功了：<br>shell&gt; numactl –hardware available: 1 nodes (0)<br>node0cpus:01234567891011121314151617181920212223<br>node 0 size: 65490 MB node 0 free: 60968 MB node distances:<br>node0 0:10<br>或者通过numactl命令将NUMA内存分配策略修改为interleave。<br>修改mysqld_safe启动脚本，添加“cmd&#x3D;”&#x2F;usr&#x2F;bin&#x2F;numactl –interleave all Scmd””一行即<br>可，启动MySQL时指定内存分配策略为interleave： shell&gt;vi $MYSQL_HOME&#x2F;bin&#x2F;mysq1d_safe<br>cmd&#x3D;”&#x2F;usr&#x2F;bin&#x2F;numactl –interleave all $cmd”<br>for i in”Sledir&#x2F;$MYSQLD””$defaults””–basedir&#x3D;SMY BASEDIR VERSION”<br>–datadir&#x3D;SDATADIR””–plugin-dir&#x3D;$plugin dir””SUSER OPTION” do<br>cmd&#x3D;”$cmd “shell quote string “si”” done<br>保存后重启MySQL进程即可。<br>如果单机运行多个MySQL实例，可以将MySQL绑定到不同的CPU节点上，同时配置合适的MySQL内存参数，并且采用绑定的内存分配策略，强制在本节点分配内存。<br>NUMA技术可以很好地解决SMP架构的扩展问题，但是NUMA一样存在缺陷，由于访问远程内存的延时远远超过访问本地内存，因此随着CPU数量增加，系统性能并不能够线性增加。<br>MPP解决了NUMA架构增加CPU并不能线性提升性能的问题，MPP由多个SMP服务器通过一定的节点互联网络进行连接，每个节点只访问自己的本地资源（内存、存储等），不访问其他节点的资源，是一种ShareNothing的架构，因而理论上可以无限扩展。<br>在MPP架构中，每个节点的CPU不能访问其他节点的内存，此时节点之间的信息交互是通过节点互联网络来实现的，这个过程称为DataRedistribution。但是MPP服务器需要复杂的机制来调度和平衡各个节点的负载和并行处理。目前一些基于MPP技术的服务器会通过例如数据库软件等系统级别的软件来屏蔽底层的复杂性。例如，Teradata就是基于MPP技术的<br>一个关系数据库软件。 18.9小结<br>本章站在操作系统的角度介绍了如何对MySQL数据库进行优化，主要讨论了IO的优化问题、文件系统分布的优化问题等。在大多数的数据库系统中，磁盘I&#x2F;O都会成为影响系统性能的瓶颈。希望读者通过本章能够掌握一些减少磁盘I&#x2F;O以提高系统性能的方法。</p>
<p>≦ 344 ≧<br>第19章 应用优化<br>前面章节介绍了很多数据库的优化措施。但是在实际生产环境中，由于数据库服务器本身的性能局限，数据库的前期设计和应用访问设计就显得非常重要。好的设计在节点瓶颈到来时，可以通过简单的扩容或者配置变更来缩短服务不可用时间，甚至可以达到无缝扩容。数据库领域有一句流传很广的名言“数据库的性能是设计出来的，而非调优调出来的”，可见<br>设计的重要性。本章将介绍一些常用的数据库设计和应用优化方法。 19.1优化数据表的设计<br>在数据库设计过程中，用户可能会经常遇到这种问题：是否应该把所有表都按照第三范式来设计？表里面的字段到底该设置为多大长度合适？这些问题虽然很小，但是如果设计不当，则会给将来的应用带来很多的性能问题。本节将介绍MySQL中一些数据表的优化方法，<br>其中一些方法不仅仅适用于MySQL，也适用于其他类型的数据库管理系统。 19.1.1优化表的数据类型<br>表需要使用何种数据类型是需要根据应用来判断的。虽然应用设计的时候需要考虑字段的长度留有一定的余，但是不推荐让很多字段都留有大量的余，这样既浪费磁盘存储空间，同时在应用程序操作时也浪费物理内存。<br>在MySQL中，可以使用函数PROCEDUREANALYSEO对当前应用的表进行分析，该函数可以对数据表中列的数据类型提出优化建议，用户可以根据应用的实际情况酌情考虑是否实施优化。<br>以下是函数PROCEDUREANALYSEO的使用方法： SELECT *FROM tbl name PROCEDURE ANALYSEO:<br>SELECT *FROM tb1_name PR0CEDURE ANALYSE(16,256):<br>输出的每一列信息都会对数据表中的列的数据类型提出优化建议。以上第二个语句告诉 PROCEDUREANALYSEO不要为那些包含的值多于16个或者256个字节的ENUM类型提出建议。如果没有这样的限制，输出信息可能很长；ENUM定义通常很难阅读。<br>根据PROCEDUREANALYSEO函数的输出信息，用户可能会发现，一些表中的字段可以修改为效率更高的数据类型。如果决定改变某个字段的类型，则需要使用ALTERTABLE语句。</p>
<p>≦ 345 ≧<br>19.1优化数据表的设计 327<br>下面分析一下表duck_cust的数据类型是否需要优化。<br>（1）首先创建测试表duck_cust，duck_cust表中记录了客户的一些基本信息：<br>drop table duck cust; CREATE TABLE duck cust(<br>cuSt_num MEDIUMINTAUTO INCREMENT，–客户编号 cust_titleTINYINT，–客户标题号<br>cuSt laSt CHAR(2O)NOT NULL，–客户姓氏 cust first CHAR(15) NOT NULL，–客户名<br>cuSt suffix ENUM（’r.,II’,’III’,’IV’,’V’,M.D.,PhD’）, –附加码<br>cuSt_add1 CHAR(30)NOT NULL，–客户地址 cust add2 CHAR（10），–客户地址<br>cuSt city CHAR(18）NOT NULL，–客户所在城市 cust_State CHAR(2） NOT NULL，–客户所在州<br>cuSt Zip1 CHAR(5)NOT NULL，–客户邮编 cust zip2 CHAR(4)，–客户邮编<br>cust duckname CHAR(25) NOT NULL,-客户名称 cust _duckbday DATE，–客户生日<br>PRIMARY KEY (cust num)） ENGINE&#x3D;InnoDB;<br>（2）然后生成一些测试数据：<br>INSERT INTO duck cust VALUES(NULL,1,Irishlord,Red’,III,1022 N.E. Sea of Rye，A207’Seacouver’,wA’，98601,3464,Netrek Rules，1967:10:21′）；<br>INSERT INTO duck cust VALUESNULL,4,Thegreat，Vicki’, NULL,2004 Singleton Dr.，0，’Freedom,ks′，67209′,4321′，Frida Kahlo de Tomayo′,1948:03:21′）;<br>INSERT INTo duck cust VALUES(NULL, 9,Montgomery,Chantel,NULL,1567 Terra Cotta Way， 0,chicago′，’IL’,89129′,4444，Bianca，1971:0729′）;<br>INSERT INTO duck cust VALUESNULL,7,Robert’,David，NULL,20113 Open Road Highway，#6′，‘Blacktop，AZ′，00606′，1952′，‘Harley’，1949:08:00′）;<br>INSERT INTO duck cust VALUES(NULL,5,Kazui,Wonko,PhD,42 Cube Farm Lane’Gatehouse vlimpt,cA,45362′,0,Fitzwhistle,1961:12:04’);<br>INSERT INTO duck cust VALUES(NULL, 6,’Gashlycrumb,Karen’,NULL,3113 Picket Fence Lane 0,Fedora′,vT,41927,5698，Tess D’urbervi11e′,1948:08:19′）<br>这时，查看一下表结构： desc duck cust;<br>|Field Type |Null | Key | Default| Extra<br>Icust num mediumint(9) NO IPRIINULL I auto increment| I cust title 1 tinyint(4) YES INULL Icust last 1char(20) NO NULL<br>Icust_first 1char(15) NO NULL cust suffix enumC’r.,’I,’III’,’V’,V’,M.D.·,’PhD’）| YES NULL<br>Icust addl char(30) NO NULL Icust add2 char(10) YES NULL 1cust city char(18) NO NULL<br>I cust_state char(2) NO NULL Icust zipl 1char(5) NULL cust zip2 char(4) IYES NULL<br>cust duckname | char(25) 1 NO NULL cust duckbday I date IYES NULL<br>（3）使用PROCEDUREANALYSEO函数确定要优化的列： mysqT&gt; SELECT * FROM duck cust PROCEDURE ANALYSEO\G;<br>Field name: sakila.duck cust.cust num<br>Min value:1 Max value:6 Min length:1 Max length: 1<br>Empties or zeros:0<br>Nuls0</p>
<p>≦ 346 ≧<br>328 第19章应用优化 Avg value or avg length: 3.5000<br>std:1.7078<br>Optimal_fie1dtype:ENUM(‘1′,2′,’3′,4′,’5′,’6’) NOT NULL<br>从结果中可以看到test.duck_cust.cust_num列的Min_length、Max_length、Avg_value_or_ avg_length，根据这些统计值，可以对列进行优化，例如，插入的数据最大长度和最小长度都是1，所以，可以优化字段cust_num为mediumint(2)；同时，上面的结果也给出了优化建议”Optimal_fieldtype:ENUM（1,2’,3’’4’,5’,6)NOTNULL”<br>看到这个建议读者可能会觉得很奇怪，怎么给出了枚举类型，而不是我们预期的整型？因为这时分析的测试表记录数太少，使得custname的唯一值太少，因此函数觉得用枚举类型会更合理。如果是对一个大表进行分析，提出的建议会更准确。<br>根据给出的统计信息和优化建议，可以使用如下语句进行字段类型的更改： mysql&gt; alter table duck cust modify cust num mediumint(2);<br>Query ok,6 rows affected (0.03 sec) Records:6Duplicates:0 warnings:0<br>19.1.2通过拆分提高表的访问效率<br>这里所说的“拆分”，是指对数据表进行拆分。如果针对InnoDB类型的表进行，那么有两种拆分方法。<br>（1）第一种方法是垂直拆分，即把主键和一些列放到一个表，然后把主键和另外的列放到另一个表中。<br>如果一个表中某些列常用，而另一些列不常用，则可以采用垂直拆分。另外，垂直拆分可以使得数据行变小，一个数据页就能存放更多的数据，在查询时就会减少I&#x2F;O次数。其缺点是需要管理余列，查询所有数据需要联合（JOIN）操作。<br>（2）第二种方法是水平拆分，即根据一列或多列数据的值把数据行放到多个独立的表或者分区中。<br>水平拆分通常在以下几种情况下使用。<br>表很大，分割后可以降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，提高查询速度。<br>表中的数据本来就有独立性，例如，表中分别记录各个地区的数据或不同时期的数据，特别是有些数据常用，而另外一些数据不常用。<br>需要把数据存放到多个介质上。<br>例如，移动电话的账单表就可以分成多个表或者多个分区。分表的话，可以把最近3个月的账单数据存在一个表中，3个月前的历史账单存放在另外一个表中，超过1年的历史账单可以存储到单独的存储介质上。如果采用分区的话，可以按月分区，并且在查询的时候都带上时间条件，这样大多数查询都只会用到表中一个分区的数据。<br>用分表的方式做水平拆分会给应用增加复杂度，例如拆表通常在查询时需要多个表名，查询所有数据需要UNION操作。在许多数据库应用中，这种复杂性会超过它带来的优点，因为只要索引关键字不大，则在索引用于查询时，表中增加2～3倍数据量，查询时也就增加读一个索引层的磁盘次数，所以水平拆分要考虑数据量的增长速度，根据实际情况决定是否需</p>
<p>≦ 347 ≧<br>19.1优化数据表的设计 329<br>要对表进行水平拆分。而分区相对来说带来的不便会小很多，所以一般来说，如果数据量不<br>是特别大，可以优先采用分区的方式来做水平拆分。 19.1.3逆规范化<br>数据库设计时要满足规范化这个道理大家都非常清楚，但是否数据的规范化程度越高越好呢？这是由实际需求来决定的。因为规范化越高，那么产生的关系就越多，关系过多的直接结果就是导致表之间的连接操作越频繁，而表之间的连接操作是性能较低的操作，直接影响到查询的速度，所以，对于查询较多的应用，就需要根据实际情况运用逆规范化对数据进行设计，通过逆规范化来提高查询的性能。<br>例如，移动电话的用户每月都会查询自己的账单。账单信息一般包含用户的名字和本月消费总金额，设想一下，如果用户的姓名和属性信息存放在一个表中，假设表名为A，而用户的编号和他对应的账单信息存放在另外一张B表中，那么，用户每次查询自己的月账单时，数据库查询时都要进行表连接，因为账单表B中并不包含用户的名字，所以必须通过关联A 表取过来，如果在数据库设计时考虑到这一点，就可以在B表增加一个余字段存放用户的名字，这样在查询账单时就不用再做表关联，可以使查询有更好的性能。<br>反规范的好处是降低连接操作的需求、降低外码和索引的数目，还可能减少表的数目，相应带来的问题是可能出现数据的完整性问题。加快查询速度，但会降低修改速度。因此，决定做反规范时，一定要权衡利弊，仔细分析应用的数据存取需求和实际的性能特点，好的索引和其他方法经常能够解决性能问题，而不必采用反规范这种方法。<br>在进行反规范操作之前，要充分考虑数据的存取需求、常用表的大小、一些特殊的计算（例如合计）、数据的物理存储位置等。常用的反规范技术有增加冗余列、增加派生列、重新组表和分割表。<br>增加余列：指在多个表中具有相同的列，常用来在查询时避免连接操作。<br>增加派生列：指增加的列来自其他表中的数据，由其他表中的数据经过计算生成。增加派生列的作用是在查询时减少连接操作，避免使用集函数。<br>重新组表：指如果许多用户需要查看两个表连接出来的结果数据，则把这两个表重新组成一个表来减少连接而提高性能。<br>分割表：可以参见19.1.2节的内容。<br>另外，逆规范技术需要维护数据的完整性。无论使用何种反规范技术，都需要一定的管理来维护数据的完整性。常用的方法是批处理维护、应用逻辑和触发器。<br>批处理维护是指对复制列或派生列的修改积累一定的时间后，运行一批处理作业或存储过程对复制或派生列进行修改，这只能在对实时性要求不高的情况下使用。<br>数据的完整性也可由应用逻辑来实现，这就要求必须在同一事务中对所有涉及的表进行增、删、改操作。在应用逻辑中控制，可以根据对数据完整性的实际需求来灵活控制，但是对于应用开发来说也会增加一定的复杂度，需要从系统整体需求综合考虑。<br>另一种方式就是使用触发器，对数据的任何修改立即触发对复制列或派生列的相应修改。触发器是实时的，而且相应的处理逻辑只在一个地方出现，易于维护。这也是解决这类问题的一种思路。</p>
<p>≦ 348 ≧<br>330 第19章应用优化<br>19.2数据库应用优化 19.2.1使用连接池<br>对于访问数据库来说，建立连接的代价比较昂贵，因此，我们有必要建立“连接池”以提高访问的性能。从名字上理解，“连接池”是一个存放“连接”的“池子”，再具体一些，我们可以把连接当作对象或者设备，统一放在一个“池子”里面，以前需要直接访问数据库的地方，现在都改为从这个“池子”里面获取连接来使用。因为“池子”中的连接都已经预先创建好，可以直接分配给应用使用，因此大大减少了创建新连接所耗费的资源。连接返回<br>后，本次访问将连接交还给“连接池”，以供新的访问使用。 19.2.2减少对MySQL的访问<br>在实际应用中，我们的硬件资源通常是有限的、无法扩充的。这种情况下，应用有什么措施能减少对数据库的访问呢？本节将向大家介绍一些简单的方法。<br>1.避免对同一数据做重复检索<br>应用中需要厘清对数据库的访问逻辑。能够一次连接就能够提取出所有结果的，就不用两次连接，这样可以大大减少对数据库无谓的重复访问。<br>例如，在某应用中需要检索某人的年龄和性别，那么就可以执行以下查询： select old,gender from users where userid &#x3D; 231;<br>之后又需要这个人的家庭住址，可以执行： select address from users where userid &#x3D; 231;<br>这样，就需要向数据库提交两次请求，数据库就要做两次查询操作，其实完全可以用一<br>句SQL语句得到想要的结果，然后把得到的结果放到变量中已备后用，比如： Select old,gender,address from users where userid &#x3D; 231;<br>不管读者是否相信，由于上面的原因导致的性能问题，在很多应用系统中都存在，因此在厘清应用逻辑并向数据库提交请求前进行深思熟虑是很有必要的。<br>2.增加CACHE层<br>在应用中，我们可以在应用端加CACHE层来达到减轻数据库负担的目的。CACHE层有很多种，也有很多种实现的方式，只要能达到降低数据库的负担又能满足应用就可以，这就需要根据应用的实际情况进行特殊处理。<br>比如，可以把部分数据从数据库中抽取出来放到应用端以文本方式存储，然后如果有查询需求，可以直接从这个“CACHE”中检索。由于这里的数据量小，所以能够达到很高的查询效率，而且也减轻了数据库的负担。当然这种方案还涉及很多其他问题，比如如果有数据更新怎么办、多长时间刷新一次“CACHE”等，都需要根据具体应用环境进行相应的处理。<br>再比如用户可以在应用端建立一个二级数据库，把访问频度非常大的数据放到二级库上，然后设定一个机制与主数据库进行同步，这样用户的主要操作都在二级数据库上进行，大大地降低了主数据库的压力，各种NoSQL数据库，例如Redis等，都可以很方便地充当这种二级数据库的角色。</p>
<p>≦ 349 ≧<br>19.3小结 331<br>各种“CACHE”层的实现方式不同，这里只是抛砖引玉，给读者一个解决问题的思路，<br>不可千篇一律地照搬照抄。 19.2.3负载均衡<br>负载均衡（LoadBalance）是实际应用中使用非常普遍的一种优化方法，它的机制就是利用某种均衡算法，将固定的负载量分布到不同的服务器上，以此来减轻单台服务器的负载，达到优化的目的。负载均衡可以用在系统中的各个层面中，从前台的Web服务器到中间层的应用服务器，最后到数据层的数据库服务器，都可以使用。本节主要介绍MySQL数据库端的一些负载均衡方法。<br>1.利用MySQL复制分流查询操作<br>利用MySQL的主从复制（具体介绍见第30章）可以有效地分流更新操作和查询操作。具体的实现是一个主服务器承担更新操作，而多台从服务器承担查询操作，主从之间通过复制实现数据的同步。多台从服务器一方面用来确保可用性，另一方面可以创建不同的索引，以满足不同查询的需要。<br>对于主从之间不需要复制全部表的情况，可以通过在主服务器上搭建一个虚拟的从服务器，将需要复制到从服务器的表设置成BLACKHOLE引擎，然后定义replicate-do-table参数只复制这些表，这样就过滤出需要复制的BINLOG，减少了传输BINLOG的带宽。因为搭建的虚拟从服务器只起到过滤BINLOG的作用，并没有实际记录任何数据，所以对主数据库服务器的性能影响也非常有限。<br>通过复制来分流查询是减少主数据库负载的一个常用方法，但是这种办法也存在一些问题，最主要的问题是当主数据库上更新频繁或者网络出现问题的时候，主从之间的数据可能存在比较大的延迟更新，从而造成查询结果和主数据库上有所差异。因此应用在设计的时候需要有所考虑。<br>2.采用分布式数据库架构<br>品分布式的数据库架构适合大数据量、负载高的情况，它具有良好的扩展性和高可用性。<br>通过在多台服务器之间分布数据，可以实现在多台服务器之间的负载平均，提高了访问的执行效率。具体实现的时候，可以使用MySQL的CLUSTER或者第三方中间件来实现读写分离、数据分片、全局事务等功能。第31章和第32章将详细介绍常用的高可用架构和中间件产品。<br>19.3小结<br>本章介绍了在数据库设计和应用层面的优化。数据表的设计是一个数据库设计的基础，一旦数据库设计完毕并投入使用，将来再进行修改就比较麻烦，因此，在数据库设计时一定要尽可能地考虑周到。<br>数据库使用方式的优化也是数据库优化的重要组成部分，数据库本身的优化有一定的局限性，到了一定程度就很难再有大的提升，但是如果从使用方式的角度进行考虑，那么还有很多可以优化的内容。我们从连接池、减少数据库访问、负载均衡以及CACHE层等方面进行了讨论。<br>应用层优化的方面还有很多与应用本身密切相关，这些内容需要读者在实际应用环境中不断总结、不断积累经验才能达到更好的优化效果。</p>
<p>≦ 350 ≧<br>第20章 PSISYS数据库<br>MySQLPerformanceSchema（PS）和SYSSchema是MySQL官方提供的，可以用来监控性能和诊断故障。<br>PS库主要用于收集数据库运行时的性能数据，通过充分利用PS库表的数据，让DBA 更了解数据库的运行状态，也有助于排查定位问题。PS数据库最早出现在MySQL5.5中，默认关闭信息收集，需要手动开启。PS库自出现以来，在每一个MySQL版本都有增强。在 MySQL5.6中，默认打开PS库信息收集。而MySQL5.7的PS库中添加了更多的监控项，如内存监控、复制信息、metadatalock监控等，统计信息更加丰富，功能跟Oracle的awr也越来越像。到了MySQL8.0版本，PS库表又添加了索引，极大地加快表的查询速度。<br>MySQL从5.7.7版本开始提供SYS库，DBA和开发同学可以使用SYS库进行数据库的性能调优和问题诊断。SYS 库除了sys_config表，其他都是视图，视图的数据来源于PS 库和 IS（information_schema）库，也就是说，SYS库本身既不采集数据也不存储数据（sys_config<br>表除外）。引人SYS库是为了以更直观、更易懂的方式展示PS库和IS库的信息。 20.1Performance Schema 库<br>本节主要介绍PerformanceSchema（PS）库的使用和表用途。 20.1.1如何开启PS库<br>PS库在MySQL5.6之后的版本是默认开启的。如果需要手工开启或者关闭PS库，可以<br>在my.cnf文件修改相应配置，例如添加以下参数，开启PS库：[mysq1d]<br>performance_schema&#x3D;ON<br>在MySQL实例中确认PS库是否已开启： mysql&gt;SHOw VARIABLES LIKE ‘performance schema’;<br>|Variable_name Ivalue丨<br>I performance schema l oN row in set (o.00 sec)<br>从查询结果上看，performance_schema参数的值为ON，表明当前实例已经开启PS库。</p>
<p>≦ 351 ≧<br>20.1Performance Schema库 333<br>PS 库的开启或者关闭，需要修改配置文件后重启实例生效。如果想在线修改performance_ schema参数的值，则会报错：<br>mysql&gt;set global performance_schema&#x3D;off;<br>ERROR 1238 (HY000): Variable ‘performance schema’is a read only variable 20.1.2PS库的表<br>PS库的表使用PERFORMANCE_SCHEMA存储引擎，可以使用showcreate table tablename命令查看表的结构，例如查看accounts表结构：<br>mysql&gt;show create table accounts\G ★★**★<br>Table: accounts<br>Create Table: CREATE TABLE accounts<br>USERchar(32) CHARACTER SET utf8 COLLATE utf8 bin DEFAULT NULL, HOST char(6O) CHARACTER SET utf8 COLLATE utf8 bin DEFAULT NULL,<br>CURRENT CONNECTIONSbigint(2O) NOT NULL, TOTAL CONNECTIONSbigint(2O) NOT NULL<br>) ENGINE&#x3D;PERFORMANCE_SCHEMA DEFAULT CHARSET&#x3D;Utf8 1 row in set (o.00 sec)<br>在MySQL5.7中，PS库一共有87个表。PS 库的setup表保存了监控的配置数据：<br>mysql&gt;SELECT TABLE NAME FROM INFORMATION SCHEMA.TABLES WHERE TABLE SCHEMA &#x3D;performance schema AND TABLE NAME LIKE ‘Setup%’;<br>|TABLE NAME setup_actors<br>Isetup_consumers setup_instruments<br>setup_objects Isetup_timers<br>5 rows in set (o.00 sec)<br>setup_actors表用于配置新的线程的监控状态，默认监控所有用户： mysql&gt;select * from setup actors;<br>|HOST IUSER | ROLE| ENABLED IHISTORY<br>1% 1% YES YES 1row in set-(0.00 sec)<br>setup_consumers表存放所有的事件消息的消费者类型以及事件的开启状态： mysql&gt;select * from setup_consumers;<br>INAME IENABLED<br>events_stages_current I NO events stages history INO<br>events stages_history_long INO Ievents_statements_current YES<br>Ievents statements history YES events_statements_history_Tong INO<br>events_transactions_current NO Ievents transactions history NO<br>Ievents_transactions_history_long NO events waits_current NO<br>events_waits_history NO events_waits_history_long NO<br>global_instrumentation YES thread_instrumentation YES Istatements_digest YES</p>
<p>≦ 352 ≧<br>334 第20章PS&#x2F;SYS数据库 15rows in set(o.o0 sec)<br>setup_instruments表存放6种类型（idle、wait、stage、statement、transaction和memory）<br>相关的instrument对象以及对象的开启状态： mysql&gt;select * from setup_instruments;<br>1NAME IENABLED TIMED wait&#x2F;synch&#x2F;mutex&#x2F;sq1&#x2F;TC LOG MMAP::LOCK tC NO 1 NO 1wait&#x2F;synch&#x2F;mutex&#x2F;sql&#x2F;Lock des_key_file NO INO 1memory&#x2F;sql&#x2F;servers_cache 1NO 1memory&#x2F;sql&#x2F;udf mem NO NO memory&#x2F;sql&#x2F;relay_log info::mts_coor NO NO 1wait&#x2F;lock&#x2F;metadata&#x2F;sql&#x2F;md7 YES YES<br>1030 rows in set (0.01 sec)<br>setup_objects存放对象和所属db的监控列表，setup_timers存放的是instrument对象所使用的timer类型。<br>对于上面的配置信息，除非有特殊的需求，一般来说使用默认项即可。<br>PS库按照各个维度对数据库进行性能监控，包括事件、文件使用、内存使用、复制相关、会话统计、socket使用、表相关和锁等维度，其中事件包括阶段事件、语句事件、事务事件和等待事件，如表20-1所示。<br>表20-1 PS库用来对数据库进行性能监控的统计维度统计维度关键字 主要功能<br>阶段事件%stages% 记录线程监视的阶段事件的状态语句事件%statements% 记录线程监视的语句事件的状态<br>事务事件%transactions% 记录线程监视的事务事件的状态等待事件%waits% 记录线程监视的等待事件的状态<br>文件使用%file% 汇总有关I&#x2F;O操作的信息内存使用%memory% 检测内存使用和聚合内存使用统计复制统计%replication% 记录多源复制和MGR的信息<br>会话统计%session% 记录会话的属性和连接的状态参数 socket使用%socket% 记录活跃会话对象实例<br>表使用%table% 按照表和索引聚合每个表的I&#x2F;O操作<br>锁统计%lock% 记录持有读写锁的记录和汇总表的锁等待信息<br>使用下面的SQL结合表20-1中的关键字可以找到对应统计维度的表，例如查看阶段事件相关的表：<br>mysql&gt; select table_name from information_schema.tables<br>where table schema &#x3D;performance schema’and table name like %stages%’; TABLE NAME<br>events stages current I events_stages_history<br>events stages_history_long<br>events stages_summary by account by_event_name events _stages summary by host by_event name events stages summary_by_thread by_event_name events stages summary by user by_event _name I events stages summary global by event name</p>
<p>≦ 353 ≧<br>20.2SYS库 335<br>8rows in set (o.00 sec)<br>查询结果包含3种不同维度的数据。<br>当前事件表：表名含有“current”，当前表包含每个线程的最新事件。<br>历史事件表：表名含有“history”，历史表与当前表结构相同，但包含更多行。例如， events_stages_history表包含每个线程最近的10个事件。events_stages_history_long包含最近 10000个事件。<br>汇总表：表名含有“summary”，汇总表包含通过事件聚合的信息，包括已经从历史<br>记录表中丢弃的事件。 20.2SYS库<br>本节主要介绍SYS库的对象和用途。 20.2.1SYS库的对象<br>SYS库中的对象按照名称划分，一种是以字母开头，另一种是以x$开头。比如 host_summary和xShost_summary，两者的底层数据是一样的，区别是host_summary对某些字段进行了格式化处理，方便阅读；xShost_summary直接展示了原始采集的数据，方便对数据进行二次加工。<br>SYS库的对象主要基于PS库，所以SYS库的监控维度跟PS库类似，主要包括主机相关、 innodb相关、io相关、内存相关、连接数和会话、db相关、SQL语句相关和等待事件相关，如表20-2所示。<br>表20-2 SYS库的统计维度统计维度关键字 主要功能<br>主机 host%和xShost% 按照主机维度汇总全局信息、文件IO信息和语句信息<br>innodb相关 innodb%和xSinnodb% 统计innodb缓冲池信息和锁等待信息 io相关 10%和x$io% 按照线程、文件和等待事件维护统计IO操作信息<br>内存 memory%和x$memory% 按照主机、线程、用户和全局维度统计内存信息<br>连接和会话%processlist%和%session% 记录连接和会话信息<br>db schema%和x$schema% 从db角度统计索引、锁和表的信息 SQL语句 statement%和xSstatement% 从表的维护汇总排序、全表扫描等信息等待事件 wait%和x$wait% 按照主机、用户、用户和全局维度统计内存信息<br>同上类似，使用下面的SQL结合表20-2中的关键字可以找到对应统计维度的对象，例如主机相关的表：<br>mysql&gt; select table name from information schema.tables where table schema &#x3D;’sys’and (table name like host%or table name like ‘x$host%’);<br>I table name I host summary<br>host_summary_by_file_io<br>host summary_by_file_io_type I host _summary_by_stages</p>
<p>≦ 354 ≧<br>336 第20章PS&#x2F;SYS数据库<br>I host summary_by_statement latency<br>host_summary_by_statement_type x$host_summary<br>1xshost summary by_file io<br>x$host_summary_by_file_io_type x$host_summary_by_stages<br>|xShost summary by_statement latency|<br>I xshost_summary_by_statement_type 12 rows in set (o.01 sec)<br>查询结果中如果包含“summary”字样，都属于汇总表，即通过特定事件来聚合信息。 20.2.2SYS对象的实际应用<br>SYS的对象基于PS库和IS库进行了整合，并格式化输出，所以直接查询SYS库将会更方便，结果也更直观。在实际工作中，通过查询SYS库的对象获取信息，可以对连接会话、表的使用、内存等进行优化。本节主要介绍SYS库的实际应用。<br>1.主机相关<br>以连接mysql实例的host为第一维度，分析文件的io等待时间、文件io的等待事件、<br>SQL语句的查询时间等信息。例如host_summary： mysql&gt;select *from host_summary\G<br>host:192.168.1.62 statements: 29760<br>statement_latency:8.76w statement avg_latency:2.97 m<br>table_scans:5424 file_ios:139382<br>file io 1atency: 12.22 s<br>current connections:1 total connections:83<br>unique users:2<br>current memory:o bytes<br>total memory allocated:0 bytes 该类对象比较重要的字段如下。<br>host:连接到MySQL实例的主机IP。<br>0 statements：主机IP执行总的SQL语句数量。<br>tatement_latency：主机IP执行SQL语句消耗的总时间。 0<br>o file_io_latency：主机IP发生文件等待事件消耗的总时间。<br>current_connections:主机IP当前总的连接数。 current_memory：实例为主机IP当前分配的内存。 0<br>通过上面的信息，我们了解到主机IP为192.168.1.62的连接，执行了29760条SQL语句，执行这些语句一共消耗了8.76w（w为week的简称），文件等待事件消耗总时间是12.22s，当前连接数只有一个，消耗了0byte的内存。如果发现上面某个维度的信息有异常，可以再进一步进行分析。<br>2.innodb相关<br>该类对象分为两部分，其中innodb_buffer_stats_by_%用于分析哪些对象占用缓冲池的内存比较多；另一类innodb_lock_waits用于行锁等待分析，得到阻塞和被阻塞的会话信息。</p>
<p>≦ 355 ≧<br>20.2SYS库 337<br>下面从表的维度，分析缓冲池使用情况。<br>mysql&gt;select * from innodb buffer stats by_table order by pages desc 1imit 1\G<br>☆*☆★★<br>object schema: employees object name: salaries allocated:143.61 MiB<br>data:132.74 MiB pages: 9191<br>pages_hashed:75 pages_o1d:5403<br>rows_cached:2841496<br>通过上面的结果，可以看到employees.salaries表占用了缓冲池143MB的内存，这样就找到了占用缓冲池内存最多的对象。<br>通过下面的例子，看看innodb_lock_waits怎么帮助用户分析行锁等待。<br>第一个会话，开始事务，根据主键更新employees.departments表的一行记录。<br>mysql&gt;use employees Database changed<br>mysql&gt;start transaction;<br>Query ok,0 rows affected (o.01 sec)<br>mysql&gt;update departments set dept name&#x3D;’Repair service’where dept no&#x3D;’doo9; Query ok, 1 row affected (0.14 sec)<br>Rows matched:1changed:1 warnings:0<br>第一个会话的事务未提交，接着开启第二个事务，更新同一行记录。为了方便观察，设置事务锁超时时间为1000s。<br>mysql&gt;set session innodb_lock wait_timeout&#x3D;1000:<br>Query ok,0 rows affected (o.oo sec) mysql&gt;start transaction:<br>Query ok,0 rows affected (o.oo sec)<br>mysql&gt;update departments set dept name&#x3D;’Customer Service’ where dept no&#x3D;’doo9’；第二个会话被第一个会话阻塞，查询innodb_lock_waits得到详细的会话信息： mysql&gt;select * from innodb_lock waits\G<br>wait started:2018-09-25 12:27:19 wait age secs:19<br>locked table:employees.departments<br>locked index: PRIMARY 1ocked type: RECORD waiting trx_id:571091<br>waiting_trx_started:2018-09-25 12:27:19<br>waiting trx_age:00:00:19<br>waiting pid:691<br>waiting_query: update departments set dept na ..service’ where dept no&#x3D;’doog<br>blocking_trx_id:571090 blocking pid:690<br>sql ki1l blocking_query: KILL QUERY 690<br>sql kill blocking connection:KILL 690 1 row in set,3 warnings (0.01 sec)<br>结果显示，第一个会话（blocking）阻塞第二个会话（waiting）。第一个会话的ID（blocking_pid）是690，第二个会话的ID（waiting_pid）是691。提交第一个事务，或者执行命令KILLQUERY690把第一个事务会话杀掉，第二个会话的事务就可以正常执行了。</p>
<p>≦ 356 ≧<br>338 第20章PS&#x2F;SYS数据库<br>3.连接数和会话相关<br>对象sys.processlist 和 sys.session的信息比information_schema.processlist全面，其中<br>sys.session去除了后台线程的信息，只保留了用户会话的信息。 mysql&gt;select * from session\G<br>***********1.rw<br>thd id:727 conn_id:693<br>user: root@localhost db:employees<br>command:sleep state: NULL time:2<br>current statement: NULL statement latency: NULL<br>progress: NULL<br>lock 1atency: 160.00 us rows_examined:2834339 rows sent:1<br>rows affected:0<br>tmp_tables:0 tmp disk tables:0<br>full scan: NO<br>last statement: select count(o) from salaries<br>last statement latency: 991.52 ms<br>current memory:o bytes<br>last wait: NULL<br>last wait latency: NULL<br>source: NULL trx latency: NULL trx_state: NULL<br>trx_autocommit: NULL<br>pid:17956<br>program name: mysq1<br>查询 sys.session，可以得到会话的ID、连接用户信息、连接时间、查询影响行数、返回行数，最后执行SQL等信息。<br>4.db相关<br>以表为第一维度，分析表和索引的使用情况。<br>查询schema_redundantindexes表，可以找出余的索引。按照最左原则找出余的索引l，例如表A有3个索引l，index1(a,b)、index2（a)和index3(b)。index1最左边第一个字段包含了 index2，所以index2是余的索引l，建议删掉，最后剩下index1和index3索引。例如， employees表结构如下：<br>mysql&gt;show create table employees\G<br>Table: employees<br>Create Table: CREATE TABLE employees（<br>emp_noint（11) NOT NULL, birth_date date NOT NULL,<br>first name  varchar(14) cOLLATE utf8 unicode ci NOT NULL, last name varchar(16) cOLLATE utf8 unicode ci NOT NULL, genderenum(‘M’,’F’) cOLLATE utf8 unicode ci NOT NULL,<br>hire date date NOT NULL, PRIMARY KEY (emp no),<br>KEYidx birth date（birth date），<br>KEY idx birth_date gender（birth dategender）<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 cOLLATE&#x3D;utf8 unicode ci 1 row in set (0.00 sec)<br>可以看到KEYidx_birth_date’（birth_date）和KEYidx_birth_date_gender’（birth_date，</p>
<p>≦ 357 ≧<br>20.2SYS库 339<br>‘gender)功能重复了，我们再来看看schema_redundantindexes表的信息： mysql&gt;select * from schema redundant indexes limit 2\G<br>table_schema:employees table_name:employees<br>redundant_index name: idx birth date<br>redundant_index columns:birth date redundant index non unique:1<br>dominant_index name: idx birth date gender dominant_index columns: birth date,gender dominant index non unique:1<br>subpart_exists:0<br>sql drop index: ALTER TABLE employees.employeesDROP INDExidx birth_date<br>2 rows in set (0.01 sec)<br>MySQL建议删除idx_birth_date索引l，并在sql_drop_index列给出删除索引引的完整命令。查询schema_table_statistics表，得到实例启动以来，每个表的详细使用情况。<br>mysql&gt;select * from schema table statistics order by rows_ fetched + rows_inserted+ update latency+rows deleted desc limit 1\G<br>table schema: employees table name: salaries total latency:5.02m rows_fetched:145870818 fetch_1atency:5.02m<br>rows_inserted:0 insert latency:0 ps rows updated:4<br>update 1atency:25.30 ms rows deleted:4047<br>delete_1atency:69.57 ms io_read_requests: 39785<br>io read:4.10 MiB<br>io_read 1atency:97.74 ms io_write_requests: 9352<br>1o write:145.75 MiB<br>io write 1atency:141.26 ms io misc_requests: 34356<br>io misc latency:213.81 ms 1 row in set(0.05 sec)<br>按照表增删改查的总行数进行倒序排序，找到写操作影响行数最多的表。日常优化过程中，通过调整影响行数和执行时间的组合规则，可以找出符合规则的热点表，然后进行优化，提高数据库实例的整体性能。<br>5.SQL语句相关<br>按照多个维度分析SQL执行情况。分析维护有全表扫描次数、是否经历排序、是否创建临时表等。<br>例如，statement_analysis表：<br>mysql&gt;select * from statement_analysis where rows examined &gt; 0 and rows_affected &gt; 0 order by exec_count desc limit 1\G<br>query:uPDATEpercona.checksums.. ANDtbl&#x3D;?ANDchunk&#x3D;? db:employees<br>full scan:<br>exec_count: 2034 err_count:0 warn count:0<br>total_1atency:7.12 s max_1atency:448.02 ms avg_latency:3.50 ms lock 1atency:235.85 ms</p>
<p>≦ 358 ≧<br>340 第20章PS&#x2F;SYS数据库<br>rows sent:0 rows_sent avg:0 rows examined:2034<br>rows examined avg:1<br>rows_affected:2034 rows affected avg:1<br>tmp_tables:0 tmp_disk_tables:0<br>rows_sorted0<br>sort merge_passes:0<br>digest:42e6500228e8aab2ecfe255339c0fd63<br>first_seen:2018-08-07 21:29:48 last_seen: 2018-08-20 22:53:15<br>row in set (o.02 sec)<br>该类对象比较重要的字段如下。<br>0 query：替换SQL语句变量并美化。 0 db：应用执行SQL时连接的db名。<br>exec_count:SQL执行总次数。 0<br>0 rows_examined：SQL执行查询的总记录数<br>rows_affected：SQL执行影响的总记录数。<br>通过上面的信息，得到SQL的执行次数、影响行数、创建临时表次数和排序记录数。如果有异常的指标，则可以进一步分析和优化。<br>20.3 小结<br>PS库从多个维度收集数据库实例运行的性能信息，SYS库通过对PS库和IS库的封装，让我们能更方便查询这些性能信息。合理使用PS库和SYS库的信息，将为我们的调优之路带来很大的便利。</p>
<p>≦ 359 ≧<br>第21章 故障诊断<br>MySQL的故障诊断，需要对整个系统的架构、硬件、软件都有比较深人的了解，由于数据库服务的特点，一旦出现问题，可能影响整个系统的可用性，需要在最短的时间内解决。<br>在这一章，笔者会结合自身的经验，对处理常见故障的一般性原则、流程和方法做一下介绍，并列举了两个实际处理故障的例子，希望能够为读者提供一些在处理故障时候的思路。当然、实际工作中遇到的故障多种多样，书中不可能完全覆盖，需要读者在解决问题的过程中，不断积累经验。<br>21.1 故障诊断和处理的原则<br>（1）沟通第一<br>数据库只是整个应用系统的一个组成部分，任何故障都不会仅限于数据库层面，数据库出了问题，也可能会导致其他系统组件出现问题，同时，数据库的故障本身也可能是由系统的其他部分带来，所以在数据库出现故障时候，务必和运维、开发、产品等其他团队保持高效沟通。<br>沟通的内容主要包括以下几个方面。<br>及时和团队内其他DBA沟通情况，寻求信息和协助。其他人可能之前处理过类似故障，也可能知道故障的原因，至少能帮忙一起想办法尽快解决问题。多人协作过程中，为了提高效率，最好对人员做合理分工，主DBA作为核心处理者，可以给其他DBA分配任务，比如有的负责和开发沟通、有的负责查各类日志、有的负责查官方BUG，重大故障还要及时通知DBA经理，由他来和其他团队的负责人以及上级领导沟通，以协调所需资源。<br>〇告知其他团队当前故障的情况、具体故障报错等，方便大家共同判断可能的原因以及可能造成的结果。例如，如果负责用户登录认证的数据库出现故障，那么及时通知其他团队，其他团队一方面可以帮忙判断当前对于数据库的访问量、访问方式是否有异常，也可以更直接地判断当前数据库故障到底会影响用户的哪些访问行为。<br>●获取其他团队的信息和帮助，结合用户反馈、故障现象、应用层报错等，通常可以更加容易地判断故障原因。例如，如果应用层报出的是数据库连接错误，那么就需要重点从数据库连接的相关设置和session的状态上做排查。此外，完成故障定位后，在解决故障的过程中，也能从其他团队那里得到支持，例如，开发和运维团队可以帮忙暂时屏蔽部分非关键</p>
<p>≦ 360 ≧<br>342 第21章故障诊断<br>服务，降低数据库的压力；产品和客服团队可以及时通知用户可能存在的问题，引导用户的访问行为等。这些都可以在一定程度上帮助DBA尽快解决问题，并为DBA争取到处理故障的宝贵时间。<br>沟通故障处理方案和进度，确定处理方案之后要及时告知其他团队，并对可能的影响、影响的范围和时间等进行说明。有的方案需要由相关团队的人员共同确认后才可以执行。例如：需要重启数据库，那么重启的时间是否可以接受；如果可能导致短期或长期的数据丢失，是否可以接受等，这些都不能只靠DBA单独做出判断。此外，如果故障不能在短时间内排除，解决的过程中也要对处理进度保持持续沟通。<br>沟通故障处理结果和预防措施，故障处理完成之后，对于故障处理的结果和预防措施要做充分的沟通，例如故障是彻底解决还是临时解决，数据是否有损失等都需要知会所有相关人员。此外，为了避免此类故障所要采取的改进的措施，往往也需要其他团队配合完成，例如逻辑调整、代码优化、网络优化、集群扩容、硬件升级等。<br>总之，DBA在遇到故障时，一定不要忘了沟通的重要性，即使时间紧迫，简要的沟通往往也能带来事半功倍的效果。从长远来看，也有利于培养和其他人、其他团队之间的合作和信任关系。<br>（2）关注人为故障。<br>在作者处理过的故障中，人为故障占了不小的比例。在手工运维的时代，人为故障所占的比例更高，所以在数据库出现故障时，要意识到这很有可能是由于当前操作所导致的。要通过及时沟通并查看操作系统和数据库历史记录，确认自己和其他DBA的操作是否有误、要和其他团队沟通是否有特殊操作、要去检查系统和数据库的参数是否符合预期。“某某系统、数据库有什么操作么”这句话永远是要第一时间问出来的。<br>当然，解决人为故障最好的方法还是将数据库运维自动化、标准化、规范化。随着自动化运维系统越来越广泛的应用，人为操作造成的故障已经逐渐减少，然而再自动化的系统也不可能覆盖到100%的操作，自动化的系统也一定会存在BUG，又由DBA在自动化运维系统中的操作触发。总之，人为故障永远是不可忽视的一个重要问题来源。<br>（3）快速解决问题、恢复服务优先。<br>在处理故障的时候，要明确的一个思路是要优先恢复服务，确保服务的最大可用性，其他的不一定要优先考虑。例如：是否完全确定了故障原因，解决方案是否完美、简洁，故障责任谁来承担等。<br>（4）三思而后行，不做破坏性操作。<br>有些故障处理的方式，有可能对数据库造成难以恢复的影响，例如删除数据库中的某个文件、truncate表等，做这些操作之前，务必要谨慎，并尽量做好备份。<br>而有些故障处理时候的操作，一般只有在出现故障时才会去做。可能由于对这些操作本身不熟悉带来额外的问题。因此，处理故障时候，不管是通过自已分析、他人建议，还是网上搜索得到的操作命令，一定要认真考虑一下这个命令可能带来的后果，避免对系统带来二次伤害。<br>（5）服务分级。<br>平时应当对服务、应用、DB做好分级，一旦出现大面积故障，可以按照服务的优先级来恢复核心业务。</p>
<p>≦ 361 ≧<br>21.2故障处理一般流程 343<br>21.2故障处理一般流程<br>本节按照发现一定位→解决的顺序，对故障处理的一般流程和关键点做一下简单介绍。 21.2.1故障发现<br>发现依赖于监控，对于数据库服务，一定要构建一套完整的监控系统，在出现问题的时候，能够通过邮件、短信、电话等形式将报警信息发送给DBA和其他相关人员，比故障更可怕的是，出现了故障还没人知道。数据库监控一般应该包括以下几个指标。<br>1.操作系统层面的指标（1）负载。<br>负载是衡量一个服务器整体压力最直观的指标，代表平均有多少进程在等待被CPU调度，<br>可以通过w、uptime、top等命令来获取。[root@hz 10 120 240251<del>]#uptime<br>10:58:23 up 685 days, 23:37,1 user, 1oad average: 0.06,0.12,0.15<br>loadaverage后面的3个数值，分别代表1min平均负载、5min平均负载、15min平均负载。假设服务器的CPU有n个核，那么所有CPU都在满负荷运转时，负载就是n。一般来说，健康的系统，负载应该保持在nx0.7以下，负载超过n之后就意味着系统开始拥塞。<br>负载的报警阈值，通常应该根据系统正常状况下的负载来制定。当系统负载显著升高时，即使还未发生拥塞，也应该及时排查原因，防患于未然。<br>（2）CPU使用率。<br>CPU使用率可以通过top或者sar等命令获取：[root@hz 10 120 240 251</del>]#sar-u-PALL-C11<br>Linux 2.6.32-504.e16.x86_64 (hz 10 120 240 251) 11&#x2F;12&#x2F;18 x8664_(8 CPU) 15:35:15 CPU%user%nice%system%iowait%steal%idle 15:35:16 al1 5.22 0.00 3.05 0.89 0.00 90.84 15:35:16 6.38 0.00 4.26 6.38 0.00 82.98<br>15:35:16 1 5.10 0.00 5.10 0.00 0.00 89.80 15:35:16 2 8.08 0.00 2.02 0.00 0.00 89.90 15:35:16 3 8.16 0.00 2.04 0.00 0.00 89.80<br>15:35:16 4 4.08 0.00 2.04 0.00 0.00 93.88 15:35:16 5 5.00 0.00 2.00 0.00 0.00 93.00 15:35:16 6 4.95 0.00 1.98 0.00 0.00 93.07<br>15:35:16 7 3.06 0.00 2.04 0.00 0.00 94.90 其中sar后的参数含义分别如下。<br>0-u:统计CPU数据。-P：统计每个核的信息。<br>ALL：展示CPU的所有指标。-C：显示注释信息。<br>11：每一秒做1次采集，总共采集1次。<br>结果中%idle表示CPU的空闲率，100%减去%idle就是CPU的使用率。如果服务器有多个CPU，那么会分别计算每个CPU的使用率和所有CPU的平均使用率。对于CPU使用率的监控，一般优先考虑监控全部CPU的平均使用率即可。一旦发现全部CPU的平均使用率过</p>
<p>≦ 362 ≧<br>344 第21章故障诊断<br>高，再进一步分析到底是消耗在user、system还是iowait上。<br>（3）磁盘空间。<br>磁盘空间可以通过df-h命令来获取，-h表示结果用最佳可读方式展现。磁盘空间满会直接导致数据库服务不可用，如果是根目录满的话，还会导致服务器登录困难，进一步影响故障处理速度。因此，建议对磁盘的所有分区都进行监控。监控的目标除了给DBA留下足够的时间来完成清理或者扩容操作之外，最好还能够对磁盘空间的异常变动进行提醒。<br>（4）I0使用率。<br>作为IO密集型服务，IO使用率是数据库监控中的重要指标，IO使用率可以通过iostat 命令来获取：<br>[root@hz 10 120_240 251<del>]#iostat -xd 22<br>Linux2.6.32-504.e16.x86_64 (hz 10 120_240 251) 11&#x2F;12&#x2F;18 x8664 (8CPU) Device: rrqm&#x2F;s wrqm&#x2F;s r&#x2F;s w&#x2F;s rsec&#x2F;s wsec&#x2F;s avgrq-sz avgqu-sz await r_await w_await svctm  %util<br>sda 0.09186.24 3.56 35.43 131.551773.38 48.85 0.03 0.86 5.11 0.44 0.481.87<br>sdb 0.08 66.01 11.31 218.52 6150.59 6753.95 56.15 0.02 0.07 2.82 0.26 0.296.68<br>sdc 0.01 72.73 0.58 53.09 22.07 1137.95 21.62 0.04 0.67 4.01 0.63 0.231.26<br>Device: rrqm&#x2F;swrqm&#x2F;s r&#x2F;s w&#x2F;s rsec&#x2F;s wsec&#x2F;s avgrq-sz avgqu-sz await rawait w await svctm %uti1<br>sda 0.00 4.50 0.00 3.00 0.00 60.00 20.00 0.00 0.00 0.00 0.00 0.000.00<br>sdb 0.00 56.00 0.00 8.00 0.00 512.00 64.00 0.00 0.25 0.00 0.25 0.190.15<br>sdc 0.00 142.50 0.00 394.00 0.00 4292.00 10.89 0.02 0.07 0.00 0.070.051.80<br>其中，-xd表示显示扩展信息和设备的利用率信息（%util），“22”表示每2s统计一次，总共统计两次。这里需要优先关注的是最后一列%util，当这一列接近100%时，代表磁盘的 IO能力已经达到极限，需要DBA从IO层面关注故障的原因。<br>（5）SWAP使用情况。<br>当系统内存不足的时候，操作系统会从SWAP分区中分配一部分空间来临时保存一部分原本计划保存在内存中的数据。由于SWAP分区实际上是保存在磁盘上，而磁盘的读写速度远远低于内存，因此，一旦发生SWAP，往往伴随着系统整体性能的大幅下降。在Linux系统<br>中，可以使用free或者top等命令来检查SWAP的使用情况：[root@hz_10 120 240_251</del>]# free -g<br>total used free shared buffers cached<br>124 1<br>Mem: 126 0 27-&#x2F;+ buffers&#x2F;cache: 96 29 Swap: 31<br>其中，-g参数表示结果以GB为单位。由于数据库的性能对IO依赖比较大，理想的状况，下，应该通过合理的设置内存参数，避免系统使用SWAP分区。对于SWAP的监控，也建议设置一个比较小的國值。<br>2.数据库层面的指标（1）数据库存活。<br>存活状态是数据库的基本监控。由于MySQL的单进程架构，相对Oracle等多进程架构</p>
<p>≦ 363 ≧<br>21.2故障处理一般流程 345<br>的数据库来说，更容易因为某些异常或BUG导致数据库实例崩溃。对于数据库存活的监控，一般通过尝试建立数据库连接来检查即可。<br>（2）连接数。<br>如果数据库出现连接数异常增长，监控需要能够及时发现，因为一旦连接数超过数据库参数中设定的最大连接，就会出现无法建立连接，影响服务的情况。此外，由于每个连接都要消耗一定的内存，因此数据库总共的连接数也应该控制在一个合理的范围内。对于连接数的监控，一般来说可以参考正常状况下的连接数来确定。数据库连接数可以通过information_ schema.processlist表来确定：<br>mysql&gt; select count(1) from information_schema.processlist; 1count（1）1<br>414<br>1 row in set (0.00 sec)（3）慢SQL。<br>慢SQL是导致数据库问题的最常见因素之一，因此需要及时发现数据库中执行效率偏低的SQL。监控慢SQL的方法有很多种，常用的一种方法是开启慢查询日志，然后通过pt-digest 工具来定期分析日志，这样可以获得慢SQL的详细信息。也可以简单地通过查询 information_schema.processlist来监控当前是否有慢SQL的存在：<br>mysql&gt; select * from information schema.processlist where user not in (‘system userevent scheduler’) and command &lt;&gt;’sleep′and Time &gt;10;<br>Empty set (o.o0 sec)（4）主从延迟。<br>从库作为主库的备份，如果延迟过大，一旦主库出现问题，那么从库将会无法及时顶替主库提供服务。此外，很多情况下从库会分担一部分主库的查询请求，如果延迟过大，那么发送到从库的查询请求也无法提供正确的结果。可以通过showslavestatus命令来检查主从的延迟情况。<br>以上提到的指标都是对于数据库最为基础的一部分监控指标，在实际工作中，需要根据<br>！实际需求，定制个性化的监控指标。 21.2.2故障定位<br>DBA收到报警之后，接下来要做的就是尽快定位故障的原因。（1）检查当前和最近的操作。<br>如果DBA、开发正在做某项操作，那么由该操作导致的故障可能性比较大，所以要首先确认当前所有相关操作。常见的导致数据库故障操作有以下几种。<br>程序发布：每次应用程序发布，都有可能引发数据库问题，例如新的业务逻辑带来的SQL变动、新上线的促销活动带来的访问量增加、发布的时候批量创建连接带来的连接冲击等，都是常见的造成数据库报警的原因。<br>●在线表变更：造成报警的常见原因包括表变更造成的锁表、复制表过程中带来的IO 压力等。<br>在线数据修改：造成报警的常见原因是大批量数据修改带来的压力，或者执行SQL 不合理导致的锁问题。</p>
<p>≦ 364 ≧<br>346 第21章故障诊断<br>后台任务、数据统计：后台任务和数据统计往往需要查询或者更新大量数据，导致操作系统CPU或IO使用率快速升高而报警。<br>数据库参数调整：在线的数据库参数调整也有可能造成意外的影响。<br>其他误操作：各种人为误操作也是报警的常见原因。（2）操作系统层检查。<br>接下来可以对操作系统和数据库的各项指标进行检查，进一步帮助自已定位故障。在操作系统层，一般需要先从下面几个角度进行排查。<br>系统进程：通过进程占用的CPU和内存情况，判断当前系统压力是否主要由MySQL 进程所致。检查是否存在其他的异常服务、是否有定时任务在运行等。<br>CPU：检查当前CPU的使用情况，并通过CPU主要等待时间消耗在哪里，来判断到底是IO能力不足，还是运算能力不足。<br>内存、SWAP：检查内存和SWAP的使用情况，来判断故障是否是由内存分配不当造成的。<br>IO：检查磁盘的IO吞吐量和IO使用率是否正常，可以辅助判断当前系统是否存在 IO能力不足的问题，以及问题到底是由于IO吞吐量下降造成的，还是由于IO量过高造成的。<br>系统日志：从dmsg、message、secure等系统日志中，可以辅助判断当前系统是否存在硬件故障、了解故障前系统都做过哪些操作等。<br>（3）数据库层检查。<br>在数据库层，DBA应该重点关注下面这些指标。<br>连接：通过检查数据库当前的session，以及活跃状态的session，DBA可以了解到当前系统的连接数、连接的使用状况是否正常。<br>慢查询：通过慢查询分析，可以最直观地了解到，是否有大量消耗系统资源的SQL，从而判断问题是否由SQL导致，由哪些SQL导致。<br>锁等待：锁等待也是常见的导致连接问题或性能问题的原因，需要通过检查数据库中的锁持有和等待的情况、锁持续的时间、被阻塞的连接数量等指标来判断问题。<br>OQPS：通过检查数据库当前的QPS，可以帮助判断数据库的访问量是否正常，从而判断是否由于业务量波动或者缓存失效等原因导致数据库的请求量异常。<br>错误日志：部分实例错误的信息，需要通过MySQL错误日志来判断，虽然当前版本中MySQL错误日志提供的信息还不够充分。未来随着MySQL版本的更新，错误日志也会越来越完善。<br>对于常见的故障，这里做了一个简单的图示（见图21-1），当遇到故障时可以作为参考。 21.2.3故障解决<br>通过定位，已经可以比较明确的确定导致故障的原因，针对不同的原因，需要用不同的方法来解决。下面我们来分析一些常见故障的解决方法。<br>1.慢SQL<br>通过分析，如果最终确定故障是由于一个或多个SQL执行慢导致的，那解决故障就是优化SQL的执行效率。常见的导致慢SQL的原因及解决方案有以下几种。</p>
<p>≦ 365 ≧<br>21.2故障处理一般流程 347<br>空间不足 inode节点不足<br>授权问题<br>拒绝连接 驱动问题<br>通过报警连接定位 连接池设置问题<br>连接数满大事务复制中断<br>主从延迟 主库写压力大<br>从库读压力大<br>表锁<br>OSC 表复制压力大数据统计 读写压力大<br>慢SQL<br>参数修改 参数修改错误<br>通过当前操作定位误操作<br>误删数据<br>Online DML<br>读写压力大新增SQL问题<br>应用发布 逻辑设计不合理<br>新增服务器锁冲突<br>连接池设置不合理<br>连接 参数设置不合理<br>SQL执行慢锁冲突<br>故障诊断思路 数据库 QPS 访问量异常<br>缓存穿透<br>慢SQL<br>实例级错误<br>错误日志 数据库BUG<br>缓存使用策略不合理<br>raid卡缓存充放电时间不合理<br>缓存失效<br>硬件 传感器问题<br>温度散热器问题硬盘坏道<br>需要进一步检查 PE耗尽<br>确诊进程消耗资源<br>进程确诊故障实例<br>磁盘故障<br>IQ IQ能力不足<br>慢SQL 慢SQL<br>CPU 锁冲突<br>异常排序<br>操作系统参数设置不合理<br>内存、SWAP 线程异常消耗内存<br>内存泄露<br>实例分配不合理<br>硬件故障安全问题<br>系统日志误操作<br>0OM 系统故障<br>图21-1常见的故障图示<br>（1）选择条件上没有索引或者索引效率低。<br>如果表的数据量不太大，而SQL上也存在着选择度比较好的条件时，可以选择直接为SQL 创建一个索引来解决故障。而如果表的数据量非常大，创建索引需要花的时间和资源也很大，这时可以先和其他团队沟通一下SQL涉及的具体业务逻辑，对于非核心业务，或许可以临时</p>
<p>≦ 366 ≧<br>348 第21章故障诊断<br>停掉这个SQL，这样可以快速恢复核心业务，并给DBA留下创建索引的时间窗口。对于核心业务的SQL，如果是由于SQL变更导致，可以考虑回滚应用程序版本。<br>此外，如果涉及的表上数据只有新增，没有修改，并且对于查询结果的准确性要求不高，可以通过创建一个空表，并和大表通过rename临时互换的方式，来加快服务恢复的速度。接下来，再跟产品和开发团队沟通SQL的具体需求，讨论是否可以通过其他高效率的方式来查询数据库，比如增加其他有索引的列作为查询条件等，从而更好地解决问题。<br>（2）有索引，但没有用到索引，或者选择了错误的索引。<br>这种情况往往是由于表的统计信息不准确，或者SQL过于复杂导致，当然也不排除MySQL 的SQL优化器有时候也会犯错误。这时还是需要优先恢复核心服务，然后通过收集统计信息，或者使用SQL改写插件来强制SQL走正确索引。如果故障影响可控，也可以选择等待应用程序修改SQL写法等方式来尝试让SQL的执行计划符合预期。<br>（3）过滤条件不强，结果集太大。<br>这常常是一些统计分析类SQL造成的，从这些SQL本身来看可能已经无法优化。对于这种SQL，首先应该停掉相应的统计分析任务，不让其影响线上服务，然后可以考虑将统计分析任务调整到从库或者调整到非业务高峰时段来执行。<br>2.SQL执行频率高（1）恶意攻击。<br>大多数数据库都是存放在内网环境，因此直接受到恶意攻击的情况不多，但是针对Web 和应用服务器的攻击，还是会通过SQL请求的方式传递到数据库。应对这种情况仅靠数据库层不容易处理，可以及时发现并反馈给应用开发和运维团队来解决，例如自动封禁掉异常访问的IP等。<br>（2）缓存失效。<br>如果应用层缓存设计不合理，导致有过多的请求穿透缓存到达数据库，那么也需要及时和应用团队沟通，改进缓存策略、加大缓存容量。<br>（3）应用实现逻辑不合理。<br>可以通过回滚等方式临时解决。此外，作为DBA，应该对自已负责业务线的关键业务逻辑有所了解，这样可以配合产品和开发团队一起，对应用逻辑做出合理的设计和调整。<br>（4）业务量突增。<br>这种情况相对比较棘手，可以首先考虑通过对部分重点SQL进行优化的方式，从一定程度上缓解压力，争取能够扛过业务峰值。之后再考虑对整个业务逻辑进行优化、数据库拆分或者对数据库集群资源进行扩容等长期方案。在紧急情况下，也可以放弃部分边缘业务，来保障核心业务的运行。<br>3.锁冲突<br>对于锁冲突带来的连接数过高的问题，一般来说可以通过临时加大最大连接数，或者手动杀掉一部分连接的方法，避免连接数达到限制，无法创建新连接的情况发生。同时应该联系开发和运维，从应用层限制锁冲突严重的接口的并发量。待服务稳定后，再根据导致锁冲突的不同原因，调整程序逻辑。下面分别是两种导致锁冲突的常见原因的解决思路。<br>大事务：通过优化逻辑，尽可能地拆分事务，调整事务内的SQL顺序，减少持有锁</p>
<p>≦ 367 ≧<br>21.3典型故障案例 349<br>的时间。<br>热点问题：可以通过分散热点、减小事务、串行化等方式来缓解热点带来的锁冲突。 4.硬件问题<br>硬件问题涉及的可能性比较广，对于数据库这种IO密集型服务来说，更多地需要从IO 层面来关注可能的硬件问题。<br>ORAID卡缓存问题：RAID卡缓存设置不合理，或者电池充放电，都有可能导致IO 性能的波动，处理方法可以参考第18章中相关的章节。<br>○硬盘损坏：硬盘损坏也是常见的造成IO性能下降的原因，需要及时更换损坏的硬盘，并且在RAID重建期间密切关注服务器的IO压力。<br>5.参数配置不合理<br>如果故障是由于操作系统或数据库参数设置不合理所导致，那么在尝试调整参数来解决故障的时候，一定要很清楚自己所做的调整可能带来的影响。对于不常操作的参数，建议先查阅文档，再通过搜索引擎了解一下其他人的处理经验，避免因为错误的参数调整，带来更多的问题。<br>21.3 典型故障案例接下来通过两个案例来完整地介绍一下故障诊断和处理的流程。<br>21.3.1 案例1<br>1.场景<br>DBA收到短信报警，数据库负载超过间值，并持续上升中。<br>收到报警后，需要尽快登录服务器，并同时通知系统的运维和开发人员，告知数据库负载高。可能影响服务，并询问当前系统正在进行的操作。<br>2.诊断<br>（1）执行TOP命令，确认负载过高并持续上升中：[root@hz 10120240 251~]#top<br>top -11:05:57 up 702 days,23:44, 11 users,1oad average: 12.79, 5.61, 2.83<br>Tasks: 385 total,2 running, 383 sleeping, 0stopped,0 zombie<br>Cpu(s):74.6%us,2.0%sy，0.0%ni,11.9%id,10.2%wa,0.0%hi0.3%si,0.0%st Mem: 132146300k total,130865208k used, 1281092k free,369816k buffers<br>Swap: 33554428k total, 892784k used, 32661644k free,27139052k cached<br>PID USER PR  NI VIRT RES SHRS%CPU %MEM TIME+COMMAND 30750 mysq1330 20 0 6234m 1.7g 7296 s 673.2 1.3 447:00.39 mysqld 32054 cetus_34 20 o 240m4788 1692s 0.7<br>38:18.95 cetus<br>977 root 20 o 0 OS 0.30.0 473:06.08 jbd2&#x2F;sdc1-8 1280 root 20 o 0 o os 0.30.0 1596:46kondemand&#x2F;0 1283 root 20 0 0 0 0s0.30.01045:31kondemand&#x2F;3<br>MySQL进程的CPU使用率为673%，显著偏高；内存和swap正常，CPU使用率的几个指标中，us即用户进程消耗的时间为74.6%，wa即io等待时间为10%，这两个指标明显高于正常值。从这些指标可以做出初步的推测，有MySQL进程大量消耗了IO资源，导致MySQL</p>
<p>≦ 368 ≧<br>350 第21章故障诊断进程中请求积压，带来负载上升。<br>（2）执行iostat-xd33，观察I0资源的使用情况：<br>Device: rrqm&#x2F;swrqm&#x2F;s r&#x2F;sw&#x2F;srsec&#x2F;swsec&#x2F;s avgrq-sz avgqu-szawait r await w await svctm %util<br>sdc 0.00 43.001408.67197.6775077.331925.33 29.26 1.16 0.72 0.810.070.3179.83<br>观察到%util即IO使用率为79.8%，每秒10量非常大，并且绝大部分为读操作，可以确定有请求大量消耗IO资源，并判断应该是由读操作导致。<br>（3）MySQL进程的大量读IO，很可能是由于SQL导致，因此接下来可以对MySQL进行SQL分析，SQL分析可以借助于自动化诊断工具来快速完成，有兴趣的同学可以参考第 23章的内容，这里先假设没有自动化分析工具，那么我们应如何来定位问题SQL呢？<br>在MySQL中执行：<br>select * from information schema.processlist where state ‘sleep’\G;<br>ID:6234 USER:emp<br>HOST:192.168.1.101 DB:employees<br>COMMAND: Query TIME:207<br>STATE: Sending data<br>INFo: select * from tb_order where order_status &#x3D;0<br>ID:6229 USER:emp<br>HOST:192.168.1.102 DB:employees<br>COMMAND:Query TIME:197<br>STATE: Sending data<br>INFo: select * from tb order where order status &#x3D;0<br>ID:6232 USER:emp<br>HOST:192.168.1.103 DB:employees<br>COMMAND:Query TIME:187<br>STATE: Sending data<br>INFo: select * from tb order where order status &#x3D;0<br>可以看到，存在大量SQL语句“select*fromtb_orderwhereorder_status&#x3D;0”，状态为sending data，其执行时间很长，200s左右还未执行完毕，说明这个SQL语句的效率很可能有问题。<br>（4）如果仅仅从processlist无法确定是哪个SQL，那么需要进一步通过分析慢查询日志<br>来确定问题SQL。建议使用percona的pt-query-digest工具，安装后执行下面的命令： pt-query-digest –since&#x3D;15m slow.log &gt; slow_report.log<br>分析完成后，可以通过slow_report.log来定位问题：[root@hz 10 120 240_251 data]#more slow_report.1og<br>#5.6s user time, 280ms system time, 34.43M rss, 218.81m vsz# Current date: Thu Nov 29 11:30:13 2018<br>#Hostname:hz 10 120 240 251#Files:slow.log<br>#overa11: 363 total,3 unique,0.04 QPs,46.10x concurrency#Time range:2018-11-29T11:16:11 to 2018-11-29T11:29:57<br>#Attribute total max avg 95%stddev median</p>
<p>≦ 369 ≧<br>21.3 典型故障案例 351<br>BIIIIBI II<br>二二<br>#Exec time 38076s 1ms 125s 105s 1245 12s 102s#Lock time 56ms 48us 32ms 153us 13lus 2ms 54us# Rows sent 202 o 98 0.56 0 6.36</p>
<h1 id="Rows-examine-60-71G-98-119-07M-182-92M-182-41M-1-67M-182-41M-Query-size-16-35k-44-69-46-12-44-60-1-58-44-60"><a href="#Rows-examine-60-71G-98-119-07M-182-92M-182-41M-1-67M-182-41M-Query-size-16-35k-44-69-46-12-44-60-1-58-44-60" class="headerlink" title="Rows examine 60.71G 98 119.07M 182.92M 182.41M 1.67M 182.41M#Query size 16.35k 44 69 46.12 44.60 1.58 44.60"></a>Rows examine 60.71G 98 119.07M 182.92M 182.41M 1.67M 182.41M#Query size 16.35k 44 69 46.12 44.60 1.58 44.60</h1><p>#Profile<br>#Rank Query ID Response time Calls R&#x2F;Ca11 V&#x2F;M<br>360 105.7667 0.45 SELECT tb_order</p>
<h1 id="1-0X2E5C1AA8E628621B6AF18E03-38076-0023-98-2"><a href="#1-0X2E5C1AA8E628621B6AF18E03-38076-0023-98-2" class="headerlink" title="1 0X2E5C1AA8E628621B6AF18E03.. 38076.0023 98.2%"></a>1 0X2E5C1AA8E628621B6AF18E03.. 38076.0023 98.2%</h1><h1 id="Query-1-0-04-QPs-46-10x-concurrency-ID-0x2E5C1AA8E628621B6AF18E035F2716DB-at-byte-176863585"><a href="#Query-1-0-04-QPs-46-10x-concurrency-ID-0x2E5C1AA8E628621B6AF18E035F2716DB-at-byte-176863585" class="headerlink" title="Query 1: 0.04 QPs, 46.10x concurrency, ID 0x2E5C1AA8E628621B6AF18E035F2716DB at byte 176863585"></a>Query 1: 0.04 QPs, 46.10x concurrency, ID 0x2E5C1AA8E628621B6AF18E035F2716DB at byte 176863585</h1><h1 id="This-item-is-included-in-the-report-because-it-matches-–limit-Scores-v-x2F-M-x3D-0-05"><a href="#This-item-is-included-in-the-report-because-it-matches-–limit-Scores-v-x2F-M-x3D-0-05" class="headerlink" title="This item is included in the report because it matches –limit.#Scores:v&#x2F;M &#x3D; 0.05"></a>This item is included in the report because it matches –limit.#Scores:v&#x2F;M &#x3D; 0.05</h1><p>#Time range:2018-11-29T11:16:11 to 2018-11-29T11:29:57<br>#Attribute pct total min max avg 95%stddev median#count 99 360</p>
<h1 id="Exec-time-98-38076s-1031s-1259s-1067s-1248s-72s-1028s-Lock-time-41-23ms-48us-327us-63us-125us-26us-54us-Rows-sent-0-0-0-0-0-0"><a href="#Exec-time-98-38076s-1031s-1259s-1067s-1248s-72s-1028s-Lock-time-41-23ms-48us-327us-63us-125us-26us-54us-Rows-sent-0-0-0-0-0-0" class="headerlink" title="Exec time 98 38076s 1031s 1259s 1067s 1248s 72s 1028s#Lock time 41 23ms 48us 327us 63us 125us 26us 54us#Rows sent 0 0 0 0 0 0"></a>Exec time 98 38076s 1031s 1259s 1067s 1248s 72s 1028s#Lock time 41 23ms 48us 327us 63us 125us 26us 54us#Rows sent 0 0 0 0 0 0</h1><p>0<br>#Rows examine 99 60.71G 190.7M 190.7M 190.7M 190.7M 0 190.7M#Query size 98 16.17k 46 46 46 46 o 46#string:<br>#Query_time distribution<br>100s#<br>#1000s+ 技技技技技技技技技技技技技技技技技技技技#Tables<br>SHOW TABLE STATUS LIKE tb order’G#<br>#SHOW CREATE TABLE tb orderG#EXPLAIN&#x2F;<em>!50100 PARTITIONS</em>&#x2F;<br>select * from tb order where order status &#x3D; O\G<br>通过分析上面的报告，也能够看出“select*fromtb_order where order_status&#x3D;0”这条SQL 语句消耗了大量的系统资源，是负载升高的主要原因。<br>（5）确定问题SQL语句之后，接下来查看表结构和SQL执行计划，执行下面的命令： mysql&gt; show create table tb order\G<br>Table:tb order<br>Create Table: CREATE TABLEtb order（<br>order idvarchar(6O) cOLLATE utf8 unicode ci NOT NULL cOMMENT订单ID<br>order timetimestamp（6） coLLATE utf8 unicode ci NOT NULL COMMENT订单时间 account idvarchar(6O) COLLATE utf8_unicode_ci DEFAULT NULL cOMMENT 账号 ID product idvarchar（6O) cOLLATE utf8 unicode_ci DEFAULT NULL cOMMENT 商品 ID product amountint（11) DEFAULT NULL cOMMENT商品数量<br>order_amountdecimal（10，2) DEFAULT NULL cOMMENT订单金额， order_statussmallint（6) DEFAULT NULL COMMENT‘订单状态， PRIMARY KEY (order_id’)<br>KEYidx order_time(order time）<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci COMMENT&#x3D;订单表 1 row in set (o.o0 sec)<br>explain select * from tb order where order status &#x3D; O\G<br>id:1<br>select_type: SIMPLE<br>table: tb order partitions: NULL<br>type: ALL<br>possible_keys: NULL<br>key： NULL key_len: NULL<br>ref: NULL<br>rows:214729138 filtered: 10.00<br>Extra: using where<br>1 row in set,1 warning (0.o0 sec)</p>
<p>≦ 370 ≧<br>352 第21章故障诊断<br>发现由于表上没有order_status的索引，导致SQL使用全表扫描，而且扫描行数非常大。（6）将问题SQL和开发团队沟通，了解到这是开发团队新增的SQL，用途是通过定时任<br>务的方式，每10s扫描一次订单表中，超过1h仍未支付的订单，然后进行订单关闭操作。<br>（7）至此，问题确定，是由于新增功能使用的SQL产生了对大表tb_order的全表扫描，并且执行频率比较高，从而导致数据库服务器的负载升高。<br>3.故障解决（1）应急处理。<br>在处理负载升高的故障时，需要注意，如果负载上升速度很快，可能导致服务器假死，同时，负载高还有可能伴随连接数过高等问题，会直接导致线上服务不可用，如果是这样的情况，应该果断要求开发团队回滚代码，DBA也需要根据情况不断杀掉问题SQL，直至数据库恢复稳定，同时尽可能保障服务的可用性。<br>在本例中，由于负载上升比较缓慢，连接数也比较稳定，因此DBA可以有相对充分的时间和开发团队一起沟通解决方案。这里考虑到关闭订单业务的时效性要求并不高，也不会影响核心业务流程，又是通过定时任务调用，因此首先联系开发人员，将这个SQL的查询频率降低到30min一次。通过这个调整先把系统负载降下来，避免影响到其他重要业务。<br>（2）接下来针对具体的这个问题，就是要降低查询超时未支付订单这个业务需求所消耗的系统资源。<br>通过分析这个SQL，首先的考虑是可以通过在status列上创建索引l，虽然status列本身选择度不高，但是由于存在定时关闭超时未支付订单的逻辑，实际上状态是未支付的订单并不多，status&#x3D;0的选择度是比较好的，因此在status列上创建索引可以有效地优化查询效率。<br>（3）考虑到这个SQL实际上要实现的业务逻辑，还可以做进一步优化。<br>首先，tb_order表本身比较大，创建索引的代价也比较大，需要由DBA选择业务低峰期来操作。其次，这个SQL每次查询会查出大量的未支付订单，其中有很多还未超过支付时限，不需要关闭的订单，这部分查询出来的数据就完全没有意义。<br>考虑上面的两点，可以通过增加order_time这个选择条件，一个作用是可以减少每次查询的结果集，另外也可以在status索引创建之前，先借用order_time上的索引来降低SQL的资源消耗。而考虑到关闭超时订单的任务设计为每半分钟执行一次，order_time的时间选择距离当前时间1～2小时的订单就可以既满足需求，又留有一定余量。因此可以建议开发人员将 SQL语句修改为“select *from tb_order where order_time&gt;date_add(nowO,interval-2hour) and order_time&lt; date_add(nowO,interval -1 hour) and order_status &#x3D;0;”<br>（4）更进一步，如果SQL做了上述调整，并且DBA在status列上创建好了索引，此时考虑到status列的特殊性，列值的分布严重倾斜，SQL优化器对status列的选择度判断可能不准确，再加上存在另一个order_time上的索引l，容易使执行计划变得不稳定，出现SQL错误选择使用order_time索引的情况。此外，单独为了一个查询就在这么大一个表上新增一个索引，对于系统资源也有一定浪费。<br>要解决这两个问题，可以考虑由DBA在业务低峰期，先创建order_time+status的组合索引，再将order_time上的索引|删除。<br>（5）因为涉及索引的调整，DBA完成上述操作之后，需要对表上的SQL进行检查，确保所有SQL的执行计划都符合预期。</p>
<p>≦ 371 ≧<br>21.3典型故障案例 353<br>21.3.2 案例2<br>1.场景<br>DBA收到短信报警，数据库连接数超过阈值，并快速上升，很快就达到数据库设置的最大连接数2000。<br>收到报警后，需要尽快登录服务器，并同时通知系统的运维和开发人员，告知数据库连接数满，可能影响服务，需要运维和开发人员配合一起确认服务状况和解决问题，此外询问近期系统是否有调整。<br>2.应急处理<br>由于数据库连接数已经达到上限，并且收到开发人员反馈，应用不断出现无法建立连接的报错，部分服务已经受到影响，因此需要首先对故障做应急处理。<br>首先检查数据库的CPU、内存、IO使用状况，发现此时CPU、内存、IO的使用率都不高，尤其是内存资源占用并没有显著异常，存在增加最大连接数的条件：<br>top -17:23:35 up 700 days, 6:02,3 users, 1oad average:1.78,1.74,1.27 Tasks: 330 total,1 running, 329 sleeping， 0stopped,0 zombie<br>Cpu(s):8.6%us，1.5%sy,0.0%ni，89.1%id,0.5%wa,0.0%hi,0.2%si,0.0%st Mem:132146300k total,125966652k used, 6179648k free, 446772k buffers Swap:33554428k total, 892784k used,32661644k free,27002416k cached<br>PID USER PR NI VIRT RES SHR S%CPU %MEM TIME+COMMAND 30750 mysq1330 20 0 10.9g 1.3g g7112 s 49.4 1.0 183:23.08 mysqld 977 root 20 0 0 0 os 0.7 0.0 460:50.38 jbd2&#x2F;sdc1-8<br>32051 cetus_34 20 0 240m51162008 S 0.7 0.032:16.60 cetus 58 root 20 0 0 0 OS 0.3 0.0 857:41.16 kb1ockd&#x2F;0 1281 root 20 0 o o oS 0.3 0.0 1089:13 kondemand&#x2F;1<br>1283 root 20 o 0 0 OS 0.3 0.0 1041:38 kondemand&#x2F;3 1287 root 20 o 0s0.30.0649:01.39kondemand&#x2F;7<br>0<br>因此首先调整最大连接数至4000，并对连接数继续保持观察，有必要的话，继续增加。<br>检查数据库中连接的状态，发现大部分连接都是下面的状态： mysql&gt; select * from PROcESSLIsT limit 10\G<br>★★★★*★**★★★★业★业 row<br>ID:4014<br>USER:order app<br>HOST:hz 10120_240_252 DB:order<br>COMMAND:Query TIME:94<br>STATE: Sending data<br>INFO: select product_price,product_stock from tb_product where product_id &#x3D;? for update ID:4117<br>USER:order app<br>HOST:hz10120240252 DB:order<br>COMMAND:Query TIME:157<br>STATE: Sending data<br>INFo: select product price,product stock from tb_product where product id &#x3D;? for update 业业六<br>ID:4108<br>USER:order app<br>HOST:hz 10 120 240 252 DB:order</p>
<p>≦ 372 ≧<br>354 第21章故障诊断<br>COMMAND:Query<br>TIME:155<br>STATE:Sending data<br>INFo: select product price,product stock from tb_product where product_id &#x3D;? for update 此时开发反馈刚刚上线一期抢购活动，将刚才的SQL和开发做了确认，确定是属于新上<br>线抢购活动的新增SQL。因此判断连接数暴涨和抢购活动新上线的SQL有关，要求应用运维马上对活动接口进行限流，并发数初步限制到100。如果不能马上限制并发数，建议临时下线抢购活动接口。<br>完成并发限制或下线接口之后，分批重启应用服务器，重建数据库连接。<br>经过上面的处置，数据库连接数下降至500左右，大部分服务已经恢复正常，但是抢购活动的效率仍然很低，开发根据应用日志发现抢购的效率大概在每秒1笔左右。<br>3.进一步诊断<br>通过前面的处理过程，我们已经可以判断抢购活动的SQL设计可能存在问题，每秒钟1 笔左右的成交效率肯定无法满足业务的需要，因此首先需要重点了解一下抢购活动的SQL设计，开发提供了整个抢购流程的设计如下。<br>（1）首先，抢购流程涉及的几个表的表结构、数据量、数据分布情况如下。<br>用户账号表：数据量在10000左右。 mysql&gt; show create table tb account\G<br>Table: tb account<br>Create Table:CREATE TABLE tb account（<br>account_idvarchar(6O) COLLATE utf8 unicode ci NOT NULL COMMENT账号ID’， user namevarchar(20O) coLLATE utf8 unicode ci DEFAULT NULL COMMENT用户名<br>account balancedecimal（10,2） DEFAULT NULL cOMMENT账户余额， PRIMARY KEY (account id’)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8unicode_ci COMMENT&#x3D;账户表 1row in set (o.00 sec)<br>活动表：记录用户报名参与活动的状态。 mysql&gt; show create table tb activity\G<br>Table:tb activity<br>Create Table: CREATE TABLE tb activity（<br>account idvarchar(6O) coLLATE utf8 unicode ci NOT NULL COMMENT账号ID, activity_idvarchar(6O) cOLLATE utf8 unicode ci NOT NULL COMMENT 活动 ID,<br>statustinyint（4） DEFAULT NULL COMMENT活动参与状态， PRIMARY KEY Caccount id,activity_id)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci COMMENT&#x3D;’活动表 1 row in set (o.o0 sec)<br>○活动商品表：只记录了参加活动的10种特价商品的价格、库存等信息。 mysql&gt; show create table tb product\G<br>Table: tb product<br>Create Table:CREATE TABLEtb_product（<br>product idvarchar（6O) COLLATE utf8 unicode_ci NOT NULL COMMENT 商品ID<br>product namevarchar(2OO) coLLATE utf8 unicode_ci DEFAULT NULL cOMMENT 商品名<br>product pricedecimal(10,2） DEFAULT NULL COMMENT商品价格 product stockint（11） DEFAULT NULL cOMMENT商品库存<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci COMMENT&#x3D;’商品表 1 row in set (o.00 sec)<br>订单表：记录了所有用户、所有产品的订单信息。 mysql&gt; show create table tb order\G</p>
<p>≦ 373 ≧<br>21.3典型故障案例 355<br>Tabletb order<br>Create Table: CREATE TABLE tb order（<br>order_idvarchar(6O) cOLLATE utf8 unicode_ci NOT NULL COMMENT 订单ID’<br>account idvarchar（6O) cOLLATE utf8 unicode ci DEFAULT NULL cOMMENT账号ID， product_id varchar（6O) cOLLATE utf8 unicode_ci DEFAULT NULL cOMMENT 商品 ID’, product_amountint(il) DEFAULT NULL cCOMMENT 商品数量<br>order_amountdecimal(10,2) DEFAULT NULL COMMENT 订单金额， order _statusSmallint（6) DEFAULT NULL cOMMENT 订单状态， PRIMARY KEY (order_id’)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci COMMENT&#x3D;’订单表’ 1 row in set(o.00 sec)<br>（2）用户参与抢购过程的SQL代码如下。开启事务：<br>start transaction;  4 es i tsa  aag<br>查询商品库存和价格：<br>select product price,product stock from tb product where product id &#x3D; for update;<br>查询用户账户余额：<br>select account balance from tb account where account id &#x3D; forupdate<br>查询用户是否领取了活动资格：<br>select status from tb activity where account id&#x3D;and activity id&#x3D;?;<br>查询用户是否有购买记录：<br>select count(1） fromtb order where product id&#x3D;and account id &#x3D;;<br>如果满足库存&gt;&#x3D;1，账户余额&gt;&#x3D;价格，用户领取了活动资格，用户购买数量没有超过限制这4个条件，那么接下来：<br>更新账户余额：<br>updatetb accountset account balance&#x3D;？whereaccount id&#x3D;？<br>更新库存信息：<br>updatetbproductsetproduct stockwhereproductid&#x3D;<br>写入订单信息：<br>nsert inotbordervalues(?？?？？，？；<br>提交：<br>心能些对性胞司病制集<br>（3）整个过程看起来很合理，但是其实隐藏着很多问题。<br>由于抢购商品表tb_product只有10行数据，因此在设计表结构的时候，并未给这个表创建任何索引。而实际上，由于抢购活动的特殊性，这个数据量最小的表，正是热点最为集中的表。如果表上有product_id字段的索引，那么每次只有一行数据被加锁，而没有给表创建索引，导致每次都会给所有记录加锁，锁竞争也增加了10倍。<br>O上面我们已经提到过，在这个抢购业务中，记录库存的tb_product表，将会成为锁竞争最为严重的表，但是整个事务的SQL设计中，却最先给这个表加锁，导致在整个事务执行的过程中，这个锁竞争最严重的表，被加锁的时间是最长的。<br>O事务中存在一些执行效率比较低的SQL，如“selectcount(1）from tb_order where product_id&#x3D;？andaccount_id&#x3D;?;”。如果用户在订单表中的购买记录比较多，那么这个SQL 的执行时间也会比较长，整个事务持有锁的时间也会更长。<br>事务没有做到最小化，例如，“select status from tb_activitywhere account_id&#x3D;？and</p>
<p>≦ 374 ≧<br>356 第21章故障诊断<br>activity_id&#x3D;？；”。用户是否领取了活动资格，不会在事务中更新，也没有必要放在事务中查询。事务中的SQL越多，加锁的时间也就越长。<br>4.故障处理<br>根据上面的分析，可以通过以下几点来解决抢购活动中遇到的问题。<br>（1）在tb_product表的product_id列上增加主键，可以有效地降低锁粒度。如果希望进一步分散热点，可以将商品做拆分，例如，将商品A拆分为商品A1和商品A2两行。<br>（2）调整事务逻辑，将无关SQL从事务中拆分出去，将热点表加锁的顺序尽可能往后放，调整后的SQL逻辑如下：<br>select status from tb activity where account id &#x3D; ? and activity id &#x3D; ？; start transaction;<br>select account balance from tb account where account_id &#x3D;? for update; select count(1) from tb_order where product id &#x3D; ? and account_id &#x3D;?;<br>select product price,product stock from tb_product where product id &#x3D;? for update; 如果满足购买条件：<br>update tb account set account balance &#x3D; ? where account id &#x3D; ?; update tb_product set product stock &#x3D; ？ where product id &#x3D; ?；<br>insert into tb order values (?，？，？，？,？，?); commit;<br>（3）优化效率偏低的SQL，例如这里通过对tb_order表做count的方式来判断用户购买数量，可以调整为通过对tb_activity表中用户状态的判断来完成。<br>（4）在应用层，增加对抢购每种商品的并发量的限制，使同时竞争某一个商品的锁数量不高于3个，对于数据库来说，也能够起到一定的保护作用。<br>（5）如果经过上面一系列的调整，仍然无法满足业务需求，需要进一步增加并发量，可以考虑将此处抢购的逻辑做进一步调整，不再让用户来竞争库存上的锁。在用户下单时，可以只是insert一条用户下单记录，再由系统中订单处理服务来做异步处理。处理完成后，将订单处理的结果反馈给用户，这样用户的下单流程就不在需要锁表，可以最大限度地保障并发<br>性，但是相应的用户只能异步接收到订单处理的结果，对用户体验可能有一定的影响。 21.4小结<br>本章总结了在故障诊断和处理过程中的一些常见思路，并用两个具体的例子做了说明，在实际工作中，可能遇到的故障多种多样，一方面需要不断积累经验来提高故障诊断和处理的能力；另一方面，也要积极尝试借助一些自动化的工具来完成。关于自动化工具的详细介绍，可以参考第23章中的相应内容。</p>
<p>≦ 375 ≧</p>
<h1 id="第四部分-管理维护篇"><a href="#第四部分-管理维护篇" class="headerlink" title="第四部分 管理维护篇"></a>第四部分 管理维护篇</h1><h1 id="第22章-MySQL高级安装和升级"><a href="#第22章-MySQL高级安装和升级" class="headerlink" title="第22章 MySQL高级安装和升级"></a>第22章 MySQL高级安装和升级</h1><p>对于Linux&#x2F;UNIX平台来说，用户还可以考虑采用另外两种安装包来进行安装，一种是二进制包（BinaryPackage），另一种是源码包（SourcePackage）。这两种包都可以从MySQL的官方网站下载（<a target="_blank" rel="noopener" href="https://dev.mysql.com/downloads/mysql/%EF%BC%89%EF%BC%8C%E5%9B%A0%E4%B8%BA%E9%92%88%E5%AF%B9%E4%B8%8D%E5%90%8C%E7%9A%84%E7%A1%AC%E4%BB%B6%E5%92%8C%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%E5%8C%85%E6%9C%89%E6%89%80%E4%B8%8D%E5%90%8C%EF%BC%8C%E6%89%80%E4%BB%A5%E8%AF%BB%E8%80%85%E5%9C%A8%E4%B8%8B%E8%BD%BD%E6%97%B6%E8%AF%B7%E6%A0%B9%E6%8D%AE%E5%AE%9E%E9%99%85%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%E9%80%89%E6%8B%A9%E7%9B%B8%E5%BA%94%E7%9A%84%E5%8C%85%E3%80%82">https://dev.mysql.com/downloads/mysql/），因为针对不同的硬件和操作系统安装包有所不同，所以读者在下载时请根据实际安装环境选择相应的包。</a></p>
<p>这两种安装包相对于RPM包的最大优点是安装配置更灵活，更适合于中高级用户，因此称为“高级”安装。本章将主要对这两种安装包的使用进行介绍。 </p>
<h2 id="22-1-Linux-x2F-UNIX平台下的安装"><a href="#22-1-Linux-x2F-UNIX平台下的安装" class="headerlink" title="22.1 Linux&#x2F;UNIX平台下的安装"></a>22.1 Linux&#x2F;UNIX平台下的安装</h2><p>本节主要介绍Linux&#x2F;UNIX平台下不同安装包之间的区别，并重点介绍二进制包和源码包的安装步骤以及参数文件的设置方法。 </p>
<h3 id="22-1-1-安装包比较"><a href="#22-1-1-安装包比较" class="headerlink" title="22.1.1 安装包比较"></a>22.1.1 安装包比较</h3><p>Linux的安装包分为RPM包、二进制包和源码包。表22-1简单描述了3种安装包之间的主要差异，其中文件布局指的是MySQL安装完毕后生成的各个目录和用途。</p>
<p>表22-1 Linux平台下的3种安装包比较</p>
<table>
<thead>
<tr>
<th></th>
<th>RPM</th>
<th>二进制</th>
<th>源码</th>
</tr>
</thead>
<tbody><tr>
<td>优点</td>
<td>安装简单，适合初学者学习使用</td>
<td>安装简单；可以安装在任何路径下，灵活性好；一台服务器可以安装多个版本的MySQL软件</td>
<td>与平台无关，可按需定制编译，最灵活；性能最好：一台服务器可以安装多个版本的MySQL软件</td>
</tr>
<tr>
<td>缺点</td>
<td>需要单独下载客户端和服务器；安装路径不灵活，默认路径不能修改，一台服务器只能安装一个版本的MySQL软件</td>
<td>已经经过编译，性能不如源码编译得好；不能灵活定制编译参数</td>
<td>安装过程较复杂；编译时间长</td>
</tr>
<tr>
<td>文件布局</td>
<td>&#x2F;usr&#x2F;bin（客户端程序和脚本）  <br/>&#x2F;usr&#x2F;sbin（mysqld服务器）<br/>&#x2F;var&#x2F;lib&#x2F;mysql（日志文件和数据库）<br/>&#x2F;usr&#x2F;share&#x2F;man（Linux文档页）<br/>&#x2F;usr&#x2F;include&#x2F;mysql（包含（头）文件）<br/>&#x2F;usr&#x2F;lib&#x2F;mysql（库文件）<br/>&#x2F;usr&#x2F;share&#x2F;mysql（错误消息和字符集文件）</td>
<td>bin（客户端程序和mysqld服务器）<br/>docs（文档）<br/>man（Linux文档页）<br/>include（包含（头）文件）<br/> lib（库文件）<br/>share（错误消息和字典、安装数据库的SQL文件)<br/>support-files（帮助文件）</td>
<td>bin（客户端程序和mysqld服务器）<br>docs （文档）<br/>man（Linux文档页）<br/>include（包含（头）文件）<br/>lib（库文件）<br/>share（错误消息和字典、安装数据库的SQL文件)<br/>support-files（帮助文件）</td>
</tr>
</tbody></table>
<h3 id="22-1-2-安装二进制包"><a href="#22-1-2-安装二进制包" class="headerlink" title="22.1.2 安装二进制包"></a>22.1.2 安装二进制包</h3><p>如果用户既不想安装最简单却不够灵活的RPM包，又不想安装复杂费时的源码包，那么，已经编译好的二进制包将是很好的选择。</p>
<p>具体安装步骤如下。</p>
<p>（1）用root登录操作系统，增加mysql用户和组，数据库将安装在此用户下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; groupadd mysql</span><br><span class="line">shell&gt; useradd -g mysql mysql</span><br></pre></td></tr></table></figure>

<p>（2）解压二进制安装包，假设安装文件放在&#x2F;home&#x2F;mysql，并对解压后的mysql目录加一<br>个符号链接“mysql”，这样对mysql目录的操作会更方便：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt;<span class="built_in">cd</span> /home/mysql</span><br><span class="line">shell&gt;tar -xzvf /home/mysql/mysq1-vERsIoN-os.tar.gz </span><br><span class="line">shell&gt; <span class="built_in">ln</span> -s mysql-VERSION-os mysql </span><br></pre></td></tr></table></figure>

<p>（3）在数据目录下创建系统数据库和系统表，–user表示这些对象的操作系统owner： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; <span class="built_in">cd</span> mysql</span><br><span class="line">shell&gt;./bin/mysqld --user=mysql --initialize</span><br></pre></td></tr></table></figure>

<p>（4）设置目录权限，将data目录owner改为mysql，其他目录和文件为root: </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; <span class="built_in">chown</span> -R root:mysql</span><br><span class="line">shell&gt; <span class="built_in">chown</span> -R mysql:mysql data</span><br></pre></td></tr></table></figure>

<p>（5）启动MySQL：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; bin/mysqld_safe --user=mysql &amp; </span><br></pre></td></tr></table></figure>



<h3 id="22-1-3-安装源码包"><a href="#22-1-3-安装源码包" class="headerlink" title="22.1.3 安装源码包"></a>22.1.3 安装源码包</h3><p>如果对数据库的性能要求很高，并且希望能够灵活地定制安装选项，安装源码包将是明智的选择。源码包的安装步骤与二进制包非常类似，具体如下。<br>（1）用root登录操作系统，增加mysql用户和组，数据库将安装在此用户下： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; groupadd mysql</span><br><span class="line">shell&gt; useradd -g mysql mysql</span><br></pre></td></tr></table></figure>

<p>（2）解压源码安装文件mysql-VERSION.tar.gz，并进人解压后的目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; tar xvfz mysql-VERSION.tar.gz </span><br><span class="line">shell&gt; <span class="built_in">cd</span> mysql-VERSION</span><br></pre></td></tr></table></figure>

<p>（3）用cmake工具来编译源码，这里可以选择很多编译参数，具体可以参考官方文档 <a target="_blank" rel="noopener" href="http://dev.mysql.com/doc/refman/5.7/en/source-installation.html%E3%80%82%E8%BF%99%E9%87%8C%E5%81%87%E8%AE%BEMySQL%E5%AE%89%E8%A3%85%E5%9C%A8/usr/local/">http://dev.mysql.com/doc/refman/5.7/en/source-installation.html。这里假设MySQL安装在/usr/local/</a> mysql 下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; cmake . --DCMAKE_INSTALL_PREFIX=/usr/local/mysql </span><br><span class="line">shell&gt; make</span><br><span class="line">shell&gt; make install</span><br></pre></td></tr></table></figure>

<p>（4）编辑配置文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; vi /etc/my.cnf</span><br></pre></td></tr></table></figure>

<p>（5）在数据目录下创建系统数据库和系统表，–user表示这些对象的操作系统owner。 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; <span class="built_in">cd</span> /usr/local/mysql</span><br><span class="line">shell&gt; bin/mysqld --initialize --user=mysql</span><br></pre></td></tr></table></figure>

<p>（6）设置目录权限，将var目录owner改为mysql（源码安装，默认数据目录为var），其他目录和文件为root。 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; <span class="built_in">chown</span> -R root</span><br><span class="line">shell&gt; <span class="built_in">chown</span> -R mysql var </span><br><span class="line">shell&gt; <span class="built_in">chgrp</span> -R mysql</span><br></pre></td></tr></table></figure>

<p>（7）启动MySQL：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; bin/mysqld_safe --user=mysql &amp;</span><br></pre></td></tr></table></figure>

<p>当采用源码包进行安装时，可以在安装源码包的过程中，根据自己的需要进行灵活配置。下面介绍源码安装常用的两个选项，有兴趣的读者可以参考MySQL官方文档，以获得更详细的信息。</p>
<p>（1）修改默认路径。</p>
<p>如果不想要位于“usr&#x2F;local&#x2F;var”目录下面的日志（log）文件和数据库，可以使用类似于下列cmake命令中的一个：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt;cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql</span><br><span class="line">shell&gt;cmake . -DCMAKE_INSTALL_PREFIX=/usr/local -DMYSQL_DATADIR=/usr/local/mysql/data</span><br></pre></td></tr></table></figure>

<p>第一个命令改变安装前缀以便将所有内容安装到“&#x2F;usr&#x2F;local&#x2F;mysql”下面而非默认的“&#x2F;usr&#x2F;local”。第二个命令保留默认安装前缀，但是覆盖了数据库目录的默认目录（通常是“&#x2F;usr&#x2F;local&#x2F;var”）并且把它改为&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data。编译完MySQL后，可以通过选项文件更改这些选项。</p>
<p>修改socket的默认位置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; cmake . -DMYSQL_UNIX_ADDR=/usr/local/mysql/tmp/mysql.sock</span><br></pre></td></tr></table></figure>

<p>（2）只选择要使用的字符集。</p>
<p>MySQL5.7使用latin1和latin1_swedish_ci作为默认的字符集和校对规则，从MySQL8.0 开始使用utf8mb4和utf8mb4_0900_ai_ci作为默认的字符集和校对规则。如果想改变安装后的默认字符集和默认排序规则，则可以使用如下编译选项：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; cmake . -DDEFAULT_CHARSET=CHARSET </span><br><span class="line">cmake . -DDEFAULT_COLLATION=COLLATION</span><br></pre></td></tr></table></figure>

<p>如果不需要安装所有的字符集，那么编译时可以选择只安装用户需要的字符集。这样可以节省更多的系统资源，并且使得安装后的MySQL速度更快。编译选项如下： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; cmake . -with_extra_charsets=LIST</span><br></pre></td></tr></table></figure>

<p>其中LIST可以是下面的任何一项：</p>
<ul>
<li>以空格为间隔的一系列字符集名；</li>
<li>complex，以包括不能动态装载的所有字符集；</li>
<li>all，包括所有字符集。</li>
</ul>
<h3 id="22-1-4-参数设置方法"><a href="#22-1-4-参数设置方法" class="headerlink" title="22.1.4 参数设置方法"></a>22.1.4 参数设置方法</h3><p>在MySQL启动过程中，首先会读取参数配置文件，如果不设置参数文件，MySQL就按照系统中所有参数的默认值来进行启动，通过“mysqld-verbose-help”命令可以来查看参数文件中所有参数的当前设置值。</p>
<p>在Windows和Linux上，参数文件可以被放在多个位置，数据库启动的时候将按照不同的顺序来搜索，如果在多个位置都有参数文件，则搜索顺序靠后的文件中的参数将覆盖靠前的参数。表22-2和表22-3分别给出了在不同操作系统中数据库启动时，MySQL搜索参数文件的顺序。</p>
<p>表22-2 Windows平台上MySQL参数文件的读取顺序</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>WINDIR\my.ini</td>
<td>全局选项</td>
</tr>
<tr>
<td>C:\my.cnf</td>
<td>全局选项</td>
</tr>
<tr>
<td>INSTALLDIR\my.ini</td>
<td>全局选项</td>
</tr>
<tr>
<td>defaults-extra-file</td>
<td>用–defaults-extra-file&#x3D;path指定的文件</td>
</tr>
</tbody></table>
<p>表22-3 Linux平台上MySQL参数文件的读取顺序</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>备注</th>
</tr>
</thead>
<tbody><tr>
<td>&#x2F;etc&#x2F;my.cnf</td>
<td>全局选项</td>
</tr>
<tr>
<td>$MYSQL_HOME&#x2F;my.cnf</td>
<td>服务器相关选项，其中$MYSQL_HOME为环境变量中指定的MySQL安装目录</td>
</tr>
<tr>
<td>defaults-extra-file</td>
<td>用–defaults-extra-file&#x3D;path指定的文件</td>
</tr>
<tr>
<td>~&#x2F;.my.cnf</td>
<td>用户相关选项</td>
</tr>
</tbody></table>
<ul>
<li><p>WINDIR典型名称为C:\WINDOWS或C:\WINNT。用户可以使用以下命令从WINDIR 环境变量值确定自己的确切位置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">C:\&gt;echo %WINDIR%</span><br></pre></td></tr></table></figure>
</li>
<li><p>INSTALLDIR是MySQL的安装目录，比如c:\mysql。</p>
</li>
<li><p>defaults-extra-file是MySQL启动时可选择的附带选项，用此参数可以指定任何路径下的配置文件。</p>
</li>
<li><p>“全局选项”表示如果一台服务器上安装了多个MySQL，则每个MySQL服务启动的时候都会首先从此选项中读取参数。</p>
<ul>
<li>注意：不管在Windows还是Linux平台上，为了避免混淆，建议最好只在一个位置指定配置文件。</li>
</ul>
</li>
<li><p>当参数需要修改时，可以选择以下3种修改方式（命令行中para_name表示要修改的参数名，value表示要修改的目标参数值）。</p>
<ul>
<li>session级修改（只对本session有效），在mysql提示符下执行如下命令： mysql&gt;set para_name&#x3D;value;</li>
<li>全局级修改（对所有新的连接都有效，但是对本session无效，数据库重启后失效），在mysql提示符下执行如下命令：mysql&gt;set global para_name&#x3D;value;</li>
<li>永久修改。将参数在my.cnf中增加或者修改，数据库重启后生效。</li>
</ul>
</li>
</ul>
<h2 id="22-2-升级MySQL"><a href="#22-2-升级MySQL" class="headerlink" title="22.2 升级MySQL"></a>22.2 升级MySQL</h2><p>MySQL的版本更新很快，新版本中往往包含了很多新功能，并且解决了很多旧版本中的 BUG，因此在很多情况下用户需要对数据库进行升级。</p>
<p>MySQL的升级很简单，以下给出了几种不同的升级方法，每种升级方法都有一定的优缺点，用户可以按照实际需求选择合适的方法进行操作。</p>
<p>1.方法1：最简单，适合于任何存储引擎（不一定速度最快）</p>
<p>（1）在目标服务器上安装新版本的MySQL。</p>
<p>（2）在新版本的MySQL上创建和老版本同名的数据库，命令如下： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqladmin -h hostname -P port -u user -p passwd create db_name</span><br></pre></td></tr></table></figure>

<p>（3）将老版本MySQL上的数据库通过管道导人到新版本数据库中，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqldump --opt db_name | mysql -h hostname -P port -u user -p passwddb name </span><br></pre></td></tr></table></figure>

<p>这里的–opt选项表明采用优化（Optimize）方式进行导出。</p>
<p>注意：如果网络较慢，可以在导出选项中加上–compress来减少网络传输。</p>
<p>对于不支持管道操作符（|）的操作系统，可以先用mysqldump工具将旧版本的数据导出为文本文件，然后再往新版本MySQL中导人此文件。其实就是把上面的操作分为两步执行，具体操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell &gt; mysqldump --opt db_name &gt; filename（旧版本MysQL上执行）</span><br><span class="line">shell &gt; mysql -u user -p passwd db_name &lt; filename（新版本MysQL上执行）</span><br></pre></td></tr></table></figure>

<p>（4）将I旧版本MySQL中的mysql数据库目录全部cp过来覆盖新版本MySQL中的mysql 数据库，在新版本服务器的shell里面执行mysql_upgrade命令升级权限表。重启新版本MySQL 服务。至此，升级完毕。</p>
<p>2.方法2：适合于任何存储引擎，速度较快</p>
<p>（1）参照方法一中的步骤（1）安装新版本MySQL。</p>
<p>（2）在I旧版本MySQL中，创建用来保存输出文件的目录并用mysqldump备份数据库： </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; <span class="built_in">mkdir</span> DUMPDIR</span><br><span class="line">shell&gt;mysq1dump --tab=DUMPDIR db_name</span><br></pre></td></tr></table></figure>

<p>这里使用–tab选项不会生成SQL文本。而是在备份目录下对每个表分别生成了.sql和.txt 文件，其中.sql保存了表的创建语句；.txt保存了用默认分隔符生成的纯数据文本。<br>（3）将DUMPDIR目录中的文件转移到目标服务器上相应的目录中并将文件装载到新版本的MySQL中，具体操作如下（以下命令都在新版本服务器中执行）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysqladmin create db_name<span class="comment">#创建数据库 </span></span><br><span class="line">shell&gt; <span class="built_in">cat</span> DUMPDIR/*.sql | mysql db_name<span class="comment">#创建数据库表</span></span><br><span class="line">shel1&gt; mysqlimport db_name DUMPDIR/*.txt<span class="comment">#加载数据</span></span><br></pre></td></tr></table></figure>

<p>（4）参照方法一中的步骤（4）升级权限表，并重启MySQL服务。</p>
<p>3.方法3：适合于任何存储引擎，速度最快</p>
<p>（1）在目标服务器上安装新版本的MySQL。</p>
<p>（2）用mysqldump命令导出I旧版本MySQL数据，使用–single-transaction参数，备份期间旧版本mysql可以写入新数据。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt;mysqldump --single-transaction -A&gt; filename</span><br></pre></td></tr></table></figure>

<p>（3）新版本MySQL导人filename中的数据，并将新版本MySQL配置为旧版本MySQL 的从库。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shell&gt;mysql -u user -p passwd db_name &lt; filename（新版本MysQL上执行）</span><br></pre></td></tr></table></figure>

<p>（4）使用高可用工具，例如MHA，做在线主从切换，将新数据写入新版本MySQL。这样就完成了MySQL版本升级。</p>
<p>上面3种方法中，前两种比较类似，第三种是通过搭建新版本从库，再做主从切换实现的。</p>
<p>这里需要读者注意两点：</p>
<ul>
<li>前两种升级方法都是假设升级期间旧版本MySQL不再进行数据更新，否则，迁移过去的数据将不能保证和原数据库一致；</li>
<li>迁移前后的数据库字符集最好能保持一致，否则可能会出现各种各样的乱码问题。</li>
</ul>
<p>MySQL一般很少降级使用（降到低版本）。使用mysqldump命令导出文本后再将其导入<br>低版本的数据库中即可。 </p>
<h2 id="22-3-小结"><a href="#22-3-小结" class="headerlink" title="22.3 小结"></a>22.3 小结</h2><p>本章主要对Linux&#x2F;UNIX平台下MySQL的不同形式的安装包进行比较，并详细介绍了二进制安装包和源码安装包的安装步骤。当使用源码包进行安装时，一并介绍了一些常用的编译选项，用户可以通过这些选项灵活地进行安装定制。在本章的最后还着重介绍了MySQL 的升级，用户可以根据实际需求进行选择。</p>
<p>≦ 382 ≧<br>第23章 MySQL中的常用工具在MySQL的日常工作和管理中，用户经常会用到MySQL相关的管理工具，包括官方的<br>和第三方的。熟练使用这些工具将会大大提高工作效率。本章将介绍这些常用工具的使用。由于这些工具一般都有很多的选项参数，限于篇幅限制，本章只选择一些最常用的进行介绍。<br>如果读者希望了解更多的选项，可以参考相应工具的帮助文档。 23.1MySQL官方工具<br>MySQL提供了大量的客户端工具程序，用于管理和维护MySQL服务器。这些工具简单易用，实现的功能众多，而且不用单独安装，在日常工作中使用率非常高。下面介绍一些常用的工具。 23.1.1mysql（客户端连接工具）<br>在MySQL提供的工具中，DBA使用最频繁的莫过于mysql。这里的mysql不是指 MySQL服务，也不是指mysql数据库，而是指连接数据库的客户端工具。它类似于Oracle数据库里的sqlplus，是操作者和数据库之间的纽带和桥梁。<br>在前面章节的例子中，曾多次使用mysql进行数据库的连接。大多数情况下，它的使用都非常简单，语法如下：<br>mysql [opTIoNs] [database]<br>这里的OPTIONS表示mysql的可用选项，可以一次写一个或者多个，甚至可以不写； database表示连接的数据库，一次只能写一个或者不写，如果不写，连接成功后需要用“use dbname”命令来进人要操作的数据库。<br>下面介绍mysql的一些常用选项，这些选项通常有两种表达方式，一种是“”+选项单词的缩写字符+选项值；另一种是“-”+选项的完整单词+“&#x3D;”+选项的实际值。例如，下面两种写法是完全等价的：<br>Omysql –uroot; Omysql –user&#x3D;root.<br>在下面的介绍中，如果有两种表达方式，都会用逗号隔开进行列出，否则将只显示一种表达方式。要了解更多的选项，可以使用mysql–help命令进行查看。</p>
<p>≦ 383 ≧<br>23.1MySQL官方工具 365<br>1.连接选项<br>-u,–user&#x3D;name<br>-p,–password[&#x3D;name] #指定用户名#指定密码<br>-h, –host&#x3D;name #指定服务器IP或者域名-P,–port&#x3D;# #指定连接端口<br>这4个选项经常一起配合使用。假设数据库创建一个本地用户<a href="mailto:&#114;&#111;&#111;&#116;&#64;&#49;&#x32;&#x37;&#46;&#48;&#46;&#48;&#x2e;&#x31;">&#114;&#111;&#111;&#116;&#64;&#49;&#x32;&#x37;&#46;&#48;&#46;&#48;&#x2e;&#x31;</a>，密码为<br>123456，数据库端口为3307。使用mysql命令，指定4个选项的值就可以连接到数据库。[root@localhost ~]$ mysql -uroot -p123456 -h127.0.0.1 -P3307<br>Warning: using a password on the command line interface can be insecure.<br>welcome to the MysQl monitor. commands end with ; or g. Your MysQL connection id is 48<br>Server version: 5.7.22-1og MysQL Community server (GPL)<br>Type #help;or h for help. Type c’ to clear the current input statement. mysq1<br>出现上面类似的输出，证明已经连接上数据库了。细心的读者会发现，连接数据库时， mysql客户端提示“Warning:Using a password on the command line interface can be insecure”。这是因为在shell命令行中使用了明文密码，会有密码泄露的风险。安全的做法是在交互窗口中输入密码。<br>[root@localhost ~]$ mysql -uroot -p -h127.0.0.1 -P3307 Enter password:<br>在mysql客户端提示“Enterpassword”后，输人密码：[root@localhost ~]$ mysql -uroot -p -h127.0.0.1 -P3307 Enter password<br>welcome to the MysQL monitor. commands end with :or g. Your MysQL connection id is 51<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;or \h’ for help. Type \c’ to clear the current input statement. mysq1&gt;<br>这样，mysql客户端就不会提示Warning了。<br>单纯输人mysql命令会出现什么结果呢？如果没有指定任何选项，mysql会在my.cnf里面找[client组内的用户名和密码，如果有，则按照此用户名和密码进行登录；如果没有，则系统会使<br>用‘root@localhost进行登录。来看下面的例子，my.cnf中有用户emp，密码为emp123：[root@ localhost ~]# more &#x2F;etc&#x2F;my.cnf<br>[client] user &#x3D; emp<br>password&#x3D; emp123<br>使用mysql命令直接登录后查看当前用户：[root@localhost ~]# mysq<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 65<br>server version: 5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;’or h’ for help. Type c’ to clear the current input statement. mysql&gt; select current userO;<br>I current_user() emp@localhost<br>1 row in set (o.o0 sec)</p>
<p>≦ 384 ≧<br>366 第23章MySQL中的常用工具<br>果然，此时的默认登录用户换成了emp@localhost。这里将[client]选项中的“user&#x3D;emp”<br>注释后，重启服务器，再次用mysql命令直接登录：[root@localhost ~]# mysq<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 69<br>Server version:5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;’or ‘h’ for help. Type \c to clear the current input statement. mysql&gt; select current userO;<br>Icurrent userO Iroot@localhost 1<br>1row in set (o.00 sec)<br>正如我们所料，此时的登录用户已经变成了‘root@localhost。<br>如果客户端和服务器位于同一台机器上，通常不需要指定-h选项，否则要指定MySQL 服务所在的IP或者主机名。如果不指定端口，默认连接到3306端口。以下是一个远程用户<br>用root账号成功连接到服务器192.168.7.55上3306端口的例子：[root@1oca1host ~]#mysq1 -h 192.168.7.55 -P 3306 -uroot -p Enter password:<br>welcome to the MysQL monitor. commands end with ; or g. Your MySQL connection id is 19<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;or \h’ for help. Type c’ to clear the current input statement. mysq1&gt;<br>注意：在正式的生产环境中，为了安全起见，一般需要创建应用账号并赋予适当权限，而不会<br>用root直接操纵数据库；默认端口（3306）一般不要使用，可以改为任意操作系统未占用的端口。<br>2.客户端字符集选项<br>–default-character-set&#x3D;charset-name<br>细心的读者可能会发现，作为服务器的字符集选项，这个选项也可以配置在my.cnf 的[mysqld]组中。同样，作为客户端字符集选项，也可以配置在my.cnf 的[mysql]组中，这样，每次用 mysql工具连接数据库时，就会自动使用此客户端字符集。当然，也可以在mysql 的命令行中手工指定客户端字符集，如下所示：<br> shell&gt;mysquuser-default-character-set&#x3D;charset<br>相当于在mysql客户端连接成功后执行：<br>setnaechaset；<br>下例描述了此选项使用前后客户端字符集的变化。（1）正常连接到MySQL服务后的客户端字符集：[root@localhost ~]# mysql<br>Welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 71<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;or h’ for help. Type \c’ to clear the current input statement. mysql&gt; show variables like chara%’;</p>
<p>≦ 385 ≧<br>23.1MySQL官方工具 367<br>| Variable name 1value character_set_client utf8 character set connection utf8 character set_database utf8 character_set_filesystem binary character set results utf8 Icharacter set server |utf8 character set_system utf8<br>|character sets dir &#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;share&#x2F;charsets&#x2F; 8rows in set (0.00 sec)<br>（2）加上参数重新连接后再次观察客户端字符集（粗体显示）：<br>[root@localhost ~]# mysq] –default-character-set&#x3D;gbk Welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 72<br>Server version:5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;’or \h’ for help. Type \c’ to clear the current input statement. mysql&gt; show variables like ‘chara%;<br>|Variable_name |value<br>|character_set client gbk Icharacter_set connection gbk<br>|character set database utf8 character set filesystem binary<br>character set results gbk 1character set server utf8<br>|character_set_system utf8 |character_sets_dir&#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;share&#x2F;charsets&#x2F;<br>8rows in set (o.o0 sec)<br>果然，系统的客户端字符集按照之前的设置发生了变化。 3.执行选项<br>-e,–execute&#x3D;name 执行SQL语句并退出<br>此选项可以直接在MySQL客户端执行SQL语句，而不用连接到MySQL数据库后再执行，对于一些批处理脚本，这种方式尤其方便。下面的例子从客户端直接查询mysql数据库的user表中的User和Host字段：<br>[root@localhost ~]$ mysq] -uroot -p -e “sELECT User, Host FROM mysql.user Enter password:<br>1user Host<br>lemp 127.0.0.11 Iroot 127.0.0.1<br>localhost<br>|mysql.session localhost mysq].sys localhost root 1ocalhost<br>可以按这种方式连续执行多个SQL语句，用英文分号（；）隔开。下面的例子中连续执行了两个SQL语句：<br>[root@localhost ~]s mysq] -u root -p employees -e”select distinct last name from employees where last name like ‘Gu1%’;select count(o) from dept manager;”<br>Enter password: Ilast name|</p>
<p>≦ 386 ≧<br>368 第23章MySQL中的常用工具<br>Gulla Gulak Gulik<br>count(0)<br>24<br>4.格式化选项<br>-E,–vertical 将输出方式按照字段顺序竖着显示-s–silent 去掉mysql中的线条框显示<br>“-E”选项类似于mysql里面执行SQL语句后加“G”，可以将输出内容比较多的行更清晰完整地进行显示，经常和“-e”选项一起使用。下例中在shell命令行直接对数据库做查询，并将结果格式化输出：<br>[root@localhost ~]s mysqT -u root -p -e “sELECT User, Host FRom mysql.user” -E Enter password:<br>row<br>user: emp<br>Host: 127.0.0.1 User: root<br>Host: 127.0.0.1<br>*+ User:emp<br>Host: Tocalhost<br>#★会会会安专会 user: mysql.session<br>Host:localhost user: mysql.sys Host: localhost<br>user: root<br>Host:localhost<br>在mysql的安静模式下，“-s”选项可以将输出的线条框去掉，字段之间用tab进行分隔，每条记录显示一行。此选项对于只显示数据的情况很有用，下例是此选项的显示结果：<br>[root@localhost ~]$ mysqT -s-uroot -p employees Enter password:<br>mysql&gt; select * from departments; dept no dept name<br>d009 Customer service d005 Development d002 Finance<br>d003 Human Resources d001 Marketing d004 Production<br>d006 Quality Management d008 Research<br>d007 Sales 5.错误处理选项<br>-f,–force 强制执行SQL–verbose 显示更多信息–show-warnings 显示警告信息<br>在一个批量执行的SQL中，如果其中一个SQL执行出错，正常情况下，该批处理将停止退出。加上-f选项，则跳过出错SQL，强制执行后面的SQL；加上-v选项，则显示出错的 SQL语句；加上–show-warnings，则会显示全部错误信息。</p>
<p>≦ 387 ≧<br>23.1MySQL官方工具 369<br>这3个参数经常一起使用，在很多情况下会对用户很有帮助，比如加载数据。如果数据中有语法错误的地方，则会将出错信息记录在日志中，而不会停止使得后面的正常SQL无法执行；而出错的语句，也可以在日志中得以查看，进行修复。下面是一个例子。<br>（1）设置测试SQL文本a.sql和测试表t2，a.sql中记录了3条insert语句，t2为只有一个 int类型字段的空表。<br>[root@locaThost ~]# more a.sq]<br>insert into t2 values（1); insert into t2 values(2a); insert into t2 values(3);<br>mysql&gt; desc t2;<br>|Field I Type |Null | Key | Default | Extra 丨 id|int(11）丨YES 1NULL<br>1row in set (o.00 sec) mysql&gt; select * from t2; Empty set (0.00 sec)<br>（2）不加任何参数将数据导人表t2。<br>[root@localhost ~]# mysql -uroot test&lt; a.sql<br>ERROR 1054 （42s22) at 1ine 2:Unknown column2ainfield 1ist 可以发现，在导入过程中出错。查看一下实际导人的记录：<br>[root@localhost ~]# mysql -uroot test -e’select * from t2’ id<br>可以发现，由于第二条记录出现语法错误，无法插入表t2，系统自动退出，第一条记录成功插人，第三条记录没有插入。<br>（3）加参数-f重新导人。<br>[root@localhost ~]#mysql -uroot test -f &lt; a.sql<br>ERROR 1054 (42s22) at 1ine 2:unknown column’2ain*field list<br>[root@localhost ~]#mysql -uroot test -e’select * from t2 id<br>可以发现，虽然导人过程依旧报错，但是出错后的记录3却已经成功插人。但是我们只能看到部分出错信息，无法定位出错的SQL语句。<br>（4）加参数-v后重新导人。<br>[root@localhost ~]# mysql -uroot test -f -v&lt; a.sq]<br>insert into t2 values(1) insert into t2 values(2a)<br>ERROR 1054 (42s22) at line 2:unknown column’2ain ‘field list’</p>
<p>≦ 388 ≧<br>370 第23章MySQL中的常用工具<br>insert into t2 values(3)<br>[root@localhost~]#mysql -uroot test-e’select *from t2<br>这时发现，出错后的SQL依然能正确插入，并且对出错SQL和错误内容都进行了提示，我们可以很容易地定位并解决问题。<br>（5）修改测试数据，将第二条记录中的“2a”改为“2222222222222222222”，显然，后<br>者超出了int数据类型的范围。[root@localhost ~]# more a.sq] insert into t2 values(1);<br>insert into t2values(2222222222222222222)；<br>insert into t2 values(3);（6）再次将a.sql导人表t2：<br>[root@localhost ~]# mysql -uroot test &lt;a.sq]<br>这次没有出现任何错误提示，此时没有设置SQL_MODE，默认是非严格的数据校验，也就是第二条记录虽然可以插入表t2，但是插入的数据是错误的。来看一下t2的数据：<br>mysql&gt; select *from t2; Iid<br>12147483647<br>31<br>3rows in set (o.00 sec<br>果然，插入的数据是int类型的最大值“2147483647”，而非“2222222222222222222”。但是由于只是警告，并没有停止出错SQL的运行，这样会导致插入错误的数据，而我们<br>却无法得知。所以下面尝试加人-v参数再次导人。<br>（7）加-v参数，再次导人t2。<br>[root@localhost ~]# mysq] -uroot -v test&lt;a.sq] insert into t2 values(1)<br>insert into t2values(2222222222222222222) insert into t2 values(3)<br>结果显示了所有SQL语句的执行情况，但是对第二条出错语句并没有任何报警提示，我们仍然无法得知数据出错。最后加上–show-warnings选项试试。<br>（8）加上–show-warnings选项再次导入表t2。<br>[root@localhost ~]# mysql -uroot -v –show-warnings test &lt;a.sq]</p>
<p>≦ 389 ≧<br>23.1MySQL官方工具 371<br>insert into t2 values(1)<br>insert into t2values(2222222222222222222)<br>warning (code 1264): out of range value adjusted for column ‘id’ at row 1 insert into t2 values(3)<br>结果发现，第二条错误数据报警，提示插入的值超出了字段的范围，可以从这个日志中很容易地找到错误数据。<br>通过上面的测试例子，可以发现-f、-v、–show-warnings选项在执行一些可能含有语法错误或者数据错误的批处理作业中，可以记录比较完整的日志，从而帮助用户发现并解决这些错误。 23.1.2mysqladmin（MySQL管理工具）<br>mysqladmin是一个执行管理操作的客户端程序。我们可以用它来检查服务器的配置和当前的状态、创建并删除数据库等。它的功能和 mysql 客户端非常类似，主要区别在于它更侧重于一些管理方面的功能，比如关闭数据库。<br>mysqladmin的用法如下：<br>shel7&gt; mysqladmin [options] command [command-options]<br>[command [command-options]].<br>使用方法、常用的选项和MySQL非常类似，这里就不再赘述。这里将可以执行的命令行简单列举如下：<br>create databasename  Create a new database<br>debug Instruct server to write debug information to log drop databasename Delete a database and all its tables extended-status Gives an extended status message from the server<br>flush-hosts Flush all cached hosts flush-logs Flush all logs<br>flush-status clear status variables flush-tables Flush all tables<br>flush-threads Flush the thread cache flush-privileges Reload grant tables (same as reload) kill id,id,… Kill mysql threads<br>password [new-password] change old password to new-password in current format old-password [new-password] change old password to new-password in old format<br>ping Check if mysqld is alive processlist Show list of active threads in server<br>reload Reload grant tables refresh Flush all tables and close and open logfiles<br>shutdown Take server down status Gives a short status message from the server<br>start-slave start slave stop-slave stop slave<br>variables Prints variables available version Get version info from server<br>这里简单给出一个关闭数据库的例子：<br>[root@localhost ~]# mysqladmin -uroot -p shutdown Enter password:<br>23.1.3mysqlbinlog（日志管理工具）<br>由于服务器生成的二进制日志文件以二进制格式保存，当我们查看这些文件时，经常需</p>
<p>≦ 390 ≧<br>372 第23章MySQL中的常用工具<br>要先转换为文本格式，此时就会用到mysqlbinlog日志管理工具。<br>mysqlbinlog的具体用法如下：<br>she7l&gt; mysqlbinlog [options] 1og-filesl 7og-files2…<br>option有很多选项，常用的选项如下。<br>O-d,–database&#x3D;name：指定数据库名称，只列出指定的数据库的相关操作。<br>-0,–offset&#x3D;#：忽略掉日志中的前n行命令。 0<br>-r,–result-file&#x3D;name:将输出的文本格式日志输出到指定文件。-S,–short-form：显示简单格式，省略掉一些信息。<br>–set-charset&#x3D;name：在输出为文本格式时，在文件第一行加上SETNAMES<br>character_set，这个选项在某些情况下装载数据时非常有用。<br>0–start-datetime&#x3D;name-stop-datetime&#x3D;name:指定日期间隔内的所有日志。<br>–start-position&#x3D;#–stop-position&#x3D;#：指定位置间隔内的所有日志。 0<br>O-V,–verbose:重构日志格式为row模式下的虚拟sql语句，-V-v会加上列的数据类型注释。<br>下面举一个例子说明这些选项的使用。<br>（1）创建新日志，对mysql和employees数据库做不同的DML操作。[root@localhost ~]#mysq] -uroot<br>Warning: using a password on the command line interface can be insecure,<br>Welcome to the MysQL monitor.  commands end with ; or g. Your MysQL connection id is 101<br>Server version: 5.7.22-1og MysQL Community Server （GPL)<br>Type’help;’or ‘\h’ for help. Type ‘\c’ to clear the current input statement. mysql&gt; flush 1ogs;<br>Query ok,0 rows affected (o.01 sec) mysql&gt; use mysq1<br>Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A<br>Database changed<br>mysql&gt; revoke ALL PRIVILEGES ONemployees<em>fromemp‘@’127.0.0.1’; Query ok,O rows affected (o.o0 sec)<br>mysql&gt; use employees Database changed<br>mysql&gt; truncate table departments; Query ok,0 rows affected (0.06 sec)<br>mysql&gt; insert into departments (dept no,dept name) values (‘doo9’,’Development’); Query ok, 1 row affected (0.o0 sec)<br>（2）仅加上-v选项，用于重构row模式下的dml语句，显示所有日志（粗体字显示上一步执行过的SQL）。<br>[root@localhost data]# mysq1binlog mysql-bin.000004 -V&#x2F;<em>I50530 SET @@SESSION.PSEUDO_SLAVE MODE&#x3D;1</em>&#x2F;:<br>&#x2F;</em>!40019 sET @@session.max insert delayed threads&#x3D;0*&#x2F;;<br>&#x2F;<em>!5O003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER&#x2F;<em>1</em>&#x2F;;#at219<br>#180612 16:28:25 server id 7237 end 1og_pos 387 CRc32 0x63bf525a Query thread id&#x3D;103 exec_time&#x3D;0 error_code&#x3D;0</p>
<p>≦ 391 ≧<br>23.1MySQL官方工具 373<br>use employees&#x2F;<em>1</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792105&#x2F;<em>!</em>&#x2F;;<br>SET @@session.pseudo_ thread_id&#x3D;103&#x2F;<em>!</em>&#x2F;:<br>SET @@session.foreign key_checks&#x3D;l, @@session.sql auto_is_null&#x3D;0, @@session.unique_ checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;:<br>SET @@session.sq1_mode&#x3D;1411907618&#x2F;<em>!</em>&#x2F;;<br>SET @session.auto_increment increment&#x3D;1, @@session.auto_increment offset&#x3D;1&#x2F;<em>!</em>&#x2F;;&#x2F;<em>!\c utf8 <em>&#x2F;&#x2F;</em>!</em>&#x2F;;<br>SET @@session.character_set client&#x3D;33,@@session.collation connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;<em>!</em>&#x2F;;<br>SET @@session.lc time names&#x3D;0&#x2F;<em>!</em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;;<br>revoke ALL PRIVILEGES ONemployees# from emp‘@127.0.0.1’<br>&#x2F;<em>!</em>&#x2F;;#at387<br>#180612 16:29:01 server id 7237 end_1og_pos 452 cRc32 0x3a733b26 GTID [commit&#x3D;yes]<br>SET @@SESSION.GTID NEXT&#x3D;ANONYMOUS&#x2F;<em>!</em>&#x2F;；#at452<br>#180612 16:29:01 server id 7237 end 1og pos 547 cRc32 0x27ff96f5 Query thread_id&#x3D;94<br>exec time&#x3D;Oerror_code&#x3D;0 use employees&#x2F;<em>1</em>&#x2F;；<br>SET TIMESTAMP&#x3D;1528792141&#x2F;<em>1</em>&#x2F;; truncate table departments<br>&#x2F;<em>!</em>&#x2F;；#at547<br>#180612 16:29:05 server id 7237 end 1og pos 612 cRc32 0x02820f2e GTID [commit&#x3D;no]<br>SET @@SESSION.GTID NEXT&#x3D;’ANONYMOUS&#x2F;<em>!</em>&#x2F;;#at 612<br>#180612 16:29:05 server id 7237 end 1og pos 686 cRc32 0xc9192bb2 Query thread id&#x3D;94<br>exec_time&#x3D;0 error_code&#x3D;0 SET TIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>!</em>&#x2F;;#at 686<br>#180612 16:29:05 server id 7237 end 1og pos 747 cRc32 0xcc321e85 Table map:employees departments mapped to number 224<br>#at747<br>#180612 16:29:05 server id 7237 end 1og_pos 801 cRc32 0x48fe0ea0 write_rows: table id<br>224 fIagS:STMT_END F BINLOG<br>UYQfWXNFHAAAPQAAAOsCAAAAAOAAAAAAAAEABnR1c3RkYgALZGVWYXJObWVudHMAAV4PBP544C4A hR4yzA&#x3D;&#x3D;<br>UYQfWx5FHAAANgAAACEDAAAAAOAAAAAAAAEAAgAC&#x2F;&#x2F;WEZDAWOQSARGV2ZWXVCG11bnSgDV5I&#x2F;<em>！</em>&#x2F;;<br>###INSERT INTo employeesdepartments###SET<br>###@1&#x3D;’d009<br>###@2&#x3D;’Development’#at 801<br>#180612 16:29:05 server id 7237 end 1og pos 876 cRc32 0x0cfb5409 Query thread id&#x3D;94 exec_time&#x3D;0 error_code&#x3D;0 SET TIMESTAMP&#x3D;1528792145&#x2F;<em>I</em>&#x2F;;<br>COMMIT&#x2F;<em>1</em>&#x2F;;<br>SET @@SESSION.GTID_NEXT&#x3D;AUTOMATIC’&#x2F;* added by mysqlbinlog <em>&#x2F; &#x2F;</em>!<em>&#x2F;:#at 876<br>#180612 16:29:23 server id 7237 end 1og pos 923 cRc32 0xf8e85261 Rotate to mysql-bin.<br>000005pos:4 DELIMITER ;<br>#End of log file<br>ROLLBACK &#x2F;<em>added by mysqlbinlog <em>&#x2F;;<br>&#x2F;</em>!50003 SET COMPLETION_TYPE&#x3D;@OLD_COMPLETION_TYPE</em>&#x2F;;&#x2F;<em>！50530 SET @@SESSION.PSEUD0 SLAVE_MODE&#x3D;0</em>&#x2F;;<br>（3）加-v-d选项，-d选项将只显示对employees数据库的操作日志。[root@localhost mysq1]# mysqlbinlog mysql-bin.000004 -v -d employees&#x2F;</em>!50530 SET @@SESSION.PSEUD0_SLAVE MODE&#x3D;1*&#x2F;;<br>&#x2F;<em>!40019 sET @@session.max insert delayed threads&#x3D;0</em>&#x2F;;</p>
<p>≦ 392 ≧<br>374 第23章MySQL中的常用工具<br>&#x2F;<em>150003 SET @OLD_COMPLETIONTYPE&#x3D;@@COMPLETION TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER&#x2F;<em>I</em>&#x2F;;#at452<br>#180612 16:29:01 server id 7237 end 1og pos 547cRc32 0x27ff96f5 Query thread id&#x3D;94<br>exec_time&#x3D;0 error code&#x3D;0 use employees&#x2F;<em>!</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792141&#x2F;<em>!</em>&#x2F;;<br>SET @@session.pseudo_thread id&#x3D;94&#x2F;<em>1</em>&#x2F;;<br>SET @@session.foreign key_checks&#x3D;l, @@session.sql_auto_is_null&#x3D;0,@@session.unique checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;;<br>SET @@session.sql _mode&#x3D;1411907618&#x2F;<em>!</em>&#x2F;;<br>SET @@session.auto increment increment&#x3D;1,@@session.auto_increment offset&#x3D;1&#x2F;<em>!</em>&#x2F;;&#x2F;<em>!\Cutf8</em>&#x2F;&#x2F;<em>!</em>&#x2F;;<br>SET @@session.character set client&#x3D;33,@@session.collation_connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;<em>1</em>&#x2F;;<br>SET @@session.lc_time_names&#x3D;0&#x2F;<em>!</em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;; truncate table departments<br>&#x2F;<em>1</em>&#x2F;#at547<br>#180612 16:29:05 server id 7237 end 1og pos 612 cRC32 0x02820f2e GTID [commit&#x3D;no]<br>SET @@SESSION.GTID NEXT&#x3D;’ANONYMOUS′&#x2F;<em>I</em>&#x2F;;#at612<br>#180612 16:29:05 server id 7237 end 1og_pos 686 CRc32 0xc9192bb2 Query thread_id&#x3D;94<br>exec_time&#x3D;0 error_code&#x3D;0 SETTIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>1</em>&#x2F;;#at686<br>#180612 16:29:05 server id 7237 end 1og pos 747 cRc32 0xcc321e85 Table map:employees<br>departments mapped to number 224#at747<br>#180612 16:29:05 server id 7237 end 1og pos 801 cRc32 0x48fe0ea0 write_rows: table id<br>224 flags:STMT END F BINLOG<br>UYQfWXNFHAAAPQAAAOsCAAAAAOAAAAAAAAEABnR1c3RkYgALZGVWYXJObWVudHMAAV4PBP544C4A hR4yzA&#x3D;&#x3D;<br>UYQfwx5FHAAANgAAACEDAAAAAOAAAAAAAAEAAgAC&#x2F;&#x2F;WEZDAwOQsARGV2ZWXVcG1TbnSgDv5I&#x2F;<em>!</em>&#x2F;;<br>###INSERT INTOemployees.departments###SET<br>###@1&#x3D;d009<br>###@2&#x3D;’Development’#at801<br>#180612 16:29:05 server id 7237 end 1og pos 876 CRc32 0x0cfb5409 Query thread id&#x3D;94 exec_time&#x3D;0 error_code&#x3D;O SET TIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>COMMIT&#x2F;#1*&#x2F;;<br>SET @@SESSION.GTID NEXT&#x3D;‘AUTOMATIC’&#x2F;* added by mySqIbinlog <em>&#x2F; &#x2F;</em>!<em>&#x2F;;#at 876<br>#180612 16:29:23 server id 7237 end 1og_pos 923 cRc32 0xf8e85261 Rotate to mysql-bin.<br>000005pos:4 DELIMITER;<br>#End of log file<br>ROLLBACK &#x2F;<em>added by mysqlbinlog <em>&#x2F;;<br>&#x2F;</em>!50003 SET COMPLETION_TYPE&#x3D;@OLD_COMPLETION_TYPE</em>&#x2F;;&#x2F;<em>150530 SET @@SESSION.PSEUD0_SLAVE_MODE&#x3D;0</em>&#x2F;:<br>日志中的粗体字显示，输出中仅仅包含对employees数据库的操作部分。（4）加-v-o选项，忽略掉前6个操作，只剩下对departments的insert操作。<br>[root@localhost data]#mysq1binlog mysql-bin.000004 -v-o 6&#x2F;<em>150530 SET @@SESSION.PSEUD0 SLAVE MODE&#x3D;1</em>&#x2F;;<br>&#x2F;</em>!40019 sET @@session.max_insert delayed threads&#x3D;0*&#x2F;;<br>&#x2F;<em>150003 SET@OLDCOMPLETIONTYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;0</em>&#x2F;; DELIMITER&#x2F;<em>I</em>&#x2F;;</p>
<p>≦ 393 ≧<br>23.1MySQL官方工具 375<br>#at 612<br>#180612 16:29:05 server id 7237 end 1og pos 686 cRc32 0xc9192bb2 Query thread_id&#x3D;94<br>exec time&#x3D;0 error code&#x3D;0 SETTIMESTAMP&#x3D;1528792145&#x2F;<em>!</em>&#x2F;;<br>SET @@session.pseudo thread id&#x3D;94&#x2F;<em>1</em>&#x2F;;<br>sET @@session.foreign key_checks&#x3D;1, @@session.sql auto_is_null&#x3D;0, @@session.unique_checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;;<br>SET @@session.sql _mode&#x3D;1411907618&#x2F;<em>!</em>&#x2F;;<br>SET @@session.auto_increment_increment&#x3D;1, @@session.auto_increment_offset&#x3D;1&#x2F;<em>!</em>&#x2F;;&#x2F;#1\cutf8 <em>&#x2F;&#x2F;<em>1</em>&#x2F;;<br>sET @@session.character set client&#x3D;33,@@session.collation_connection&#x3D;33,@@session.co1lation server&#x3D;192&#x2F;<em>1</em>&#x2F;;<br>SET @@session.lc time names&#x3D;0&#x2F;</em>!<em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;</em>!<em>&#x2F;;<br>BEGIN&#x2F;<em>1</em>&#x2F;:#at686<br>#180612 16:29:05 server id 7237 end 1og pos 747 cRc32 0xcc321e85 Table map:employees<br>.departmentsmapped to number 224#at747<br>#180612 16:29:05 server id 7237 end 1og pos 801 cRc32 0x48fe0ea0 write rows: table id<br>224 flagS:STMT_ENDF BINLOG<br>UYQfWXNFHAAAPQAAAOsCAAAAAOAAAAAAAAEABnR1c3RkYgALZGVWYXJObWVudHMAAV4PBP544C4A hR4yzA&#x3D;&#x3D;<br>UYQfwx5FHAAANgAAACEDAAAAAOAAAAAAAAEAAgAC&#x2F;&#x2F;WEZDAWOQsARGV2ZWXVCG1TbnSgDV5I’&#x2F;<em>1</em>&#x2F;;<br>###INSERT INTO employees.departments###SET<br>###@1&#x3D;’d009′<br>###@2&#x3D;’Development’#at801<br>#180612 16:29:05 server id 7237 end 1og pos 876 cRc32 0x0cfb5409 Query thread id&#x3D;94<br>exec time&#x3D;0 error_code&#x3D;0 SET TIMESTAMP&#x3D;1528792145&#x2F;</em>!<em>&#x2F;;<br>COMMIT&#x2F;<em>1</em>&#x2F;;<br>SET @@SESSION.GTID NEXT&#x3D;AUTOMATIC’&#x2F;<em>added by mysq1binlog <em>&#x2F; &#x2F;<em>1</em>&#x2F;;#at 876<br>#180612 16:29:23 server id 7237 end 1og pos 923 cRc32 0xf8e85261 Rotate to mysql-bin.<br>000005pos:4 DELIMITER;<br>#End of log file<br>ROLLBACK &#x2F;</em> added by mysqlbinlog <em>&#x2F;;<br>&#x2F;<em>150003 SET COMPLETION_TYPE&#x3D;@OLD COMPLETION_TYPE</em>&#x2F;;&#x2F;</em>!50530 SET @@SESSION.PSEUDO SLAVE MODE&#x3D;0</em>&#x2F;;<br>（5）加-r选项，将上面的结果输出到文件resultfile中。<br>[root@localhost data]#mysqlbinlog mysql-bin.000004 -v -o 6-r resultfile[root@localhost data]# more resultfile<br>&#x2F;</em>!50530 SET @@SESSION.PSEUD0 SLAVE MODE&#x3D;1*&#x2F;;<br>&#x2F;<em>!40019 sET @@session.max insert delayed threads&#x3D;0</em>&#x2F;;<br>&#x2F;<em>I500O3 SET @OLD COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER &#x2F;<em>!</em>&#x2F;;#at612<br>#180612 16:29:05 server id 7237 end 1og_pos 686 cRc32 0xc9192bb2 Query thread id&#x3D;94 exec_time&#x3D;0 error_code&#x3D;0 SET TIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>SET @@session.pseudo_thread id&#x3D;94&#x2F;<em>!</em>&#x2F;;<br>sET @@session.foreign_key checks&#x3D;1,@@session.sql_auto_is_null&#x3D;0,@@session.unique checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;;<br>SET @@session.sql _mode&#x3D;1411907618&#x2F;<em>!</em>&#x2F;;<br>SET @@session.auto increment increment&#x3D;1, @@session.auto_increment offset&#x3D;1&#x2F;<em>!</em>&#x2F;;&#x2F;<em>!\c utf8 <em>&#x2F;&#x2F;</em>!</em>&#x2F;;<br>sET @@session.character set client&#x3D;33,@@session.collation_connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;<em>1</em>&#x2F;;<br>SET @@session.1c time names&#x3D;0&#x2F;<em>1</em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;;</p>
<p>≦ 394 ≧<br>376 第23章MySQL中的常用工具<br>BEGIN&#x2F;<em>1</em>&#x2F;;#at 686<br>#180612 16:29:05 server id 7237 end 1og pos 747 cRc32 0xcc321e85 Table map:employees<br>departmentsmapped to number 224#at747<br>#180612 16:29:05 server id 7237 end 1og pos 801 CRc32 0x48fe0ea0 write_rows: table id<br>224 flags: STMT END F BINLOG<br>UYQfWXNFHAAAPQAAAOsCAAAAAOAAAAAAAAEABnR1c3RkYgALZGVWYXJObWVudHMAAV4PBP544C4A hR4yzA&#x3D;&#x3D;<br>UYQfWx5FHAAANgAAACEDAAAAAOAAAAAAAAEAAgAC&#x2F;&#x2F;WEZDAWOQsARGV2ZWXVcG1lbnSgDv5I*&#x2F;<em>!</em>&#x2F;;<br>###INSERT INToemployeesdepartments###SET<br>###@1&#x3D;d009<br>###@2&#x3D;’Development#at 801<br>#180612 16:29:05 server id 7237 end log pos 876 cRc32 0x0cfb5409 Query thread_id&#x3D;94<br>exec time&#x3D;Oerror_code&#x3D;0 SET TIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>COMMIT&#x2F;<em>！</em>&#x2F;;<br>SET @aSESSION.GTID NEXT&#x3D;AUTOMATIC’&#x2F;<em>added by mysqTbinlog <em>&#x2F; &#x2F;</em>!</em>&#x2F;;#at876<br>#180612 16:29:23 server id 7237 end 1og_pos 923 cRc32 0xf8e85261 Rotate to mysql-bin.<br>000005 pos:4 DELIMITER ;<br>#End of log file<br>ROLLBACK &#x2F;* added by mysqlbinlog <em>&#x2F; ;<br>&#x2F;</em>!50003 SET COMPLETION TYPE&#x3D;@OLD COMPLETION TYPE*&#x2F;;&#x2F;<em>!50530 SET @@SESSION.PSEUDO SLAVE MODE&#x3D;0</em>&#x2F;;<br>（6）结果显示的内容较多，显得比较乱，加-s选项可将上面的内容进行简单显示。<br>[root@localhost data]# mysq1binlog mysql-bin.000004 -v -&#x2F;<em>150530 SET @@SESSION.PSEUDO_SLAVE MODE&#x3D;1</em>&#x2F;:<br>&#x2F;<em>!40019 sET @@session.max_insert _delayed threads&#x3D;0</em>&#x2F;;<br>&#x2F;<em>!50003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;:<br>DELIMITER&#x2F;<em>I</em>&#x2F;;#[empty]<br>SET @@SESSION.GTID_NEXT&#x3D;<em>ANONYMOUS&#x2F;</em>!<em>&#x2F;; use employees&#x2F;</em>!<em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792105&#x2F;</em>!<em>&#x2F;;<br>SET @@session.pseudo_thread id&#x3D;999999999&#x2F;</em>!<em>&#x2F;;<br>SET @@session.foreign key_checks&#x3D;1, @@session.sql_auto_is null&#x3D;o, @@session.unique_checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;</em>!<em>&#x2F;;<br>SET @@session.sql_mode&#x3D;1411907618&#x2F;</em>!<em>&#x2F;;<br>SET @@session.auto_increment_increment&#x3D;1, @@session.auto_increment offset&#x3D;1&#x2F;</em>!<em>&#x2F;;&#x2F;</em>!\cutf8*&#x2F;&#x2F;<em>!</em>&#x2F;；<br>SET @@session.character_set _client&#x3D;33,@@session.collation _connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;<em>1</em>&#x2F;;<br>SET @@session.lc time_names&#x3D;0&#x2F;<em>!</em>&#x2F;;<br>SET @@session.collation_database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;:<br>revoke ALL PRIVILEGEs ON employees.* from emp′@’127.0.0.1′&#x2F;<em>!</em>&#x2F;;<br>SET @@SESSION.GTID_NEXT&#x3D;’ANONYMOUS&#x2F;<em>I</em>&#x2F;; use employees&#x2F;<em>!</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792141&#x2F;<em>!</em>&#x2F;;<br>truncate table departments&#x2F;1*&#x2F;;<br>SET @@SESSION.GTID NEXT&#x3D;ANONYMOUS&#x2F;<em>!</em>&#x2F;; SET TIMESTAMP&#x3D;1528792145&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>!</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792145&#x2F;<em>!</em>&#x2F;;<br>COMMIT&#x2F;<em>!</em>&#x2F;;<br>SET @@SESSION.GTID NEXT&#x3D;AUTOMATIC’&#x2F;<em>added by mysq1binlog <em>&#x2F; &#x2F;</em>!</em>&#x2F;; DELIMITER</p>
<p>≦ 395 ≧<br>23.1MySQL官方工具 377<br>#End of log file<br>ROLLBACK &#x2F;<em>added by mysqlbinlog <em>&#x2F;;<br>&#x2F;</em>!50003 SET COMPLETION TYPE&#x3D;@OLD COMPLETION TYPE</em>&#x2F;;&#x2F;<em>!50530 SET @@SESSION.PSEUD0 SLAVE MODE&#x3D;0</em>&#x2F;;<br>可以发现，内容的确比上文精简了，仅保留了ddl语句，dml语句已经被过滤掉了。（7）加“–start-datetime–stop-datetime”选项显示16:27:34~16:28:26的日志。<br>[root@localhost data]# mysq1binlog mysql-bin.000004 –start-datetime&#x3D;<em>2018-06-12 16:27:34’–stop-datetime&#x3D;’2018-06-1216:28:26’-V<br>&#x2F;<em>150530 SET @@SESSION.PSEUD0_SLAVE_MODE&#x3D;1</em>&#x2F;;<br>&#x2F;<em>140019 sET @@session.max_insert delayed_threads&#x3D;0</em>&#x2F;;<br>&#x2F;<em>150OO3 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER &#x2F;</em>!<em>&#x2F;;#at4<br>#180612 16:27:34 server id 7237 end_1og_pos 123 cRc32 0x32a82b82 Start: binlog v4, server v 5.7.22-1og created 180612 16:27:34<br>BINLOG<br>9oMfww9FHAAAdWAAAHSAAAAAAAQANS43LjIyLWXVZWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXWAEGggAAAAICAgCAAAACgoKKioAEjQA<br>AYIrqDI&#x3D;’&#x2F;<em>！</em>&#x2F;#at 123<br>#180612 16:27:34 server id 7237 end 1og pos 154 cRc32 0x31567282 Previous-GTIDs<br>#[empty]#at154<br>#180612 16:28:25 server id 7237 end 1og pos 219 cRc32 0xa43e01c1 GTID [commit&#x3D;yes]<br>SET @@SESSION.GTID NEXT&#x3D;’ANONYMOUS&#x2F;<em>I</em>&#x2F;;#at219<br>#180612 16:28:25 server id 7237 end 1og pos 387 CRc32 0x63bf525a Query. thread id&#x3D;103<br>exec_time&#x3D;0 error_code&#x3D;0 use employees&#x2F;</em>!<em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792105&#x2F;<em>1</em>&#x2F;;<br>SET @@session.pseudo_thread id&#x3D;103&#x2F;</em>!<em>&#x2F;;<br>SET @@session.foreign key checks&#x3D;1, @@session.sql auto_is_null&#x3D;0,@@session.unique_checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>1</em>&#x2F;;<br>SET @@session.sql_mode&#x3D;1411907618&#x2F;<em>1</em>&#x2F;;<br>SET @@session.auto_increment_increment&#x3D;l,@@session.auto_increment_offset&#x3D;1&#x2F;<em>I</em>&#x2F;;&#x2F;</em>!\cutf8*&#x2F;&#x2F;<em>1</em>&#x2F;;<br>SET @@session.character_set_client&#x3D;33,@@session.collation_connection&#x3D;33,@@session.collation_ server&#x3D;192&#x2F;<em>1</em>&#x2F;;<br>SET @asession.lc time_names&#x3D;0&#x2F;<em>1</em>&#x2F;;<br>SET @@session.collation_database&#x3D;DEFAULT&#x2F;<em>1</em>&#x2F;;<br>revoke ALL PRIVILEGES ON employees<em>from‘emp‘@’127.0.0.1&#x2F;<em>1</em>&#x2F;;<br>SET @@SESSION.GTID_NEXT&#x3D;AUTOMATIC’&#x2F;<em>added by mysqlbinlog <em>&#x2F;&#x2F;</em>!</em>&#x2F;; DELIMITER;<br>#End of log file<br>ROLLBACK &#x2F;<em>added by mysqlbinlog</em>&#x2F;;<br>&#x2F;<em>150003 SET COMPLETIONTYPE&#x3D;@OLD_COMPLETION_TYPE</em>&#x2F;;&#x2F;<em>150530 SET @@SESSION.PSEUD0 SLAVE_MODE&#x3D;0</em>&#x2F;;<br>开始日期和结束日期可以只写一个。如果只写开始日期，表示范围是开始日期到日志结束；如果只写结束日期，表示日志开始到指定的结束日期。<br>（8）–start-position&#x3D;#和-stop-position&#x3D;#，与日期范围类似，不过可以更精确地表示范围。例如，将以上例子改成位置范围后：<br>[root@localhost data]# mysqlbinlog mysql-bin.000004 –start-position&#x3D;219 –stop-position&#x3D;387 -v&#x2F;</em>!50530 SET @@SESSION.PSEUD0_SLAVE_MODE&#x3D;1*&#x2F;;<br>&#x2F;<em>140019 sET @@session.max insert delayed threads&#x3D;0</em>&#x2F;;<br>&#x2F;<em>150003 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER&#x2F;<em>!</em>&#x2F;;#at4<br>#180612 16:27:34 server id 7237 end_1og pos 123 CRC32 0x32a82b82 Start: binlog v 4, serverv5.7.22-1og created 180612 16:27:34<br>BINLOG<br>9oMfWw9FHAAAdWAAAHSAAAAAAAQANS43LjIyLWXVZWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA</p>
<p>≦ 396 ≧<br>378 第23章MySQL中的常用工具<br>AAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQA<br>AYIrqDI&#x3D;&#x2F;<em>1</em>&#x2F;;#at219<br>#180612 16:28:25 server id 7237 end 1og_pos 387 cRc32 0x63bf525a Querythread id&#x3D;103<br>exec_time&#x3D;0 error_code&#x3D;0 useemployees&#x2F;<em>1</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1528792105&#x2F;<em>!</em>&#x2F;;<br>SET @@session.pseudo_thread id&#x3D;103&#x2F;<em>1</em>&#x2F;;<br>SET @@session.foreign key_checks&#x3D;l, @@session.sql auto is_null&#x3D;0, @@session.unique_checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>1</em>&#x2F;:<br>SET @@session.sql_mode&#x3D;1411907618&#x2F;<em>!</em>&#x2F;:<br>SET @@session.auto_increment increment&#x3D;l,@@session.auto_increment offset&#x3D;1&#x2F;<em>I</em>&#x2F;;&#x2F;<em>!\c utf8 <em>&#x2F;&#x2F;</em>!#&#x2F;;<br>SET @@session.character set client&#x3D;33,@@session.collation connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;</em>!<em>&#x2F;;<br>SET @@session.lc time_names&#x3D;0&#x2F;</em>!<em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;<em>I</em>&#x2F;;<br>revoke ALL PRIVILEGES ONemployees</em> <a href="mailto:&#102;&#114;&#x6f;&#x6d;&#x65;&#x6d;&#112;&#x40;&#49;&#x32;&#55;&#46;&#48;&#46;&#x30;&#46;&#49;">&#102;&#114;&#x6f;&#x6d;&#x65;&#x6d;&#112;&#x40;&#49;&#x32;&#55;&#46;&#48;&#46;&#x30;&#46;&#49;</a>&#x2F;<em>1</em>&#x2F;；<br>DELIMITER;<br>#End of log file<br>ROLLBACK &#x2F;*added by mysqlbinlog *&#x2F;;<br>&#x2F;<em>150003SETCOMPLETION_TYPE&#x3D;@OLD_COMPLETION_TYPE</em>&#x2F;;&#x2F;<em>150530 SET @@SESSION.PSEUD0 SLAVE_MODE&#x3D;0</em>&#x2F;;<br>23.1.4mysqlcheck（表维护工具）<br>MySQL实例开启状态下，可以用mysqlcheck来检查、修复、优化和分析表。维护期间， mysqlcheck会在表上加上读锁，此时表不能执行DML和DDL操作。<br>mysqlcheck的用法如下：<br>shell&gt; mysqlcheck [options] db name [tbl name …] shell&gt; mysqlcheck [options] –databases db_name<br>shell&gt; mysqlcheck [options] –all-databases option有很多选项，常用的选项如下。<br>O–all-databases，-A:除了INFORMATION_SCHEMA和performace_schema数据库，检查剩下所有数据库的所有表。<br>O–analyze，-a:分析表，此时命令等同于mysqlanalyze。 O–check：检查表是否有错误，属于默认选项。<br>–databases，-B:检查指定数据库下的所有表。一般mysqlcheck把命令行的第一个名字识别为数据库名，后面的名字识别为表名。使用这个参数后，所有的名字都将识别为数据库名。<br>–fast,-F：仅检查表是否正确关闭，检查速度很快。 O–force,-f:忽略发现的错误，继续执行后续操作。<br>–optimize,-o:优化表，此时命令等同于mysqloptimize。<br>–repair,-r：修复表。出了不能修复主键有重复数据，几乎能修复其他所有问题。 O–skip-database&#x3D;db_name:反向排除数据库。<br>O–tables:覆盖–databases或者-B选项，这个选项后面的所有名字都将被识别为表名。–write-binlog：默认开启，开启这个选项后mysqlcheck生成的分析表、优化表和修复<br>表语句将记录到二进制日志中。可以使用-skip-write-binlog选项，mysqlcheck将不在二进制日志中记录操作语句，这样可以减少从库应用主库日志的延迟。</p>
<p>≦ 397 ≧<br>23.1MySQL官方工具 379<br>注意：建议使用mysqlcheck工具前，先备份需要维护的表，因为在某些极端情况下，可能会导致<br>数据丢失！<br>下面通过具体例子来说明这些选项的使用。检查所有数据库的表：<br>[mysq13307@loca1host ~]s mysq1check -uroot -s&#x2F;tmp&#x2F;mysql_3307.sock –check -A employees.city<br>employees.country<br>employees.departments employees.dept _emp employees.dept_manager employees.emp<br>mysql.time_zone_transition_type OK mysql.user OK<br>分析employees数据库的salaries表：<br>[mysq13307@1oca1host ~]$ mysq1check -uroot -s&#x2F;tmp&#x2F;mysql 3307.sock -a emp1oyees salaries employeessalaries<br>随着时间的推移，在伴随着数据被频繁写人和删除后，数据表会出现碎片化，这时可以对这些表进行优化操作。下面是一个具体例子：<br>查看salaries表的数据量，一共有284万条数据。 mysql&gt;select count(*) as total from salaries;<br>| total 128440361<br>表在磁盘上的表空间文件大小如下：<br>[mysq13307@localhost employees]s 1s -1trh Igrep salaries<br>-rw-r—–1 mysq13307 mysq13307 8.5k May 23 14:52 salaries.frm<br>1 mysq13307 mysq13307 104M Ju1 24 21:45 salaries.ibd<br>-rw-r- 1&#x2F;104m 下面删除一部分数据：<br>mysql&gt;delete from salaries where emp_no &gt;399999; Query 0k, 946354 rows affected (9.04 sec)<br>通过delete删除数据，表空间文件没有缩小。<br>[mysq13307@localhost employees]s 1s -1trh Igrep salaries<br>–1 mysq13307 mysq13307 8.5k May 23 14:52 salaries.frm—-1 mysq13307 mysq13307 104m Ju1 24 21:56 salaries.ibd<br>下面再对salaries表进行优化：<br>[mysq13307@localhost emp1oyees]s mysq1check -uroot -s&#x2F;tmp&#x2F;mysq1 3307.sock -o employees salaries employees.salaries<br>note:Table does not support optimize, doing recreate + analyze instead status<br>再看一下表空间文件大小：<br>[mysq13307@localhost employees]s 1s -ltrh lgrep salaries<br>-1mysq13307 mysq13307 8.5k Jul 24 21:58 salaries.frm<br>-rw-r-<br>-rw-r—– 1 mysq13307 mysq13307 80m Ju1 24 21:58 salaries.ibd<br>从这里看到，ibd文件从104MB减小到了80MB，salaries表使用InnoDB引擎，mysqlcheck 对InnoDB引擎的表进行优化，实际上是做了altertable操作，对表进行重构，重新整理表空间文件。</p>
<p>≦ 398 ≧<br>380 第23章MySQL中的常用工具<br>mysqlcheck做检查、分析和恢复操作时，默认情况下，会在BINLOG文件中记录下来相应语句，然而我们在某些情况下并不希望BINLOG文件记录这些操作，例如备份BINLOG文件，用于以后恢复增量数据，因为我们需要尽量减少恢复时间。mysqlcheck提供了–skip-write-binlog选项来解决类似的问题。<br>登录MySQL，查看当前BINLOG位置： mysql&gt;show master status;<br>File:mysql-bin.000035 Position:154<br>Binlog Do DB: Binlog Ignore DB: Executed Gtid_Set:<br>1 row in set (0.00 sec) 优化salaries表：<br>[mysq13307@loca1host ~]$ mysq1check -uroot -s&#x2F;tmp&#x2F;mysq1 3307.sock-0 employees salaries employees.salaries<br>note:Table does not support optimize,doing recreate + analyze instead statusoK<br>使用mysqlbinlog命令，查看BINLOG文件的信息：<br>[mysq13307@localhost data]s mysq1binlog -vvv mysql-bin.000035#at219<br>#180725 17:28:46 server id 7237 end 1og pos 328 CRC32 0x5934d815 Query thread_id&#x3D;37<br>exec_time&#x3D;3 error code&#x3D;0 useemployees&#x2F;<em>1</em>&#x2F;;<br>SET TIMESTAMP&#x3D;1532510926&#x2F;<em>!</em>&#x2F;；<br>SET @@session.pseudo_thread_id&#x3D;37&#x2F;<em>!</em>&#x2F;;<br>SET @@session.foreign key_checks&#x3D;l, @@session.sql auto is_null&#x3D;0, @@session.unique checks&#x3D;1,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;;<br>SET @@session.sql_mode&#x3D;1143472162&#x2F;<em>1</em>&#x2F;:<br>SET @@session.auto_increment increment&#x3D;1,@@session.auto_increment offset&#x3D;1&#x2F;<em>I</em>&#x2F;;&#x2F;<em>！\Cutf8</em>&#x2F;&#x2F;<em>!</em>&#x2F;;<br>sET @@session.character_set_client&#x3D;33,@@session.co1lation_connection&#x3D;33,@@session.collation server&#x3D;192&#x2F;<em>!</em>&#x2F;;<br>SET @@session.1c time_names&#x3D;0&#x2F;<em>I</em>&#x2F;;<br>SET @@session.collation_database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;;<br>OPTIMIZE TABLE salaries&#x2F;<em>1</em>&#x2F;;<br>可以看到BINLOG文件记录了optimizetable命令。<br>再次优化salaries表，此次增加–skip-write-binlog选项，使得BINLOG文件不再记录 optimize table命令。<br>[mysq13307@localhost ~]s mysqlcheck-uroot -s&#x2F;tmp&#x2F;mysql 3307.sock -o–skip-write-binlog employees salaries<br>empToyees.salaries<br>:Table does not support optimize, doing recreate + analyze instead<br>note<br>statusOK<br>这时BINLOG文件中已经找不到optimizetable命令，证明–skip-write-binlog选项已经生效了。<br>23.1.5mysqldump（数据导出工具）<br>mysqldump客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表或装载表的SQL语句。<br>可以使用以下3种方式来调用mysqldump：</p>
<p>≦ 399 ≧<br>23.1MySQL官方工具 381<br>shell&gt; mysqldump [options] db_name [tables] #备份单个数据库或者库中部分数据表 shell&gt; mysqldump [options] —database DB1 [DB2 DB3…] #备份指定的一个或者多个数据库 shell&gt; mysqldump [options] –all-database #备份所有数据库<br>下面是mysqldump的一些常用选项，要查阅更详细的功能，可以使用“mysqldump-help”查看。 1.连接选项<br>-u,–user&#x3D;name<br>-p,–password[&#x3D;name] 指定用户名指定密码<br>-h,–host&#x3D;name 指定服务器IP或者域名-P，–port&#x3D;# 指定连接端口<br>这4个选项经常一起配合使用，如果客户端位于服务器上，则通常不需要指定host。如果不指定端口，那么默认连接到3306端口。以下是一个远程客户端连接到服务器的例子：[root@localhost ~]#mysq1dump -h192.168.7.55 -P3306 -uroot -p employees &gt; employees.txt<br>Enter password: ********** 2.输出内容选项<br>–add-drop-database 每个数据库创建语句前加上DROPDATABASE语句–add-drop-table 在每个表创建语句前加上DROPTABLE语句<br>以上这两个选项可以在导人数据库时不用先手工删除旧的数据库，而是会自动删除，提高导人效率，但是导人前一定要做好备份并且确认旧数据库的确已经可以删除，否则误操作将会造成数据的损失。在默认情况下，这两个参数会自动加上。<br>-n,–no-create-db 不包含数据库的创建语句-t,–no-create-info 不包含数据表的创建语句-d,–no-data 不包含数据<br>这3个选项分别表示备份文件中不包含数据库的创建语句、不包含数据表的创建语句、不包含数据，在不同的场合下，用户可以根据实际需求来进行选择。<br>下例中只导出表的创建语句，不包含任何其他信息：<br>[root@localhost ~]# mysqldump -uroot –compact -p -d employees departments &gt; departments.sq][root@localhost ~]# cat departments.sq]<br>&#x2F;*!40101 SET @saved cs_client&#x3D; @@character_set client <em>&#x2F;;<br>&#x2F;</em>!40101 SET character_set client &#x3D; utf8 <em>&#x2F;； CREATE TABLE departments<br>dept no char(4) cOLLATE utf8 unicode ci NOT NULL,<br>dept namevarchar(40) cOLLATE utf8 unicode_ci NOT NULL, PRIMARY KEY （dept_no）,<br>UNIQuE KEYdept name(dept name)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci;<br>&#x2F;</em>!40101 SET character set client &#x3D; @saved cs client <em>&#x2F;; 3.输出格式选项<br>-compact选项使得输出结果简洁，不包括默认选项中的各种注释。下例对employees数据库中的表emp进行简洁导出：<br>[root@localhost ~]# mysqldump -uroot –compact employees departments &gt; departments.sq][root@localhost ~]# cat departments.sql<br>&#x2F;</em>!40101 sET @saved cs client &#x3D;@@character_set client <em>&#x2F;；<br>&#x2F;</em>!40101 sET character_set_client &#x3D; utf8 <em>&#x2F;; CREATE TABLEdepartments<br>dept nochar(4) cOLLATE utf8 unicode ci NOT NULL,<br>dept_namevarchar(40) coLLATE utf8 unicode ci NOT NULL, PRIMARY KEY (dept no),<br>UNIQuE KEYdept name(dept name）<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_unicode_ci;&#x2F;</em>!40101 SET character_set client &#x3D; @saved cs client *&#x2F;;<br>INSERT INTodepartmentsVALUEs （’doo9′,Customer Service’）,（’doo5′,‘Development’）,（’doo8,’Research’),(‘d007’,’sales’);</p>
<p>≦ 400 ≧<br>382 第23章MySQL中的常用工具<br>-c或者–complete-insert选项使得输出文件中的insert语句包括字段名称，默认是不包括字段名称的。下例对employees数据库中的表emp使用此选项进行导出：<br>[root@localhost ~]# mysqldump -uroot -c –compact employees departments &gt; departments.sq][root@localhost ~]# cat departments.sq]<br>&#x2F;*!40101 SET @saved cs_client &#x3D;@@character_set_client <em>&#x2F;;<br>&#x2F;</em>!40101 sET character set client&#x3D;utf8 *&#x2F;; CREATE TABLEdepartments（<br>dept nochar(4) COLLATE utf8 unicode ci NOT NULL,<br>dept namevarchar(40) cOLLATE utf8 unicode ci NOT NULL, PRIMARY KEY (dept no),<br>UNIQUE KEYdept name（dept_name)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci;&#x2F;*140101 sET character set client &#x3D; @saved cs_client <em>&#x2F;;<br>INSERT INTodepartments（dept_no,dept name） VALUES（’doo9’,’Customer Service’),（’doo5′,’Development’),（’d008’,Research’),（’d007′,’sales’）;<br>-T选项将指定数据表中的数据备份为单纯的数据文本和建表SQL两个文件，经常和下面几个选项一起配合使用，将数据导出为指定格式显示。下面几个选项的具体使用方法将会在第25章中进行详细讲解。<br>-T，–tab&#x3D;name（备份数据和建表语句）; O–fields-terminated-by&#x3D;name（域分隔符）； O–fields-enclosed-by&#x3D;name（域引|用符）;<br>O–fields-optionally-enclosed-by&#x3D;name（域可选引用符）; O–fields-escaped-by&#x3D;name（转义字符）。<br>在下面的例子中，将employees数据库中的表departments导出为单纯的数据文本和建表 SQL两个文件，并存放在当前路径下的&#x2F;tmp子目录下。<br>（1）将testl数据库下的表t2备份到bak目录下。<br>[root@localhost ~]s mysqldump -uroot -p employees departments -T &#x2F;tmp Enter password:<br>（2）进入&#x2F;tmp目录，发现生成了两个文件：一个是.sql；另一个是.txt。<br>[root@localhost tmp]# ls departments</em> departments.sql departments.txt<br>（3）查看两个文件的内容，sql文件存放了建表语句，而.txt文件存放了实际的数据。<br>[root@localhost tmp]# cat departments.sq]-Table structure for tabledepartments<br>DROP TABLE IF EXISTSdepartments；<br>&#x2F;*140101 SET @saved cs_client &#x3D;@@character_set client *&#x2F;;<br>&#x2F;*140101 sET character set client&#x3D; utf8 *&#x2F;; CREATE TABLE departments<br>dept nochar(4) coLLATE utf8 unicode_ci NOT NULL,<br>dept namevarchar(40) coLLATE utf8 unicode ci NOT NULL; PRIMARY KEY （dept no）,<br>UNIQUE KEYdept name（dept name’)<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_Ci;[root@localhost tmp]# cat departments.txt<br>d009 Customer Service d005 Development<br>d002 Finance d003 Human Resources</p>
<p>≦ 401 ≧<br>23.1MySQL官方工具 383<br>4.字符集选项<br>–default-character-set&#x3D;name选项可以设置导出的客户端字符集。系统默认的客户端字符集可以通过以下命令来查看：<br>[root@localhost ~]# mysqld –verbose –helplgrep character-set-serverlgrep -v name character-set-server<br>这个选项在导出数据库时非常重要，如果客户端字符集和数据库字符集不一致，数据在导出的时候就需要进行字符集转换，将数据库字符集转换为客户端字符集，经过转换后的数据很可能成为乱码或者“？”等特殊字符，使得备份文件无法恢复。<br>下面是一个字符集导出中文的例子。<br>（1）测试表emp字符集为latinl，插人测试记录。 mysql&gt; show create table emp\G<br>row<br>Table:emp<br>Create Table: CREATE TABLE emp（ idint（11) NOT NULL DEFAULT’O’ namevarchar(200) DEFAULT NULL, content text,<br>PRIMARY KEY (id’)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl<br>1 row in set (0.03 sec) mysql&gt; set names latin1;<br>Query ok, rows affected (o.o0 sec)<br>mysql&gt; INSERT INTO emp(id,name,content) VALUEs （1,z1′,aa）; Query ok,1 row affected (0.o7 sec)<br>mysql&gt; INSERT INTO emp(id,name,content） VALUES (2,中国,aa’）; Query ok,1 row affected （0.06 sec)<br>（2）用默认客户端字符集导出表emp。<br>[root@localhost ~]# mysqld –verbose –helplgrep character-set-serverlgrep -v name<br>character-set-server utf8<br>[root@localhost ~]# mysqldump -uroot –compact employees emp &gt;emp.sq][root@localhost ~]# more emp.sql<br>&#x2F;*!40101 SET @saved cs_client &#x3D;@@character_set client <em>&#x2F;;<br>&#x2F;</em>!40101 SET character set client &#x3D; utf8 <em>&#x2F;; CREATE TABLE emp（<br>idint(11) NOT NULL DEFAULT O, namevarchar(200) DEFAULT NUL, content  text,<br>PRIMARY KEY (id’)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latinl;<br>&#x2F;</em>!40101 sET character_set_client &#x3D; @saved cs client <em>&#x2F;; INSERT INTOempVALUES（1,’z1′,’aa’）,(2,’a,-a&gt;’,aa’）;<br>可以发现“中国”这两个汉字已经变成了乱码。（3）手工设置客户端字符集为latinl，重新导出。<br>[root@localhost ~]#mysqldump -uroot –compact –default-character-set&#x3D;latin1 employees emp &gt;emp.sql[root@localhost ~]# more emp.sq]<br>&#x2F;</em>!40101 SET @saved cs client &#x3D;@@character set_client *&#x2F;;<br>&#x2F;*140101 SET character_set client &#x3D;utf8 <em>&#x2F;; CREATE TABLEemp（<br>idint(11) NOT NULL DEFAULT O′ namevarchar(20O) DEFAULT NULL, content text,<br>PRIMARY KEY (id’)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;latin1;<br>&#x2F;</em>!40101 sET character set client &#x3D; @saved cs client *&#x2F;； INSERT INTOempVALUES（1,z1,aa)，(2,中国’,aa’）;</p>
<p>≦ 402 ≧<br>384 第23章MySQL中的常用工具<br>这次，中文字符可以正确地导出。 5.其他常用选项<br>另外，还有两个常用的选项值得一提。<br>-F–flush-logs（备份前刷新日志）：加上此选项后，备份前将关闭旧日志，生成新日志。使得进行恢复的时候直接从新日志开始进行重做，大大方便了恢复过程。<br>O-1–lock-tables（给所有表加读锁）：可以在备份期间使用，使得数据无法被更新，<br>从而使备份的数据保持一致性，可以配合-F选项一起使用。 23.1.6mysqlpump（并行的数据导出工具）<br>从MySQL5.7.8开始，MySQL官方提供了一个新的数据导出工具mysqlpump。相对于 mysqldump，mysqlpump有以下几个特点。<br>并行导出表数据，提高导出效率。<br>更好地控制数据库和表、存储过程、用户账号的导出。导出用户账号通过create user和grant语句实现。<br>导出文件的同时支持在线压缩。显示导出进度。<br>先导出建表语句，接着导出insert语句，最后再导出二级索引，提高数据导入速度。 mysqlpump大多数选项与mysqldump是一致的，下面只介绍mysqlpump独有且常用的<br>参数。<br>-add-drop-user 每个create user命令前，记录drop user命令。-compress-output&#x3D;algorithm 压缩结果文件，默认不开启。支持LZ4和ZLIB压缩算法。–default-parallelism&#x3D;N 默认并行线程数。默认值是2。<br>–defer-table-indexes 导出文件先记录建表语句，再记录insert语句，最后创建二级索引。–include-databases&#x3D;db_list 导出数据库的列表，用逗号分隔-include-tables&#x3D;table_list 导出表的列表，用逗号分隔<br>–include-users&#x3D;user_list 导出用户的列表，用逗号分隔-parallel-schemas&#x3D;[N:]db_1ist 创建一个队列，用于导出数据库列表的表。如果指定N的值，那么这个队列将开启<br>N个线程：如果N未指定，那么将用–default-parallelism指定的值作为默认线程数。<br>-users 以create uer和grant语法导出导出用户。-watch-progress 显示导出进度。使用–skip-watch-progress关闭显示进度。<br>注意：mysqlpump默认不导出information_schema、performance_schema、ndbinfo和 sys数据库。下面来看几个例子。<br>导出所有数据库，默认开启一个队列，两个线程。<br>[mysq13307@1oca1host ~]s mysq1pump -uroot -s&#x2F;tmp&#x2F;mysql 3307.sock-A&gt; backup.sq] Dump progress:1&#x2F;2 tables, 0&#x2F;0 rows<br>Dump progress: 10&#x2F;61 tab1es, 1142206&#x2F;2745024 rows Dump progress:28&#x2F;61 tab1es,2443005&#x2F;2745024 rows<br>Dump completed in 2626 mi11iseconds 导出所有数据库，启用压缩功能。<br>[mysq13307@1ocaThost ~]s mysq1pump -uroot -S&#x2F;tmp&#x2F;mysq1 3307.sock-A–compress-output&#x3D;Lz4&gt; backup.1z4<br>Dump progress:1&#x2F;2 tab1es,0&#x2F;0 rows<br>Dump progress:10&#x2F;61 tab1es, 995206&#x2F;2745024 rows Dump progress:19&#x2F;61 tab1es, 2008086&#x2F;2745024 rows Dump completed in 3084 mi1liseconds<br>解压backup.LZ4，如果本机没有lz4工具，则可以用yuminstall lz4来安装。</p>
<p>≦ 403 ≧<br>23.1MySQL官方工具 385<br>[mysq13307@1oca1host<del>]s1z4-d backup.1z4 Decoding file backup<br>backup.1z4 :decoded 123398461 bytes<br>导出所有数据库。其中一个队列导出employees和testdb数据库，该队列分配10个线程；另一个队列导出剩下的数据库，队列分配3个线程。<br>mysq1pump-uroot-s&#x2F;tmp&#x2F;mysq1_3307.sock -A–paral1el-schemas&#x3D;10:employees,testdb –default-para1lelism&#x3D;3&gt;backup.sq1<br>Dump progress:1&#x2F;2 tables,0&#x2F;0 rows<br>Dump progress:54&#x2F;60 tab1es,1253262&#x2F;2745023 rows Dump progress: 62&#x2F;64 tab1es,2443906&#x2F;2749076 rows Dump completed in 4492 mi1liseconds<br>导出数据库db_master1的表结构和所有用户。<br>[mysq13307@localhost</del>]$ mysqlpump -uroot -s&#x2F;tmp&#x2F;mysql 3307.sock-d–users -B db_master1&gt; backup.sq1<br>Dump completed in 1484 mi1liseconds<br>[mysq13307@localhost ~]s more backup.sq]<br>Dump created by MysQL pump utility, version: 5.7.22,1inux-glibc2.12 (x86 64)<br>Dump start time:Wed Jul 2520:27:352018 server version:5.7.22<br>GRANT SELECT ON *<em>TOemp‘@’%’;<br>CREATE USER rep1‘@’% IDENTIFIED WITH ‘mysql_native pasSWord’ AS</em>A424E797031BF97C69A2E88<br>CF9231C5C2038CO39 REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT U NLOCK;<br>23.1.7mysqlimport（数据导入工具）<br>mysqlimport是客户端数据导人工具，用来导人mysqldump加-T选项后导出的文本文件。它实际上是客户端提供了LOADDATAINFILEQL语句的一个命令行接口。用法和LOAD DATAINFILE子句非常类似，第25章将对mysqlimport和LOADDATAINFILE的用法进行详细的介绍，这里不再赘述。<br>mysqlimport的基本用法如下：<br>shell&gt; mysqlimport [options] db_name textfilel[textfile2…] 23.1.8mysqlshow（数据库对象查看工具）<br>mysqlshow客户端对象查找工具，用于快速查找存在哪些数据库、数据库中的表、表中的列或索引。和mysql客户端工具很类似，不过有些特性是mysql客户端工具所不具备的。<br>mysqlshow的使用方法如下：<br>shell&gt; mysqlshow[option] [db_name [tbl_name [col_name]]]<br>如果不加任何选项，默认情况下会显示所有数据库。下例显示了当前MySQL中的所有数据库：<br>[root@localhost ~]# mysqlshow -uroot<br>Databases<br>|information schema<br>|employees mysq1<br>Iperformance_schema sys</p>
<p>≦ 404 ≧<br>386 第23章MySQL中的常用工具<br>下面是mysqlshow的一些常用选项。<br>（1）–count（显示数据库和表的统计信息）。<br>如果不指定数据库，则显示每个数据库的名称、表数量、记录数量；如果指定数据库，则显示指定数据库的每个表名、字段数量，记录数量；如果指定具体数据库中的具体表，则显示表的字段信息，如下例所示。<br>不指定数据库：<br>[root@localhost ~]# mysqlshow -uroot –count<br>Databases Tables| Total Rows<br>I information_schema 611 3336681 1employees 19 4519075 1mysql 2949 performance schema 46532 sys 101 4456<br>6 rows in set. 指定数据库：<br>[root@localhost ~]# mysqlshow -uroot employees –count Database: employees<br>Tables 1columns |Total Rows<br>current dept emp 41 300024 dept_emp 41 331603<br>Idept emp_latest date 3 3000241 Idept manager 24<br>lemployees 300024 1salaries 4 2844047<br>6 rows in set<br>指定数据库和表：<br>[root@localhost ~]# mysqlshow -uroot employees depantments –count Database:employees Table: departments Rows:9<br>Field IType lCollation |Null|key|Default|Extra|Privileges |Comment|<br>Idept noIchar(4) lutf8 unicode ci INo |PRI| select,nsrt,dat,fre dept name|varchar(40)|utf8 unicode ciINo |uNI) select,nsert,update,referencs<br>（2）-k或者–keys（显示指定表中的所有索引l）。<br>此选项显示了两部分内容，一部分是指定表的表结构，另外一部分是指定表的当前索引信息。下例显示了employees库中表departments的表结构和当前索引信息：<br>[root@localhost ~]# mysqlshow -uroot employees departments –count -k Database: employees Table: departments Rows:9<br>|Field 1Type 1collation |Nulll Key |Default丨 Extra 丨 Privileges<br>Comment<br>|dept no1char(4) utf8 unicode ci NO PRI1 |select,insert, update,references<br>|dept name | varchar(40) |utf8unicode ci IUNII I select,insert, update,references I</p>
<p>≦ 405 ≧<br>23.1MySQL官方工具 387<br>1Table Seq in index |Column_name |collation | cardinality Packed |Null |Index type | Comment | Index comment|<br>|departments|0 IPRIMARY 11 | dept no A 19<br>BTREE<br>dept_name dept_name 19<br>BTREE<br>细心的读者可能会发现，显示的内容实际上和在mysql客户端执行“showfullcolumns fromdepartments”和“showindexfromdepartments”的结果完全一致。<br>（3）-i或者–status（显示表的一些状态信息）。下例显示了test数据库中emp表的一些状态信息：<br>[root@localhost <del>]#mysqlshow -uroot employees departments -i<br>I Name Engine I Version I Row format ROWS Avg_row_length Data length I Max<br>data_length Index length Data free | Auto increment Create_time Update_time check time collation Checksum | Create options Comment<br>丨InnODB丨10<br>departments Dynamic 9 11820 |16384 o<br>|16384 2018-05-2314:52:20 utf8unicode ci<br>此命令和mysql客户端执行“showtable statusfromemployees like’departments”的结果完全一致。<br>23.1.9：perror（错误代码查看工具）<br>在MySQL的使用过程中，可能会出现各种各样的error。这些error有些是由于操作系统引起的，比如文件或者目录不存在；有些则是由于存储引擎使用不当引起的。这些error一般都有一个代码，类似于“error：#”或者“Errcode：#”，“#”代表具体的错误号。perror的作用就是解释这些错误代码的详细含义。<br>perror的用法很简单，如下所示：<br>PerrOr [OPTIONS] [ERRORCODE [ERRORCODE..]]<br>在下面的例子中，可以看一下错误号30和60分别指的是什么错误：[root@localhost</del>]#perror 30 60<br>os error code 30: Read-only file system Os error code 60: Device not a stream<br>23.1.10MySQL Shell<br>MySQLShell是MySQLServer的高级客户端和代码编辑器。除了提供类似MySQL的SQL 功能，MySQLShell还提供了JavaScript和Python的脚本功能，并包含用于处理MySQL的 API。MySQLShell支持批量执行代码，支持Tabbed、Table和JSON这3种输出格式。<br>MySQLShell的用法如下：</p>
<p>≦ 406 ≧<br>388 第23章MySQL中的常用工具<br>she77&gt; mysqlsh [OPTIONS] [URI]<br>she77&gt; mysqlsh [opTIoNS] [URI] -f <path> [script args…] she77&gt; mysqlsh [oPTIoNs] [uRI] –dba [command]<br>shell&gt; mysqlsh [oPTIONS] [URI] -cluster 以下是登录MySQLShell常用的选项：–execute&#x3D;<cmd> 执行命令并退出<br>,–file&#x3D;file 要在批处理模式下处理的文件<br>-uri&#x3D;value 指定连接字符串，格式为[user[：pass]@]host[：port][&#x2F;db]-mx,–mysq1x 以x协议创建连接，使用mysq1x_port端口连接MysQL<br>–mysq1 以经典模式创建连接，使用port端口连接MySQL-sql 以sQL模式登录，使用port 端口连接MySQL<br>-sq1x 以x协议的sQL模式登录。使用mysq1x _port端口连接MySQL<br>javascript 以JS模式登录<br>-py,–python 以python模式登录-json[&#x3D;format] 以json格式打印输出-table 以表格格式显示输出<br>–1og-level&#x3D;value 指定日志级别，可以是1到8的整数，或是[none，internal，error，warning，info，debug， debug2,debug3]<br>登录MySQLShell后，可以使用V？命令调出帮助文档：<br>MyQL127.0.0.134880+S&gt; M0 0 3L 20 00920 0580631<br>帮助文档主要包括5个方面。<br>OAdminAPI:包括dba全局object和InnoDBCluster管理API，用于创建和管理InnoDB Cluster环境。使用\？dba命令可调出详细帮助信息。<br>OShell命令：mysqlsh自带的shell命令帮助文档。<br>OShellAPI:包含shell和util全局object的帮助信息；在mysql模式下，还包含mysql 模块的帮助信息。可分别使用?Shell、?util、?mysql调出详细帮助信息。<br>SQL语法：列出指定SQL语句的帮助信息。使用?sqlsyntax命令调出详细帮助信息，其中sql syntax为具体的sql语法，例如使用\？select查看select的语法帮助。<br>XDevAPI:mysqlx模块和XDevAPI的使用方法，使用\？mysqlx调出详细帮助信息。 1.MySQLShell软件的安装<br>（1）以8.0.12版本为例，下载Linuxx86二进制软件安装包：<br>[mysq13488@1oca1host ~]s,wget <a target="_blank" rel="noopener" href="https://cdn.mysql.com//Downloads/MysQL-she11/mysq1-she11">https://cdn.mysql.com//Downloads/MysQL-she11/mysq1-she11</a><br>-8.0.12-1inux-glibc2.12-x86-64bit.tar.gz（2）解压安装包：<br>[mysq13488@ 1oca1host ~]s tar xvfz mysql-she11-8.0.12-linux-g1ibc2.12-x86-64bit.tar.gz<br>[mysq13488@ 1ocalhost ~js cd mysql-she11-8.0.12-1inux-glibc2.12-x86-64bit（3）配置MySQLShell环境变量：<br>[mysq13488@ 1oca1host ~]$ export MYsQL_SHELL_HoME&#x3D;&#x2F;home&#x2F;mysq13488&#x2F;mysq1-she11-8.0.12-1inux-glibc2.12-x86-64bit<br>[mysq13488@ 1ocaThost ~]s export PATH&#x3D;$SMYSQL_SHELL HOME&#x2F;bin:SPATH<br>[mysq13488@ 1ocalhost ~]s export C INCLUDE_PATH&#x3D;SMYSQL SHELL HOME&#x2F;include:$C INCLUDE_PATH[mysq13488@ 1ocalhost ~]s export LD LIBRARY_PATH&#x3D;SMYSQL SHELL HOME&#x2F;lib:$LD_LIBRARY_PATH[mysq13488@ 1ocalhost ]$ which mysq1sh<br>~&#x2F;mysq1-she11-8.0.12-1inux-glibc2.12-x86-64bit&#x2F;bin&#x2F;mysq1sh（4）使用emp用户，以SQL模式登录MySQLShell：<br>[mysq13488@ 1ocalhost ~]$ mysq1sh emp’:emp123@’127.0.0.1’:3488&#x2F;emp1oyees –sq1 mysqlsh: [warning] using a password on the command line interface can be insecure. Creating a session to ‘<a href="mailto:&#x65;&#109;&#x70;&#64;&#49;&#50;&#x37;&#46;&#48;&#46;&#48;&#46;&#49;">&#x65;&#109;&#x70;&#64;&#49;&#50;&#x37;&#46;&#48;&#46;&#48;&#46;&#49;</a>:3488&#x2F;emp1oyees’<br>Fetching schema names for autocompletion… Press Ac to stop.<br>Fetching table and column names from employees for auto-completion… Press Λc to stop. YourMysQLconnectionid isi</p>
<p>≦ 407 ≧<br>23.1MySQL官方工具 389<br>Server version: 8.0.11 MysQL Community Server - GPL<br>Default schema set to employees. MySQL She11 8.0.12<br>Type \help′ or ‘?‘ for help;’\quit’ to exit.<br>MySQL 127.0.0.1:3488 ss1 emp1oyees SQL &gt;show databases;<br>|Database 1employees<br>I information_schema<br>2rows in set (0.0012 sec)<br>（5）从SQL模式切换到JS模式：<br>MySQL 127.0.0.1:3488 ss1 emp1oyees SQL&gt;Ajs Switching to Javascript mode..<br>MySQL 127.0.0.1:3488 ss1 employees Js&gt; 2.MySQLShelI使用JS模式查询数据（1）确认MySQL安装了mysqlx插件。 mysql&gt;show plugins;<br>1Name I Status 1Type |Library ILicense<br>1mysq1x |ACTIVE DAEMON 1NULL GPL 1mysqlx cache_cleaner 1ACTIVE |AUDIT NULL IGPL<br>（2）启用mysqlx插件。<br>在my.cnf配置mysqlx参数，并重启实例。测试实例端口为3488，mysqlx的监听端口相<br>应设置为34880：[mysqld]<br>loose mysqlx socket&#x3D; mysqlx.sock<br>loose mysqlx_port &#x3D; 34880 确认mysqlx端口已启用：<br>mysq1&gt;show variables likemysqlx port; Ivariable_name |value |<br>Imysqlx_port 348801 1 row in set (o.o0 sec)<br>（3）通过mysqlx协议登录MySQLShell：<br>she11&gt;mysq1sh emp’:<a href="mailto:&#x65;&#109;&#x70;&#49;&#50;&#51;&#64;&#x31;&#x32;&#55;&#46;&#48;&#x2e;&#48;&#x2e;&#49;">&#x65;&#109;&#x70;&#49;&#50;&#51;&#64;&#x31;&#x32;&#55;&#46;&#48;&#x2e;&#48;&#x2e;&#49;</a>‘:34880 –js -mx<br>Creating an x protoco1 session to‘<a href="mailto:&#101;&#x6d;&#112;&#x40;&#x31;&#x32;&#x37;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;">&#101;&#x6d;&#112;&#x40;&#x31;&#x32;&#x37;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;</a>:34880&#x2F;employees<br>Fetching schema names for autocompletion… Press c to stop. Your MysQL connection id is 13 (x protoco1)<br>Server version: 8.0.11 MysQL Community Server - GPL Default schema employees accessible through db. MySQL She11 8.0.12<br>Type \help′or ‘?’ for help;\quit’to exit.<br>MySQL127.0.0.1:34880+ Ss1JS&gt;（4）在JS模式下查询表记录。设置当前db变量：</p>
<p>≦ 408 ≧<br>390 第23章MySQL中的常用工具<br>MysQl  127.0.0.1:34880+ ss1Js &gt; var employees&#x3D;session.setcurrentschema(‘emp1oyees’) MySQL127.0.0.1:34880+ ss1Js&gt; emp1oyees<br><a href="Schema:employees">Schema:employees</a> 查看db下所有的表：<br>MySQL 127.0.0.1:34880+ ss1Js&gt;emp1oyees.getTab1esO<br><a href="Table:departments">Table:departments</a>, <a href="Table:dept_emp">Table:dept_emp</a>, &lt;Table:dept manager&gt;, <a href="Table:employees">Table:employees</a>, <a href="Table:sal">Table:sal</a>,<br><a href="Table:salaries">Table:salaries</a>, <a href="Table:titles">Table:titles</a>, <a href="Table:titlesl">Table:titlesl</a><br>设置departments表变量：<br>MysQL 127.0.0.1:34880+ sslJs&gt;var departments&#x3D;emp1oyees.getTab1e(‘departments’) MySQL 127.0.0.1:34880+ ss1  Js&gt; departments<br><Tabedearent> 查看departments表记录：<br>MySQL 127.0.0.1:34880+ ss1 Js&gt; departments.selectO Idept no | dept name<br>1d009 Customer service d005 I Development<br>d002 Finance d003 I Human Resources d001 |Marketing<br>d004 Production d006 Quality Management<br>d008 I Research d007 Isales<br>9rows in set (0.0012 sec)<br>通过上面的命令，读者可以了解MySQLShell的一些用法，在操作上也比较简单。遇到不熟悉的操作时，多使用MySQL Shell提供的帮助命令。<br>MySQLShell的一个重要的功能是配置InnoDBCluster环境，详细的配置方法可以参考第 31章中的相关内容。<br>23.2Percona工具包<br>上面介绍了MySQL官方提供的一些常用工具，但在实际工作过程中，官方提供的工具并不能完全解决各种问题。MySQL的开源社区中涌现了不少高质量的工具，PerconaToolkit（工具包）就是其中的依者。<br>PerconaToolkit 前身源自于Maatkit和Aspersa工具，是各种高级命令行工具的集合，用于执行重复或者复杂的MySQL任务和系统任务。这些工具相互独立，不依赖其他安装包。该工具集涵盖了MySQL的开发管理、性能优化、配置管理、监控管理、复制管理、系统统计等诸多方面。下面介绍几个较为常用的工具。</p>
<p>≦ 409 ≧<br>23.2Percona工具包 391<br>23.2.1pt-archiver（数据归档工具）<br>pt-archiver是一个数据归档工具，用于迁移源表数据到另外一个表或者文件，也可以删除源表数据。pt-archiver工具原理是根据表中索引l（默认是主键索引）找到第一条记录，然后顺序找到更多需要归档的记录，从而小批量地、慢慢地归档数据，以减少对线上业务的影响。该工具主要适用于历史数据迁移或者删除过期的数据等比较耗时而重复性又比较高的场景。<br>pt-archive的用法如下：<br>she7l&gt; pt-archiver [oPTIoNS] –source DSN –where WHERED<br>下面是一些常用的选项：<br>–analyze 任务完成后，分析表<br>–ascend-first 按照索引的最左列做升序查找，避免在有多列字段的索引上，根据多列字段查找数据–charset 设置字符集<br>–[no]check-charset 确认连接和表的字符集是否一致，默认开启<br>–check-interval 如果使用–check-slave-1ag选项，指定检测从库延迟的间隔，默认1s<br>–check-slave-lag 是否开启从库延迟检查，默认开启。当从库延迟超过–max-1ag指定的值后，任务将暂停，直至从库延迟的值小于–max-1ag指定的值<br>-columns 只迁移指定的列，列名用逗号分隔<br>–commit-each 归档完一批数据后，立刻提交事务。这个参数与–txn-size互斥，与–limit配合使用–dest DSN格式，指定数据迁移到的目的地。如果–dest的值与–source一致，可忽略此参数–dry-run 仅打印归档过程运行的sq1语句，而不真正执行<br>–file 将数据归档到这个文件，导出的数据格式跟SELECTINTOOUTFILE一致<br>–host pt工具连接的主机ip–ignore 为insert语句加上ignore参数–1imit<br>每次从源表取记录并归档到目的地的记录数量<br>–max-lag 从库最大延迟时间，默认1s。配合–check-s1ave-1ag使用<br>–no-delete 数据归档到目的地后，不删除源表的数据。如果不指定这个参数，默认删除源表数据-optimize 任务完成后，优化表–password 指定密码–pid 运行任务的时候，生成pid文件，可避免重复执行归档任务<br>–progress 指定操作N条记录后，打印进度信息。进度信息包括当前时间，已消耗时间，已迁移记录数–purge 在源表删除数据，不进行数据归档-run-time 指定任务运行时间。超过指定时间后，即使数据未迁移完，任务也会停止<br>–sleep 指定每次在源表取数的间隔–source DSN格式，指定数据源端的连接方式<br>–statistics 收集信息和打印任务总的时间统计–txn-size 指定每个事务迁移N条记录。N为O表示不开启事务，启用事务自动提交<br>–where 增加where条件，过滤需要归档的数据下面来看几个具体例子。<br>删除employees.salaries表from_date小于1987-02-25的数据，每删除1万条数据打印一次进度信息，每次删除1000条数据。<br>[mysq13307@localhost employees]$ pt-archiver –source h&#x3D;127.0.0.1,D&#x3D;employees,t&#x3D;salaries,u&#x3D;root,<br>P&#x3D;3307 –charset&#x3D;utf8 –where “from date &lt;’1987-02-25·”–purge –progress&#x3D;10000 –1imit 1000<br>TIME ELAPSED COUNT 2018-07-28T15:44:38 0<br>2018-07-28T15:44:52 13 10000 2018-07-28T15:45:05 27 20000<br>2018-07-28T15:45:19 40 30000 2018-07-28T15:45:33 54 40000<br>2018-07-28T15:45:46 68 50000 2018-07-28T15:46:00 81 60000 2018-07-28T15:46:04 86 63250<br>将employees.salaries表from_date小于1987-02-25的数据，归档到employees.salaries history表。每次归档2万条记录，归档2万条记录后立刻提交，每次归档间隔2s。任务结束后，打印总的统计信息。</p>
<p>≦ 410 ≧<br>392 第23章MySQL中的常用工具<br>归档前查看employees.salaries符合条件的记录数。<br>mysql&gt;select count(0) from salaries where from date &lt;’1987-02-25’; count(o)<br>63250<br>row in set(1.20 sec)<br>查看employees.salaries_history表的记录数。 mysql&gt;select count(o) from salaries history; count(0)1<br>1 row in set (0.00 sec)<br>开始把数据归档到历史表。<br>[mysq13307@localhost employees]$ pt-archiver –source h&#x3D;127.0.0.1,D&#x3D;employees,t&#x3D;salaries,u&#x3D;root, P&#x3D;3307 –dest h&#x3D;127.0.0.1,D&#x3D;employees,t&#x3D;salaries history,u&#x3D;root,P&#x3D;3307 –charset&#x3D;utf8 –where from date &lt;’1987-02-25”–1imit 20000 –commit-each –sleep 2–statistics<br>started at 2018-07-28T16:02:45,ended at 2018-07-28T16:03:37 Source: A&#x3D;utf8,D&#x3D;emp1oyees,P&#x3D;3307,h&#x3D;127.0.0.1,t&#x3D;salaries,u&#x3D;root<br>Dest:A&#x3D;utf8,D&#x3D;emp1oyees,P&#x3D;3307,h&#x3D;127.0.0.1,t&#x3D;salaries history,u&#x3D;root<br>SELECT 63250 INSERT 63250 DELETE 63250<br>Action Count Time Pct deleting 63250 18.8361 36.53 inserting<br>sleep 63250 5 15.0347 29.16<br>8.0010 15.52<br>select 1.6581 3.22 commit 10 0.2996 0.58 other 7.7289 14.99<br>根据统计信息，可以知道每个操作类型消耗的总时间：删除数据用了18s，插人数据用了 15s；其间sleep两次，一共4s。<br>看看employees.salaries表的记录数。<br>mysql&gt;select count(0) from salaries where from date &lt;’1987-02-25’: 1count（o)<br>1 row in set (1.13 sec)<br>结果显示，employees.salariesfrom_date在1987-02-25前的63250条数据已经被删掉，再看employees.salaries_history表的记录数：<br>mysql&gt;select count(o) from salaries history; |count（o）1<br>632501<br>1 row in set (0.02 sec)<br>employees.salaries_history有63250条记录，跟我们的预期是一致的。再看看把记录归档到文件中的例子。<br>将employees.salaries表from_date小于1987-02-25的数据，归档到&#x2F;tmp目录下，归档文件名为归档时间和数据库名、表名的组合。每次归档100条记录，任务最多只运行10s，不删</p>
<p>≦ 411 ≧<br>23.2Percona工具包 393<br>除源表的记录，打印总的统计信息。<br>开始任务前，查看employees.salaries表符合条件的记录数： mysql&gt;select count(0) from salaries where from date &lt;’1987-02-25’;<br>1count（o)1 632501<br>1row in set (1.20 sec) 开始归档数据：<br>[mysq13307@localhost tmp]s time pt-archiver -source h&#x3D;127.0.0.1,D&#x3D;employees,t&#x3D;salaries,u&#x3D;root, P&#x3D;3307–file’&#x2F;tmp&#x2F;%Y-%m-%d-%D.%t–charset&#x3D;utf8–where”from date&lt;’1987-02-25–1imit 100 –run-time 10 –no-delete –statistics<br>Started at 2018-07-28T16:33:36,ended at 2018-07-28T16:33:46 Source:A&#x3D;utf8,D&#x3D;emp1oyees,P&#x3D;3307,h&#x3D;127.0.0.1,t&#x3D;salaries,u&#x3D;root SELECT 40000<br>INSERTO DELETE0<br>Action Count Time Pct commit 39904 3.1803 31.80<br>select 400 1.6762 16.76 print file 39903 0.3048 3.05 other o 4.8389 48.39<br>real 0m13.256s user 0m5.119s sys 0m1.869s<br>注意：根据time命令统计的运行时间是13.256s，pt-archiver的Time统计时间累加是10s。所以<br>–run-time是按照pt-archiver本身的统计时间为准的。<br>再次查询employees.salaries表符合条件的记录数：<br>mysql&gt;select count(0) from salaries where from date &lt;’1987-02-25’; 1count（0)1<br>632501<br>1 row in set(1.32 sec)<br>可以看到，employees.salaries表的记录没有被删除。查看归档的文件：<br>[mysq13307@1ocalhost tmp]s more 2018-07-28-employees.salaries<br>10001 60117 1986-06-26 1987-06-26 10004 40054 1986-12-01 1987-12-01<br>10009 60929 1985-02-18 1986-02-18 10009 64604 1986-02-18 1987-02-18<br>10009 64780 1987-02-18 1988-02-18 10013 40000 1985-10-20 1986-10-20<br>employees.salaries表数据量很大，即使没有完全归档数据，10s后任务自动停止了。通过<br>限定任务的执行时间，可以减少对现有环境的影响。 23.2.2pt-config-diff（参数对比工具）<br>pt-config-diff用于找出配置文件和MySQL内存值不一样的参数，其使用方法： shell&gt; pt-config-diff [OPTIONS] CONFIG CONFIG [cONFIG..]<br>CONFIG可以是配置文件名字，也可以是DSN连接串。pt-config-diff只比较两个CONFIG</p>
<p>≦ 412 ≧<br>394 第23章MySQL中的常用工具都包含的变量。<br>以下是一些常用的选项：<br>–charset 指定连接字符集<br>–defaults-file 指定mysq1的配置文件–host 连接的主机ip<br>–[no]ignore-case 对比的参数是否区分大小写。默认为yes<br>–ignore-variables 忽略比较的变量比较两个配置文件，区分大小写：<br>[mysq13307@localhost mysqlhome]s pt-config-diff –noignore-case my.cnf my1.cnf 2 config differences<br>variable my.cnf my1.cnf<br>init_connect SET NAMES utf8 set NAMES utf8 port 3307 3308<br>可以看到，命令区分大小写后，set和SET被识别为两个值。比较MySQL实例内存与cnf配置文件：<br>[mysq13307@1oca1host mysq7home]s pt-config-diff h&#x3D;127.0.0.1,u&#x3D;root,P&#x3D;3307 my1.cnf 10 config differences<br>Variable localhost my1.cnf innodb buffer pool size 5368709120 5242880000 port 3307 3308 secure_file priv&#x2F;tmp&#x2F; &#x2F;tmp<br>slave parallel type DATABASE LOGICAL_CLOCK<br>23.2.3pt-duplicate-key-checker（检查余索引l工具）<br>这个工具用于检查表中是否有余的索引和外键。工具通过showcreate table查看表的索引，如果一个索引与另外一个索引具有相同的列，并且列在索引的顺序是一样的，或者被另一个索引的前几列所覆盖，那么这个索引就是重复索引；检查见余外键时，如果两个外键覆盖的字段一样，且字段指向的父表也一样，那么其中一个外键是余的。最后工具给出优化对应的索引或者外键的SQL语句。<br>pt-duplicate-key-checker的使用方法如下：<br>she77&gt; pt-duplicate-key-checker [OPTIoONs] [DsN]<br>常用参数如下：<br>–databases,-d 只检查列出的数据库的表，每个数据库用逗号分隔–defaults-file 从给定的配置文件读取MySQL参数<br>-ignore-databases 不检查这些数据库下的表，，每个数据库用逗号分隔 ignore-order 忽略索引字段顺序。选项启用后，key（a，b）和key（b，a）属于同一索引<br>-ignore-tables 忽略检查的表。表名前要加上db名，用逗号分隔–key-types 检查的key类型，默认为fk。f为外键，k为索引<br>-[no]sq] 打印dropkey的sql语句，默认开启-[no]summary 打印索引统计信息，默认开启<br>-tables,-t 只检查指定表。表名前要加上db名，用逗号分隔下面来看一些具体的例子。<br>检查重复、冗余索引，不检查外键。<br>[mysq13307@localhost ~1$ pt-duplicate-key-checker –socket &#x2F;tmp&#x2F;mysql 3307.sock –user root-key-types&#x3D;k<br>技技技技技技#employees.departments<br>技技技技技技技技</p>
<p>≦ 413 ≧<br>23.2Percona工具包 395<br>#idx dept no is a duplicate of PRIMARY#Key definitions:<br>KEYidx deptno（dept no）<br>PRIMARY KEY（dept_no’）,#Column types:<br>dept nochar（4) collate utf8 unicode ci not nul1<br>#To remove this duplicate index,execute:<br>ALTER TABLEemployees.departmentsDROP INDEXidx dept_no；<br>结果显示，idx_dept_no为余索引l，工具给出了drop索引的命令。 23.2.4pt-find（查找工具）<br>pt-find工具通过 show tables和 show table status 获得信息，查找符合特定规则的表。默认输出数据库名和表名。<br>pt-find的使用方法如下：<br>shell&gt; pt-find [OPTIONs] [DATABASES]<br>常用参数如下：<br>–case-insensitive 大小写不敏感–charset 设置默认连接的字符集<br>用or替代and连接输入的命令：or和and不能混合使用<br>下面来看几个例子。<br>（1）查看数据库大于100MB的表：<br>[mysq13307@localhost ~]$ pt-find –user.root -S&#x2F;tmp&#x2F;mysql 3307.sock –tablesize +100M employees’.salaries<br>（2）查看一天内创建的存储引擎为innodb的表：<br>[mysq13307@localhost ~]$ pt-find –user root-s&#x2F;tmp&#x2F;mysq] 3307.sock –ctime -1-engine InnoDB employees&#96;.departments<br>23.2.5pt-heartbeat（监控主从延迟工具）<br>pt-heartbeat工具用于监控从库复制是否延迟，通过在主库更新心跳表的时间戳字段，从<br>而对比从库该字段与主机的时间差异，来评估延迟情况。<br>注意：主从MySQL实例的主机时间要保持一致。 pt-heartbeat工具的使用方法如下：<br>shell&gt; pt-heartbeat [oPTroNs] [DsN] –update&#x2F;–monitor&#x2F;–check&#x2F;–stop<br>常用参数如下：<br>–check 只检查一次从库的延迟。如果指定-recurse选项，会检查所有的级联从库–check-read-only 如果开启，工具不在read_only&#x3D;on的实例做任何插入操作<br>-create-table 创建心跳表–daemonize 把任务放到后台运行<br>-database 连接的数据库名-interval 更新或检查心跳表的间隔，默认1s–1og 把任务放到后台运行后，可以指定输出到一个1og文件<br>–master-server-id 指定当前数据库的主库的server-id。如果未指定，工具会尝试主动获取-monitor 监控从库延迟。每秒打印出当前从库的延迟情况<br>-recurse 递归检查从库延迟-replace 在-update选项中，用replace操作代替update操作–run-time 任务的最大运行时间<br>–slave-user 指定连接从库的用户名-slave-password 指定连接从库的用户名–update 更新主库心跳表的时间戳</p>
<p>≦ 414 ≧<br>396 第23章MySQL中的常用工具<br>下面来看一些具体的例子，首先创建心跳表的数据库：<br>root@localhost:mysql 3307.sock [(none)]&gt;create database percona; Query ok,1 row affected (o.o0 sec)<br>root@localhost:mysql 3307.sock [(none)]&gt;use percona; Database changed<br>root@localhost:mysql_3307.sock [percona]&gt;show tables; Empty set(O.oo sec)<br>创建心跳表：<br>[mysq13307@localhost ~]s pt-heartbeat –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysq1_3307.sock -D percona<br>-create-table –master-server-id&#x3D;7237 –check 1.00<br>root@localhost:mysql 3307.sock [percona]&gt;show tables;<br>| Tables_in percona 1heartbeat<br>1 row in set (o.00 sec)<br>root@localhost:mysql_3307.sock [percona]&gt;select * from heartbeat\G<br>ts:2018-08-02 15:29:05 server_id:7237<br>file: NULL position: NULL<br>relay_master_log_file: NULL exec_master_log pos: NULL 1 row in set (o.00 sec)<br>可以看到，心跳表已经创建好。如果未指定，表名默认为heartbeat，ts为时间戳字段。运行后台任务，每秒更新心跳时间戳，任务只运行30s。<br>[mysq13307@loca1host ~]s pt-heartbeat –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysql 3307.sock -D percona–master-server-id&#x3D;7237 –interval 1 –run-time 30 –update –daemonize<br>30s后，pt-heartbeat进程退出，查看心跳表：<br>root@localhost:mysql 3307.sock [percona]&gt;select * from heartbeat\G<br>ts:2018-08-02T15:36:24.001270 server_id:7237<br>file:mysql-bin.000043 position: 40153<br>relay_master_log file: NULL exec_master log_pos: NULL 1row in set(o.00 sec)<br>时间戳ts、file和position字段已经更新了。连接从库，监控从库的复制延迟：<br>[mysq13307@loca1host ~]s pt-heartbeat –user&#x3D;root  –socket&#x3D;&#x2F;tmp&#x2F;mysql 3308.sock -D percona<br>-master-server-id&#x3D;7237 –interval 1–monitor 31.00s 0.52s, 0.10s， 0.03s] 32.00s 1.05s, 0.21s, 0.07s]<br>33.00s 1.60s, 0.32s, 0.11s ] 34.00s 2.17s, 0.43s, 0.14s] 35.00s L 2.75s， 0.555, 0.18s]<br>36.00s 3.35s, 0.67s， 0.22s] 37.00s 3.97s, 0.79s, 0.26s]<br>L<br>38.00s 4.60s, 0.925, 0.31s] 0.00s 4.60s, 0.92s, 0.31s] 0.91s 4.62s, 0.92s, 0.31s] 1.91s 4.65s, 0.93s, 0.31s] 2.91s 4.70s， 0.94s,0.31s]</p>
<p>≦ 415 ≧<br>23.2Percona工具包 397<br>0.00s[ 4.70s, 0.94s,0.31s] 0.00s4.70s,0.94s,0.31s]<br>pt-heartbeat监控从库延迟输出有4列，第一列是当前时间跟从库时间戳ts字段的差值，<br>单位为s；后三列为1min、5min、15min的平均延迟。 23.2.6pt-kill（杀死会话工具）<br>pt-kill工具用于杀死找到符合条件的连接。pt-kill可以通过执行showprocesslist得到信息，也可以通过给定文件得到信息。<br>pt-kill工具的使用方法如下：<br>she71&gt;tki7 oPTIONS】[DSN]<br>常用参数如下：<br>-create-log-table 创建存放1og的表-daemoni ze 把任务放到后台运行-database 连接的数据库名<br>-interval 检查间隔。如果未指定–busy-time，默认为30s；如果已指定–busy-time，默认为<br>-busy-time指定值的一半：如果两个都指定，以–interval的值为准<br>-log-dsn 在dsn指定的数据库，保存被杀掉的查询的信息<br>–query-id 打印被杀死的查询ID。打印的ID格式跟pt-query-digest输出格式一样<br>-run-time 任务的最大运行时间-slave-user 指定连接从库的用户名–slave-password 指定连接从库的用户名<br>-victims 杀死匹配查询的类别，默认值为oldest。oldest：只杀掉匹配查询中，运行时间最长的：<br>all：杀掉所有匹配的查询：all-but-oldest：除了运行时间最长的查询，其他查询都杀掉<br>–wait-after-kill 杀掉一个查询后，等待多少时间再杀掉下一个查询。设置这个参数的目的是为了让其他被阻<br>塞的查询有机会继续执行<br>-wait-before-ki1l 杀掉一个查询前等待的时间。设置这个参数的目的是让–execute-command指定的命令<br>有机会查看匹配的查询和收集MySQL、系统的信息<br>下面看一些具体的例子。<br>（1）杀死运行时间超过20s的查询，打印查询ID。执行 sleep语句：<br>mysq1&gt;slects1eep（20）；些据体<br>运行pt-kill 命令：<br>[mysq13307@1oca1host ~]$ pt-ki11 –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysql 3307.sock –busy-time 10-kili –query-id<br>sleep语句运行20s后，连接被杀掉：<br>mysql&gt;select 1eep(20) 90<br>ERROR 2013 (HY00o):Lost connection to MySQL server during query  执行pt-kill命令的窗口，打印出QueryID：<br>Query ID:0xF9A57DD5A41825CA<br>（2）每10s打印Command为Sleep的所有连接，但是不杀掉连接：<br>[mysq13307@loca1host ~]$ pt-ki11 –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysql _3307.sock –match-command sleep –print –victims all –interval 10<br>#2018-08-02T17:28:58 KILL 118 (S1eep 99 sec) NULL#2018-08-02T17:28:58 KILL 117 (Sleep 92 seC) NULL#2018-08-02T17:28:58 KILL 119 (Sleep 70 sec) NULL<br>23.2.7pt-online-schema-change（在线修改表结构工具）<br>该工具简称pt-osc，支持在线修改表结构，加锁时间短，对线上业务影响小。此工具首先</p>
<p>≦ 416 ≧<br>398 第23章MySQL中的常用工具<br>根据需要修改的源表的表结构创建一个临时使用的空表，然后在源表创建触发器，接下来开始慢慢地将数据从源表复制到新表中，在复制过程中，如果源表数据发生变化，则通过触发器同步到新表中，当数据完成复制后，调用rename table指令，互换源表和新表名字，换下来的废弃的表默认就被删除了。另外，源表必须要有主键或者唯一索引（唯一索引不能存在空值）。<br>pt-online-schema-change工具的使用方法如下：<br>she&gt;ponine-schema-change[oPTIONS] DSNP<br>常用参数如下：<br>–alter 用于修改表结构，不用加上ALTER TABLE关键字。多个修改命令用逗号分隔–charset 设置字符集<br>–[no]check-alter 检查–alter命令的正确性，默认yes<br>-check-interval 检查从库延迟是否达到–max-1ag的间隔，默认为1s-check-slave-lag 检查从库延迟，当延迟超过-max-1ag后，停止复制数据<br>–chunk-size 每次复制块的记录数，默认为1000–chunk-size-limit 每次复制块的尺寸，默认为4<br>–chunk-time 根据–chunk-time的时间动态调节复制块的记录数，默认为0.5s–database 连接的数据库名<br>–[no]drop-new-table 如果复制源表失败，删除新表，默认为yes。此时源表仍然保留–[no]drop-old-table 如果成功rename 到新表，删除源表，默认为yes<br>-dry-run 仅创建和修改新表的结构，不复制数据，也不执行rename操作-execute 使用pt-osc修改源表结构<br>–max-lag 如果从库延迟大于–max-1ag，复制数据任务暂停，直至从库延迟小于–max-1ag，默认为1s–new-table-name 指定新表的名字<br>–print 打印使用的sq1，而不真正执行，配合–dry-run使用–sleep 每次复制数据块的间隔，默认为0s<br>下面看一些具体的例子。<br>（1）模拟数据库employees的salaries_id表添加amount字段，并不真正执行：<br>[mysq13307@loca1host ~]s pt-online-schema-change –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysql 3307.sock–charset&#x3D;utf8 –alter “add column amount bigint(10)” D&#x3D;employees,t&#x3D;salaries_id –print –dry-run<br>Operation, tries, wait: analyze_table,10,1 copy_rows,10,0.25 create triggers,10,1 drop_triggers, 10,1 swap_tables,10,1<br>update_foreign_keys,10,1<br>starting a dry run.employees salaries id will not be altered.Specify–execute instead<br>of –dry-run to alter the table. Creating new table…<br>CREATE TABLEemployeessalaries id new（ idint(11) NOT NULL AUTO INCREMENT,<br>emp_no int(i1) NOT NULL, salary int(11) NOT NULL, from date date NOT NULL, to date date NOT NULL, PRIMARY KEY(id）,<br>KEYemp_no(emp_nofrom date）<br>) ENGINE&#x3D;InnoDB AUTO INCREMENT&#x3D;14220236 DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci<br>Created new table employees. salaries_id new ok. Altering new table…<br>ALTER TABLE employees salaries id new add column amount bigint（10) Altered employees salaries id newok.<br>Not creating triggers because this is a dry, run. Not copying rows because this is a dry run.<br>INSERT LoW PRIORITY IGNORE INToemployeessalaries id newidemp_nosalaryfrom date,to date SELECTid,empnosalary,from dateto dateFROMemployeessalaries idFORCE INDEX(PRIMARY) WHERE (Cid&gt;&#x3D;?))AND (Cid&lt;&#x3D;?）))LOCK IN SHARE MODE&#x2F;*pt-onTine-schema-change 30889 copy nibb1e*&#x2F;<br>SELECT &#x2F;*!400O1 SQL NO CACHE *&#x2F;idFROM employees.salaries idFORCE INDEXCPRIMARY) WHERE ((id&gt;&#x3D; ?))ORDER BYidLIMIT ？,2&#x2F;<em>next chunk boundary</em>&#x2F;</p>
<p>≦ 417 ≧<br>23.2Percona工具包 399<br>Not swapping tables because this is a dry run. Not dropping old table because this is a dry run. Not dropping triggers because this is a dry run.<br>DROP TRIGGER IF EXISTs employees.pt osc employees_salaries id del DROP TRIGGER IF EXISTS employees.pt osc employees salaries id upd DROP TRIGGER IF EXISTS employees.pt_osC_employees_salaries_id_ins 2018-08-07T10:33:16 Dropping new table..<br>DROP TABLE IF EXISTS employees.salaries_id new; 2018-08-07T10:33:16 Dropped new tab1e 0K.<br>Dry run complete.employees.salaries idwas not altered.<br>这里可以看到pt-osc工具的工作流程，主要的步骤是创建临时表、修改临时表、拷贝数据、切换源表和临时表，以及删除源表。<br>（2）将数据库employees下的titles表转换为分区表，按emp_no字段进行hash分区，分区数为3：<br>[mysq13307@locaThost ~]s pt-online-schema-change –user&#x3D;root –socket&#x3D;&#x2F;tmp&#x2F;mysql 3307.sock–charset&#x3D;utf8 –alter “PARTITION BY HASH( emp no ） PARTITIONS 3” D&#x3D;employees,t&#x3D;titles –execute Cannot connect to A&#x3D;utf8,S&#x3D;&#x2F;tmp&#x2F;mysq1 3307.sock,h&#x3D;127.0.0.1,u&#x3D;root<br>No slaves found. See –recursion-method if host localhost has slaves.<br>Not checking slave lag because no slaves were found and –check-slave-lag was not specified.<br>Operation, tries, wait: analyze table, 10,1 copy_rows, 10, 0.25 create triggers, 10,1 drop_triggers,10,1 swap_tables,10,1<br>update foreign_keys,10,1 Alteringemployees’.titles. Creating new table…<br>Created new table employees. titles_new OK. Altering new table..<br>Alteredemployees._titles newoK. 2018-08-07T11:06:39 Creating triggers.. 2018-08-07T11:06:39 Created triggers OK.<br>2018-08-07T11:06:39 Copying approximately 441297 rows… 2018-08-07T11:06:49 Copied rows OK.<br>2018-08-07T11:06:49 Analyzing new table.. 2018-08-07T11:06:49 Swapping tables.<br>2018-08-07T11:06:49 Swapped original and new tables 0K. 2018-08-07T11:06:49 Dropping o1d table..<br>2018-08-07T11:06:49 Dropped old tableemployees. titles_o1dOK.<br>2018-08-07T11:06:49 Dropping triggers.. 2018-08-07T11:06:49 Dropped triggers OK. Successfully altered employees<code>.</code>titles”<br>23.2.8pt-query-digest（SQL分析工具）<br>pt-query-digest工具用于分析MySQL慢查询日志、全量SQL日志、二进制日志文件，同时也能分析showprocesslist获取的结果和tcpdump抓包的MySQL协议数据。在日常工作中，这个工具主要用于分析MySQL的慢日志，可以更直观、更形象地展现分析结果。<br>pt-query-digest工具的使用方法如下：<br>shell&gt; pt-query-digest [oPTIONs] [FILES] [DSN]<br>常用参数如下：<br>–limit 展示最耗时SQL的数量，默认95%：20。如果同时写百分比和数量，则以先满足的条件为准–since 指定分析SQL的开始时间<br>–type 解析的输入类型，默认为s1ow1og。可选类型为binlog、s1owlogtcpdump、raw1og-until 指定分析SQL的结束时间<br>下面看一些具体的例子。</p>
<p>≦ 418 ≧<br>400 第23章MySQL中的常用工具<br>分析2018-11-05从16点到17点的慢查询日志：<br>[mysq13307@localhost data]s pt-query-digest –since2018-11-05 16:00:00’–until ‘2018-11-0517:00:00–1imit 100% s1ow3307.1og<br>#280ms user time, 20ms system time,24.60m rss, 204.98m vsz#Current date: Mon Nov 5 16:52:38 2018</p>
<h1 id="Hostname-localhost-Files-slow3307-1og"><a href="#Hostname-localhost-Files-slow3307-1og" class="headerlink" title="Hostname:localhost#Files:slow3307.1og"></a>Hostname:localhost#Files:slow3307.1og</h1><p>#Overal1:9 total,1 unique, 0.16 Qps,0.14x concurrency#Time range:2018-11-05T16:51:38 to 2018-11-05T16:52:33<br>#Attribute total min max avg 95%stddev median#</p>
<h1 id="Exec-time-85-386ms-35-873ms-35-920ms-412ms-Lock-time-6ms-176us-5ms-71lus-5ms-1ms-185us-Rows-sent-9-1-1-o-1-Rows-examine-12-74M924-17k-2-71M-1-42M-2-62M-739-82k915-49k-Query-size-438-47-49-48-67-46-83-o-46-83"><a href="#Exec-time-85-386ms-35-873ms-35-920ms-412ms-Lock-time-6ms-176us-5ms-71lus-5ms-1ms-185us-Rows-sent-9-1-1-o-1-Rows-examine-12-74M924-17k-2-71M-1-42M-2-62M-739-82k915-49k-Query-size-438-47-49-48-67-46-83-o-46-83" class="headerlink" title="Exec time 85 386ms 35 873ms 35 920ms 412ms#Lock time 6ms 176us 5ms 71lus 5ms 1ms 185us#Rows sent 9 1 1 o 1#Rows examine 12.74M924.17k 2.71M 1.42M 2.62M 739.82k915.49k#Query size 438 47 49 48.67 46.83 o 46.83"></a>Exec time 85 386ms 35 873ms 35 920ms 412ms#Lock time 6ms 176us 5ms 71lus 5ms 1ms 185us#Rows sent 9 1 1 o 1#Rows examine 12.74M924.17k 2.71M 1.42M 2.62M 739.82k915.49k#Query size 438 47 49 48.67 46.83 o 46.83</h1><p>#Profile<br>#Rank Query ID Response time calls R&#x2F;call v&#x2F;M<br>10XD038FC7210F92F0689CD4E3405472409 7.8556 100.0% 90.8728 0.97 SELECT salaries#Query 1:0.16 QPs,0.14x concurrency,ID 0xD038FC7210F92F0689cD4E3405472409 at byte 0</p>
<h1 id="This-item-is-included-in-the-report-because-it-matches-–limit-Scores-V-x2F-M-x3D-0-97"><a href="#This-item-is-included-in-the-report-because-it-matches-–limit-Scores-V-x2F-M-x3D-0-97" class="headerlink" title="This item is included in the report because it matches –limit.#Scores:V&#x2F;M&#x3D; 0.97"></a>This item is included in the report because it matches –limit.#Scores:V&#x2F;M&#x3D; 0.97</h1><p>#Time range:2018-11-05T16:51:38 to 2018-11-05T16:52:33<br>#Attribute pct total min max avg 95%stddev median#Count 100 9<br>#Exec time 100 85 386ms 35 873ms 3s 920ms 412ms#Lock time 99 6ms 176us 5ms 711us 5ms 1ms 185us#Rows sent 100 9 1 1#Rows examine 100 12.74M924.17k 2.71M 1.42M 2.62M 739.82k 915.49k#Query size 100 438 47 49 48.67 46.83 46.83#String:<br>#Databases employees#Hosts localhost#Users root#Query time distribution<br>#lus#10us#100us#1ms 10ms<br>#10s+#Tables<br>SHOW TABLE STATUS FROM employeesLIKE salaries\G<br>#<br>SHOW CREATE TABLE employeessalaries\G#<br>#EXPLAIN&#x2F;<em>!50100 PARTITIONS</em>&#x2F;<br>select count(0) from salaries where emp_no&gt;1000\G<br>分析结果首先展示所有慢SQL总的汇总部分。第5行Overall行，显示共有9个慢SQL， 1个不同的SQL，也就是说有1个慢SQL出现了9次；第6行Timerange行显示慢SQL的时间跨度；Attribute行和接下来的6行展示了另外的汇总信息。Exectime指的是慢SQL的执行时间，Rows sent指的是慢SQL的返回行数，Rowsexamine指的是慢SQL检索的记录行数。可以按照字面意思理解Attribute行的内容，例如Exec time行和total列指向的是8s，表示所有的慢SQL执行的总时间是8s；Rowssent行和avg列指向的是1，表示慢SQL平均的返回记录行数是1。<br>接下来Profile以下就是每个SQL的汇总部分。QueryID为SQL指纹的id，同一个SQL如果仅是常量的不同，被识别为同一个指纹id；Responsetime为SQL总的执行时间和占总时间的百</p>
<p>≦ 419 ≧<br>23.2Percona工具包 401<br>分比；Calls为慢SQL执行次数，这里Rank为1的SQL执行了9次；R&#x2F;Call为慢SQL平均执行时间，例如Rank为1的SQL，其Responsetime为7.8556s，执行了9次，7.8556除以9约等于 R&#x2F;Call 0.8727s。<br>最后是每个SQL的明细部分，Attribute行和接下来7行，跟SQL汇总部分含义一致。后面还列出了执行sql对应的数据库名、客户端的IP信息、用户名、慢SQL执行时间在每个时间段的比例。根据这些信息，可以很容易地定位慢SQL来自哪个应用，慢SQL执行时间主要分布在哪个时间区间，例子中的慢SQL执行时间主要分布在100ms～1s的区间。随后还给出慢SQL的一个样例，方便在数据库执行explain命令。<br>pt-query-digest仅是一个命令行工具，缺少可视化的展示界面，当数据库规模达到一定程度时，手工操作变得很烦琐，这时可以通过Anemometer平台自动分析慢SQL，具体可以参考第24章相关内容。<br>23.2.9pt-table-checksum（数据检验工具）<br>pt-table-checksum工具用于校验从库数据跟主库是否一致，校验时主库可以保持读写。工具在主库执行SQL统计表的数据，然后通过BINLOG把在主库执行的SQL传到从执行，所以在校验过程需要开启从库的IO进程和SQL进程，并且从库延迟要尽可能得小。<br>pt-table-checksum的使用方法如下： she7l&gt; pt-table-checksum [oPTIoNs] [DSN]<br>常用参数如下：<br>–[no］check-binlog-format检查所有主从实例的binlog format是否一致，默认为yes<br>–check-interval 检查从库延迟是否达到–max-1ag的间隔，默认为1s–check-slave-lag 检查从库延迟，当延迟超过-max-1ag后，停止检查数据<br>–chunk-index 指定检查表时遍历数据的索引–chunk-index-columns 指定使用–chunk-index索引最左边的几个字段遍历数据<br>-chunk-size 每次检查块的记录数，默认为1000–chunk-size-limit 每次检查块的尺寸，默认为2<br>–chunk-time 根据–chunk-time的时间动态调节检查块的记录数，默认为0.5s–databases,-d 只检查指定数据库下的表，多个数据库用逗号分隔–explain 展示检查表锁使用的查询，而不真正检查表。如果指定两次–explain，将展示工具迭代<br>分块算法，打印每次送代分块的上界和下界<br>–ignore-databases 忽略检查指定数据库下的表，多个数据库用逗号分隔-ignore-tables 忽略检查指定的表，表名前要加上数据库名，多个表用逗号分隔<br>–max-1ag 如果从库延迟大于–max-1ag，检查数据任务暂停，直至从库延迟小于–max-1ag，默认为1s–replicate 指定存放检查结果的表<br>-run-time 任务的最大运行时间–tables 只检查指定的表，表名前要加上数据库名，多个表用逗号分隔–truncate-replicate-table每次检查任务开始前，清空结果表<br>–where 只检查匹配where语句的记录，语句里面不用写where关键字下面看一些具体的例子。<br>校验主从数据，不检查主从实例的BINLOG格式，检查结果存人percona.checksums表， pt工具自动找从库的信息：<br>[mysq13307@localhost~]s pt-table-checksum–no-check-binlog-format –replicate&#x3D;percona. checksums –host&#x3D;127.0.0.1–port 3307-uroot<br>Checking if all tables can be checksummed .. Starting checksum<br>TS ERRORS DIFFS ROWS DIFF ROWS CHUNKS SKIPPED TIMETABLE<br>08-20T21:42:51 0 1 9 0 1 0 0.313 emp1oyees.departments 08-20T21:42:53 0 4 331603 0 6 0 1.652 emp1oyees.dept emp<br>1<br>08-20T21:42:53 0 24 o 1 0 0.31 employees.dept manager 08-20T21:42:55 o 300024 1.671 employees.employees</p>
<p>≦ 420 ≧<br>402 第23章MySQL中的常用工具<br>08-20T21:43:530 443306 2.938 employees.titles<br>5<br>结果显示，employees.departments表有9条记录，通过1个chunk检查（chunks），diffs 的chunk数也为1，代表主从的9条记录数据不一致。employees.dept_emp表有331603条记录，通过6个chunk检查，每个chunk的数据不一定均匀，其中4个chunk中的主从数据不一致。<br>在上面命令的基础上，每1s检查一次检查从库延迟，如果从库延迟大于1s，校验数据任务将暂停，直到从库延迟小于1s：<br>[mysq13307@localhost ~]s pt-table-checksum–no-check-binlog-format –replicate&#x3D;percona. checksums –host&#x3D;127.0.0.1 –port 3307 -uroot –check-interval 1–max-lag 1<br>Checking if all tables can be checksummed. Starting checksum<br>Replica lag is 55 seconds on localhost. waiting.<br>ERRORS DIFFS ROWS DIFF ROWS CHUNKS SKIPPED TIME TABLE TS<br>08-20T21:42:510 9 0 1 0.313 employees.departments 08-20T21:42:530 4 331603 o 6 0 1.652 employees.dept emp<br>11<br>08-20T21:42:530 1 24 0 0 0.31 employees.dept manager 08-20T21:42:550 o 300024 0 1.671 employees.employees<br>08-20T21:43:530 443306 2.938 employees.titles<br>0 0<br>在开始任务前，从库的延迟大于1s；校验任务处于暂停状态，当从库延迟小于1s，校验任务正常开始。<br>23.2.10pt-table-sync（数据同步工具）<br>pt-table-sync工具用于从库同步主库的表数据，不同步表结构和索引l，该工具主要适用于主从库少量数据不一致的场景。<br>pt-table-sync的使用方法如下：<br>pt-table-Sync[OPTIONS] DSN [DSN]<br>常用参数如下：<br>-charset 设置字符集 chunk-index 指定检查表时遍历数据的索引<br>-chunk-index-columns 指定使用–chunk-index索引最左边的几个字段遍历数据-databases,-d 只同步指定数据库下的表，多个数据库用逗号分隔–dry-run 分析同步过程使用的算法，而不真正执行。配合-verbose参数可以打印模拟的结果<br>-execute 执行数据同步任务-explain-hosts 打印同步任务要连接的所有主机，并且退出任务<br>-ignore-databases 忽略同步指定数据库下的表，多个数据库用逗号分隔-ignore-tables 忽略检查的表。表名前要加上db名，用逗号分隔。-lock 在主库锁定正在对比的数据库。0：不锁定数据；1：每次同步的循环锁定：2：同步表数<br>据结束前，锁定表：3：锁全库所有表<br>-print 不真正执行数据同步，仅打出过程使用的sql-replicate 同步表中记录的数据不一致的表，表中数据可以由pt-table-checksum校验得到-slave-user 指定连接从库的用户名<br>-slave-password 指定连接从库的用户名 sync-to-master 把命令中列的DSN认定为从库，根据主库同步数据-tables,-t 只同步指定表。表名前要加上db名，用逗号分隔。<br>下面看一些具体的例子。<br>模拟同步departments表，但是仅打印同步过程执行的SQL，而不是真正地执行：<br>[mysq13308@localhost ~]s pt-table-sync –replicate&#x3D;percona.checksumsV &gt;h&#x3D;127.0.0.1–port 3307-uroot</p>
<blockquote>
<p>–databases employees –tables departments –print</p>
</blockquote>
<p>≦ 421 ≧<br>23.3小结 403<br>REPLACE INToemployeesdepartments（dept no,dept name）VALUEs （’doO1,Marketing’)&#x2F;<em>percona-too1kit src db:employees src tb1:departments src dsn:P&#x3D;3307,h&#x3D;127.0.0.1,u&#x3D;root dst db: employees dst tbl:departments dst dsn:P&#x3D;3308,h&#x3D;127.0.0.1,u&#x3D;root 1ock:1 transaction:1 changing src:percona.checksums replicate:percona.checksums bidirectional:0 pid:22485 user:mysq13308 host:localhost</em>&#x2F;;<br>真正同步departments表，：<br>[mysq13307@localhost~]s pt-table-sync–replicate&#x3D;percona.checksums h&#x3D;127.0.0.1–port 330 7-uroot –databases employees –tables departments –execute<br>同步任务完成后，再用pt-table-checksum校验主从数据：<br>[mysq13307@localhost ~]s pt-table-checksum  –replicate&#x3D;percona.checksums –no-check-binlog-format –host&#x3D;127.0.0.1–port 3307 -uroot–databases employees –tables departments<br>Checking if all tables can be checksummed . Starting checksum..<br>TS ERRORS DIFFS ROWS DIFF ROWS CHUNKS SKIPPED TIME TABLE<br>08-20T22:53:15 0 00.346 emp1oyees.departments<br>0<br>结果显示，从库employees.departments表数据已经跟主库数据一致了。 23.3小结<br>本章介绍了在MySQL运维过程中的一些常用工具，并举例说明了它们的使用方法。熟练掌握这些工具将会给工作带来很大的便利。由于这些工具参数众多，这里不再一一列举，如果读者想了解更多工具的使用方法，读者可以参考相关的帮助文档。</p>
<p>≦ 422 ≧<br>第24章 MySQL日志<br>在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的方方面面，以帮助数据库管理员追踪数据库曾经发生过的各种事件。MySQL也不例外，在MySQL中，有6种不同的日志，分别是错误日志（ErrorLog）、二进制日志（BinaryLog）查询日志（GeneralQuery Log）慢查询日志（SlowQueryLog）中继日志（RelayLog）和元数据日志（DDLLog）。这些日志记录着数据库在不同方面的踪迹。<br>从库通过IVO线程拉取主库二进制日志，记录到本地，生成中继日志，中继日志跟二进制日志相差不多；元数据日志记录数据定义语句（如alter table）的操作，用于MySQLcrash 恢复，目前用户无法配置元数据日志相关的选项和参数。由于用户很少主动使用中继日志和元数据日志，本章将详细介绍错误日志、二进制日志、查询日志和慢查询日志的作用和使用<br>方法，希望读者能充分利用这些日志对数据库进行各种维护和调优。 24.1错误日志<br>错误日志是MySQL中最重要的日志之一，它记录了当mysqld启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志。<br>可以用–log-error[&#x3D;file_name]选项来指定mysqld（MySQL服务器）保存错误日志文件的位置。如果没有给定file_name值，mysqld使用错误日志名host_name.err（host_name为主机名）并默认在参数DATADIR（数据目录）指定的目录中写人日志文件。<br>以下是MySQL正常启动和关闭的一段日志，不同的版本可能略有不同：[root@localhost mysql]# more localhost.localdomain.err<br>2018-07-21T11:01:35.588314+08:00 0[Note] InnoDB:File&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;ibtmp1’size is now 12 MB.<br>2018-07-21T11:01:35.589687+08:00 0 [Note] InnoDB: 96 redo ro11back segment(s) found. 96 redo rollback segment(s) are active<br>2018-07-21T11:01:35.589714+08:00 0 [Note] InnoDB: 32 non-redo ro11back segment(s) are active. 2018-07-21T11:01:35.590327+08:00 0 [Note] InnoDB:waiting for purge to start<br>2018-07-21T11:01:35.649848+08:00 0 Note] InnoDB:5.7.22 started;1og sequence number 8023211655 2018-07-21T11:01:35.650358+08:00 0[Note] InnoDB: Loading buffer poo1(s) from &#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;ib_buffer_pool<br>2018-07-21T11:01:35.650718+08:00 0 [Note] Plugin’FEDERATED’is disabled.<br>2018-07-21T11:01:36.355876+08:00 0 [Note] server hostname (bind-address):*’: port: 3307 2018-07-21T11:01:36.355935+08:00 0 [Note] IPv6 is available.<br>2018-07-21T11:01:36.355955+08:00 0[Note]:resolves to;<br>2018-07-21T11:01:36.355992+08:00 0 [Note] Server socket created on IP:::’</p>
<p>≦ 423 ≧<br>24.2二进制日志 405<br>2018-07-21T11:01:36.569714+08:00 0 [Note] Event Scheduler:Loaded 0 events<br>2018-07-21T11:01:36.569926+08:00 1 [Note] Event Scheduler: scheduler thread started with id 1 2018-07-21T11:01:36.570157+08:00 0[Note] &#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;bin&#x2F;mysq1d:ready for connections.<br>version:5.7.22-1ogsocket:&#x2F;tmp&#x2F;mysq1 3307.sock’port:3307MysQL Community Server (GPL)<br>上面是启动日志下面是关闭日志<br>2018-07-21T11:01:08.827360+08:00 0 [Note] Shutting down plugin ‘INNODB LOCKS 2018-07-21T11:01:08.827367+08:00 0 [Note] Shutting down pluginINNODB TRX 2018-07-21T11:01:08.827373+08:00 0 [Note] shutting down plugin ‘InnoDB*<br>2018-07-21T11:01:08.903530+08:00 0 [Note] InnoDB: FTS optimize thread exiting. 2018-07-21T11:01:08.903801+08:00 0 [Note] InnoDB:Starting shutdown.<br>2018-07-21T11:01:09.008627+08:00 0 [Note] InnoDB: Dumping buffer poo1(s) to &#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;ib buffer pool<br>2018-07-21T11:01:09.041581+08:00 0 [Note] InnoDB:Buffer poo1(s) dump completed at 180721 11:01:09 2018-07-21T11:01:10.495131+08:00 0 [Note] InnoDB: shutdown completed;1og sequence number 802 3211655<br>2018-07-21T11:01:10.518026+08:00 0 [Note] InnoDB:Removed temporary tablespace data file:ibtmp1 2018-07-21T11:01:10.518052+08:00 0 [Note] Shutting down plugin sha256_password<br>2018-07-21T11:01:10.518062+08:000 [Note] shutting down plugin *mysql native password 2018-07-21T11:01:10.518356+08:00 0 [Note] shutting down plugin binlog<br>2018-07-21T11:01:10.533994+08:000[Note]&#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;bin&#x2F;mysqld:Shutdown complete 24.2二进制日志<br>二进制日志（BINLOG）记录了所有的DDL（数据定义语言）语句和DML（数据操纵语言）语句，但是不包括数据查询语句。语句以“事件”的形式保存，它描述了数据的更改过<br>程。此日志对于灾难时的数据恢复起着极其重要的作用。 24.2.1日志的位置和格式<br>当用–log-bin[&#x3D;file_name]选项启动时，mysqld开始将数据变更情况写人日志文件。如果没有给出file_name值，默认名为主机名后面跟“-bin”。如果给出了文件名，但没有包含路径，则文件默认被写人参数DATADIR（数据目录）指定的目录。<br>在MySQL5.7中，二进制日志的格式分为3种：STATEMENT、ROW和MIXED，可以在启动时通过参数–binlog_format进行设置。<br>1.STATEMENT<br>MySQL5.1之前的版本都采用这种方式，顾名思义，日志中记录的都是语句（statement），每一条对数据造成修改的SQL语句都会记录在日志中，通过mysqlbinlog工具，可以清晰地看到每条语句的文本。主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次。这种格式的优点是日志记录清晰易读、日志量少，对I&#x2F;O影响较小；缺点是在某些情况下，slave的日志复制会出错。<br>2.ROW<br>MySQL5.1.11之后，出现了这种新的日志格式。现在是目前MySQL默认的日志格式，它将每一行的变更记录到日志中，而不是记录SQL语句。比如一个简单的更新SQL，update empsetname&#x3D;abc’，如果是STATEMENT格式，日志中会记录一行SQL文本；如果是ROW，由于是对全表进行更新，也就是每一行记录都会发生变更，如果是一个100万行的大表，则日志中会记录100万条记录的变化情况，日志量大大增加。这种格式的优点是会记录每一行</p>
<p>≦ 424 ≧<br>406 第24章MySQL日志<br>数据的变化细节，不会出现某些情况下无法复制的情况；缺点是日志量大，对I&#x2F;O影响较大。<br>3.MIXED<br>该日志混合了STATEMENT和ROW两种日志。默认情况下采用STATEMENT，但在一些特殊情况下采用ROW来进行记录，比如采用NDB存储引擎，此时对表的DML语句全部采用ROW；客户端使用了临时表；客户端采用了不确定函数，比如currentuserO等，因为这种不确定函数在主从中得到的值可能不同，导致主从数据产生不一致。MIXED格式能尽量利用两种模式的优点，而避开它们的缺点。<br>注意：可以在global和session级别对binlog_format进行日志格式的设置，但一定要谨慎操作，<br>确保从库的复制能够正常进行。<br>24.2.2日志的读取<br>由于日志以二进制方式存储，不能直接读取，需要用mysqlbinlog工具来查看，语法如下： she1l &gt; mysq1binlog 1og-file;<br>mysqlbinlog的用法在第23章中已经详细介绍过，这里不再赘述。下面以STATEMENT 格式为例演示了二进制日志的读取过程。<br>（1）往测试表emp中插人两条测试记录。 mysql&gt; use employees<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed<br>mysql&gt; insert into emp values(1,z1’）; Query ok,1 row affected (o.o0 sec)<br>mysql&gt; insert into emp values(1,<em>z2’); Query ok,1 row affected (0.00 sec)<br>（2）使用mysqlbinlog工具进行日志查看，粗体字显示了步骤（1）中所做的操作。<br>[root@localhost mysql]# mysq1binlog -vv localhost-bin.000001&#x2F;<em>150530 SET @@SESSION.PSEUD0_SLAVE MODE&#x3D;1</em>&#x2F;;<br>&#x2F;</em>!40019 sET @@session.max insert delayed threads&#x3D;0*&#x2F;;<br>&#x2F;<em>1500O3 SET @OLD_COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER &#x2F;<em>I</em>&#x2F;;#at4<br>#181008 14:23:32 server id 1 end 1og_pos 120 cRc32 0x218fea45 Start: binlog v 4,server v5.6.34-1og created 181008 14:23:32<br>#warning: this binlog is either in use or was not closed properly. BINLOG<br>5Pe6WW8BAAAAdAAAAHgAAAABAAQANS42LjMOLWXVZWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXAAEGggAAAAICAgCAAAACgoKGRkAAUXq jyE&#x3D;<br>&#x2F;#1*&#x2F;；#at 120<br>#181008 14:23:39 server id 1 end 1og pos 192 cRc32 0xd0f6bc2a Query thread id&#x3D;2 exec time&#x3D;0 error_code&#x3D;0<br>SET TIMESTAMP&#x3D;1538979819&#x2F;<em>!</em>&#x2F;;<br>SET @@session.pseudo thread id&#x3D;2&#x2F;<em>I</em>&#x2F;;<br>SET @@session.foreign_key_checks&#x3D;l, @@session.sql_auto_is_null&#x3D;0, @@session.unique_checks&#x3D;l,@@session.autocommit&#x3D;1&#x2F;<em>!</em>&#x2F;:<br>SET @@session.sq1 mode&#x3D;1073741824&#x2F;<em>1</em>&#x2F;;<br>SET @@session.auto_increment_increment&#x3D;l, @@session.auto_increment offset&#x3D;1&#x2F;<em>1</em>&#x2F;;&#x2F;<em>!\cutf8mb4 <em>&#x2F;&#x2F;</em>!</em>&#x2F;；<br>SET @@session.character_set client&#x3D;45,@@session.collation connection&#x3D;45,@@session.collation</p>
<p>≦ 425 ≧<br>24.2二进制日志 407<br>server&#x3D;33&#x2F;<em>!</em>&#x2F;;<br>SET @@session.lc time names&#x3D;0&#x2F;<em>1</em>&#x2F;;<br>SET @@session.collation database&#x3D;DEFAULT&#x2F;<em>!</em>&#x2F;;<br>BEGIN&#x2F;<em>!</em>&#x2F;;#at192<br>#181008 14:23:39 server id1 end 1og pos 241 cRC32 0xd0ec50cf Table map:employees,emp<br>mapped to number 71#at241<br>#181008 14:23:39 server id 1 end 1og pos 284 cRc32 0x80b83184 write_rows: table id71 flags: STMT_END_F<br>BINLOG<br>6&#x2F;e6WxMBAAAAMQAAAPEAAAAAAECAAAAAAAEABHR1c3QAA2VtCAACAW8C&#x2F;WADZ1DsOA&#x3D;&#x3D;<br>6&#x2F;e6Wx4BAAAAKwAAABWBAAAAAEcAAAAAAAEAAgAC&#x2F;&#x2F;WBAAAAAnoxhDG4gA&#x3D;&#x3D; +&#x2F;<em>1</em>&#x2F;；<br>###INSERT INTOemployeesemp###SET<br>###@1&#x3D;1&#x2F;<em>INT meta&#x3D;0 nu1lable&#x3D;1 is_nu11&#x3D;0 <em>&#x2F;<br>###@2&#x3D;’z1&#x2F;<em>VARSTRING（255) meta&#x3D;255 nu11able&#x3D;1 is_nu11&#x3D;0</em>&#x2F;#at 284<br>#181008 14:23:39 server id 1 end 1og pos 315 cRc32 0x48e56802 xid&#x3D;14<br>COMMIT&#x2F;<em>1</em>&#x2F;;#at315<br>#181008 14:23:44 server id 1 end 1og pos 387 cRc32 0x8fa2d170 Query thread id&#x3D;2 exec<br>time&#x3D;0 error_code&#x3D;0 SETTIMESTAMP&#x3D;1538979824&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>1</em>&#x2F;;#at 387<br>#181008 14:23:44 server id 1 end 1og pos 436 cRC32 0x31df9046 Table map:test.emp mapped to number 71<br>#at436<br>#181008 14:23:44 server id 1 end 1og pos 479 cRC32 0x840fc684 write rows: table id 71 flags: STMT END F<br>BINLOG<br>8Pe6WXMBAAAAMQAAALQBAAAAAECAAAAAAAEABHR1c3QAA2VtCAACAW8C&#x2F;WADRpDfMQ&#x3D;&#x3D;<br>8Pe6Wx4BAAAAKWAAAN8BAAAAAECAAAAAAAEAAgAC&#x2F;&#x2F;WBAAAAAnoyhMYPhA&#x3D;&#x3D;</em>&#x2F;&#x3D;1#&#x2F;;<br>###INSERT INTOemployees.emp###SET<br>###@1&#x3D;1&#x2F;<em>INT meta&#x3D;0 nullable&#x3D;1 is_nu71&#x3D;0</em>&#x2F;<br>###@2&#x3D;’z2&#x2F;<em>VARSTRING(255）meta&#x3D;255nu11ab1e&#x3D;1is_nu71&#x3D;0</em>&#x2F;#at479<br>#181008 14:23:44 server id 1 end 1og pos 510 cRC32 0xed444efe xid &#x3D;15<br>COMMIT&#x2F;<em>1</em>&#x2F;; DELIMITER;<br>#End of log file<br>ROLLBACK&#x2F;</em> added by mysqlbinlog *&#x2F;;<br>&#x2F;<em>150003 SET COMPLETION TYPE&#x3D;@OLD_COMPLETION TYPE</em>&#x2F;;&#x2F;<em>！50530 SET @@SESSION.PSEUDO SLAVE MODE&#x3D;0</em>&#x2F;;<br>可以看到，二进制日志中记录了MySQL实例信息、会话中的参数信息、执行事件类型与事件块位置、执行语句等内容，在之后的24.2.4节会做简要的分析。<br>24.2.3 日志的删除<br>对于比较繁忙的OLTP（在线事务处理）系统，由于每天生成日志量大，这些日志如果长时间不清除，将会对磁盘空间带来很大的浪费。因此，定期删除日志是DBA维护MySQL数据库的一个重要工作内容。下面介绍几种删除日志的常见方法。<br>1.方法1<br>执行“RESETMASTER;”命令，删除所有BINLOG日志，新日志编号从“000001”开始。</p>
<p>≦ 426 ≧<br>408 第24章MySQL日志<br>在MySQL8.O中，支持RESETMASTERTO+编号的命令，可以自定义新日志的开始编号。下例中删除了当前的所有日志。<br>（1）查看删除前日志。<br>mysql&gt; system 1s -ltrh mysql-bin*<br>1 mysq13307 mysq13307 128k sep 26 20:39 mysq1-bin.000052<br>-rw-r<br>-rw-r–1 mysq13307 mysq13307 281 Sep 26 20:42 mysq1-bin.000053-rw-r–1 mysq13307 mysq13307 578 Sep 26 20:43 mysq1-bin.000054<br>1 mysq13307 mysq13307 578 Sep 26 20:43 mysq1-bin.000055 1mysq13307 mysq13307 281 Sep 26 20:47 mysql-bin.000056 1mysq13307 mysq13307 880 Sep 26 20:47 mysql-bin.000057<br>-rw-r<br>1mysq13307 mysq13307 281 Sep 26 20:49 mysq1-bin.000058<br>-rw-r 1mysq13307 mysq13307 312 Sep 26 20:49mysq1-bin.index-rw-r-1 mysq13307 mysq13307 828 Sep 26 20:50 mysql-bin.000059<br>结果中的“mysql-bin.index”是日志的索引文件，记录了最大的日志序号，本例中可以将此文件忽略。<br>（2）用RESETMASTER命令进行日志删除。 mysql&gt; reset master;<br>Query OK,0 rows affected (0.08 sec)（3）查看删除后的日志。<br>mysq1&gt; system 1s-1trh mysq1-bin*<br>1 mysq13307 mysq13307 154 sep 26 20:54 mysq1-bin.000001<br>-rw-r-<br>-rw-r-1mysq13307 mysq1330739 Sep26 20:54 mysq1-bin.index<br>可以发现，以前的日志全部被清空。新日志重新从“000001”开始编号。 2.方法2<br>执行“PURGE MASTERLOGS TO’mysql-bin.<strong><strong><strong>“”命令，删除“</strong></strong></strong>”编号之前的所有日志。下例删除了“mysql-bin.000057”之前编号的所有日志。<br>（1）查看删除前日志。<br>mysql&gt; system 1s -1trh mysq1-bin*<br>1 mysq13307 mysq13307 128k Sep 26 20:39 mysq1-bin.000052<br>-rw-r-<br>-rw-r—-1 mysq13307 mysq13307 281 Sep 26 20:42 mysq1-bin.000053<br>578 Sep 26 20:43 mysq1-bin.000054<br>-rw-r 1mysq13307 mysq13307<br>1mysq13307 mysq13307 578 Sep 26 20:43 mysq1-bin.000055<br>-rw-r<br>1mysq13307 mysq13307 281 sep 26 20:47 mysq1-bin.000056<br>-rw-r<br>1 mysq13307 mysq13307 880 sep 26 20:47 mysq1-bin.000057<br>-rw-r<br>-rw-r-1 mysq13307 mysq13307 281 Sep 26 20:49 mysq1-bin.000058<br>1 mysq13307 mysq13307 312 Sep 26 20:49 mysq7-bin.index<br>-rw-r-<br>1 mysq13307 mysq13307 828 Sep 2620:50 mysq1-bin.000059<br>rw-r<br>（2）用PURGE命令进行删除。<br>mysql&gt; purge master logs tomysql-bin.000057’;<br>Query oK, 0 rows affected (0.04 sec)（3）查看删除后日志。<br>mysql&gt; system 1s -1trh mysql-bin*<br>-1mysq13307 mysq73307 880 Sep 26 20:47 mysq1-bin.000057<br>-rw-r<br>-1mysq13307 mysq13307 281 Sep 26 20:49 mysql-bin.000058<br>-rw-r-<br>-rw-r–1 mysq13307 mysq73307 828 Sep 26 20:50 mysq1-bin.000059<br>–1mysq13307 mysq13307 117 Sep 2620:57 mysql-bin.index<br>从结果中发现，编号“000057”之前的所有日志都已经被删除。 3.方法3<br>执行“PURGE MASTERLOGS BEFORE‘yyyy-mm-dd hh24:mi:ss”命令，删除日期为</p>
<p>≦ 427 ≧<br>24.2二进制日志 409<br>“yyyy-mm-dhh24:mi:ss”之前产生的所有日志。下例删除了日期在“2018-09-2620:58:00” 之前的所有日志。<br>（1）查看删除前日志。<br>mysql&gt; system 1s -1trh mysql-bin*<br>1mysq13307 mysq13307 540M Ju1 25 16:22 mysq1-bin.000032.1og<br>-rw-rw-r–<br>-rw-r-1 mysq13307 mysq13307 880 sep 26 20:47 mysq1-bin.000057<br>281 sep 26 20:49 mysq1-bin.000058<br>-rw-r-1 mysq13307 mysq13307<br>875 sep 26 20:58 mysq1-bin.000059<br>-rw-r 1 mysq13307 mysq13307<br>7281 Sep 26 20:58 mysq1-bin.000060<br>rw-r-1 mysq13307 mysq13307<br>-rw-r–1 mysq13307 mysq13307 281 Sep 26 20:58 mysql-bin.000061<br>-1 mysq13307 mysq13307 281 sep 26 20:58 mysq1-bin.000062-1mysq13307 mysq13307 273 Sep 2620:58 mysq1-bin.index<br>rw-r-<br>–1 mysq13307 mysq13307 234 sep 26 20:58 mysq7-bin.000063<br>rw-r-<br>（2）用PURGE命令删除“2018-09-2620:58:00”之前的所有日志。<br>mysql&gt; purge master 1ogs before 2018-09-26 20:58:00’; Query Ok, 0 rows affected (0.04 sec)<br>（3）查看删除后日志，系统只保留了两个指定删除日期后的日志。 mysql&gt; system 1s -ltrh mysql-bin*<br>rw-r——1 mysq13307 mysq13307 875 Sep 2620:58 mysq1-bin.000059<br>–1 mysq13307 mysq13307 281 sep 26 20:58 mysq1-bin.000060<br>-rw-r-<br>-rw-r—-1 mysq13307 mysq13307 281 Sep 26 20:58 mysq1-bin.000061-rw-r-1 mysq13307 mysq13307 281 Sep 2620:58 mysq1-bin.000062-rw-r–1 mysq13307 mysq13307 234 Sep 26 20:58 mysq1-bin.000063-rw-r—– 1 mysq13307 mysq13307 195 Sep 26 20:59 mysq7-bin.index 4.方法4<br>设置参数–expire_logs_days&#x3D;#，此参数的含义是设置日志的过期天数，过了指定的天数后日志将会被自动删除，这样将有利于减少DBA管理日志的工作量。下例将通过手工更改系统<br>日期来测试此参数的使用。（1）查看删除前日志。<br>mysql&gt; system 1s -1tr mysq1-bin*<br>-rw-r–1 mysq13307 mysq13307 875 Sep 2620:58 mysq1-bin.000059-rw-r–1 mysq13307 mysq13307 281 Sep 26 20:58 mysq1-bin.000060<br>1 mysq13307 mysq13307 281 sep 26 20:58 mysq1-bin.000061<br>-rw-r-<br>-rw-r-1 mysq13307 mysq13307 281 Sep 26 20:58 mysq1-bin.000062-rw-r–1 mysq13307 mysq13307 234 sep 26 20:58 mysq1-bin.000063<br>1 mysq13307 mysq13307 195 sep 2620:59 mysql-bin.index<br>-rw-r<br>（2）动态修改expire_logs_day&#x3D;3，如果需要持久化，记得修改my.cnf配置文件。 mysql&gt;show variables like ‘expire logs_days’;<br>1 Variable_name Value<br> expire logs days |7 1 row in set (0.o0 sec)<br>mysql&gt;set global expire_logs days&#x3D;3; Query ok,0 rows affected (o.o0 sec)<br>mysql&gt;show variables like ‘expire logs days’;<br>| Variable_name 1 Value I<br>Iexpire_logs_days13 1 row in set (0.00 sec)<br>（3）将系统时间改为1天以后。</p>
<p>≦ 428 ≧<br>410 第24章MySQL日志<br>[root@localhost <del>]# date Thu Sep 26 21:08:38 cST 2018<br>[root@loca1host ~]# date -s’2018-09-27 21:10:00 Thu Sep 27 21:10:00 cST 2018<br>（4）用“flushlogs”触发日志文件更新，由于没有到3天，所有日志将不会被删除。 mysql&gt;flush logs;<br>Query oK,O rows affected (o.oo sec) mysql&gt;system 1s -1tr mysql-bin*<br>-rw-r-1 mysq13307 mysq13307 875 sep 26 20:58 mysq1-bin.000059-rw-r-1 mysq13307 mysq13307 281 Sep 26 20:58 mysq1-bin.000060-rw-n 1 mysq13307 mysq13307 281 Sep 26 20:58 mysq1-bin.000061-rw-r 1 mysq13307 mysq13307 281 sep 26 20:58 mysq1-bin.000062-rw-r 1 mysq13307 mysq13307 281 Sep 27 21:02 mysq1-bin.000063-rw-r-1 mysq13307 mysq13307 234 Sep 27 21:02 mysq1-bin.index-rw-r-1 mysq13307 mysq13307 234 Sep 27 21:02 mysq1-bin.000064<br>（5）将日期改为3天以后，再次执行“flushlogs”触发日志文件更新。[root@loca1host</del>]# date -s’2018-09-30 21:10:00’<br>Sun Sep 30 21:10:00 CST 2018 mysql&gt;flush logs;<br>Query ok, 0 rows affected (0.01 sec) mysql&gt;system 1s -1tr mysql-bin*<br>-1 mysq13307 mysq13307 281 Sep 30 21:10 mysql-bin.000064<br>-rw-r<br>-rw-r 1 mysq13307 mysq13307 234 Sep 30 21:10 mysq1-bin.000065<br>-1mysq13307 mysq13307 78 sep 30 21:10 mysql-bin.index<br>-rw-r-<br>从结果中可以看出，3天前日志mysql-bin.000059–mysql-bin.000063都已经被删除了。 5.方法5<br>MySQL8.0版本新增了参数binlog_expire_logs_seconds，BINLOG日志过期时间可以精确到秒，并将expire_logs_days参数定义为deprecated，后续版本将废弃这个参数。建议使用 binlog_expire_logs_seconds来管理BINLOG日志的生命周期。<br>（1）查看删除前参数。<br>mysql&gt;show variables like expire_logs days’;<br>1Variable name |value|<br>1expire_logs days17 1 row in set (0.00 sec)<br>mysql&gt;show variables 1 like’binlog expire_logs seconds;<br>Variable name 1Value<br>Ibinlog expire_logs seconds |0 1 row in set (0.00 sec<br>binlog_expire_logs_seconds参数为0，expire_logs_days参数为7，实例会自动删除7天前的BINLOG日志文件。<br>（2）查看删除前日志。<br>mysql&gt;seTect nowO; Inow()<br>12018-09-2621:42:21</p>
<p>≦ 429 ≧<br>24.2二进制日志 411<br>1 row in set (0.01 sec) mysq1]&gt;flush logs;<br>Query oK,0 rows affected (0.o0 sec) mysql&gt; system 1s-1trh mysql-bin*<br>1 mysq13488 mysq13488 242 Sep 26 21:39 mysql-bin.000013<br>-rw-r<br>-1 mysq13488 mysq13488 242 Sep 2621:39 mysq1-bin.000014<br>rw-r<br>1 mysq13488 mysq13488 195 Sep 26 21:39 mysql-bin.000015<br>-rw-r<br>-1mysq13488 mysq13488 117 Sep 26 21:39 mysql-bin.index<br>-rw-r<br>这里可以看到，现有的BINLOG文件的生成时间跟当前时间属于同一天，所以日志没有被删除。<br>（3）动态修改binlog_expire_logs_seconds&#x3D;300，删除300s前的BINLOG日志文件。 mysql&gt;set GLoBAL binlog expire_logs seconds&#x3D;300;<br>ERROR 11079 (HY0o0): The option expire_ logs days cannot be used together with option binlog expire_logs_seconds. Therefore,value of expire_logs_days is ignored.<br>mysql&gt;show global variables like ‘binlog_expire_logs_seconds’; |Variable name 1value丨<br>I binlog expire_logs_seconds | 0 1 row in set (0.03 sec)<br>在MySQL8.0.11版本中，expire_logs_days参数和binlog_expire_logs_seconds参数不<br>可同时设置。需要先将expire_logs_days设置为0，再设置binlog_expire_logs_seconds。 mysql&gt;set global expire_1ogs days&#x3D;0;<br>Query oK,0 rows affected,1 warning (0.o0 sec) mysql &gt;set GLoBAL binlog expire_logs _seconds&#x3D;300; Query ok,O rows affected (o.oo sec)<br>mysql &gt;show global variables like‘binlog expire_logs seconds’;<br>IVariable_name |value丨<br>|binlog expire_logs_seconds | 300 1 row in set (0.00 sec)<br>（4）再次执行“flush logs”触发日志文件更新。<br>mysql&gt;select now(); now(<br>12018-09-2622:00:34 1row in set(0.00 sec) mysql&gt;flush logs;<br>Query ok,O rows affected (o.oo sec) mysq1&gt;system 1s-1trh mysq1-bin*<br>-1 mysq13488 mysq13488 242 Sep 26 21:59 mysq1-bin.000016<br>-rw-r<br>-1 mysq13488 mysq13488 195 sep 26 21:59 mysq1-bin.000017<br>-rw-r<br>1 mysq13488mysq13488 78 Sep 26 21:59 mysq1-bin.index<br>-rw-r<br>从结果中可以看出，300s前日志mysql-bin.000013–mysql-bin.000015都已经被删除。 24.2.4日志的事件<br>在24.2.2节中，ROW格式的日志可以被拆分为多个事件（event）。在解析后的文件中，</p>
<p>≦ 430 ≧<br>412 第24章MySQL日志<br>每个事件的起始都是“#at+数字”的格式，代表事件在二进制文件中起始的位置。一个二进制日志由大量的事件组成，如图24-1 所示。<br>QUERY_EVENT<br>其中FORMATDESCRIPTIONEVENT TABLE_MAP_EVENT<br>calhost-bin.000001<br>与ROTATEEVENT仅有一个，分别位于日志 WRITE_ROW_EVENT<br>UPDATE_ROW_EVENT<br>的起始和结尾，ROTATE_EVENT在日志关闭<br>DELETE_ROW_EVENT<br>时才会生成。<br>日志的中间有多个QUERY_EVENT、<br>ROTATE_EVENT<br>TABLEMAPEVENT、WRITEROWEVENT&#x2F;<br>图24-1日志的组成<br>UPDATEROWEVENT&#x2F;DELETEROWEV<br>ENT，分别对应建库建表事件、DML事务前的对应表信息和DML语句事件，其中TABLE MAP_EVENT和ROW_EVENT是成对出现的。<br>除此之外，日志中还有GTID_LOG_EVENT&#x2F;ANONYMOUS_GTID_LOG_EVENT和XID EVENT等事件。<br>在这里我们拆分一下24.2.2节中的DML事务，也就是insert intoempvalues（1,z1）语句，对应TABLE_MAP_EVENT与WRITE_ROW_EVENT这两个事件，来分析一个insert语句在<br>二进制日志中所生成的内容。 TABLE MAP EVENT:<br>#at192&#x2F;&#x2F;事件在二进制文件中的起始位置<br>#18100814:23:397&#x2F;事件发生的时间 server id1&#x2F;&#x2F;MysQL的server_id end_1og_pos241&#x2F;&#x2F;结束位置<br>CRC320xd0ec50cf&#x2F;&#x2F;循环余校验码<br>Table map:test.empmapped to number 71&#x2F;&#x2F;表名与id<br>WRITE ROW EVENT:#at241<br>#181008 14:23:39 server id 1 end 1og_pos 284 CRc32 0x80b83184 write rows: table id 71 flags:STMT_END_F<br>BINLOG<br>6&#x2F;e6WXMBAAAAMQAAAPEAAAAAAECAAAAAAAEABHR1c3QAA2VtCAACAW8C&#x2F;WADz1DsOA&#x3D;&#x3D;<br>6&#x2F;e6Wx4BAAAAKwAAABwBAAAAAECAAAAAAAEAAgAC&#x2F;&#x2F;WBAAAAAnoxhDG4gA&#x3D;&#x3D;&#x2F;<em>1</em>&#x2F;;<br>###INSERT INTOtest.emp###SET<br>###@1&#x3D;1 &#x2F;*INT meta&#x3D;0 nullable&#x3D;1 is nu11&#x3D;0 *&#x2F;<br>###@2&#x3D;z1&#x2F;<em>VARSTRING(255）meta&#x3D;255nu11ab1e&#x3D;1isnu11&#x3D;0</em>&#x2F;&#x2F;&#x2F;解析后的SQL语句<br>可以看出，二进制日志完整地记录了一条DML命令的所有信息，我们可以应用这份日志<br>做主从复制、数据恢复、闪回等功能。 24.2.5日志闪回<br>日志的闪回是指当用户执行并提交了某些错误的删除或写入语句时，可以通过二进制日志将对应的事件逆向化，转为相反的写入或删除语句，并重新应用新生成的语句来抵消掉之前误操作的过程。日志闪回与数据库的正常备份恢复是不同的，因为使用日志进行闪回针对的是已</p>
<p>≦ 431 ≧<br>24.2二进制日志 413<br>知的语句，条件颗粒化到表级别、语句类型级别甚至是条件内容级别，可以在语句已经提交并同步到备库后，逆向的执行语句来恢复数据。能够做到无损地恢复数据并将错误造成的影响控制到最小。<br>日志闪回主要针对的是单个或少量已知误操作的紧急恢复，与数据库的备份并不相关。下面简单介绍一下二进制日志做闪回的原理。首先我们看一个事件在二进制文件中的具<br>体结构。<br>event l timestamp header<br>type_code I server_id<br>event_length next position<br>|flags<br>event fixed part data<br>variable part<br>所有事件的结构都如上所示，包括eventheader和event data两部分，其中header的结构是固定的，记录了该事件的时间戳、类型、事件长度、下个事件位置等内容。而data部分对于不同的事件而言结构都是不同的，例如建表或写入语句，会有不同的语句结构部分（fixed part）和不同的语句内容长度（variablepart）。在这里我们不逐个分析所有的事件结构，仅通过DML语句来演示闪回语句是如何生成的。<br>1.insert&#x2F;delete语句首先写人并删除一条数据。<br>mysql&gt; insert into emp values(1,z1’); Query ok, 1 row affected (0.00 sec)<br>mysql&gt; delete from emp where a&#x3D;1; Query ok,1 row affected (0.00 sec)<br>之后解析二进制日志并取出需要查看的事件。#at192<br>#181008 17:34:11 server id1 end 1og pos 241 cRC32 0xb970ec62 Table map: testemp<br>mapped<br>to number 73#at241<br>#181008 17:34:11 server id 1 end 1og pos 284 cRc32 0x74a8cbc7 write rows: table id 73 flags:<br>STMT_ENDF BINLOG<br>kyS7WXMBAAAAMQAAAPEAAAAAAEkAAAAAAAEABHR1c3QAA2VtCAACAW8c&#x2F;WADYuxWuQ&#x3D;&#x3D;<br>kyS7Wx4BAAAAKWAAABWBAAAAAEkAAAAAAAEAAgAC&#x2F;&#x2F;WBAAAAAnoxx8uodA&#x3D;-&#x2F;<em>1</em>&#x2F;;<br>###INSERT INTO###SET<br>###@1&#x3D;1 &#x2F;*INTmeta&#x3D;0 nu1lable&#x3D;1 is null&#x3D;0 *&#x2F;<br>###@2&#x3D;’z1′&#x2F;<em>VARSTRING(255)meta&#x3D;255 nu1lab1e&#x3D;1 isnu11&#x3D;0</em>&#x2F;#at387<br>#181008 17:34:22 server id 1 end 1og pos 436 CRc32 0x1e19728f Table map: test.emp mapped</p>
<p>≦ 432 ≧<br>414 第24章MySQL日志<br>to number 73#at 436<br>#181008 17:34:22 server id 1 end 1og pos 479 cRC320x707bea77 Delete rows: table id 73 flags<br>STMT ENDF BINLOG<br>nis7WxMBAAAAMQAAALQBAAAAAEkAAAAAAAEABHR1c3QAA2VtCAACAW8C&#x2F;WADj3IZHg&#x3D;&#x3D;<br>niS7WyABAAAAKWAAAN8BAAAAAEkAAAAAAAEAAgAC&#x2F;&#x2F;wBAAAAAnoxd+p7cA&#x3D;:’&#x2F;<em>1</em>&#x2F;;<br>###DELETE FROMtest.emp###WHERE<br>###@1&#x3D;1&#x2F;<em>INT meta&#x3D;0 nu1lable&#x3D;1 is nu71&#x3D;0 <em>&#x2F;<br>###@2&#x3D;’z1&#x2F;<em>VARSTRING(255) meta&#x3D;255 nullable&#x3D;1 isnu71&#x3D;0</em>&#x2F;<br>可以看到日志中有一条写人和删除的事件。仔细观察可以发现，在delete语句中虽然只写了a&#x3D;1这一个条件，但实际上整条数据都记录在日志中了，也就是说在二进制文件中， WRITE_ROW_EVENT和DELETE_ROW_EVENT这两个事件不同之处仅在于类型的不同，也就是eventheader 中type code 不同（WRITE_ROW_EVENT type code 为Oxle， DELETE_ROW_EVENTv2的typecode为Ox20），我们可以简单地通过修改二进制文件中type code的内容，就能将insert和delete两种类型的语句互换，如图24-2所示。<br>WRITE_ROW_EVENT DELETE_ROW_EVENT<br>event header event data event header event data<br>type_code ype oxle<br>0x20<br>图24-2 事件类型的修改<br>2.update语句<br>这次我们更新一条数据。<br>mysql&gt; insert into emp values(1,’z1’); Query ok,1 row affected (0.00 sec)<br>mysql&gt; update emp set b&#x3D;’z2where a&#x3D;1; Query oK, 1 row affected (o.o0 sec)<br>Rows matched:1Changed:1 warnings:0<br>取出对应的TABLE_MAP_EVENT和UPDATE_ROW_EVENT事件。#at777<br>#181008 18:03:23 server id 1 end_log_pos 826 cRc32 0xe7806c15 Table map:test.emp mapped to number 73<br>#at826<br>#181008 18:03:23 server id 1 end 1og pos 878 cRc32 0x78c39704 Update rows: table id 73<br>flags: STMT END F BINLOG<br>ayu7WxMBAAAAMQAAADoDAAAAAEkAAAAAAAEABHR1c3QAA2VtCAACAw8C&#x2F;wADFWyA5W&#x3D;-<br>ayu7Wx8BAAAANAAAAG4DAAAAAEkAAAAAAAEAAgAC&#x2F;&#x2F; &#x2F;8AQAAAAJ6MfWBAAAAAnoyBJfDeA&#x3D;&#x2F;</em>!</em>&#x2F;;<br>###UPDATEtest.emp”###WHERE<br>###@1&#x3D;1&#x2F;<em>INT meta&#x3D;0 nu1lable&#x3D;1 is nu11&#x3D;0</em>&#x2F;<br>###@2&#x3D;z1&#x2F;<em>VARSTRING(255）meta&#x3D;255nu1lable&#x3D;1 is nu11&#x3D;0</em>&#x2F;###SET<br>###@1&#x3D;1 &#x2F;*INT meta&#x3D;0 nu7lable&#x3D;1 isnu11&#x3D;0 *&#x2F;<br>###@2&#x3D;’z2&#x2F;<em>VARSTRING（255)meta&#x3D;255nu1lable&#x3D;1isnu11&#x3D;0</em>&#x2F;<br>同样可以看到，日志中完整地记录了一条数据从修改前到修改后的数据内容，我们可以</p>
<p>≦ 433 ≧<br>24.3查询日志 415<br>交换这两个数据段的位置，便可以将一个更新语句逆向化，生成一个新的闪回语句。如上两种情况中，具体的二进制文件修改功能的编码过程这里就不做介绍了。<br>得到逆向的语句之后，需要重新执行新语句来应用到数据库中。但是需要注意执行顺序问题，如图24-3所示。<br>TABLE_MAPEVENT TABLE_MAP_EVENT TABLE_MAP_EVENT<br>X<br>WRITE_ROW_EVENT DELETE_ROW_EVEN UPDATE_ROW_EVENT<br>(reverse)<br>TABLE_MAP_EVENT TABLE_MAP_EVENT TABLE_MAP_EVENT<br>UPDATE_ROW_EVENT<br>UPDATE_ROW_EVENT(reverse) DELETE_ROW_EVENT<br>图24-3新事件列表反转<br>我们需要将整个的事件列表以（TABLE_MAP_EVENT,ROW_EVENT）为一个单位完全反转过来，然后按顺序执行图中最后一个列表的内容，才能完成一个闪回的操作。<br>由此可以看出，日志闪回能够有效地解决DML误操作所带来的问题，但当操作是drop 或truncate等命令时，数据库将无法通过这种方式进行闪回。<br>目前MySQL已经有binlog2sql、MyFlash等可用的闪回工具可以直接使用。当然读者也<br>可以根据上面所涉及的二进制日志闪回原理，设计并编写一套属于自己的闪回工具。 24.3查询日志<br>查询日志记录了客户端的所有语句，而二进制日志不包含查询数据的语句。 24.3.1日志的位置和格式<br>查询日志和慢查询日志（见24.4节）都可以选择保存在文件或者表中，并使用参数–log-output[&#x3D;value..]来进行控制，value值可以是TABLE、FILE、NONE的一个或者多个组合，中间用逗号进行分割，分别表示日志保存在表、文件、不保存在表和文件中，这里的表指的是mysql库中的general_log（慢查询日志是slow_log）表。其中NONE的优先级最高，比如–log-output&#x3D;TABLE,FILE表示日志可以同时输出到表和文件中，而–log-output &#x3D;TABLE,NONE，由于NONE的优先级，表示日志不保存在表和文件中。如果不显式设置此参数，则默认输出到文件。日志记录到表比记录到文件要占用更多的系统资源。如果需要更高的性能，则建议使用文件来记录日志。<br>如果要启用查询日志，可以通过参数–general_log[&#x3D;{0|1}]和–general_log_file&#x3D;file_name 来进行控制。前者控制是否启用日志，后者控制日志文件的路径。–general_log设置为1或者不带值都可以启用查询日志；设置为0则关闭查询日志，如果不指定此参数也不会启用查询</p>
<p>≦ 434 ≧<br>416 第24章MySQL日志<br>日志。如果没有指定–general_log_file&#x3D;file_name的值，且没有显式设置–log-output参数，那么日志将写入参数DATADIR（数据目录）指定的路径下，默认文件名是host_name.log。这两个参数都是global类型，可以在系统启动时或者系统运行时进行动态修改，如果想在session 级别控制日志是否被记录，则通过在session中设置参数sql_log_off为on或者off来进行控制。<br>24.3.2日志的读取<br>查询日志格式是纯文本，可以直接进行读取。下面是一个读取查询日志的例子。<br>（1）首先在客户端对数据库做一些简单操作，包括查询和插入。 mysql&gt; use employees<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed<br>mysql&gt;select *from departments; I dept no I dept name<br>do09 Customer Service |d005 Development 1d002 IFinance<br>3rows in set (0.00 sec)<br>mysql&gt;insert into departments values(‘d010’,’IT’）; Query ok,1 row affected (0.03 sec)<br>（2）然后查看查询日志中记录的客户端的所有操作，对应的内容如下：[root@localhost data]# more localhost.log<br>2018-09-27T19:53:08.299817+08:00716 Query select * from departments<br>2018-09-27T19:53:51.666781+08:00 716 Query insert into departments values(‘d010’,’IT’) 2018-09-27T19:54:03.439720+08:00716 Quit<br>注意：log日志中记录了所有数据库的操作，对于访问频繁的系统，此日志对系统性能的影响较大，<br>建议关闭。<br>24.4慢查询日志<br>慢查询日志记录了所有执行时间超过参数long_query_time（单位为s）设置值并且扫描记录数不小于min_examined_row_limit的所有SQL语句的日志（注意，获得表锁定的时间不算作执行时间）。long_query_time默认为10s，最小为0，精度可以到微秒。<br>在默认情况下，有两类常见语句不会记录到慢查询日志：管理语句和不使用索引进行查询的语句。这里的管理语句包括ALTERTABLE、ANALYZETABLE、CHECKTABLE、CREATE INDEX、DROPINDEX、OPTIMIZETABLE和REPAIRTABLE。如果要监控这两类SQL语句，可以分别通过参数–log-slow-admin-statements 和–log-queries-not-using-indexes进行控制。<br>24.4.1文件位置和格式<br>慢查询日志默认是关闭的，可以用两个参数来控制开启状态和输出方式：使用-slow_query_log[&#x3D;{0l1}]显式指定慢查询的状态，如果不指定值或者指定值为1都会打开慢查</p>
<p>≦ 435 ≧<br>24.4慢查询日志 417<br>询；使用 slow_query_log_file[&#x3D;file_name]来指定慢查询日志的路径，如果没有给定file_name 的值，日志将写入参数DATADIR（数据目录）指定的路径下，默认文件名是host_name-slow.log。另外，如前所述，还可以使用–log-output参数来指定日志的输出方式，默认会输出到文件，<br>当然也可以选择输出到表。 24.4.2日志的读取<br>和错误日志、查询日志一样，慢查询日志记录的格式也是纯文本，可以被直接读取。下例中演示了慢查询日志的设置和读取过程。<br>（1）首先查询一下long_query_time的值。 mysql&gt; show variables like ‘long%’;<br>|variable name 1value<br>1long query time 1 10 1 row in set (o.00 sec)<br>（2）为了方便测试，将修改慢查询时间为2s。 mysql&gt; set long_ query_time&#x3D;2;<br>Query ok, 0 rows affected (0.02 sec)（3）依次执行下面两个查询语句。<br>第一个查询因为查询时间低于2s而不会出现在慢查询日志中： mysql&gt; select count(1) from salaries;<br>1count(1)1 128343391<br>1 row in set (0.93 sec)<br>第二个查询因为查询时间大于2s而应该出现在慢查询日志中：<br>mysql&gt; select count(1) from salaries t,salaries t1 where t.emp_no&#x3D;t1.emp_no;<br>1count(1)1 1335212811<br>1row in set (24.68 sec)（4）查看慢查询日志。<br>[root@localhost data]# more localhost-slow.log#Time:2018-09-27T19:59:10.609135+08:00<br>#User@Host:root[root] @localhost []Id:717<br>#Query time:24.675446 Lock time:0.000381 Rows sent:1 Rows examined: 36355620 SET timestamp&#x3D;1538049550;<br>select count(1) from salaries t,salaries tl where t.emp_no&#x3D;tl.emp_no;<br>从上面的日志中可以发现查询时间超过2s的SQL，而小于2s的则没有出现在此日志中。（5）设置微秒级慢查询。<br>mysql&gt; set global long_query_time&#x3D;0.01; Query ok,0 rows affected (o.oo sec)<br>mysql&gt; show variables like long%;<br>1Variable name 1value</p>
<p>≦ 436 ≧<br>418 第24章MySQL日志<br>1long_query_time |0.010000| 1row in set (0.01 sec)<br>查看日志输出方式为文件和表同时写： mysql&gt; show variables like %output%’; I variable name | value<br>log output FILE,TABLE 执行慢查询SQL如下：<br>mysql&gt; select count(o) from dept_emp; |count(o)1<br>2868091<br>1 row in set (0.09 sec)<br>查看日志文件记录，日期的确精确到微秒：#Time:2018-09-27T20:04:20.918640+08:00<br>#User@Host:root[root] @ localhost [] Id:718<br>#Query_time: 0.090921 Lock time:0.000298 Rows_sent:1 Rows_examined:286809 SET timestamp&#x3D;1538049860:<br>select count(o) from dept emp;<br>查询系统表记录，如前所述，时间无法精确到微秒：<br>mysql&gt; select query_time,sql_text from mysql.slow_log where sql_text 1ike %select count(o) from dept_emp%’;<br>Iquery_time |sql text<br>10:00:00.090921 1 select count(0) from dept emp 1 1row in set(0.00 sec)<br>如果慢查询日志中记录内容很多，可以使用pt-query-digest工具进行分析，可以得到每个 SQL的响应时间、最大执行时间、最小执行时间、执行时间对比等信息，结果非常直观。 pt-query-digest的详细用法可以参考第23章中的相关内容。<br>如果没有安装pt-query-digest工具，想简单分析慢日志信息，也可以使用mysqldumpslow 工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。下例中对日志文件 localhost-slow.log进行了分类汇总，只显示汇总后的摘要结果：<br>[root@localhost mysql]# mysqldumpslow localhost-slow.log<br>Count:2 Time&#x3D;23.37s （46s) Lock&#x3D;0.00s (0s) Rows&#x3D;1.0 (2),root[root]@localhost select count(N) from salaries t,salaries tl where t.emp_no&#x3D;tl.emp_no<br>Count: 1 Time&#x3D;0.09s (Os)Lock&#x3D;0.00os (0s) Rows&#x3D;1.0 (1),root[root]@localhost select count(N)from dept emp<br>Count:3 Time&#x3D;0.00s (Os)Lock&#x3D;0.00s (0s) Rows&#x3D;2.3（7),root[root]@loca1host select time format(query time,’s’) time,sql text from mysql.slow log<br>Count:1 Time&#x3D;0.00s (0s)Lock&#x3D;0.00s (0s)Rows&#x3D;5.0 (5),root[root]@localhost select * from mysql.slowlog<br>对于SQL文本完全一致，只是变量不同的语句，mysqldumpslow将会自动视为同一个语句进行统计，变量值用N来代替。这个统计结果将大大增加用户阅读慢查询日志的效率，并迅速定位系统的SQL瓶颈。</p>
<p>≦ 437 ≧<br>24.4慢查询日志 419<br>注意：慢查询日志对于我们发现应用中有性能问题的SQL很有帮助，建议正常情况下，打开此日<br>志并经常查看分析。<br>24.4.3Anemometer简介<br>慢查询日志的重要性不言而喻，在数据库优化和故障诊断时，通常会先检查慢查询日志，往往能找到一些蛛丝马迹。此时使用pt-query-digest工具，根据时间区间、汇总方式等需求，手工分析慢查询日志文件，得到比较直观的结果。然而随着MySQL实例增多，手工处理的方式已经满足不了要求；日常工作中，我们也希望给开发人员提供查看慢查询日志的接口，让开发人员自己优化SQL。一些公司会开发分析慢查询日志的平台，减少手工操作的工作量。如果自己不希望开发类似的平台，可以使用开源工具Anemometer。<br>Anemometer是图形化展示MySQL慢查询日志的一个工具平台。它的好处是提供了丰富的选项和友好的显示界面，用户只需操作鼠标，就可以查看相应实例的慢查询日志；缺点是没有权限认证，数据安全性低。<br>Anemometer需要以下工具和组件：<br>O存放汇总慢查询日志的MySQL数据库； Opt-query-digest 工具；<br>被监控实例主机上部署crontab任务；<br>OPHP5.5版本以上的Web服务。 Anemometer的架构如图24-4所示。<br>在Web界面查看explain执行计划 Anemometer<br>应用<br>查询汇总信息，并在Web页面展示<br>定时分析slowlog，推到汇总库，方便Anemometer查询<br>crontab<br>查询日志汇总库<br>图24-4Anemometer架构示意图<br>在Anemometer的架构中，由被监控MySQL实例的主机运行crontab任务，定时用 pt-query-digest工具分析慢查询日志文件，将分析结果推到慢查询汇总库。用户在Web 端选择查询条件后，Anemometer到汇总库查询，在Web页面显示慢查询SQL。如果用户想了解慢查询SQL的执行计划，Anemometer会到被监控数据库执行explain命令，并在Web页面显示。<br>Anemometer的安装并不复杂，读者按照GitHub上的提示安装即可。如果安装完成 Anemometer，在浏览器中输入<a target="_blank" rel="noopener" href="http://sip/anemometer%E5%8D%B3%E5%8F%AF%E7%99%BB%E5%BD%95%EF%BC%8C%E5%85%B6%E4%B8%AD$ip%E4%B8%BAAnemometer%E5%B9%B3%E5%8F%B0%E6%89%80%E5%9C%A8%E4%B8%BB%E6%9C%BA%EF%BC%8C%E5%A6%82%E5%9B%BE24-5%E6%89%80%E7%A4%BA%E3%80%82">http://Sip/anemometer即可登录，其中$ip为Anemometer平台所在主机，如图24-5所示。</a></p>
<p>≦ 438 ≧<br>420 第24章MySQL日志<br>Box Anem<br>Search<br>0.31630301475524<br>图24-5Web端查询页面<br>从图24-5中能看到很多选项，在框内写人相应的限制条件，可以在汇总库找到想要的慢查询日志信息。下面介绍几个常用的选项。<br>0 From，To：框定需要查看的时间范围。 Queryfirst seen since:慢SQL第一次出现在日志中的时间。 0<br>TableFields：选择显示慢SQL的信息字段。只有选中的字段，才会在结果中显示。<br>FilterByHost:选择过滤MySQL服务所在的主机名称，默认为空。 0<br>GroupBy：按照哪个字段进行分组，默认是checksum字段。<br>OrderBy：按照哪个字段进行排序，默认是按照Query_time_sum字段倒序。<br>Limit:只去前N条慢SQL，配合上面的OrderBy使用。默认是20，即找出Top20 的慢SQL。<br>ReviewedStatus:根据慢SQL的审核状态查询，默认为空。<br>OShowRawSQL：显示用户选定所有过滤条件后，Anemometer到汇总库查询的真实 SQL。参考这个SQL，可以知道查询逻辑跟我们期望的是否一致，方便高阶用户使用。<br>为了加深理解，这里做一个简单的查询，From时间为2018-09-0200:00:35，To时间为 2018-09-3000:00:35，平台会查询这个时间区间的慢SQL。Queryfirstseen since为2018-09-05 00:00:00，在上面的查询结果中，再限定所有慢查询日志SQL，第一次出现的时间在2018-09-05 00:00:00之后。Group By为 snippet，即按照SQL前几个单词进行分组。Order By为query time_avgDESC，即按照query_time_avg字段倒序排序。Limit为5，取结果集排序后的前5 行。查询界面如图24-6所示。<br>如果想查看所有条件组合的原始查询SQL，可以单击左下角的“ShowRawSQL”按钮。单击“Search”按钮，可以看到查询结果，一共查出5条记录，如图24-7所示。<br>单击“checksum”字段会跳转到另外一个页面，在这个页面可以对慢查询SQL进行分析和审核。分析功能包括查看慢SQL出现的频率、执行计划、表结构和表状态等。以上功能基本能覆盖用户工作中的大多数需求。如果想更详细地了解Anemometer，可以参见GitHub的官方主页<a target="_blank" rel="noopener" href="https://github.com/box/Anemometer/wiki%E3%80%82">https://github.com/box/Anemometer/wiki。</a></p>
<p>≦ 439 ≧<br>24.5小结 421<br>2018-09-0200:00:35 2018-09-300:00:35 菜 2018-09-0500:00:00<br>GroupBy snippet<br>OrderBy<br>queryfimeavg DESC<br>Query Sample Cont<br>Search<br>+ShowRaw SQLUPermlinkJSON<br>图24-6Web端查询页面<br>Query_time_sum Lock time sum<br>RowE son<br>210 645524.5 0.129192983<br>15023410320281982 1.5023410320281982 0.00017899999511426177<br>图24-7查询结果<br>Anemometer的缺点是没有登录和权限认证。如果多个业务共用一个MySQL实例，所有业务的慢查询SQL是放在一起的，用户能查看所有业务的慢查询SQL，在某些情况下这是不安全的。针对这种情况，一种方法是将业务拆分，每业务专用自已的MySQL实例；第二种方式是对Anemometer进行二次开发，实现登录和权限认证需求。读者可以采取适合自己的解决方法。<br>24.5小结<br>日志是数据库中很重要的记录内容，它可以帮助我们诊断数据库出现的各种问题。本章主要介绍了MySQL常用的4种日志类型：错误日志、二进制日志、查询日志和慢查询日志。这4种日志各有不同的用途。<br>系统故障时，建议首先查看错误日志，以帮助用户迅速定位故障原因。<br>?二进制日志记录数据的变更和DDL操作，是数据备份、数据复制和数据恢复等操作的基础，应默认开启此日志。<br>O如果希望记录数据库发生的任何操作，包括SELECT，则需要用–general_log将查询日志打开，此日志默认关闭，一般情况下建议不要打开此日志，以免影响系统整体性能。<br>如果希望查看系统的性能问题，希望找到有性能问题的SQL语句，则需要用–slow_query_log打开慢查询日志。对于大量的慢查询日志，建议使用pt-query-digest工具来进行汇总查看。</p>
<p>≦ 440 ≧<br>第25章 备份与恢复<br>备份和恢复在任何数据库里面都是非常重要的内容，好的备份方法和备份策略将会使得数据库备份更高效、数据更安全。与很多数据库类似，MySQL的备份主要分为逻辑备份和物<br>理备份。本章将重点介绍这两种方式的备份和恢复方法。 25.1备份&#x2F;恢复策略<br>对于一个DBA来说，定制合理的备份策略无疑是很重要的。以下是我们在进行备份或恢复操作时需要考虑的一些因素。<br>确定要备份的表的存储引擎是事务型还是非事务型，两种不同的存储引擎备份方式在处理数据一致性方面是不太一样的。<br>确定使用全量备份还是增量备份。全量备份的优点是备份保持最新备份，恢复的时候可以花费更少的时间；缺点是如果数据量大，将会花费很多的时间，并对系统造成较长时间的压力。增量备份则恰恰相反，只需要备份每天的增量日志，备份时间少，对负载压力也小；缺点就是恢复的时候需要全量备份加上次备份到故障前的所有日志，恢复时间会长一些。<br>可以考虑采取复制的方法来做异地备份，但是记住，复制不能代替备份，它对数据库的误操作也无能为力。<br>要定期做备份，备份的周期要充分考虑系统可以承受的恢复时间。备份要在系统负载较小的时候进行。<br>O确保MySQL打开log-bin选项，有了BINLOG，MySQL才可以在必要的时候做完整恢复，或基于时间点的恢复，或基于位置的恢复。<br>要经常做备份恢复测试，确保备份是有效的，并且是可以恢复的。 25.2逻辑备份和恢复<br>在MySQL中，逻辑备份的最大优点是对于各种存储引擎都可以用同样的方法来备份，而物理备份则不同，不同的存储引擎有着不同的备份方法。因此，对于不同存储引擎混合的数据库，用逻辑备份会更简单一些。本节将详细介绍逻辑备份以及相应的恢复方法。</p>
<p>≦ 441 ≧<br>25.2逻辑备份和恢复 423<br>25.2.1备份<br>MySQL中的逻辑备份是将数据库中的数据备份为文本文件，备份的文件可以被查看和编辑。在MySQL中，可以使用mysqldump工具来完成逻辑备份。可以使用以下3种方法来调用mysqldump。<br>备份指定的数据库或者此数据库中的某些表。<br>[shell&gt; mysqldump [options] db name [tables]<br>备份指定的一个或多个数据库。<br>shell&gt; mysqldump [options] —database DB1 [DB2 DB3…]<br>备份所有数据库。<br>shell&gt; mysqldump [options] –all-database<br>如果没有指定数据库中的任何表，默认导出所有数据库中的所有表。以下给出一些使用 mysqldump工具进行备份的例子。<br>（1）备份所有数据库：<br>[mysq13307@localhost ~]s mysqldump -uroot-p –all-database &gt; all.sq] Enter password:<br>（2）备份数据库employees：<br>[mysq13307@localhost ~]$ mysqldump -uroot -p empToyees&gt;employees.sq] Enter password:<br>（3）备份数据库employees下的表salaries：<br>[mysq13307@localhost ~]s mysqldump -uroot -p employees salaries &gt; salaries.sql Enter password:<br>（4）备份数据库employees下的表dept_emp和salaries：<br>[mysq13307@localhost ~]s mysqldump -uroot -p employees dept_emp salaries &gt; dept emp_salaries.sql Enter password:<br>（5）备份数据库employees下的所有表为逗号分割的文本，备份到&#x2F;tmp：<br>[mysq13307@localhost tmp]#mysqldump -uroot -T&#x2F;tmp employees dept emp–fields-terminated-by,[mysq13307@localhost tmp]# more dept emp.txt<br>11025,d003,1998-09-07,2000-05-26 11026,d004,1991-11-08,9999-01-01 11027,d004,1986-05-07,9999-01-01 11028,d004,1986-06-18,1997-09-04 11029,d007,1992-12-27,9999-01-01 11030,d007,1988-05-09,1988-07-08 11032,d005,2000-12-15,9999-01-01 11033,d005,1991-03-14,9999-01-01 11036,d002,1988-10-24,9999-01-01 11037,d004,1988-01-28,9999-01-01 11038,d008,1985-07-15,9999-01-01<br>其中mysqldump的选项很多，具体可以使用“–help”参数查看帮助： mysq1dump-he1p<br>需要强调的是，为了保证数据备份的一致性，MyISAM存储引擎在备份时需要加上-1参数，表示将所有表加上读锁，在备份期间，所有表将只能读而不能进行数据更新。但是对于事务存储引擎（InnoDB）来说，可以采用–single-transaction选项。此选项将使得InnoDB存</p>
<p>≦ 442 ≧<br>424 第25章备份与恢复<br>储引擎得到一个快照（Snapshot），保证备份的数据能够一致。<br>注意：MySQL8.0的系统表已经废弃MyISAM存储引擎，默认存储引擎为InnoDB<br>日常工作中，我们也经常使用mydumper进行逻辑备份。它是一个多线程备份工具，通过增加线程数，极大地提高备份速度。与mysqldump不同，mydumper为每个表创建一个或者多个文本文件，方便并行备份和并行恢复数据。<br>注意：可以在<a target="_blank" rel="noopener" href="https://github.com/maxbube/mydumper%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E5%8C%85%E3%80%82">https://github.com/maxbube/mydumper下载安装包。</a><br>mydumper使用方法跟mysqldump基本一致，对于两者相同的参数将不再赘述。下面是<br>mydumper一些常用的选项，要查阅更多的选项，可以使用“–help”参数查看帮助。-B,–database 需要备份的数据库，一个数据库写一条命令。如果不指定，默认备份所有数据库。<br>T,–tables-list 需要备份的表-0,–outputdir 导出文件存放目录<br>-s,–statement-size 按照insert语句插入的数据大小拆分，单位bytes，默认值1000000<br>rows 按照行数对结果文件进行拆分<br>F,–chunk-filesize 按照导出文件大小进行拆分，单位为MB-t,–threads 线程并行数，默认4个线程<br>下面来看一些使用mydumper工具的例子。（1）备份employees数据库：<br>[mysq13307@1oca1host ~]s mydumper-uroot -s&#x2F;tmp&#x2F;mysq1 3307.sock<br>-0&#x2F;data2&#x2F;backup&#x2F;mydumper -B employees-p Enter password:<br>[mysq13307@1oca1host mydumper]s cd &#x2F;data2&#x2F;backup&#x2F;mydumper<br>[mysq13307@1oca1host mydumper]s 11 total4<br>drwx—–2 mysq13307 mysq13307 4096 oct 11 20:31 export-20181011-203134<br>[mysq13307@1oca1host mydumper]s 1l export-20181011-203134&#x2F; tota1 209596<br>-rw-rw-r– 1 mysq13307 mysq13307 624 0ct 11 20:31 emp1oyees.dept manager-schema.sq1-rw-rw-r– 1 mysq13307 mysq13307 1168 0ct 11 20:31 employees.dept manager.sql-rw-rw-r–1 mysq13307 mysq13307 484 0ct 11 20:31 employees.salaries-schema.sql-rw-rw-r– 1 mysq13307 mysq13307 118693182 0ct 11 20:31 employees.salaries.sql<br>-rw-rw-r–1 mysq13307 mysq13307 484 0ct 11 20:31 employees.titles-schema.sql<br>-rw-rw-r–1 mysq13307 mysq13307 21708866 0ct 11 20:31 employees.titles.sq1-rw-rw-r– 1 mysq13307 mysq13307 21708866 0ct 1120:31 metadata<br>可以看到，备份结果文件一共有3类。第一类是db.table.sql文件，存放表数据；第二类是db.table-schema.sql文件，存放表结构；第三类是metadata文件，记录备份的开始时间和结束时间，以及BINLOG日志文件名、位置和GTID信息。可以根据metadata记录的信息进行完全恢复或基于位置的恢复。下面以employees.dept_manager表为例进行讲解。<br>查看表数据：<br>[mysq13307@1ocalhost mydumper]s cd export-20181011-203134<br>[mysq13307@loca7host export-20181011-203134]s cat employees.dept manager.sql&#x2F;<em>!40101 SET NAMES binary</em>&#x2F;；<br>&#x2F;<em>!40014 SET FOREIGN_KEY_CHECKS&#x3D;0</em>&#x2F;;&#x2F;<em>!40103 SET TIME ZONE&#x3D;′+00:00′</em>&#x2F;; INSERT INTo dept managerVALUES<br>(110022,”d001”,”1985-01-01”,”1991-10-01”)，(110039,”d001”,”1991-10-01”,”9999-01-01”),(110085,”d002”,”1985-01-01”,”1989-12-17”)(110114,”d002”,”1989-12-17”,“9999-01-01”)(110183,”d003”,”1985-01-01”,”1992-03-21”)，<br>(111784,“d009”,”1988-10-17”,”1992-09-08”)</p>
<p>≦ 443 ≧<br>25.2逻辑备份和恢复 425<br>（111877,”d009”,”1992-09-08”,”1996-01-03”),(111939,”d009”,”1996-01-03”,”9999-01-01”);<br>查看表结构：<br>[mysq13307@loca1host export-20181011-203134]s cat employees.dept_manager-schema.sql&#x2F;<em>140101 SET NAMES binary</em>&#x2F;;<br>&#x2F;<em>!40014 SETFOREIGN_KEY_CHECKS&#x3D;0</em>&#x2F;;&#x2F;<em>140103 SETTIME ZONE&#x3D;+00:00′</em>&#x2F;;<br>CREATE TABLE dept manager（ empnoint（11) NOT NULL,<br>dept no char(4) COLLATE utf8 unicode ci NOT NULL,<br>from date date NOT NULL, to_date date NOT NULL,<br>PRIMARY KEY（emp_no，dept_no）， KEYdept no（dept no），<br>CONSTRAINT dept manager ibfk 1FOREIGN KEY （emp_no) REFERENCEsemployees（emp no) ON DELETE CASCADE,<br>CONSTRAINTdept manager ibfk 2FOREIGN KEY（dept no） REFERENCES departments（dept no）) ON DELETE CASCADE<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci; 查看备份开始时间和结束时间：<br>[mysq13307@loca1host export-20181011-211838]s cat metadata<br>Started dump at:2018-10-11 21:14:57 SHOW MASTER STATUS:<br>Log: mysql-bin.000008 PoS:2750<br>GTID:b509f331-cd14-11e8-866a-0024e869b4d5:1-18044<br>Finished dump at:2018-10-11 21:15:00<br>（2）备份employees数据库的salaries表，开启3个并发线程数，每个文本文件最大50MB。[mysq13307@loca1host~]$ mydumper-uroot-s&#x2F;tmp&#x2F;mysql _3307.sock<br>-0&#x2F;data2&#x2F;backup&#x2F;salaries-B employees-T salaries-t3-F 50-p Enter password:<br>[mysq13307@localhost salaries]$ cd &#x2F;data2&#x2F;backup&#x2F;salaries<br>[mysq13307@loca1host salaries]s 1s -1trh total 114M<br>-rw-rw-r–1 mysq13307 mysq13307 92 0ct 11 20:50 employees-schema-create.sq1-rw-rw-r–1 mysq13307 mysq13307 484 0ct 11 20:50 employees.salaries-schema.sql-rw-rw-r–1 mysq13307 mysq13307 49M 0ct 11 20:50 employees.salaries.00001.sq1-rw-rw-r–1 mysq13307 mysq13307 49M 0ct 11 20:50 employees.salaries.00002.sq1-rw-rw-r–1 mysq13307 mysq13307 16M 0ct 11 20:50 employees.salaries.00003.sq1-rw-rw-r–1 mysq13307 mysq13307 181 0ct 11 20:50 metadata<br>25.2.2完全恢复<br>mysqldump的恢复也很简单，将备份作为输人执行即可，具体语法如下：<br>mysqlurootpdbnamebakfile 5-<br>注意，将备份恢复后数据并不完整，还需要将备份后执行的日志进行重做，语法如下： mysqlbinlog binlog-file &#x2F; mysql -u root -p*#<br>以下是一个完整的mysqldump备份与恢复的例子。（1）上午9点，备份数据库：<br>[mysq13307@localhost mysq1]# mysqldump -uroot -p –single-transaction -F employees &gt;employees.dmp Enter password:<br>其中–single-transaction参数表示给InnoDB表加生成快照，保证数据一致性，-F表示生成一个新的日志文件，此时，employees数据库中departments表的数据如下：</p>
<p>≦ 444 ≧<br>426 第25章备份与恢复<br>mysql&gt; select * from employees.departments; I dept no I dept name<br>d009 Customer Service<br>d005 Development d002 Finance<br>d003 Human Resources d010<br>d001 Marketing d004 Production<br>d006 Quality Management<br>d008 Research d007 Sales<br>10 rows in set (0.00 sec)<br>（2）9点半备份完毕，然后，插人新的数据：<br>mysql&gt; insert into departments values(do11’,YEATIoN’）; Query ok, 1 row affected (0.01 sec)<br>mysql&gt; insert into departments values(‘d012’,Koala’）; Query ok, 1 row affected (0.01 sec)<br>（3）10点，数据库突然发生故障，数据无法访问，需要恢复备份：[mysq13307@1oca1host mysq1]# mysql -uroot -p employees&lt; employees.dmp<br>Enter password: 恢复后的数据如下：<br>mysql&gt; select * from employees.departments; I dept no | dept name<br>d009 Customer Service d005 Development d002 Finance<br>d003 Human Resources d010 IT<br>d001 Marketing d004 Production d006 Quality Management<br>d008 Research d007 Sales<br>10 rows in set (0.o0 sec)<br>（4）使用mysqlbinlog恢复自mysqldump备份以来的BINLOG。<br>[mysq13307@localhost mysq1]# mysq1binlog localhost-bin.000015 | mysql -u root -p employees Enter password:<br>查询完全恢复的数据如下：<br>mysql&gt; select * from employees.departments; dept_no I dept name<br>d009 Customer service d005 Development d002 Finance<br>d003 IHuman Resources d010 IT<br>d012 Koala d001 Marketing<br>d004  Production d006 Quality Management |<br>d008 Research d007 I sales |d011 YEATION</p>
<p>≦ 445 ≧<br>25.2逻辑备份和恢复 427<br>12 rows in set (0.00 sec) 至此，数据库完全恢复。<br>25.2.3基于时间点恢复<br>由于误操作，比如误删除了一张表，这时使用完全恢复是没有用的，因为日志里面还存在误操作的语句，我们需要的是恢复到误操作之前的状态，然后跳过误操作语句，再恢复后面执行的语句，完成我们的恢复。这种恢复叫作不完全恢复。在MySQL中，不完全恢复分为基于时间点的恢复和基于位置的恢复。<br>以下是基于时间点恢复的操作步骤。<br>（1）如果上午10点发生了误操作，可以用备份和BINLOG将数据恢复到故障前，所用语句如下：<br>she11&gt;mysq1bin1og –stop-date&#x3D;”2018-10-20 9:59:59”<br>&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.1234561mysql-uroot-pmypwd<br>（2）跳过故障时的时间点，继续执行后面的BINLOG，完成恢复。 she11&gt;mysq1binlog –start-date&#x3D;”2018-10-20 10:01:00”<br>&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.123456|mysq1-u root-pmypwd 25.2.4基于位置恢复<br>和基于时间点的恢复类似，但是更精确，因为同一个时间点可能有很多条SQL语句同时执行。恢复的操作步骤如下。<br>（1）在shell下执行如下命令：<br>she11&gt;mysq1bin1og –start-date&#x3D;”2018-10-20 9:55:00”–stop-date&#x3D;”2018-10-20 10:05:00”&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.123456&gt;&#x2F;tmp&#x2F;mysql_restore.sql<br>该命令将在&#x2F;tmp目录创建小的文本文件，编辑此文件，找到出错语句前后的位置号，例如前后位置号分别是368312和368315。<br>（2）恢复了以前的备份文件后，应从命令行中输人下面的内容：<br>she11&gt;mysq1binlog –stop-position&#x3D;”368312”&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.123456<br>1mysql-u root-pmypwd<br>she1l&gt;mysq1binlog –start-position&#x3D;”368315”&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.123456<br>|mysql-uroot-pmypwd<br>上面的第一行将恢复到停止位置为止的所有事务。下一行将恢复从给定的起始位置直到二进制日志结束的所有事务。因为mysqlbinlog的输出包括每个SQL语句记录之前的SET TIMESTAMP语句，因此恢复的数据和相关MySQL日志将反映事务执行的原时间。<br>25.2.5 并行恢复<br>如果使用mydumper进行备份，可以使用配套的myloader工具并行恢复数据，大大减少恢复时间。下面是myloader的一些常用选项，读者可以使用“–help”参数查看帮助，了解更多选项。<br>-d,–directory 备份文件所在目录-0,–overwrite-tables 是否覆盖已有表<br>-B,–database 执行需要恢复的数据库-e,–enable-binlog 是否记录BINLOG。如果在主库导入数据，开启此选项，才能把数据同步到从库-t,–threads 线程并行数，默认为4个线程</p>
<p>≦ 446 ≧<br>428 第25章备份与恢复<br>下面看一个myloader并行恢复的例子。（1）查看表数据量：<br>root@localhost:mysql 3307.sock [employees]&gt;select count(0) from salaries;<br>|count(o) 128440471<br>1 row in set (0.86 sec)（2）删掉部分数据：<br>root@localhost:mysql 3307.sockemployees]&gt;delete from salaries 1imit 47；<br>（3）使用25.2.1节中的备份文件恢复salaries表。开启3个并发线程数，覆盖已存在的表：<br>[mysq13307@1oca1host ~]smyloader -u root -s &#x2F;tmp&#x2F;mysq1_3307.sock<br>-d&#x2F;data2&#x2F;backup&#x2F;salaries -B employees -t 3-o -p Enter password<br>（4）查看恢复后表数据量：<br>root@localhost:mysq1 3307.sock [employees]&gt;select count(0) from salaries;<br>1countco)1 28440471<br>1 row in set (0.86 sec)<br>恢复后表记录数与备份前的记录数相同，证明表恢复成功了。 25.3 物理备份和恢复<br>物理备份分为冷备份和热备份两种，和逻辑备份相比，它的最大优点是备份和恢复的速度更快，因为物理备份的原理都是基于文件的cp。本节将介绍MySQL中的物理备份及其恢复的方法。<br>25.3.1冷备份和热备份<br>冷备份其实就是停掉数据库服务，cp数据文件的方法。这种方法对MyISAM和InnoDB 存储引擎都适合，但是一般很少使用，因为很多应用是不允许长时间停机的。<br>O进行备份的操作如下：停掉MySQL服务，在操作系统级别备份MySQL的数据文件和日志文件到备份目录。<br>进行恢复的操作如下：首先停掉MySQL服务，在操作系统级别恢复MySQL的数据文件；然后重启MySQL服务，使用mysqlbinlog工具恢复自备份以来的所有BINLOG。<br>热备份是在数据库运行的情况下，同时备份数据文件和备份期间产生的BINLOG的方法。即热备份是系统处于正常运转状态下的备份。<br>在MySQL中，对于不同的存储引擎热备份方法也有所不同。下面重点介绍MyISAM和 InnoDB两种存储引擎的热备份方法。</p>
<p>≦ 447 ≧<br>25.3物理备份和恢复 429<br>25.3.2MyISAM存储引I擎的热备份<br>MyISAM存储引擎的热备份方法，本质其实就是将要备份的表加读锁，然后再cp数据文件到备份目录。在5.7版本之前，官方提供了mysqlhotcopy工具来完成备份功能；5.7版本之后，由于MyISAM使用越来越少，此工具已从安装包中删除。如果要备份MyISAM表，操作步骤如下。<br>（1）数据库中所有表加读锁：<br>myq&gt;FLUSHTBLESWITHREADOCK<br>（2）cp数据文件到备份目录： cp source&#x2F;datadir target&#x2F;datadir<br>（3）释放表锁完成备份： mysql&gt;unlock tables;<br>25.3.3InnoDB存储引擎的热备份<br>InnoDB存储引擎的物理热备份通常有两种方式，一种是使用表空间迁移技术，cp数据文件，类似于上文MyISAM的备份方式，这种方式主要适用于备份指定的单表或者多表；另一种是使用专门的热备份工具，比如MySQL官方企业版提供的收费工具ibbackup或者percona 提供的免费工具Xtrabackup，后者使用更为广泛。下面详细介绍这两种备份方式。<br>1.利用表空间迁移备份表<br>MySQL5.6.6版本开始，基于表空间迁移技术，可以快速迁移或备份InnoDB引擎的表。使用表空间迁移要求innodb_file_per_table参数设置为ON；迁移过程，表处于只读状态，不能进行DDL和写操作。下面看一个具体的例子。<br>（1）查看表记录数：<br>root@localhost:mysql_3307.sock [employees]&gt;select count(0) from salaries;<br>1count(o)1 128439961<br>1row in set (0.86 sec)（2）备份salaries表：<br>执行FLUSHTABLES..FOREXPORT命令，在数据库目录生成cfg文件，此时salaries 处于只读状态。<br>root@localhost:mysql 3307.sock [employees]&gt; flush tables salaries for export;<br>[mysq13307@loca1host emp1oyees]s cd&#x2F;data2&#x2F;mysq13308&#x2F;data&#x2F;emp1oyees[mysql3307@localhost employees]s 1l salaries.*<br>-1 mysq13308 mysq13308 849 Nov 28 17:55 salaries.cfg<br>-rw-r-<br>-1mysq13308 mysq13308<br>-rw-r-8790 0ct 11 16:00 salaries.frm<br>-1 mysq13308 mysq13308 239075328 Nov 19 18:22 salaries.ibd<br>备份ibd文件和cfg文件。ibd文件保存表数据；cfg文件保存元数据，元数据用于验证导人表空间文件时的模式。<br>[mysq13307@1oca1host emp1oyees]s mkdir -p &#x2F;home&#x2F;mysq13307&#x2F;backup<br>[mysq13307@loca1host employees]s cp salaries.cfg salaries.ibd &#x2F;home&#x2F;mysq13307&#x2F;backup&#x2F;</p>
<p>≦ 448 ≧<br>430 第25章备份与恢复<br>解锁salaries表，表备份完成。<br>root@localhost:mysql 3307.sock [employees]&gt; unlock tables;<br>Query ok,0 rows affected (O.o0 sec)（3）模拟误删salaries表：<br>root@localhost:mysql 3307.sock [employees]&gt;drop table salaries;<br>（4）重新创建salaries表：<br>root@localhost:mysql_3307.sock[employees]&gt; CREATE TABLEsalaries（<br>emp noint(11) NOT NULL, salaryint(11) NOT NULL, from date date NOT NULL, to date date NOT NULL,<br>salary by 1kint(11) GENERATED ALWAYS AS (round((salary&#x2F; 10oo),0)) VIRTUAL, dept name varchar(1oO) COLLATE utf8_unicode ci DEFAULT NUL<br>PRIMARY KEY(emp no,from date）, KEYtest salaries（’to date）,<br>KEYidx salary by 1k(salary by 1k’）,<br>CONSTRAINT salaries ibfk 1FOREIGN KEY(emp no) REFERENCEsemployees(emp no)<br>ON DELETE CASCADE<br>-&gt;) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci; Query ok,0 rows affected (o.o5 sec)<br>root@localhost:mysql 3307.sock [employees]&gt;select count(0) from salaries; 1count（o)1<br>1 rowin set(0.00 sec)（5）下线salaries表：<br>root@localhost:mysql 3307.sock [employees]&gt; alter table salaries discard tablespace; Query ok,0 rows affected (o.o0 sec)<br>（6）拷贝步骤二备份的ibd和cfg文件到数据库目录：<br>[mysq13308@loca1host employees]s cp &#x2F;home&#x2F;mysq13308&#x2F;backup&#x2F;salaries.cfg &#x2F;data2&#x2F;mysq13308&#x2F;data&#x2F; empToyees&#x2F;<br>[mysq13308@1oca1host employees]$cp&#x2F;home&#x2F;mysq13308&#x2F;backup&#x2F;salaries.ibd&#x2F;data2&#x2F;mysq13308&#x2F;data&#x2F; employees&#x2F;<br>（7）加载salaries表：<br>root@localhost:mysql 3307.sock [employees]&gt; alter table salaries import tablespace;<br>Query ok,0 rows affected (o.o0 sec)（8）查看表恢复后记录数：<br>root@localhost:mysql_3307.sock [employees]&gt;select count(0) from salaries;<br>1count(o)1 12843996<br>1 row in set (0.86 sec)<br>恢复后表记录数与备份前的记录数相同，证明表恢复成功了。 2.使用Xtrabackup做全量备份<br>Xtrabackup是Percona公司CTOVadim参与开发的一款基于InnoDB的在线热备工具，具有开源、免费、支持在线热备、备份恢复速度快、占用磁盘空间小等特点，并且支持不同情况下的多种备份形式。Xtrabackup的官方下载地址为<a target="_blank" rel="noopener" href="http://www.percona.com/redir/downloads/">http://www.percona.com/redir/downloads/</a> XtraBackup.</p>
<p>≦ 449 ≧<br>25.3物理备份和恢复 431<br>Xtrabackup包含两个主要的工具，即xtrabackup和innobackupex，两者区别如下：<br>Oxtrabackup只能备份InnoDB和XtraDB两种数据表，而不能备份MyISAM数据表； Oinnobackupex是一个封装了xtrabackup的Perl脚本，支持同时备份InnoDB和<br>MyISAM，但在对MyISAM备份时需要加一个全局的读锁。<br>下面以innobackupex为例，来介绍一下此工具备份、恢复、增量备份恢复的原理。（1）备份过程。<br>Innobackupex的备份过程如图25-1所示。<br>startxtrabackuplog copyibd;idata1<br>3<br>flushtableswithreadlock<br>4<br>copyfmMYDMYImiscfiles<br>innobackupex<br>Get binarylogposition<br>6 unlock tables<br>stopand copy xtrabackup_log<br>图25-1innobackupex备份过程<br>在图25-1中，备份开始时首先会开启一个后台检测进程，实时检测mysqlredo的变化，一旦发现redo中有新日志写人，立刻将日志记入后台日志文件xtrabackup_log中。之后复制 InnoDB的数据文件和系统表空间文件ibdatal，待复制结束后，执行flushtableswithreadlock 操作，复制.frm、.MYI、.MYD等文件（执行flushtableswithreadlock的目的是为了防止数据表发生DDL操作，并且在这一时刻获得BINLOG的位置），最后会发出unlocktables，把表设置为可读写状态，最终停止xtrabackup_log。<br>（2）全备恢复。<br>这一阶段会启动XtraBackup内嵌的InnoDB实例，回放xtrabackup日志xtrabackup_log，将提交的事务信息变更应用到InnoDB数据&#x2F;表空间，同时回滚未提交的事务（这一过程类似 InnoDB的实例恢复）。恢复过程原理如图25-2所示。<br>读数据到内存<br>innodbmini instance<br>innobackupex<br>Memory<br>调用xtrabackup<br>②应用日志 ibd+ibdata 1<br>xtrabackup_log<br>图25-2innobackupex恢复过程</p>
<p>≦ 450 ≧<br>432 第25章备份与恢复<br>（3）增量备份。<br>innobackupex增量备份过程中的“增量”处理，其实主要是相对InnoDB而言，对MyISAM 和其他存储引擎而言，它仍然是一个全拷贝。<br>“增量”备份的过程主要是通过拷贝InnoDB中有变更的“页”（这些变更的数据页指的是“页”的LSN大于xtrabackup_checkpoints 中给定的LSN）。增量备份是基于全备的，第一次增备的数据必须要基于上一次的全备，之后的每次增备都是基于上一次的增备，最终达到一致性的增备。<br>增量备份过程如图25-3所示，和全备过程很类似，区别仅在第?步。<br>0<br>start xtrabackup_log<br>②<br>copy pageschanged inididata1<br>③<br>flush tables with read lock<br>4<br>copyfmMYDMYImis fles<br>Get binary log position<br>unlock tables<br>①<br>stopandcopyxtrabackuplog<br>图25-3innobackupex增量备份过程<br>（4）增量备份恢复。<br>和全备份恢复类似，也需要两步，一是数据文件的恢复，如图25-4所示，这里的数据来源由3部分组成：全备份、增量备份和xtrabackuplog。二是对未提交事务的回滚，如图25-5 所示。<br>MySQL数据页<br>①应用改变的数据页<br>增量备份 ②应用日志全备份<br>xtrabackup_log<br>图25-4innobackupex增量备份恢复过程1</p>
<p>≦ 451 ≧<br>25.3物理备份和恢复 433<br>MySQL数据页<br>②回滚未提交的数据<br>undo space<br>①应用日志 全备份+增备<br>xtrabackup log<br>图25-5innobackupex增量备份恢复过程2<br>下面将通过示例向读者详细介绍innobacupex的使用方法。首先从<a target="_blank" rel="noopener" href="http://www.percona.com/">http://www.percona.com</a><br>下载和安装PerconaXtraBackup软件：[root@localhost <del>]#wget -c<br><a target="_blank" rel="noopener" href="https://www.percona.com/downloads/xtraBackup/Percona-xtraBackup-2.4.12/binary/redhat/6/x86">https://www.percona.com/downloads/xtraBackup/Percona-xtraBackup-2.4.12/binary/redhat/6/x86</a> 64&#x2F;percona-xtrabackup-24-2.4.12-1.e16.x86_64.rpm<br>[root@1oca1host</del>]#rpm -ivh percona-xtrabackup-24-2.4.12-1.e16.x86_64.rpm<br>warning:percona-xtrabackup-24-2.4.12-1.e16.x86_64.rpm:Header V4 DSA&#x2F;SHA1 Signature,key ID cd2efd2a:NOKEY<br>Preparing…### 1:percoxtrabackup2###########################################[o][root@localhost ~]# innobackupex -v<br>xtrabackup: recognized server arguments:–datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql innobackupex version 2.4.12 Linux （x86 64) （revision id: 170eb8c) 注意：确认本机操作系统版本，并下载对应的RPM包。<br>（1）全量备份。创建备份用户：<br>mysql&gt; CREATE USER‘backup‘@%IDENTIFIED BY123456′;<br>mySqT&gt; GRANT RELOAD,LOCK TABLES,REPLICATION CLIENT,CREATE TABLESPACE,SUPER,PROCESS ON TO‘backup‘@’%’;<br>规划好备份目录路径为mkdir-p&#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;。创建innobackupex的配置文件&#x2F;tmp&#x2F;my.cnf，如下所示：<br>[mysq1d]<br>datadir&#x3D;”&#x2F;data2&#x2F;mysq13307&#x2F;data”<br>innodb data home dir&#x3D;”&#x2F;data2&#x2F;mysq13307&#x2F;data”<br>innodb data file path &#x3D;”ibdatal:10m:autoextend” innodb_1og_group_home_dir&#x3D;”&#x2F;data2&#x2F;mysq13307&#x2F;data<br>innodb_log_files_in_group &#x3D;3 innodb log_file size &#x3D;1024M 创建测试表：<br>mysql&gt;create database if not exists test; mysql&gt;use test;<br>mysql&gt;create table test(id int auto_increment not null primary key,name varchar(2o));<br>mysql&gt;insert into test(name) values(‘testl’); mysql&gt;insert into test(name) values(‘test2’); mysql&gt;insert into test(name) values(‘test3’); mysql&gt;insert into test(name) values(‘test4’); 进行全量备份：<br>innobackupex–defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf –user&#x3D;backup –password&#x3D;123456–socket&#x3D;&#x2F;tmp&#x2F;mysql_3307.sock&#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;full–no-timestamp</p>
<p>≦ 452 ≧<br>434 第25章备份与恢复<br>恢复全量备份：<br>innobackupex–apply-log –use-memory&#x3D;5G&#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;ful1<br>恢复备份到MySQL的数据文件目录，这一过程要先关闭MySQL数据库，重命名原数据文件目录，再创建一个新的数据文件目录，将备份数据复制到新的数据文件目录下，赋权，启动MySQL数据库：<br>she1l&gt;mysqladmin-s &#x2F;tmp&#x2F;mysql 3307.sockshutdown<br>she11&gt;mv&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;data2&#x2F;mysq13307&#x2F;databak she11&gt;mkdir&#x2F;data2&#x2F;mysq13307&#x2F;data<br>she1l&gt;innobackupex –defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf–copy-back–rsync &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;full&#x2F; she11&gt;chown -Rmysq13307:mysq13307 &#x2F;data2&#x2F;mysg13307&#x2F;data<br>she11&gt;cd &#x2F;home&#x2F;mysq13307&#x2F;mysq1home.&#x2F;bin&#x2F;mysqld safe -user&#x3D;mysq13307&amp;<br>校验恢复后数据库的一致性，查看test数据表： mysql&gt;use test;<br>mysql&gt;select*from test; Iid 丨name<br>1ltestl Itest2 3|test3 1test4<br>4rows in set (0.00 sec)<br>可以看到test库下test数据表已经成功恢复。（2）增量备份。<br>在MySQL中进行增量备份时，首先要进行一次全量备份，第一次增量备份是基于全备的，之后的增量备份是基于上一次的增量备份。<br>创建基础备份base：<br>innobackupex–defauTts-file&#x3D;&#x2F;tmp&#x2F;my.cnf–user&#x3D;backup –password&#x3D;123456 –socket&#x3D;&#x2F;tmp&#x2F;mysq1 3307.sock &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base–no-timestamp<br>在test库下增加增量数据：<br>mysql&gt; insert into test(name) values(*test5’); Query oK, 1 row affected (o.00 sec)<br>mysql&gt; insert into test(name) values(‘test6’); Query ok,1 row affected (0.00 sec)<br>mysql&gt; insert into test(name) values(‘test7’); Query oK,1 row affected (0.02 sec)<br>mysql&gt; insert into test(name) values(‘test8’); Query oK,1 row affected (o.o0 sec)<br>mysql&gt; select * from test; lid | name<br>01<br>testl test2 test3 test4 test5 test6 test7 test8<br>8rows in set (0.00 sec)</p>
<p>≦ 453 ≧<br>25.3物理备份和恢复 435<br>创建增量备份incremental_one:<br>innobackupex –defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf –user&#x3D;backup –password&#x3D;123456 –socket&#x3D;&#x2F;tmp&#x2F;mysq1 3307 sock –incremental &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;incremental one –incremental-basedir&#x3D;&#x2F;data2&#x2F;backup&#x2F; hotbackup&#x2F;base –no-timestamp –parallel&#x3D;2<br>在test库下继续插人增量数据：<br>mysql&gt; insert into test（name) values(‘test9’); Query ok,1 row affected (0.00 sec)<br>mysql&gt; insert into test(name) values(‘test10’); Query ok,1 row affected (0.00 sec)<br>mysql&gt; select * from test; | id|name<br>test1 test2 test3 test4 test5 test6 test7 test8 test9<br>10 test10 10 rows in set (0.00 sec)<br>创建增量备份incremental_two：<br>innobackupex–defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf–user&#x3D;backup–password&#x3D;123456 –socket&#x3D;&#x2F;tmp&#x2F;mysq1_3307 sock –incremental &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;incremental_two –incremental-basedir&#x3D;&#x2F;data2&#x2F;backup&#x2F; hotbackup&#x2F;incremental one–no-timestamp –parallel&#x3D;2<br>（3）增量备份恢复。<br>增量备份的恢复大体分为3个步骤。恢复基础备份（全备）。<br>○恢复增量备份到基础备份（开始恢复的增量备份要添加–redo-only参数，到最后一次增量备份去掉–redo-only参数）。<br>对整体的基础备份进行恢复，回滚那些未提交的数据。<br>恢复基础备份（注意这里一定要加–redo-only参数，该参数的意思是只应用xtrabackup 日志中已经提交的事务数据，不回滚还未提交的数据）：<br>innobackupex –apply-log –redo-only –use-memory&#x3D;5G &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base<br>将增量备份incremental_one应用到基础备份base：<br>innobackupex –apply-log –redo-only –use-memory&#x3D;5G &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base –incremental-dir&#x3D;&#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;incremental one&#x2F;<br>将增量备份incremental_two应用到基础备份base（注意恢复最后一个增量备份时需要去掉–redo-only参数，回滚xtrabackup日志中那些还未提交的数据）：<br>innobackupex –apply-log–use-memory&#x3D;5G &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base –incremental-dir&#x3D;&#x2F; data2&#x2F;backup&#x2F;hotbackup&#x2F;incremental_two&#x2F;<br>把所有合在一起的基础备份整体进行一次apply操作，回滚未提交的数据：<br>innobackupex –apply-log –use-memory&#x3D;5G &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base A 把恢复完的备份复制到数据文件目录中，赋权，然后启动MySQL数据库：</p>
<p>≦ 454 ≧<br>436 第25章备份与恢复 mysq1admin-s&#x2F;tmp&#x2F;mysql_3307.sock shutdown<br>mv&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;data2&#x2F;mysq13307&#x2F;data_bak mkdir&#x2F;data2&#x2F;mysq13307&#x2F;data<br>innobackupex –defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf –copy-back –rsync &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;base&#x2F;<br>chown -R mysq13307:mysq13307 &#x2F;data2&#x2F;mysq13307&#x2F;data cd&#x2F;home&#x2F;mysq13307&#x2F;mysq1home<br>&#x2F;bin&#x2F;mysqld safe -user&#x3D;mysq13307 &amp;<br>查看最终数据： mysql&gt; use test;<br>mysql&gt; select * from test; idl name<br>testl |test2 test3 test4 test5 5<br>test6 test7 test8<br>8<br>9 test9 110| test10<br>10 ows in set (0.00 sec)（4）不完全恢复。<br>上文已经详细介绍了如何通过mysqlbinlog进行不完全恢复，mysqlbinlog的不完全恢复的方法同样适合于innobackup热备的不完全恢复。<br>例如，在2018年10月11日14:00的时候开发人员在测试环境上进行了一次误操作，drop 掉了一张业务表，这个时候找到DBA，由于库并不是很大，并且为测试库，并没有访问，这时可以进行基于位置和基于时间点的不完全恢复。<br>首先找到早上的备份：<br>cd &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;fu11&#x2F;20181011 1s-1<br>total 3244496<br>-rw-r-1root root 489 oct 11 13:09 backup-my.cnf drwxr-x 2 root root 4096 oct1 1113:12 emp1oyees-rw-r-1 root root 258850 oct 11 13:09 ib buffer_pool<br>-rw-r-1root root 1073741824 0ct 11 13:13 ib 1ogfile0-rw-r-1 root root 1073741824 0ct 11 13:13 ib logfile1-rw-r-1 root root 1073741824 0ct 1113:13 ib 1ogfile2<br>-rw-r-1root root 79691776 0ct 11 13:13 ibdata1-rw-r-1root root 12582912 0ct 11 13:13 ibtmp1 drwxr-x-4096oct 11 13:12 mysql drwxr-x 2root root 4096 oct 11 13:12 performance_schema<br>2root root<br>drwxr-x 2 root root 12288 0ct 11 13:12 sys drwxr-x-2 root root 40960ct 11 13:12 test-rw-r 1root root 110 oct 11 13:12 xtrabackup binlog info<br>1root root 22 0ct 11 13:13 xtrabackup binlog_pos_innodb<br>-rw-r<br>-rw-r-1 root root 121 oct 11 13:13 xtrabackup_checkpoints-rw-r-1root root 7910ct 11 13:12 xtrabackup info-rw-r-1root root 8388608 0ct 11 13:12 xtrabackup_logfile<br>–r– 1 root root<br>-rw-r-1 0ct 11 13:13 xtrabackup master key id 找到记录备份结束时刻的BINLOG的位置文件xtrabackup_binlog_info，查看备份结束时<br>刻BINLOG的名称和位置。 cat xtrabackup binlog_info<br>mysql-bin.000001516847<br>查看当前数据库的BINLOG文件和位置：</p>
<p>≦ 455 ≧<br>25.3物理备份和恢复 437<br>mysql&gt; show master logs;<br>1 Log_name | File size丨 1mysql-bin.000001 517340 1mysql-bin.000002 107<br>2 rows in set (0.00 sec)<br>从全备中恢复数据库，恢复全备，之后再从热备结束时刻BINLOG的位置开始，恢复到<br>误操作时刻14:00之前的BINLOG。 cd &#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;<br>mysq1binlog –start-position&#x3D;”516847”–stop-datetime&#x3D; 2018-10-11 13:59:59” mysql-bin.000001 mysql-bin.000002 1 mysql -u root -pmypwd<br>跳过故障点的误操作的时间点，应用之后的所有BINLOG文件。 cd &#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;<br>mysqlbinlog –start-datetime&#x3D;”2018-10-11 14:01:00mysql-bin.00001 mysql-bin.000002 1mysql -u root -pmypwd<br>到此为止，一次基于位置和时间点的不完全恢复完成。（5）克隆slave。<br>在日常生活中，我们做得比较多的操作是在线添加从库，比如线上有一主一从两个数据库，由于业务的需要一台从库的读取量无法满足现在的需求，这样就需要我们在线添加从库，出于安全考虑，我们通常需要在从库上进行在线克隆slave。<br>克隆slave时，常用参数–slave-info和–safe-slave-backup。<br>O–slave-info会将master的BinaryLog的文件名和偏移位置保存到xtrabackup_slave_info 文件中。<br>O–safe-slave-backup则会暂停slave的SQL线程，直到没有打开的临时表的时候开始备份。待备份结束后SQL线程会自动启动，这样操作的目的主要是确保一致性的复制状态。<br>以下示例将介绍在一主一从的情况下在线搭建新的从库，环境如下： Master:192.168.1.1&#x2F;&#x2F;主机名为master<br>slave:192.168.1.2&#x2F;&#x2F;主机名为slave News1ave:192.168.1.3&#x2F;&#x2F;主机名为news1ave<br>在上述示例中，主机名为newslave的主机即为新搭建的从库。在主机名为slave的主机上进行备份：<br>[root@slave<del>]# innobackupex –defaults-file&#x3D;&#x2F;tmp&#x2F;my.cnf –user&#x3D;backup –password&#x3D;123456–socket &#x3D;&#x2F;tmp&#x2F;mysql 3307.sock –slave-info –safe-slave-backup &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;cloneslave –no-timestamp –parallel&#x3D;2<br>查看目录下生成的文件：<br>[root@slave</del>]# 1s -1rt &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;cloneslave total 78276<br>-rw-r—-1 root root 79691776 0ct 11 15:14 ibdatal drwxr-x-2 root root 4096 0ct 11 15:14 mysql drwxr-x-2 root root 4096 0ct 11 15:14 test<br>drwxr-x-2 root root 4096 oct 11 15:14 performance schema drwxr-x-2 root root 4096oct 11 15:14 testdb drwxr-x–2root root 4096 0ct 11 15:14 employees drwxr-x-root root 122880ct 11 15:14 sys<br>1 root root 73 0ct 11 15:14 xtrabackup_slave_info<br>-rw-r 1 root root 70 0ct 11 15:14 xtrabackup binlog info-rw-r-1root root 2560 0ct 11 15:14 xtrabackup_logfile-rw-r-1root root 121 oct 11 15:14 xtrabackup_checkpoints<br>258850 0ct 11 15:14 ib buffer_pool<br>-rw-r 1 root root-rw-r-1 root root 489 0ct 11 15:14 backup-my.cnf<br>693 0ct 11 15:14 xtrabackup_info<br>-rw-r  1 root root</p>
<p>≦ 456 ≧<br>438 第25章备份与恢复<br>查看xtrabackup_slave_info文件的内容，这个内容即为搭建从库时刻的changematerto参数：<br>[root@slave<del>]#cat &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;clones1ave&#x2F;xtrabackup_slave_info CHANGE MASTER TO MASTER LOG FILE&#x3D;’mySql-bin.000004’, MASTER LOG POS&#x3D;553;<br>在主机名为slave的主机上进行还原：<br>[root@slave</del>]#innobackupex –apply-1og –redo-only–use-memory&#x3D;5G&#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F; cloneslave<br>将还原的文件复制到新的从库newslave上：<br>[root@slave<del>]#rsync -avprp -e ssh &#x2F;data2&#x2F;backup&#x2F;hotbackup&#x2F;cloneslave newslave:&#x2F;home&#x2F; mysq13307&#x2F;mysq1home&#x2F;data<br>在主机名为master的主库上添加对主机newslave的授权：<br>mysql&gt; GRANT REPLICATION SLAVE ON **TO repl‘@’sTave2 IDENTIFIED BY’123456’;<br>在主机newsalve上复制主机为slave的my.cnf文件，并且修改server-id参数，修改完毕后，启动新的从库newslave：<br>[root@newslave</del>]# scp slave:&#x2F;etc&#x2F;mysql&#x2F;my.cnf &#x2F;etc&#x2F;mysql&#x2F;my.cnf<br>skip-slave-start server-id&#x3D;3<br>log-slave-updates&#x3D;1<br>查找主机slave备份后生成的xtrabackup_slave_info文件，提取其中的master_log_file和 master_log_pos信息，然后在新的从库newslave上进行changemasterto操作。<br>在newslave 上:<br>mysql&gt; CHANGE MASTER TO<br>MASTER HOST&#x3D;’master MASTER USER&#x3D;’repl·<br>MASTER PASSWORD&#x3D;123456<br>MASTER LOG_FILE&#x3D;’mysq1-bin.000004’， MASTER LOG POS&#x3D;553;<br>启动从库，并且检查复制是否正常： mysql&gt; START SLAVE;<br>slave IO Running: Yes slave SQL Running: Yes<br>25.4表的导入和导出<br>在数据库的日常维护中，表的导人和导出是很频繁的一类操作。本节将对MySQL中的<br>这类操作进行详细的介绍，希望读者能够熟练掌握。 25.4.1导出<br>在某些情况下，为了一些特定的目的，经常需要将表里的数据导出为某些符号分割的纯数据文本，而不是SQL语句。这些目的可能有以下一些：<br>用来作为Excel显示；单纯为了节省备份空间；<br>O为了快速地加载数据，LOADDATA的加载速度比普通的SQL加载要快20倍以上。为了满足这些应用，可以使用以下两种办法来实现。</p>
<p>≦ 457 ≧<br>25.4表的导入和导出 439<br>1.方法1<br>使用SELECT..INTOOUTFILE…命令来导出数据，具体语法如下： mysqT&gt; SELECT * FROM tabTename INTO OUTFILE ‘target_file’[option]; 其中，option参数可以是以下选项：<br>FIELDSTERMINATEDBYstring（字段分隔符，默认为制表符\t’）：<br>FIELDS[oPTIONALLY】ENCLOSED BYchar（字段引用符，如果加OPTIONALLY选项则只用在char、Varchar和<br>text等字符型字段上。默认不使用引用符）；<br>FIELDSESCAPED BYchar（转义字符，默认为\）；<br>LINES STARTINGBYstring（每行前都加此字符串，默认为）：<br>TERMINATED BYstring（行结束符，默认为\n）：<br>LINES<br>其中，char表示此符号只能是单个字符，string表示可以是字符串。<br>例如，将dept_manager表中数据导出为数据文本，其中，字段分隔符为“”，字段引用符为“”（双引号），记录结束符为回车符，具体实现如下：<br>mysql&gt; select * from dept manager into outfile’&#x2F;tmp&#x2F;dept manager.txt’ fields terminated by , enclosed by<br>Query ok, 24 rows affected (0.00 sec) mysq1&gt;<br>mysql&gt; system more &#x2F;tmp&#x2F;dept manager.txt“110022”,”d001”,”1985-01-01”,”1991-10-01””110039”,”d001”,”1991-10-01”,”9999-01-01”“110085”,”d002”,”1985-01-01”,”1989-12-17””110114”,”d002”,”1989-12-17”,”9999-01-01””110183”,”d003”,”1985-01-01”,”1992-03-21””110228”,”d003”,”1992-03-21”,”9999-01-01””110303”,”d004”,”1985-01-01”,”1988-09-09””110344”,”d004”,”1988-09-09”,”1992-08-02””110386”,”d004”,”1992-08-02”,”1996-08-30”<br>发现第一列是数值型，如果不希望字段两边用引号引起，则语句改为：<br>mysql&gt; select * from dept manager into outfile&#x2F;tmp&#x2F;dept manager.txt’ fields terminated by optionally enclosed by‘<br>Query ok,24 rows affected (0.00 sec) mysql&gt; system more &#x2F;tmp&#x2F;dept manager.txt 110022,”d001”,”1985-01-01”,”1991-10-01” 110039,”d001”,”1991-10-01”,”9999-01-01” 110085,”d002”,”1985-01-01”,”1989-12-17 110114,”d002”,”1989-12-17”,”9999-01-01” 110183,”d003”,”1985-01-01”,”1992-03-21” 110228,”d003”,”1992-03-21”,”9999-01-01” 110303,”d004”,”1985-01-01”,”1988-09-09”<br>结果如我们所愿，第一列的双引号被去掉。<br>下面来测试一下转义字符。转义字符，顾名思义，就是由于含义模糊而需要特殊进行转换的字符，在不同的情况下，需要转义的字符是不一样的。MySQL导出的数据中需要转义的字符主要包括以下3类：<br>转义字符本身；字段分隔符；记录分隔符。<br>在下面的例子中，对表dept_manager中的dept_no更新为含以上3类字符的字符串，然后导出：</p>
<p>≦ 458 ≧<br>440 第25章备份与恢复<br>mysql&gt; update dept manager set dept no&#x3D;’\“##!do01′ where dept no&#x3D;’do01’; Query ok,2 rows affected (o.o0 sec)<br>Rows matched:2changed: 2warnings:0 mysql&gt; system rm &#x2F;tmp&#x2F;dept_manager.txt<br>mysql&gt; select * from dept manager into outfile’&#x2F;tmp&#x2F;dept manager.txt’ fields terminated by”,”optionally enclosed by “;<br>Query ok,24 rows affected (0.00 sec) mysql&gt; system more &#x2F;tmp&#x2F;dept_manager.txt<br>110022,”\1&quot;##!d001”,”1985-01-01”,”1991-10-01” 110039,”\&quot;##!d001”,”1991-10-01”,”9999-01-01”<br>110085,”d002”,”1985-01-01”,“1989-12-17” 110114,”d002”,”1989-12-17”,”9999-01-01 110183,”d003”.”1985-01-01”,”1992-03-21” 110228,”d003”,”1992-03-21”,“9999-01-01”<br>以上例子中，dept_no中含有转义字符本身“”和域引l用符“””，因此，在输出的数据中我们发现这两种字符前面都加上了转义字符“\”，“#”变成了“\#”。继续进行测试，将dept_no 为do02的dept_no更新为含有字段分隔符“”的字符串：<br>mysql&gt; update dept manager set dept no&#x3D;’\“#,#,!d002’where dept no&#x3D;’d002’; Query ok, 2 rows affected (o.o0 sec)<br>Rows matched:2Changed:2warnings:0 mysql&gt; system rm &#x2F;tmp&#x2F;deptmanager.txt<br>mysql&gt; select * from dept manager into outfile’&#x2F;tmp&#x2F;dept manager.txt’fields terminated by”， optionally enclosed by”<br>Query 0k, 24 rows affected (0.01 sec) mysql&gt; system more &#x2F;tmp&#x2F;dept_manager.txt 110022,”d001”,”1985-01-01”,”1991-10-01” 110039,”d001”,”1991-10-01”,”9999-01-01”<br>110085,”\“#,#，!d002”,”1985-01-01””1989-12-17” 110114,”\&quot;#，#，!d002”，”1989-12-17”,”9999-01-01”<br>110183,”d003”,”1985-01-01”,”1992-03-21” 110228,”d003”,”1992-03-21”,”9999-01-01” 110303,”d004”,”1985-01-01”,”1988-09-09”<br>注意：在MySQL客户端连接成功后，如果要执行操作系统的命令，那么可以用“system+操作系<br>统命令”来进行执行。<br>这个时候，发现数据中的字符“，”并没有被转义，这是为什么呢？其实仔细想想就明白了，因为每个字符串的两边带有引用符“”（双引号），所以当MySQL看到数据中的“”时，由于它处在前半个引用分隔符之后，后半个引用分隔符之前，所以并没有将它作为字段分隔符，而只是作为普通的一个数据字符来对待，因而不需要转义。继续做测试，将输出文件的字段引用符去掉，这个时候，我们的预期是数据中的“”将成为转义字符而需要加上“”： mysql&gt; system rm &#x2F;tmp&#x2F;dept manager.txt<br>mysql&gt; select * from dept managerl into outfile &#x2F;tmp&#x2F;dept manager.txt fields terminated by<br>Query ok,24rows affected (0.00 sec) mysql&gt; system more &#x2F;tmp&#x2F;dept manager.txt<br>110022,d001,1985-01-01,1991-10-01 110039,d001,1991-10-01,9999-01-01<br>110085,&quot;#,#,!d002,1985-01-01,1989-12-17 110114,&quot;#,#,!d002,1989-12-17,9999-01-01<br>110183,d003,1985-01-01,1992-03-21 110228,d003,1992-03-21,9999-01-01 110303,d004,1985-01-01,1988-09-09 110344,d004,1988-09-09,1992-08-02</p>
<p>≦ 459 ≧<br>25.4表的导入和导出 441<br>果然，现在的“”前面加上了转义字符“”。而刚才的引用符“”却没有被转义，因为它已经没有什么歧义，不需要被转义。<br>通过上面的测试，可以得出以下结论：<br>○当导出命令中包含字段引用符时，数据中含有转义字符本身和字段引用符的字符需要被转义；<br>当导出命令中不包含字段引用符时，数据中含有转义字符本身和字段分隔符的字符需要被转义。<br>注意：SELECT..INTOOUTFILE.产生的输出文件如果在目标目录下有重名文件，将不会创建成功，<br>源文件不能被自动覆盖。<br>2.方法2<br>使用mysqldump导出数据为文本的具体语法如下：<br>mysgldumuusernameTtargetdirdbnametablenameoption]<br>其中，option参数可以是以下选项：<br>–fields-terminated-by&#x3D;name（字段分隔符）；–fields-enclosed-by&#x3D;name（字段引用符）;；<br>O–fields-optionally-enclosed-by&#x3D;name（字段引用符，只用在char、varchar和text等字符型字段上);<br>–fields-escaped-by&#x3D;name（转义字符）; O–lines-terminated-by&#x3D;name（记录结束符）。<br>下面的例子中，采用mysqldump生成了指定分隔符分隔的文本：<br>[mysq13307@localhost tmp]# mysq1dump -uroot -T&#x2F;tmp employees dept manager –fields-terminated<br>-by–fields-optionally-enclosed-by[mysq13307@localhost tmp]# more &#x2F;tmp&#x2F;dept manager.txt<br>110022,”\“##!d001”,”1985-01-01”,”1991-10-01” 110039,”\&quot;##!d001”,”1991-10-01”,”9999-01-01” 110085，”\\“#，#,!d002”,”1985-01-01”,“1989-12-17” 110114,”\“#，#，!d002”,”1989-12-17”,”9999-01-01”<br>110183,”d003”,”1985-01-01”,”1992-03-21” 110228,”d003”,”1992-03-21”,”9999-01-01” 110303,”d004”,”1985-01-01”,”1988-09-09” 110344,”d004”,”1988-09-09”,”1992-08-02”<br>除了生成数据文件dept_manager.txt之外，还生成一个dept_manager.sql文件，里面记录了emp表的创建脚本，记录的内容如下：<br>[mysq13307@localhost tmp]# more emp.sq1<br>MySQL dump 10.13Distrib 5.7.22,for 1inux-g1ibc2.12（x8664)<br>Host: localhost Database: employees<br>Server version 5.7.22-1og<br>&#x2F;<em>!40101 SET @OLD_CHARACTER_SET CLIENT&#x3D;@@CHARACTER SET_CLIENT <em>&#x2F;;&#x2F;</em>!40101 SET @OLD CHARACTER_SET_RESULTS&#x3D;@@CHARACTER SET_RESULTS</em>&#x2F;;&#x2F;<em>!40101 SET @OLD_COLLATION_CONNECTION&#x3D;@@COLLATION_CONNECTION <em>&#x2F;;&#x2F;</em>!40101 SET NAMES utf8 <em>&#x2F;;<br>&#x2F;</em>!40103 SET @OLD_TIME ZONE&#x3D;@@TIME ZONE</em>&#x2F;;&#x2F;<em>140103 SET TIME ZONE&#x3D;</em>+00:00′*&#x2F;;<br>&#x2F;<em>!40101 SET @OLD_SQL MODE&#x3D;@@SQL_MODE,SQL MODE&#x3D;’</em>&#x2F;;&#x2F;*!40111 SET @OLD_SQL_NOTES&#x3D;@@SQL_NOTES, SQL NOTES&#x3D;0 *&#x2F;;</p>
<p>≦ 460 ≧<br>442 第25章备份与恢复<br>-Table structure for table dept manager DROP TABLE IF EXISTSdept manager；<br>&#x2F;*140101 SET @saved cs_client &#x3D;@@character set client *&#x2F;;&#x2F;*140101 sET character set client &#x3D; utf8 <em>&#x2F;;<br>CREATE TABLEdept managerl（ emp_no int(11) NOT NULL,<br>dept no char(14) cOLLATE utf8 unicode ci NOT NULL,<br>from date date NOT NULL, to datedate NOT NULL,<br>PRIMARY KEY (emp no,dept no’）, KEYdept no(dept no)<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci;&#x2F;</em>!40101 sET character _set client&#x3D; @saved cs_client *&#x2F;;<br>&#x2F;<em>140103 SET TIME_ZONE&#x3D;@OLD_TIME ZONE</em>&#x2F;;&#x2F;<em>140101 SET SQL MODE&#x3D;@OLD SQL MODE</em>&#x2F;;<br>&#x2F;*140101 SET CHARACTER SET_CLIENT&#x3D;@OLD_CHARACTER SET CLIENT <em>&#x2F;;&#x2F;</em>!40101 SET CHARACTER SET RESULTS&#x3D;@OLD_CHARACTER SET RESULTS *&#x2F;;&#x2F;*140101 SET COLLATION CONNECTION&#x3D;@OLD COLLATION CONNECTION <em>&#x2F;;<br>&#x2F;</em>!40111 SET SQL NOTES&#x3D;@OLD SQL NOTES *&#x2F;; Dump completed on 2018-10-11 17:20:28<br>可以发现，除多了一个表的创建脚本文件外，mysqldump和SELEC…INTOOUTFILE. 的选项和语法非常类似。其实，mysqldump实际调用的就是后者提供的接口，并在其上面添<br>加了一些新的功能而已。 25.4.2导入<br>本节只讨论用SELECT..INTOOUTFILE或者mysqldump导出的纯数据文本的导人方法。和导出类似，导入也有两种不同的方法，分别是LOADDATAINFILE..和mysqlimport，它们的本质是一样的，区别只是在于一个在MySQL内部执行，另一个在MySQL外部执行。<br>1.方法1<br>使用“LOADDATAINFILE..”命令，具体语法如下：<br>mysql &gt;LOAD DATA[LoCAL] INFILE fiTename’ INTO TABLE tablename [option]<br>option可以是以下选项：<br>o FIELDSTERMINATEDBY’string’（字段分隔符，默认为制表符t）； FIELDS[OPTIONALLY]ENCLOSEDBY’char（字段引用符，如果加OPTIONALLY<br>选项则只用在char、Varchar和text等字符型字段上。默认不使用引l用符）； FIELDSESCAPEDBY’char’（转义字符，默认为）；<br>LINESSTARTINGBY’string’（每行前都加此字符串，默认为”）; O<br>O LINESTERMINATEDBY’string’（行结束符，默认为n’）;<br>IGNOREnumberLINES（忽略输入文件中的前n行数据）；<br>（col_name_or_user_var…）（按照列出的字段顺序和字段数量加载数据）;；<br>SETcol_name&#x3D;expr…（将列做一定的数值转换后再加载）。其中，char表示此符号只能是单个字符，string表示可以是字符串。<br>FILELD、LINES和前面SELECT…INTOOUTFILE…的含义完全相同，不同的是多了儿个不同的选项，下面的例子将文件“&#x2F;tmp&#x2F;emp.txt”中的数据加载到表emp中：</p>
<p>≦ 461 ≧<br>25.4表的导入和导出 443<br>mysql&gt; load data infile&#x2F;tmp&#x2F;dept manager.txt’into table dept manager fields terminated by,’enclosed by “<br>Query oK,24 rows affected (0.03 sec)<br>Records:24Deleted:0skipped:0warnings:0 mysql&gt; select *from dept manager;<br>Iemp_no dept noI from date 1to_date<br>61<br>110022 d001 1985-01-01 1991-10-01 110039 d001 1991-10-01 9999-01-01 110085 d002 1985-01-01 1989-12-17 110114 d002 1989-12-17 9999-01-01 110183 d003 1985-01-01 1992-03-21 111692 d009 1985-01-011 1988-10-17<br>111784 d009 1988-10-17<br>111877 d009 1992-09-08 1992-09-08<br>1996-01-03<br>111939 d009 1996-01-03 9999-01-01 24rows in set (0.00 sec)<br>如果不希望加载文件中的前两行，可以进行如下操作：<br>mysql&gt; load data infile&#x2F;tmp&#x2F;dept_manager.txt’ into table dept manager fields terminated by Query oK,22 rows affected (0.04 sec)<br>Records:22Deleted:0 skipped:0warnings:0 mysql&gt; select * from dept_manager;<br>1 emp no | dept no| from date| to date<br>110085 d002 1985-01-0111989-12-17 110114 1d002 1989-12-17 19999-01-01 110183 d003 1985-01-0111992-03-21<br>110228 d003 1992-03-21 9999-01-01 110303 d004 1985-01-01 1988-09-09 110344 d004 1988-09-09 1992-08-021<br>111400 d008 1985-01-01 1991-04-08 111534 d008 1991-04-08 9999-01-01 111692 do09 1985-01-01 1988-10-17<br>111784 d009 1988-10-17 1992-09-08 111877 d009 1992-09-08 1996-01-03 1111939 d009 1996-01-03 9999-01-01<br>22 rows in set (0.00 sec) 此时数据只加载了22行。<br>如果发现文件中的列顺序和表中的列顺序不符，或者只想加载部分列，可以在命令行中加上列的顺序，如下所示：<br>mysql&gt; load data infile &#x2F;tmp&#x2F;dept manager.txt into table dept manager fields terminated by<br>,enclosed by ‘ignore 2 lines （emp_no,dept no,to date,from date); Query ok,22rows affected (0.05 sec)<br>Records:22Deleted:0skipped:0warnings:0 mysql&gt; select * from dept manager;<br>Iemp_no| deptnoI from date 1to_date<br>110022 d001 1991-10-01 1985-01-011 110039 |d001 9999-01-01 1991-10-01<br>110085 d002 1989-12-17 1985-01-01 110114 d002 9999-01-01 1989-12-17<br>110183 d003 1992-03-21 1985-01-01 1110228 1d003 9999-01-01 11992-03-21</p>
<p>≦ 462 ≧<br>444 第25章备份与恢复<br>110386 Id004 1996-08-3011992-08-02 111692 d009 1988-10-17 1985-01-01 111784 d009 1992-09-08 1988-10-17 111877 d009 1996-01-03 1992-09-08 111939 d009 9999-01-01 1996-01-031<br>22 rows in set (0.00 sec)<br>可以发现，文件中第三列的内容放到了to_date里面，第四列的内容放到了from_date 里面。<br>如果只想加载第一列，字段的列表里面可以只加第一列的名称：<br>mysql&gt; load data infile &#x2F;tmp&#x2F;dept manager.txt into table dept manager fields terminated by enclosed by ignore 2 lines (emp no）;<br>Query ok,22 rows affected,2 warnings (0.04 sec) Records:22Deleted:0skipped:0Warnings:2<br>mysql&gt; select * from dept manager;<br>Iemp_nol dept_noIfrom_date|to_date|<br>110085 NULL NULL NULL 110114 NULL NULL NULL<br>1110183 NULL NULL NULL 1110228 NULL NULL NULL<br>|111784 NULL NULL 111877 NULL NULL NULL<br>111939 NULL NULL NULL 22rows in set (0.00 sec)<br>如果希望将id列的内容加上10后再加载到表中，可以如下操作：<br>mysql&gt; load data infile&#x2F;tmp&#x2F;dept manager.txt* into table dept manager fields terminated by<br>,enclosed by  set emp no &#x3D; emp no +10; Query ok,24rows affected (0.03 sec)<br>Records:24Deleted:0skipped:0warnings:0<br>mysql&gt; select t<em>from dept manager;<br>emp_no1 dept_no from_date to_date<br>110095 d002 1989-12-17 1985-01-01 1110124 d002 19999-01-01 1989-12-171<br>110193 d003 11992-03-21 1985-01-01 110238 d003 19999-01-01 1992-03-211<br>111794 d009 11992-09-08 1988-10-171 111887 d009 1996-01-03 1992-09-081 111949 d009 9999-01-01 1996-01-031<br>24rows in set (0.00 sec) 2.方法2<br>用mysqlimport来实现，具体命令如下。<br>she77 &gt;mysq7import -u root -p</em>**[–LocAL] dbname order_tab.txt [option]<br>其中option参数可以是以下选项：<br>O–fields-terminated-by-name（字段分隔符）； O–fields-enclosed-by&#x3D;name（字段引|用符）;；<br>O–fields-optionally-enclosed-by&#x3D;name（字段引用符，只用在char、varchar和text等字符型字段上)；</p>
<p>≦ 463 ≧<br>25.5小结 445<br>–fields-escaped-by&#x3D;name（转义字符）;<br>–lines-terminated-by&#x3D;name（记录结束符）； O–ignore-lines&#x3D;number（忽略前几行）。<br>这与mysqldump的选项几乎完全相同，这里不再详细介绍，简单来看一个例子：<br>[mysq13307@localhost tmp]# mysqlimport -uroot employees &#x2F;tmp&#x2F;dept_manager.txt-fields-terminated-by&#x3D;’,–fields-enclosed-by&#x3D;”<br>employees.dept manager:Records:24Deleted:0 skipped:0 warnings:0[mysq13307@loca1host tmp]#<br>[mysq13307@localhost tmp]# mysql -uroot employees -e ‘select count(10) from dept manager 1count（10)i<br>241<br>[mysq13307@localhost tmp]# mysql -uroot emp1oyees -e’select * from dept manager I emp_no I dept no from date to_date<br>110022 d001 1985-01-01 1991-10-01 110039 d001 1991-10-01 9999-01-01 110085 d002 110114 d002 1985-01-01 1989-12-171<br>1989-12-17 9999-01-01<br>110183|d003 1985-01-01 1992-03-21 1<br>111877 d009 1992-09-08 1996-01-03 1119391 d009 1996-01-03 9999-01-01<br>注意：如果导入和导出是跨平台操作的（Windows和Linux），那么要注意设置参数line-terminated-<br>by，Windows上设置为line-terminated-by&#x3D;′\r\n’，Linux上设置为line-terminated-by&#x3D;\n’。<br>25.5小结<br>本章主要介绍了MySQL的备份和恢复方法。和其他数据库类似，MySQL也分为逻辑备份和物理备份。两种备份方法各有优缺点，逻辑备份保存的是SQL文本，可以在各种条件下恢复，但是对于大数据量的系统，备份和恢复的时间都比较长；物理备份恰恰相反，由于是文件的物理cp，备份和恢复时间都比较短，但是备份的文件在不同的平台上不一定兼容。<br>其中，mysqldump是常用的逻辑备份工具，适合各种存储引引擎，希望读者重点掌握。物理备份对于不同的存储引擎，备份方式有所不同。对于MyISAM引擎，读者了解一下手工热备份的方法；对于InnoDB的热备份，读者主要掌握innobackupex的使用方法，此工具属于开源工具，效率高且不收费的，因此普及率很高，而MySQL官方目前没有提供免费的InnoDB 热备份工具。<br>对于数据表的导人和导出方法，应重点掌握SELECT..INTOOUTFILE和LOADDATA INFILE的使用，mysqldump和mysqlimport实际上是调用了前两种方法接口，只不过是在 MySQL外部执行罢了。数据的导人和导出在数据库的管理与维护中使用非常频繁，而LOAD DATAINFILE是加载数据最快的方法，因此读者应重点掌握。</p>
<p>≦ 464 ≧<br>第26章 MySQL权限与安全<br>MySQL的权限系统主要用来对连接到数据库的用户进行权限的验证，以此来判断此用户是否属于合法的用户。如果是合法用户，则赋予相应的数据库权限。<br>数据库的权限和数据库的安全是息息相关的，不当的权限设置可能会导致各种各样的安全隐患，操作系统的某些设置也会对MySQL的安全造成影响。<br>本章对MySQL的权限系统以及相应的安全问题进行了一些探讨，希望能够帮助读者对这些方面有深入的认识。<br>26.1MySQL权限管理<br>本节从MySQL权限系统的工作原理和账号管理两个方面来进行介绍。读完本节后，希<br>望读者能够在了解权限系统的工作原理基础上，熟练掌握账号的管理和使用方法。 26.1.1权限系统的工作原理<br>MySQL权限系统通过下面两个阶段进行认证：<br>对连接的用户进行身份认证，合法的用户通过认证，不合法的用户拒绝连接；<br>对通过认证的合法用户赋予相应的权限，用户可以在这些权限范围内对数据库做相应的操作。<br>对于身份的认证，MySQL是通过IP地址和用户名联合进行确认的，例如MySQL用户 root@localhost表示用户root只能从本地（localhost）进行连接才可以通过认证，此用户从其他任何主机对数据库进行的连接都将被拒绝。也就是说，同样的一个用户名，如果来自不同的IP地址，则MySQL将其视为不同的用户。<br>MySQL的权限表在数据库启动的时候就载入内存，当用户通过身份认证后，就在内存中<br>进行相应权限的存取，这样，此用户就可以在数据库中做权限范围内的各种操作了。 26.1.2权限表的存取<br>在权限存取的两个过程中，系统会用到mysql数据库（安装MySQL时被创建，数据库名称叫作mysql）中user和db这两个最重要的权限表。在MySQL5.7.22版本，它们的定义如表26-1所示。</p>
<p>≦ 465 ≧<br>26.1MySQL权限管理 447<br>表26-1 mysql数据库中的两个权限表定义<br>表名 user db<br>host host<br>用户列 user user<br>authentication_string<br>db<br>select _priv select_priv insert_priv insert_priv update_priv update_priv delete_priv delete_priv create_priv create_priv drop_priv drop_priv<br>reload_priv shutdown_priv process_priv file_priv<br>grant_priv grant _priv references_priv<br>index_priv index_priv<br>权限列 alter_priv alter_priv<br>show_db_priv super_priv<br>create_tmp_table_priv create_tmp_table_priv lock_tables_priv lock tables_priv execute_priv execute_priv<br>repl_slave_priv repl_client _priv<br>create_view_priv create_view_priv show_view_priv show_view_priv<br>create_routine_priv create_routine_priv alter _routine_priv alter_routine_priv create_user_priv<br>event _priv event_priv trigger_priv trigger_priv create_tablespace_priv<br>权限列 create_role_priv<br>drop_role_priv<br>ss_type ss_cipher x509_issuer x509_subject<br>安全列 password_expired<br>password_last_changed password_lifetime account_locked plugin</p>
<p>≦ 466 ≧<br>448 第26章MySQL权限与安全<br>续表<br>max_questions<br>资源控制列 max_updates<br>max <em>connections<br>max_user_connections<br>在这两个表中，最重要的表是user表，其次是db表。user中的列主要分为4个部分：用户列、权限列、安全列和资源控制列。<br>通常用得最多的是用户列和权限列，其中权限列又分为普通权限和管理权限。普通权限主要用于数据库的操作，比如select_priv、create_priv等；而管理权限主要用来对数据库进行管理的操作，比如process_priv、super_priv等。<br>当用户进行连接时，权限表的存取过程有以下两个阶段。<br>先从user表中的host、user和uthentication_string这3个字段中判断连接的IP、用户名和密码是否存在于表中，如果存在，则通过身份验证，否则拒绝连接。<br>如果通过身份验证，则按照以下权限表的顺序得到数据库权限：user→db→tables_priv→ columns_priv.<br>在这几个权限表中，权限范围依次递减，全局权限覆盖局部权限。上面的第一阶段好理解，下面以一个例子来详细解释一下第二阶段。<br>（1）创建用户emp_sel@localhost，并赋予所有数据库上的所有表的select权限。<br>mysql&gt;create user emp sel@localhost identified by ‘emp_sel123’; Query ok,0 rows affected (0.22 sec)<br>mysq1&gt;grant select on <em>.</em> to emp sel@localhost; Query ok, 0 rows affected, 1 warning (0.00 sec)<br>mysql&gt;select * from user where user&#x3D;’emp</em> sel’ and host&#x3D;’localhost’\G<br>Host:localhost User: emp sel<br>select priv:Y Insert priv:N update priv:N Delete priv: N Create priv:N Drop priv:N<br>authentication string:<em>FBEFDCEDE1FA35EDEA26B60FBFCD646A24D47DF6（2）再来看db表：<br>mysql&gt;select * from db where user&#x3D;’emp sel′ and host&#x3D;localhost’\G Empty set(0.02 sec)<br>可以发现，user表的select_priv列是Y，而db表中并没有记录，也就是说，对所有数据库都具有相同权限的用户记录并不需要记人db表，而仅仅需要将user表中的select_priv改为 Y即可。换句话说，user表中的每个权限都代表了对所有数据库都有的权限。<br>（3）将emp_sel@localhost上的权限改为只对employees数据库上所有表的select权限。<br>mysql&gt;revoke select on <em>.</em> from emp_sel@localhost; Query ok, 0 rows affected, 1 warning (0.o0 sec)<br>mysql&gt;grant select on employees.</em> to emp sel@localhost; Query ok,0 rows affected,1 warning (0.o2 sec)<br>mysql&gt;select * from user where user&#x3D;’emp sel’ and host&#x3D;’localhost’\G</p>
<p>≦ 467 ≧<br>26.1MySQL权限管理 449<br>Host:localhost User: emp sel<br>select priv:N Insert priv:N Update_priv:N Delete priv:N Create priv:N Drop priv:<br>authentication string:*FBEFDCEDE1FA35EDEA26B60FBFCD646A24D47DF6 mysql&gt;select * from db where user&#x3D;’emp sel’ and host&#x3D;’localhost’\G<br>Host:localhost Db:employees User: emp sel<br>select priv:Y Insert priv:N Update priv: N Delete priv:N Create priv:N Drop priv:N<br>1 row in set(0.00 sec)<br>这个时候发现，user表中的select_priv变为N，而db表中则增加了db为employees的一条记录。也就是说，当只授予部分数据库某些权限时，user表中的相应权限列保持N，而将具体的数据库权限写人db表。table和column的权限机制和db类似，这里就不再赘述。<br>从上面的例子可以看出，当用户通过权限认证，进行权限分配时，将按照user→db→ tables_priv→columns_priv的顺序进行权限分配，即先检查全局权限表user，如果user中对应权限为Y，则此用户对所有数据库的权限都为Y，将不再检查db、tables_priv和 columns_priv；如果为N，则到db表中检查此用户对应的具体数据库，并得到db中为Y的权限；如果db中相应权限为N，则检查tables_priv中此数据库对应的具体表，取得表中为 Y的权限；如果tables_priv中相应权限为N，则检查columns_priv中此表对应的具体列，取得列中为Y的权限。<br>26.1.3账号管理<br>理解了权限系统的工作原理后，本节开始介绍账号的管理。账号管理也是DBA日常工作中很重要的工作之一，主要包括账号的创建、权限更改和账号的删除。用户连接数据库的第一步都从账号创建开始。<br>1.创建账号<br>有两种方法可以用来创建账号：使用CREATEUSER配合GRANT的语法创建或者直接操作授权表，但更推荐使用第一种方法，因为操作简单，出错概率更少。下面详细讲述这两种方式的使用方法。<br>（1）CREATEUSER的常用语法如下： CREATE USER [IF NOT EXISTS]<br>user [auth_option] [, user [auth_option]] .<br>[REQUIRE [NONE&#x2F; tIs_option [[AND] tisoption]..][WITh resource_option resource_option] …]<br>[password option &#x2F; 1ockoption] …（2）GRANT的常用语法如下：</p>
<p>≦ 468 ≧<br>450 第26章MySQL权限与安全<br>GRANT<br>priv_type [（column_list)]<br>[,priv_type [（column_list)]] . ON[object type] priv_leve]<br>TO user [auth_option] [,user [auth_option]] .<br>[REQUIRE NONE &#x2F; tis_option [[AND] tisoption]..H] [WITH {GRANT OPTION I resource<br>option….<br>object_type:<br>TABLE<br>&#x2F;FUNCTION&#x2F;PROCEDURE<br>注意：在8.0版本以前，可以用grant命令自动创建用户；在8.0版本以后，必须先createuser，再<br>grant权限，否则会报错：ERROR1133（42000):Can’tfindanymatchingrowintheuser table。<br>下面来看几个例子。<br>例1：创建用户emp，权限为可以在所有数据库上执行所有权限，只能从本地进行连接。<br>mysql&gt; create user emp@localhost; Query oK,O rows affected (o.o0 sec)<br>mysql&gt;grant all privileges on **to emp@localhost; Query oK,0 rows affected,1 warning (0.o0 sec)<br>mysql&gt;select * from user where user&#x3D;’emp′ and host&#x3D;’localhost’\G;<br>Host: localhost user:emp<br>Select priv:Y Insert_priv:Y Update priv:Y Delete priv:Y Create_priv:Y Drop priv:Y Reload priv:Y shutdown priv:Y Process priv:Y File priv:Y Grant_priv:N<br>References priv:Y<br>Index priv:Y Alter_priv:Y Show db priv:Y Super priv:Y<br>Create_tmp_table priv:Y<br>Lock tables priv:Y<br>Execute priv:Y Repl slave priv:Y Repl client priv:Y Create view priv:Y Show view priv:Y<br>Create_routine priv:Y Alter_routine priv:Y Create user priv:Y<br>可以发现，除了Grant_priv权限外，所有权限在user表里面都是Y。例2：在例1基础上，增加对emp的grant权限。<br>mysql&gt;grant all privileges on <em>.</em> to emp@localhost with grant option; Query Ok,0 rows affected (o.o0 sec)<br>mysql&gt;select * from user where user&#x3D;’emp’ and host&#x3D;’localhost’\G<br>Host:localhost user: emp<br>Select priv:Y</p>
<p>≦ 469 ≧<br>26.1MySQL权限管理 451<br>Insert priv:Y Update priv:Y Delete priv:Y Create priv:Y Drop priv:Y Reload priv:Y shutdown priv:Y Process priv:Y File priv:Y Grant_priv:Y<br>例3：在例2基础上，设置密码为“emp123”。<br>mysql&gt; alter user emp@localhost identified by’emp123’;<br>Query ok,0 rows affected (o.o0 sec) 从user表中查看修改的密码：<br>mysql&gt; select * from user where user&#x3D;’emp’and host&#x3D;localhost’\G mysql&gt;select * from user where user&#x3D;’emp’ and host&#x3D;’localhost’\G<br>Host: localhost user: emp<br>select priv:Y Insert priv:Y Update priv:Y Delete priv:Y Create priv:Y<br>authentication_string:<em>31D409663B40D0EE6FCA4EE0c19F8C9576352E13<br>可以发现，密码变成了一堆加密后的字符串。在MySQL5.7里面，密码的算法是生成一个以“</em>”开始的41位的字符串，安全性很高。<br>例4：创建新用户emp，可以从任何IP进行连接，权限为对employees数据库里的所有表进行SELECT、UPDATE、INSERT和DELETE操作，初始密码为“emp123”。<br>mysql&gt;create user emp@’%’ identified by’emp123’; Query ok,0 rows affected (0.10 sec)<br>mysql&gt;grant select,insert,update,delete on employees.<em>to emp@’%’; Query ok,0 rows affected (0.11 sec)<br>mysql&gt;select * from user where user&#x3D;’emp’ and host&#x3D;’%’\G<br>Host:% User:emp<br>Select priv:N Insert priv:N update priv:N Delete priv:N<br>authentication_string:<em>31D409663B40D0EE6FCA4EE0c19F8c9576352E13 mysql&gt;select * from db where user&#x3D;’emp</em> and host&#x3D;</em>%*\G<br>Host:%<br>Db:employees user: emp<br>Select priv:Y Insert priv:Y Update priv:Y Delete priv:Y<br>如上文所述，user表中的权限都是N，db表中增加的记录权限则都是Y。一般地，我们只授予用户适当的权限，而一般不会授予过多的权限，本例中的权限适合于大多数应用账号。<br>本例中的IP限制为所有IP都可以连接，因此设置为“%”，mysql数据库中是通过user</p>
<p>≦ 470 ≧<br>452 第26章MySQL权限与安全表的Host字段进行控制的，Host可以是以下类型的赋值。<br>Host值可以是主机名或IP号，或localhost指出本地主机。可以在Host列值使用通配符字符“%”和“_”。<br>○Host值“%”匹配任何主机名，空Host值等价于“%”。它们的含义与LIKE操作符的模式匹配操作相同。例如，“%”的Host值与所有主机名匹配，而“%.mysql.com”匹配 mysql.com域的所有主机。<br>使用Host值与User值的组合进行连接的例子如表26-2所示。表26-2 Host和User组合进行连接的例子<br>Host值 User值 被条目匹配的连接<br>‘thomas.loc.gov’’fred’ fred，通过thomas.loc.gov连接<br>thomas.loc.gov 任何用户，通过thomas.loc.gov连接“%’fred’ fred，通过任何主机连接<br>“%” 任何用户，通过任何主机连接<br>%.loc.gov’fred’ fred，通过loc.gov域的任何主机连接<br>‘x.y.%“fred’ fred，通过x.y.net、x.y.com、x.y.edu等连接<br>144.155.166.177“fred’ fred，通过IP地址为144.155.166.177的主机连接<br>‘144.155.166.%’fred’ fred，从来自144.155.166这个C类子网的任何主机进行连接<br>可能读者会有这样的疑问，如果权限表中的Host既有“thomas.loc.gov”，又有“%”，而此时，连接从主机thomas.loc.gov过来。显然，user表里面这两条记录都符合匹配条件，那系统会选择哪一个呢？<br>如果有多个匹配，那么服务器必须选择使用哪个条目。按照下述原则来解决：服务器在启动时读入user表后进行排序；<br>然后当用户试图连接时，以排序的顺序浏览条目；服务器使用与客户端和用户名匹配的第一行。<br>当服务器读取表时，它首先以最具体的Host值排序。主机名和IP号是最具体的。“%” 意味着“任何主机”并且是最不特定的。有相同Host值的条目首先以最具体的User值排序（空User值意味着“任何用户”并且是最不特定的）。下例是排序前和排序后的结果。<br>排序前：<br>|Host User<br>root jeffrey<br>%<br>localhos root<br>localhost 排序后：<br>|Host Iuser<br>localhost root localhost<br>% jeffrey<br>Iroot<br>很显然，在上面的例子中应该匹配host为“thomas.loc.gov”所对应的权限。</p>
<p>≦ 471 ≧<br>26.1MySQL权限管理 453<br>注意：mysql数据库的user表中Host的值为“%”或者空，表示所有外部IP都可以连接，但是不<br>包括本地服务器localhost，因此，如果要包括本地服务器，必须单独为localhost赋予权限。例5：授予SUPER、PROCESS、FILE权限给用户emp@%。<br>mysql&gt;grant super,process,file on <em>,</em> to ‘emp‘@’%; Query ok,0 rows affected (o.o0 sec)<br>因为这几个权限都属于管理权限，因此不能够指定某个数据库，on后面必须跟“** 下面的语法将提示错误：<br>mysql&gt; grant super,process,file on employees.* to emp‘@’%’;<br>ERROR 1221 (HYO0O):Incorrect usage of DB GRANT and GLOBAL PRIVILEGES 例6：只授予登录权限给emp@localhost。<br>mysql&gt;create user emp@’localhost’identified byemp123’;<br>Query ok,0 rows affected (o.o0 sec) 创建用户后，不用grant，用户默认有usage权限。<br>[mysq13307@loca1host ~]s mysql -uemp -hloca7host -s&#x2F;tmp&#x2F;mysq1 3307.sock -p Enter password:<br>welcome to the MysQL monitor.  Commands end with ; or g. Your MysQL connection id is 217<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>Copyright (c) 2000, 2018, oracle and&#x2F;or its affiliates. A1l rights reserved. oracle is a registered trademark of oracle corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type ‘help;or Vh’ for help. Type ‘\c’ to clear the current input statement.<br>mysql&gt;show databases; |Database<br>Iinformation schema 1 row in set (o.o0 sec)<br>usage权限可以登录数据库，只能查询information_schema数据库下的部分表，权限非常小。直接操作权限表也可以进行权限的创建，其实GRANT操作的本质就是修改权限表后进<br>行权限的刷新，因此，GRANT比操作权限表更简单。下面继续以上文的例4为例来说明一下更新权限表的用法。<br>创建新用户empl，可以从任何IP进行连接，权限为对employees数据库里的所有表进行 SELECT、UPDATE、INSERT和DELETE，初始密码为emp123，具体步骤如下：<br>mysql&gt;create user empi@’%’ identified by ‘emp123’; Query ok,0 rows affected (o.o0 sec)<br>mysql&gt;grant select,insert,update,delete on employees.* to ‘emp1‘@’%’;<br>Query ok,O rows affected (o.oo sec) 直接操作权限表如下：<br>[mysq13307@localhost ~]s mysql -uroot –socket&#x3D;&#x2F;tmp&#x2F;mysql 3307.sock mysq]<br>Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A<br>welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 246<br>Server version:5.7.22-1og MysQL Community Server (GPL)<br>Copyright (c) 2000, 2018, oracle and&#x2F;or its affiliates. A1l rights reserved.<br>Oracle is a registered trademark of oracle Corporation and&#x2F;or its affiliates. other names may be trademarks of their respective</p>
<p>≦ 472 ≧<br>454 第26章MySQL权限与安全<br>owners<br>Type ‘help;’or \h’ for help. Type \c’ to clear the current input statement.<br>mysql&gt;insert into user (host,user,ssl cipher,x509_issuer,x509_subject,authentication_string)<br>values （’%’,’emp1′， ,password（’emp123’)）; Query ok,1 row affected,1 warning (0.o0 sec)<br>mysql&gt;insert into db (Host,Db,User,Select priv,Insert priv,Update priv,Delete priv) values(‘%, employees’,’empl’,’Y<br>Query ok,1 row affected (0.00 sec) mysql&gt;flush privileges;<br>Query ok,O rows affected (o.o0 sec)<br>[mysq13307@1oca1host ~]s mysql -uemp1 -hlocalhost -s&#x2F;tmp&#x2F;mysql 3307.sock-p Enter password:<br>welcome to the MysQL monitor. commands end with  or g. Your MysQL connection id is 247<br>Server version: 5.7.22-1og MySQL Community Server （GPL)<br>Copyright （c) 2000, 2018,Oracle and&#x2F;or its affiliates.A1l rights reserved. oracle is a registered trademark of oracle corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type ‘help;or \h’ for help. Type ‘\c’ to clear the current input statement.<br>emp1@localhost:mysq1 3307.sock [(none)]&gt;show databases; Database<br>information_schem employees<br>2 rows in set (0.00 sec)<br>创建完账号后，时间长了可能就会忘记分配的权限而需要查看账号权限，也有可能会经过一段时间后需要更改以前的账号权限。<br>2.查看账号权限<br>账号创建好后，可以通过如下命令查看权限：<br>show grants for user@host;<br>如下例所示：<br>mysql&gt;show grants for emp@’localhost’: 1Grants for emp@localhost<br>IGRANT USAGE ON *<em>TO‘emp‘@’localhost<br>IGRANT SELECT, INSERT,UPDATE,DELETE ONemployees</em>TO ‘emp‘@’localhost 2rows in set (o.o0 sec)<br>host可以不写，默认是“%”，如下所示： mysql&gt; show grants for emp;<br>ERROR 1141 (42000):There is no such grant defined for user’emp’on host ‘%<br>mysql&gt;create user emp@’%identified by’emp123’; Query ok,0 rows affected (o.o0 sec)<br>mysql&gt; show grants for emp; 1Grants for emp@%<br>GRANT USAGE ON*.*TOemp‘@’%</p>
<p>≦ 473 ≧<br>26.1MySQL权限管理 455<br>1row in set (o.00 sec) 3.更改账号权限<br>可以进行权限的新增和回收。和账号创建一样，权限变更也有两种方法：使用GRANT（新增）和REVOKE（回收）语句，或者更改权限表。<br>第二种方法和前面一样，直接对user、db、tables_priv和columns_priv中的权限列进行更新即可，这里重点介绍第一种方法。<br>和创建账号语法完全一样，GRANT可以直接用来对账号进行增加。其实GRANT语句在执行的时候，如果权限表中不存在目标账号，则创建账号；如果已经存在，则执行权限的新增。下面来看一个例子。<br>（1）emp@localhost目前只有登录权限。<br>mysql&gt;show grants for emp@locaThost; 1Grants for emp@localhost<br>|GRANT USAGE ON **TO emp‘@localhost 1row in set (o.00 sec)<br>（2）赋予emp@localhost所有数据库上的所有表的SELECT权限。<br>mysql&gt;grant select on <em>.</em> to emp‘@locaThost’; Query ok,0 rows affected,1 warning (0.00 sec)<br>mysql&gt;show grants for emp@localhost; 1Grants for emp@localhost<br>GRANT SELECT ON *<em>TO ‘emp‘@’localhost 1row in set (o.00 sec)<br>（3）继续给emp@localhost赋予SELECT和INSERT权限，和已有的SELECT权限进行合并。<br>mysql&gt;grant select,insert on <em>.</em> to‘emp‘@’localhost’; Query ok,0 rows affected, 1 warning (0.o0 sec)<br>mysql&gt;show grants for emp@localhost; |Grants for emp@localhost<br>GRANT SELECT,INSERT ON</em>.<em>TO ‘emp‘@’locaThost’ 1row in set (0.00 sec)<br>REVOKE语句可以回收已经赋予的权限，语法如下：<br>REvokE priv_type [(column_list)] [,priv_type [（column_7ist)]] .<br>ON [object_type] [tbl_name &#x2F; <em>&#x2F;</em>.</em>&#x2F; db_name.*} FROM user [,user]..<br>REVOKE ALL PRIVILEGES, GRANT OPTION FROM uSer [, uSer]<br>对于上面的例子，这里决定要收回emp@localhost上的INSERT和SELECT权限：<br>mysql&gt;revoke select,insert on <em>.</em> from emp@localhost; Query ok,0 rows affected,1 warning (o.o0 sec)<br>mysql&gt;show grants for emp@localhost; |Grants for emp@localhost</p>
<p>≦ 474 ≧<br>456 第26章MySQL权限与安全<br>|GRANT USAGE ON <em>.<em>TO‘emp‘@’localhost’ 1 row in set (0.00 sec)<br>usage权限不能被回收，也就是说，REVOKE用户并不能删除用户。<br>mysql&gt;show grants for emp@localhost; 1Grants for emp@localhost<br>|GRANT USAGE ON</em>，</em>TO‘emp‘@’1ocalhost’ 1row in set (0.00 sec)<br>mysql&gt;revoke usage on <em>.</em> from emp@localhost; Query ok,0 rows affected,1 warning (0.o0 sec)<br>mysql&gt;show grants for emp@localhost; I Grants for emp@localhost<br>|GRANT USAGE ON<strong>To‘emp‘@’localhost’<br>1row in set (0.o0 sec) 4.修改账号密码<br>方法1：可以用mysqladmin命令在命令行指定密码。<br>shell&gt; mysqladmin -u user name -h host name password “newpwd”<br>方法2：执行alter user语句。下例中将账号“jeffrey@”%”的密码改为“biscuit””。 mysql&gt; alter user jeffrey@’% identified by ‘biscuit’;<br>方法3：还可以在全局级别使用GRANTUSAGE语句（在“</strong>”）来指定某个账户的密码而不影响账户当前的权限。<br>mySql&gt; GRANT USAGE ON <em>,<em>TO‘jeffrey‘@’% IDENTIFIED BY’biscuit’;<br>方法4：直接更改数据库的user表。<br>mysql&gt;insert into user (host,user,ssl cipher,x509 issuer,x509 subject,authentication string)<br>values （</em>%’,emp’,,,</em>,password（’emp123’））; Query ok,1 row affected,1 warning (0.00 sec)<br>mysql&gt;flush privileges;<br>Query ok,O rows affected (o.o0 sec)<br>mysql&gt;UPDATE user SET authentication string &#x3D; PASSWORD(‘123456’) WHERE Host&#x3D;’%AND User &#x3D;emp: Query ok, 1 row affected, 1 warning (0.o0 sec)<br>Rows matched:1changed:1 warnings:1 mysql&gt;flush privileges;<br>Query ok, 0 rows affected (o.01 sec)<br>注意：MySQL8.0废弃了PASSWORD函数，所以方法4在MySQL8.0已不适用。<br>方法5：以上方法在更改密码时，用的都是明文，这样就会存在安全问题，比如修改密码的机器被入侵，那么通过命令行的历史执行记录就可以很容易地得到密码。因此，在一些重要的数据库中，可以直接使用MD5密码值来对密码进行更改，如以下例子：<br>GRANT USAGE ON **TO‘jeffrey‘@’%’IDENTIFIED BYPASSWORD *6BB4837EB74329105EE4568DDA7DC<br>67ED2CA2AD9’; 或者：<br>set pasSWord&#x3D;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9’；其中的MD5密码串可以事先用其他方式获得。</p>
<p>≦ 475 ≧<br>26.1MySQL权限管理 457<br>注意：MySQL8.0废弃了PASSWORD函数，所以方法5的grant命令在MySQL8.0已不适用。 5.删除账号<br>要彻底删除账号，同样也有两种实现方法，即DROPUSER命令和修改权限表。<br>DROPUSER语法非常简单，具体如下： DROP USER user [,user] ..<br>举一个简单的例子，将emp@localhost用户删除：<br>mysql&gt;show grants for emp@localhost; |Grants for emp@localhost<br>|GRANT USAGE ON *.*TO‘emp‘@’localhost’1 1 row in set (o.00 sec)<br>mysql&gt;drop user emp@localhost;<br>Query ok, 0 rows affected (o.o0 sec) mysql&gt;show grants for emp@localhost ;<br>ERROR 1141 (42000): There is no such grant defined for user’emp’ on host ‘localhost’<br>修改权限表方法只要把user用户中的用户记录删除即可，这里不再演示。 6.账号资源限制<br>创建MySQL账号时，还有一类选项前面没有提及，我们称为账号资源限制（Account ResourceLimit）。这类选项的作用是限制每个账号实际具有的资源限制，这里的“资源”主要包括以下内容：<br>单个账号每小时执行的查询次数；一单个账号每小时执行的更新次数；单个账号每小时连接服务器的次数；单个账号并发连接服务器的次数。<br>在实际应用中，可能会发生这种情景，由于程序BUG或者系统遭到攻击，使得某些应用短时间内发生了大量的点击，从而对数据库造成了严重的并发访问，数据库短期无法响应甚至岩机，对生产带来负面影响。为了防止这种问题的出现，我们可以通过对连接账号进行资源限制的方式来解决，比如按照日常访问量加上一定余设置每小时查询1万次，那么1小时内如果超过1万次查询，数据库就会给出资源不足的提示，而不会再分配资源进行实际查询。<br>设置资源限制的语法如下：<br>GRANT …With option 国9h<br>其中，option的选项可以是以下几个。<br>OMAX_QUERIES_PER_HOURcount:每小时最大查询次数。 OMAX_UPDATES_PERHOURcount:每小时最大更新次数。<br>OMAX_CONNECTIONS_PER_HOURcount:每小时最大连接次数。 OMAX_USER_CONNECTIONScount:最大用户连接数。<br>其中，MAX CONNECTIONSPER HOURcount和MAX_USER_CONNECTIONScount 的区别在于前者是每小时累计的最大连接次数，而后者是瞬间的并发连接数。系统还有一个全局参数MAX_USER_CONNECTIONS，它和用户MAX_USER_CONNECTIONScount的区</p>
<p>≦ 476 ≧<br>458 第26章MySQL权限与安全<br>别在于如果后者为O，则此用户的实际值应该为全局参数值，否则就按照用户MAX_USER_ CONNECTIONScount的值来设置。<br>下面举例来说明一下资源限制的使用方法。<br>创建用户emp，要求具有employees库上的select权限，并且每小时查询次数小于等于6 次，最多同时只能有3个此用户进行并发连接，代码如下：<br>Grant select on employees.*to emp@localhost<br>With MAX QUERIES PER HOUR6 MAX_USER CONNECTIONS 3:<br>从mysql数据库的user表中可以看到相关资源的值：<br>mysql&gt;select user,max questions,max updates,max connections from user where user&#x3D;’emp’;<br>1user I max questions l max updates 1 max connections | Iemp1 o 1 row in set (0.00 sec)<br>用emp登录后，执行下面的查询：<br>[mysq13307@1oca1host ~]s mysq] -uemp -s&#x2F;tmp&#x2F;mysq1 3307.sock employees -p Enter password:<br>Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A<br>welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 34<br>Server version:5.7.22-1og MysQL Community Server (GPL)<br>Copyright (c) 2000, 2018, Oracle and&#x2F;or its affiliates. All rights reserved. oracle is a registered trademark of oracle corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type ‘help;’or\h’ for help.Type ‘\c’to clear the current input statement.<br>emp@localhost:mysql_3307.sock[employees]&gt;select count(0) from city; count(0)1<br>1<br>1 row in set (o.00 sec)<br>emp@localhost:mysql 3307.sock [employees]&gt;select count(0) from city;<br>ERROR 1226 (42000):User ‘emp′ has exceeded the‘max questions’resource (current value:6) 可以发现，登录后执行到第2个查询时提示用户emp已经超过了最大查询的资源限制，<br>从而提示出错。这里有些读者可能有疑问，设置为6应该是执行到第7个查询的时候出错才对，为什么第2个就报错了呢？其实MySQL里面很多非“select”语句都会归类到“查询”，比如“show”语句、“desc”语句等，还有一些隐式的查询包含在内，上面的查询从日志中可以查到在登录后隐式执行了以下SQL语句，这才导致了上面的结果。<br>2018-07-21T14:24:41.867892+08:00 35 Query SET NAMES utf8 2018-07-21T14:24:41.869351+08:00 35 Query show databases 2018-07-21T14:24:41.869927+08:00 35Query show tables<br>2018-07-21T14:24:41.874695+08:00 35Query select @@version comment limit 1 2018-07-21T14:24:41.877209+08:00 35 Query select USERO)<br>需要注意的是，资源限制是对某一个账号进行累计的，而不是对账号的一次连接进行累计。当资源限制到达后，账号的任何一次相关操作都会被拒绝。如果要继续操作，只能清除</p>
<p>≦ 477 ≧<br>26.1MySQL权限管理 459<br>相关的累加值。可以使用root执行flushuser_resources&#x2F;flushprivileges&#x2F;mysqladminreload这3 个命令中的任何一个来执行清除工作。如果数据库发生重启，则原先累计的计数值清零。<br>如果要对账号的资源限制进行修改或者删除，将相应参数设置为0即可：<br>GRANTUSAGE ON **TO‘emp‘@’localhost WITH MAX CONNECTIONS PER HOUR O;<br>注意：账号的资源限制设置一定要非常小心，一般不建议设置。如果一定要设置，就要对系统的<br>高峰访问情况了解清楚并加上足够的冗余后再进行设置，为了防止达到资源限制后所有功能的失效，将不同的功能分给不同的用户是一个可行的办法。<br>7.用户密码管理<br>对于一些敏感用户，为了提高安全性，我们需要定期修改用户的密码。MySQL提供基于时间维度定期修改密码的功能。这个功能涉及mysql.user表的3个字段。<br>password_expired：密码是否过期，默认值为N。 password_last_changed:最后修改密码的时间。 Opassword_lifetime：密码有效时间，单位为天。<br>可以通过alteruser命令设置password_expired字段值为Y，要求用户重置账号的密码。当密码过期后，新连接需要用alteruser命令重置密码后才能执行SQL语句，密码过期对旧连接没有影响。<br>从mysql数据库的user表中可以看到password_expired和password_last_changed的值： mysql&gt; select password expired,password last_changed from user where User&#x3D;’emp’ and Host&#x3D;%; Ipassword expired I password last changed 1<br>2018-10-1614:21:36<br>1 row in set (0.00 sec)<br>结果显示，password_expired的值为N，代表密码未过期；上次修改密码时间password last_changed字段的值为2018-10-1614:21:36。<br>使用emp用户登录数据库的实例如下：<br>[mysq13307@localhost~]$ mysql -uemp -pemp123 -h127.0.0.1 -P3307<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 94<br>Server version:5.7.22-1og MysQL Community Server （GPL)<br>Type ‘help;’or \h’ for help. Type ‘\c’ to clear the current input statement. mysq1&gt;<br>修改password_expired字段值为Y：<br>mysql&gt;alter user emp@’%’ password expire;<br>mysql&gt; select password expired,password last_changed from user where User&#x3D;’emp’ and Host&#x3D;’%’; Ipassword expired | password last changed1<br>IY |2018-10-1614:21:36 1 row in set (o.00 sec)<br>成功修改password_expired字段后，使用emp用户旧连接会话执行命令：<br>mysql&gt;show databases | Database</p>
<p>≦ 478 ≧<br>460 第26章MySQL权限与安全<br>information schema I<br>employees mysq1<br>performance_schema<br>sys testdb<br>6rows in set (o.00 sec)<br>旧的连接执行命令正常。下面用emp用户新建立连接，执行命令：[mysq13307@1oca1host ~]$ mysq] -uemp -pemp123 -h127.0.0.1 -P3307<br>Welcome to the MysQL monitor. commands end with : or g. Your MysQL connection id is 95<br>server version: 5.7.22-1og MysQL community Server (GPL)<br>Type ‘help;’or ‘\h’ for help. Type \c’ to clear the current input statement. mysql&gt;show databases;<br>ERROR 1820 (HYoo0): You must reset your password using ALTER USER statement before executing this statement.<br>新会话执行命令前做校验，发现密码过期，会报ERROR1820。<br>在以上报错的连接会话中，重置emp用户的密码： mysql&gt;alter user emp@%’ identified by ‘emp123’;<br>Query ok,O rows affected (o.o0 sec) 再执行命令：<br>mysql&gt;show databases; |Database<br>information_schema<br>employees mysql<br>performance_schema<br>sys testdb<br>6rows in set (0.00 sec)<br>mysql&gt; select password expired,password last _changed from user where user&#x3D;’emp’ and Host&#x3D;’%’; I password expired I password last_changed 1<br>2018-10-16 14:33:20<br>1row in set (o.o0 sec)<br>如我们所料，命令可以正常执行了，密码的上次修改时间也变成最新时间。<br>注意：这里重置的新密码与旧密码相同，但是为了安全，建议设置一个不同的新密码。<br>password_lifetime指的是用户密码的有效天数。如果当天时间减去password_last_changed 字段值，所得天数超过password_lifetime的值，password_expired被设置为Y。如果对所有的用户应用同一个密码有效天数，可以指定全局参数default_password_lifetime，单位为天。设置用户密码有效时间为默认配置：<br>mysql&gt;alteruseremp@%passwordexpiredefaut<br>8.锁定用户<br>从MySQL5.7.6版本开始，可以执行alteruser命令锁定和解锁用户，用于临时禁止用户登录。<br>下面来看一个锁定用户的简单例子。查看emp用户的锁定状态：</p>
<p>≦ 479 ≧<br>26.2MySQL安全问题 461<br>mysql&gt;select account_ locked from user where User&#x3D;’emp’ and Host&#x3D;%’;<br>account_locked| IN<br>1 row in set (o.00 sec)<br>结果显示，emp用户处于非锁定状态，下面将用户锁定：<br>mysql&gt;alter user emp@’%’ account lock; Query Ok,0 rows affected (o.o0 sec)<br>再次查看emp用户的锁定状态：<br>mysql&gt;select account_locked from user where user&#x3D;’emp’ and Host&#x3D;’%’;<br>|account locked1 Y<br>1 row in set (0.00 sec)<br>account_locked字段值为Y，用户已被锁定。重新登录创建连接：<br>[mysq13307@localhost<del>]$mysql -uemp -pemp123-h127.0.0.1-P3307<br>ERROR 3118 (HY000):Access denied for user ‘emp‘@’127.0.0.1’. Account is locked<br>由于用户被锁定，尝试登录会报错ERROR3118，emp用户已无法登录。用root用户解锁emp用户：<br>mysql&gt;alter user emp@’%’ account unlock;<br>Query oK,0 rows affected (o.o0 sec) 解锁后，尝试登录数据库：<br>[mysq13307@loca1host</del>]$ mysq]-uemp -pemp123-h127.0.0.1-P3307<br>Welcome to the MysQL monitor. Commands end with ; or g. Your MysQL connection id is 96<br>Server version:5.7.22-1og MySQL Community Server (GPL)<br>Type ‘help;’or \h’ for help. Type \c’to clear the current input statement. mysq1&gt;<br>结果如我们所料，可以正常登录了。 26.2MySQL安全问题<br>对于任何一种数据库来说，安全问题都是非常重要的。如果数据库出现安全漏洞，轻则数据被窃取，重则数据被破坏，这些后果对于一些重要的数据库来说，都是非常严重的。本节将从操作系统和数据库两个层面对MySQL的安全问题进行探讨。<br>26.2.1 操作系统相关的安全问题<br>本节介绍一些常见的操作系统安全问题，这些问题主要出现在MySQL的安装和启动过程中，希望读者能够从安装开始就重视安全问题。<br>1.严格控制操作系统账号和权限<br>在数据库服务器上要严格控制操作系统的账号和权限，比如：锁定mysql用户；<br>其他任何用户都采取独立的账号登录，管理员通过mysql专有用户管理MySQL，或</p>
<p>≦ 480 ≧<br>462 第26章MySQL权限与安全者通过rootsu到mysql用户下进行管理；<br>mysql用户目录下，除了数据文件目录，其他文件和目录属主都改为root。 2.防止DNS欺骗<br>创建用户时，host可以指定域名或者IP地址。但是，如果指定域名，就可能带来如下安全隐患：如果域名对应的IP地址被恶意修改，则数据库就会被恶意的IP地址进行访问，导致安全隐患。<br>在下例中，尝试改变域名对应的IP地址，以此来观察一下对连接的影响。（1）创建测试用户emp，域名指定为testhostname。<br>mysql&gt;grant select on employees.* to emp@test hostname identified by emp123’; Query ok,0 rows affected (o.oo sec)<br>mysql&gt; show grants for emp@test hostname; I Grants for emp@test hostname<br>GRANT USAGE ON **To‘emp‘@’test hostname<br>IGRANT SELECT ONemployees.*TO‘emp‘@’test hostname（2）编辑hosts文件，增加此域名和IP地址的对应关系：[root@localhost ~]# vi &#x2F;etc&#x2F;hosts<br>#Do not remove the following line, or various programs# that require network functionality will fail.<br>127.0.0.1 localhost.localdomain localhost 192.168.7.55 localhost.localdomain<br>192.168.52.24 test hostname（3）客户端尝试连接成功：<br>c:\mysqTbin&gt;ipconfig Windows IP configuration<br>Ethernetadapter 无线网络连接：<br>Media state:Media disconnected<br>Ethernet adapter 本地连接：<br>Connection-specific DNs Suffix :netease.internal<br>IP Address. 192.168.52.24 Subnet Mask：255.255.254.0 Default Gateway：192.168.52.254<br>c:\mysq1\bin&gt;mysq1 -h192.168.7.55-P3307 -uemp -p Enter password:<br>welcome to the MysQL monitor. Commands end with ; or g.<br>Your MysQL connection id is 6 to server version: 5.7.22-beta-1og<br>Type help;or h’for help. Type ‘c’to clear the buffer. mysql&gt; exit<br>（4）修改域名IP地址的对应关系，将192.168.52.24改为192.168.52.23：[root@localhost ~]# vi &#x2F;etc&#x2F;hosts<br>#Do not remove the following line, or various programs# that require network functionality will fail.<br>127.0.0.1 localhost.localdomain localhost 192.168.7.55 localhost.localdomain 192.168.52.23 test hostname</p>
<p>≦ 481 ≧<br>26.2MySQL安全问题 463<br>（5）客户端再次尝试连接失败：<br>C:\mysq1\bin&gt;mysq1-h192.168.7.55-P3307 -uemp-p Enter password:<br>ERROR 1045 (28000):Access denied for user‘emp‘@’192.168.52.24(using No) 26.2.2数据库相关的安全问题<br>本节介绍一些常见的数据库安全问题，这些问题大多数是由于账号的管理不当造成的。希望读者读完本节后能够认识到账号管理的重要性，同时加强对账号管理的安全意识。<br>1.给root账号设置口令<br>安装MySQL5.7，如果使用-initialize-insecure选项初始化数据库，则root的默认口令为空，需要马上修改root口令：<br>[mysq13307@1oca1host<del>]s mysql -uroot-s&#x2F;tmp&#x2F;mysql 3307.sock welcome to the MysQL monitor. Commands end with ; or g. Your MysQL connection id is4<br>Server version:5.7.22-1og MysQL Community server (GPL)<br>Type help;*or Vh’ for help. Type ‘\c’ to clear the current input statement. mysql&gt; alter user root@’localhost’ identified by *newpassword’;<br>Query oK,0 rows affected (o.o0 sec) 不写密码登录将被拒绝：<br>[mysq13307@ 1oca1host ~]$mysq] -uroot -s&#x2F;tmp&#x2F;mysql_3307.sock<br>ERROR 1045 (28000):Access denied for user root‘@’1ocalhost’（using password: No) 2.设置安全密码<br>密码的安全体现在以下两个方面：<br>设置安全的密码，建议使用8位以上字母、数字、下划线和一些特殊字符组合而成的字符串；<br>使用密码期间尽量保证使用过程的安全，不会被别人窃取。<br>第一点就不说了，越长、越复杂、越没有规律的密码越安全。对于第二点，可以总结一下，在日常工作中，使用密码一般是采用以下几种方式。<br>（1）直接将密码写在命令行中：<br>[mysq13307@loca1host</del>]smysq] -uroot-S&#x2F;tmp&#x2F;mysq1_3307.sock -p123<br>Welcome to the MysQL monitor. Commands end with;or g. Your MysQL connection id is 8<br>Server version: 5.7.22-1og MySQL Community Server (GPL)（2）交互式方式输人密码：<br>[mysq13307@loca1host ~]$ mysq] -uroot -s&#x2F;tmp&#x2F;mysql 3307.sock -p Enter password:<br>welcome to the MysQL monitor. Commands end with ; or g. Your MysQL connection id is 11<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>（3）将用户名和密码写在配置文件里面，连接的时候自动读取。比如应用连接数据库或者执行一些批处理脚本。对于这种方式，MySQL供了一种方法，在my.cnf里面写入连接信息：[client]<br>user&#x3D;username<br>password&#x3D;password<br>然后对配置文件进行严格的权限限制，例如：</p>
<p>≦ 482 ≧<br>464 第26章MySQL权限与安全<br>chmod +600 my.cnf<br>以上是3种常见的密码使用方式。很显然，第1种最不安全，因为它将密码写成为明文；第2种比较安全，但是只能使用在交互式的界面下；第3种使用比较方便，但是需要将配置文件设置严格的存取权限，而且任何只要可以登录操作系统的用户都可以自动登录，存在一定的安全隐患。<br>下面举一个第3种方法的例子。输人mysql无法登录。<br>[mysq73307@loca1host <del>]s mysql<br>ERROR 1045 (28000): Access denied for user ‘hr‘@’localhost’ （using password: NO)<br>在执行mysql客户端用户的家目录，创建.my.cnf文件，加人连接信息。[mysq13307@loca7host</del>]s cd<br>[mysq13307@loca1host ~]svi.my.cnf[client]<br>user &#x3D; root password &#x3D; 123<br>socket&#x3D;&#x2F;tmp&#x2F;mysq1_3307.sock<br>[mysq13307@loca1host ~]$ chmod 660 .my.cnf 再次输入mysql。<br>[mysq13307@loca1host ~]$ mysq]<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 12<br>Server version:5.7.22-1og MysQL Community Server （GPL)<br>Copyright （c) 2000, 2018,0racle and&#x2F;or its affiliates. A1l rights reserved. oracle is a registered trademark of oracle corporation and&#x2F;or its<br>affiliates. other names may be trademarks of their respective owners.<br>Type ‘help:’or ‘\h’ for help. Type ‘\c’ to clear the current input statement. mysql&gt; select current userO;<br>lcurrent userO1 1root@localhost 1<br>1row in set (o.00 sec)<br>3.只授予账号必需的权限<br>只需要赋予普通用户必需的权限，比如：<br>Grant select,insert,update,delete on tablename to username‘@’hostname；<br>在很多情况下，DBA为了方便，经常赋予用户allprivileges权限。这个allprivileges到底具体包含哪些权限呢？来看下面的这个例子：<br>mysql&gt;grant all privileges on empToyees.* to ‘emp‘@’localhost’;<br>Query ok,0 rows affected, 1 warning (0.00 sec) mysql&gt; select * from db where user&#x3D;’emp’\G<br>Host:localhost Db:employees user: emp<br>Select_priv:Y Insert priv:Y Update_priv:Y Delete priv: Y Create priv:Y Drop_priv:Y</p>
<p>≦ 483 ≧<br>26.2MySQL安全问题 465<br>Grant priv:N References priv:Y<br>Index priv:Y Alter_priv:Y<br>Create_tmp_table_priv:Y<br>Lock_tables_priv:Y Create view_priv:Y Show view priv:Y<br>Create_routine_priv:Y Alter_routine_priv:Y<br>Execute priv:Y Event priv:Y Trigger_priv:Y<br>1 row in set (o.00 sec)<br>all privileges里面的权限远远超过了一般应用所需要的权限。而且，有些权限如果误操作，将会产生非常严重的后果，比如drop_priv等。因此，赋予用户权限的时候越具体，对数据库越安全。<br>4.除root外，任何用户不应有mysql库user表的存取权限<br>由于MySQL中可以通过更改mysql数据库的user表进行权限的增加、删除、变更等操作，因此，除了root以外，任何用户都不应该拥有对user表的存取权限（SELECT、UPDATE、 INSERT、DELETE等），否则容易造成系统的安全隐患。下例中对普通用户emp授予了user 表的存取权限，看看会对系统产生怎样的安全隐患。<br>（1）创建普通用户emp，拥有对mysql数据库中user表的各种权限。[mysq13307@localhost<del>]$mysql -uroot -p123<br>welcome to the MysQL monitor. Commands end with ; or g. Your MySQL connection id is 25<br>Server version:5.7.22-1og MysQL Community Server (GPL)<br>Type ‘help;’or h′ for help. Type ‘\c’ to clear the current input statement. mysql&gt;grant select,update,insert,delete on mysql.user to emp@localhost;<br>Query ok,O rows affected (o.oo sec)（2）用emp来更新root权限。<br>[mysq13307@loca1host</del>]s mysq]-uemp<br>welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 30<br>Server version: 5.7.22-1og MysQL Community Server (GPL) mysql&gt; use mysq1<br>mysql&gt; update user set authentication string&#x3D;password(‘abcd’) where user&#x3D;root’ and host&#x3D;’localhost’; Rows matched:1 changed:1 warnings:0<br>（3）当数据库重启或者root刷新权限表后，root登录时密码已经被更改。[mysq13307@]ocalhost~]$ mysql -uroot -p123<br>mysql: [warning] using a password on the command line interface can be insecure. ERROR 1045 (28000): Access denied for user root‘@’localhost’（using password: YES)<br>[mysq13307@loca1host ~]s mysql -uroot -pabcd<br>mysql: [warning] using a password on the command line interface can be insecure.<br>welcome to the MysQL monitor.commands end with ;or g. Your MysQL connection id is 36<br>Server version:5.7.22-1og MysQL Community Server (GPL) mysq1&gt;<br>5.不要把FILE、PROCESS或SUPER权限授予管理员以外的账号 FILE权限主要有以下两种作用。</p>
<p>≦ 484 ≧<br>466 第26章MySQL权限与安全<br>O将数据库的信息通过SELECT…INTOOUTFILE…写到服务器上有写权限的目录下，作为文本格式存放。如果导出的数据量很大，将有耗尽系统磁盘空间的风险。<br>O可以将有读权限的文本文件通过LOADDATAINFILE..命令写入数据库表，如果这些文本文件中存放了很重要的信息，将对系统造成很大的安全隐患。<br>在MySQL5.7版本，可以设置secure_file_priv参数，指定用户只能在有权限的目录中执行SELECT…INTOOUTFILE和LOADDATAINFILE命令。<br>PROCESS权限能被用来执行“showprocesslist”命令，查看当前所有用户执行的查询的明文文本，包括设定或改变密码的查询。在默认情况下，每个用户都可以执行“showprocesslist” 命令，但是只能查询本用户的进程。因此，对PROCESS权限管理不当，有可能会使得普通用户能够看到管理员执行的命令。<br>下例中对普通用户赋予了PROCESS权限，来看看会造成什么安全隐患。<br>（1）将PROCESS权限授予普通用户：[mysq13307@localhost~]$mysql -uroot -p<br>Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A<br>welcome to the MysQL monitor.  Commands end with ;or \g. Your MysQL connection id is 39<br>Server version:5.7.22-1og MysQL Community Server (GPL) mysql&gt;show processlist;<br>mysql&gt; grant process on ** to ‘emp‘@’localhost’; Query ok,0 rows affected (o.oo sec)<br>（2）锁定表user，可以让进程阻塞，以方便用户看到进程内容： mysql&gt;lock table user read;<br>Query ok,0 rows affected (o.o0 sec)<br>（3）打开另外一个session，用root执行修改密码操作，此时因为user表被锁定，此进程被阻塞挂起：<br>mysql&gt;set password&#x3D;password(‘123)；<br>（4）打开第3个session，用emp登录，执行showprocesslist语句：<br>[mysq13307@localhost ~]s mysql -uemp -p Enter password<br>welcome to the MysQL monitor.  commands end with ; or g. Your MysQL connection id is 42<br>Server version:5.7.22-1og MySQL Community Server (GPL) mysql&gt;show processlist\G<br>Id：40 user: emp<br>Host:localhost db:employees<br>Command: Query Time:11<br>State: waiting for table metadata lock Info: set password&#x3D;password(‘123’)<br>可以发现，emp显示的进程中清楚地看到了root的修改密码操作，并看到了明文的密码，这将对系统造成严重的安全隐患。<br>SUPER权限能执行kill命令，终止其他用户进程。在下面的例子中，普通用户拥有了 SUPER权限后，便可以任意kill任何用户的进程。<br>（1）emp登录后想kill掉上面例子中root修改密码进程（进程号40）：</p>
<p>≦ 485 ≧<br>26.2MySQL安全问题 467<br>mysq1&gt;ki71 40;<br>ERROR 1095 (HY000): You are not owner of thread 40（2）kil失败后，root将super权限赋予emp： mysql&gt;grant super on ** to emp@localhost;<br>Query oK,0 rows affected (o.o0 sec) mysql&gt;show grants for emp@’localhost’;<br>|Grants for emp@localhost<br>GRANT PROCESS, SUPER ON *.*TO emp‘@’Tocalhost<br>GRANT SELECT,INSERT,UPDATE,DELETE ON mysquser TOemp@ocalhost（3）emp用户重新登录重新killroot的进程成功：<br>[mysq13307@loca1host~]s mysq] -uemp-p Enter password:<br>welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 47<br>Server version:5.7.22-1og MysQL Community Server (GPL) mysql&gt;show processlist;<br>*****57.row<br>Id:40 user: emp<br>Host:localhost db:employees<br>Command:Query Time:11<br>State: waiting for table metadata lock Info:set password&#x3D;password(‘123’)<br>mysq1&gt;ki11 40;<br>Query ok, 0 rows affected (o.o0 sec)<br>从上面的例子中，可以看到了FILE、PROCESS、SUPER这3个管理权限可能带来的安全隐患，因此，除了管理员外，不要把这些权限赋予普通用户。<br>6.LOADDATALOCAL带来的安全问题<br>LOADDATA如果权限控制不好，会带来了以下安全问题。可以任意加载本地文件到数据库。<br>O在Web环境中，客户从Web服务器连接，用户可以使用LOADDATALOCAL语句来读取Web服务器进程有读访问权限的任何文件（假定用户可以运行SQL服务器的任何命令）。在这种环境中，MySQL服务器的客户实际上是Web服务器，而不是连接Web服务器的用户运行程序。<br>解决方法是，通过设置secure_file_priv来满足实际业务的需要，secure_file_priv的值及其含义如表26-3所示。<br>表26-3 secure_file_priv的值及其含义<br>值含<br>空不做任何限制<br>&#x2F;tmp&#x2F; 数据库只能导入&#x2F;tmp下有读权限的文件<br>NULL 不允许执行导入操作<br>注意：更改secure_file_priv的值需要重启MySQL实例。<br>7.DROPTABLE命令并不收回以前的相关访问授权<br>DROP表的时候，其他用户对此表的权限并没有被收回，这样导致重新创建同名的表时，</p>
<p>≦ 486 ≧<br>468 第26章MySQL权限与安全<br>以前其他用户对此表的权限会自动赋予，进而产生权限外流。因此，在删除表时，要同时取消其他用户在此表上的相应权限。<br>下面的例子说明了不收回相关访问授权的隐患。<br>（1）用root创建用户emp，授予对employees下所有表的select权限： mysql&gt;grant select on employees.city to emp@locaThost;<br>Query oK,0 rows affected (o.o0 sec) mysql&gt;show grants for emp@localhost; |Grants for emp@localhost<br>|GRANT USAGE ON *.*TO‘emp‘@’localhost‘<br>1GRANT SELECT ONemployees.cityTO‘emp@’localhost’ 2rows in set(o.00 sec)<br>（2）emp登录，测试权限：<br>[mysq13307@loca1host <del>]s mysq] -uemp<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 54<br>Server version: 5.7.22-1og MysQL Community Server (GPL) mysql&gt;use employees<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed<br>emp@1ocalhost:mysql 3307.sock [emp1oyees]&gt;show tables;<br>1Tables_in_employees1 I city<br>1row in set (0.00 sec)<br>（3）root登录，删除表city： mysql&gt;drop table city;<br>（4）emp登录，再次测试权限：[mysq13307@loca1host</del>]s mysq] -uemp<br>welcome to the MysQL monitor.Commands end with ;or g. Your MysQL connection id is 56<br>Server version:5.7.22-1og MysQL Community Server (GPL) mysq1&gt;use employees<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed<br>emp@localhost:mysql_3307.sock [employees]&gt;show tables; Empty set (o.00 sec)<br>（5）此时city表已经看不到了： mysql&gt;show grants for emp@localhost; |Grants for emp@localhost<br>|GRANT USAGE ON ** TO emp‘@’localhost<br>GRANT SELECT ONemployees.cityTO‘emp‘@localhost’ 2 rows in set (o.00 sec)<br>emp用户仍然有employees下city表的SELECT权限（安全漏洞）。</p>
<p>≦ 487 ≧<br>26.2MySQL安全问题 469<br>（6）root再次登录，创建city表： mysql&gt;CREATE TABLEcity（<br>city_idsmallint(5) unsigned NOT NULL DEFAULT’O<br>city Varchar(5O) CHARACTER SET utf8 NOT NULL, country_id smallint(5) unsigned NOT NULL,<br>last update  timestamp NOT NULL DEFAULT CURRENT TIMESTAMP ON UPDATE CURRENT TIMESTAMP) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci;<br>Query ok, O rows affected (o.o1 sec)（7）emp登录，对city权限依l旧存在：[mysq13307@loca1host ~]s mysq] -uemp<br>Welcome to the MysQL monitor. Commands end with ; or g Your MysQL connection id is 58<br>Server version: 5.7.22-1og MysQL Community server (GPL) mysql&gt;use employees<br>emp@loca1host:mysql 3307.sock [employees]&gt;show tables;<br>1Tables in employees lcity<br>1 row in set (o.o0 sec)<br>emp@loca1host:mysql 3307.sock [employees]&gt;select * from city; Empty set (o.00 sec)<br>注意：对表做删除后，其他用户对此表的权限不会自动收回，一定记住要手工收回。 8.使用SSL<br>SSL（Secure SocketLayer，安全套接字层）是一种安全传输协议，最初由Netscape公司所开发，用以保障在Internet上数据传输的安全，利用数据加密（Encryption）技术，可确保数据在网络上的传输过程中不会被截取及窃听。MySQL通过两种方式支持SSL，一种是使用 OpenSSL，另一种是使用YaSSL。在MySQL8.0版本前，MySQL社区版本使用的是YaSSL； 8.0版本后，MySQL把OpenSSL作为企业版本和社区版本的统一默认TLS&#x2F;SSL库。<br>SSL协议提供的服务主要有3种。<br>认证用户和服务器，确保数据发送到正确的客户机和服务器。 ○加密数据以防止数据中途被窃取。<br>维护数据的完整性，确保数据在传输过程中不被改变。<br>在MySQL中，要想使用SSL进行安全传输，需要在命令行中或选项文件中设置“–ssI”选项。对于服务器，“–ssI”选项规定该服务器允许SSL连接。对于客户端程序，它允许客户使<br>用SSL连接服务器。单单该选项不足以使用SSL连接，还必须指定–ssl-ca、–ssl-cert和–ssl-key 选项。如果不想启用SSL，则可以将选项指定为–skip-ssI或–ssl&#x3D;0。<br>注意：如果编译的服务器或客户端不支持SSL，则使用普通的未加密的连接。<br>确保使用SSL连接的安全方式是，使用含REQUIRESSL子句的GRANT语句在服务器上创建一个账户，然后使用该账户来连接服务器，服务器和客户端均应启用SSL支持。下面的例子创建了一个含REQUIRESSL子句的账号：<br>mysql&gt;grant select on**to emp identified byemp123REQUIRE ssl； Query ok, 0 rows affected, 1 warning (0.o0 sec)<br>O–ssl-ca&#x3D;file_name:含可信SSLCA的清单的文件的路径。 O–ssl-cert&#x3D;file_name:SSL证书文件名，用于建立安全连接。</p>
<p>≦ 488 ≧<br>470 第26章MySQL权限与安全<br>O–ssl-key&#x3D;file_name:SSL密钥文件名，用于建立安全连接。 9.如果可能，给所有用户加上访问IP限制<br>对数据库来说，我们希望从客户端过来的连接都是安全的，因此，就很有必要在创建用户时指定可以进行连接的服务器IP或者HOSTNAME，只有符合授权的IP或者HOSTNAME 才可以进行数据库访问。<br>10.REVOKE命令的漏洞<br>当用户被多次赋予权限后，由于各种原因，需要将此用户的权限全部取消，此时，REVOKE 命令可能并不会按照我们的意愿执行，来看下面的例子。<br>（1）连续赋予用户两次权限，其中，第2次是对所有数据库的所有权限。<br>mysql&gt;grant select,insert on employees.* to emp@localhost; Query ok, 0 rows affected, 2 warnings (0.o0 sec)<br>mysql&gt;grant all privileges on <em>.</em> to emp@localhost; Query ok, 0 rows affected, 1 warning (0.o0 sec)<br>mysql&gt;show grants for emp@localhost; | Grants for emp@localhost<br>IGRANT ALL PRIVILEGES ON *.<em>TO emp‘@’localhost<br>IGRANT SELECT,INSERT ON employees</em>Toemp@localhost 2 rows in set (0.o0 sec)<br>（2）此时，需要取消此用户的所有权限。<br>mysql&gt;revoke all privileges on <em>,</em> from emp@localhost; Query ok,0 rows affected,1 warning (o.o0 sec)<br>（3）我们很可能以为，此时用户已经没有任何权限了，而不会再去查看他的权限表。而实际上，此时的用户依然拥有employees上的SELECT和INSERT权限。<br>mysql&gt;show grants for emp@localhost; |Grants for emp@localhost<br>GRANT uSAGE oN <strong>TO emp‘@localhost<br>IGRANT SELECT,INSERT ONemployees*TOemp@localhost 2rows in set (0.00 sec)<br>这个是MySQL权限机制造成的隐患，在一个数据库上多次赋予权限，权限会自动合并；但是在多个数据库上多次赋予权限，每个数据库上都会认为是单独的一组权限，必须在此数据库上用REVOKE命令来单独进行权限收回，而REVOKEALLPRIVILEGESON</strong>并不会替用户自动完成这个过程。<br>11.使用角色管理用户权限<br>MySQL角色（role）是8.0版本提供的新特性。角色是一组权限的集合，角色被授予MySQL 用户后，用户将获得相应的权限。多个用户共用一组权限，方便统一运维和管理。<br>下面介绍一下角色的使用方法。<br>（1）创建只读角色role_sel，赋予角色拥有查询employees数据库的权限。 mysql&gt;create role role sel;<br>Query ok,0 rows affected (0.15 sec)<br>mysql&gt;grant select on employees.* to role sel; Query oK, 0 rows affected (0.10 sec)</p>
<p>≦ 489 ≧<br>26.3其他安全设置选项 471<br>（2）创建只读用户emp_sel，将role_sel角色赋予emp_sel用户。 mysql&gt;create user emp_sel@’%identified by emp sel123’:<br>Query ok, 0 rows affected (0.15 sec) mysql&gt;grant role sel to emp sel@’%’; Query Ok, 0 rows affected (0.10 sec)<br>（3）查看emp_sel用户权限，使用usingrole选项，将列出角色所拥有的权限。<br>mysql&gt;show grants for emp_sel@’%’ using role sel; 1Grants for emp_sel@%<br>1GRANT USAGE ON*<em>TOemp Sel@%<br>GRANT SELECT ONemployees</em>TOemp_sel@%<br>1 GRANT role_sel@%Toemp_sel@% 3 rows in set (o.00 sec)<br>（4）对账户在登录数据库之后要激活的role进行设置。 mysql&gt;set default role all to emp_sel@’%’;<br>Query ok, 0 rows affected (0.01 sec)（5）用emp_sel用户登录数据库实例。<br>[mysq13307@1oca1host ~]$ mysq] -uemp se] -pemp_se1123 -h127.0.0.1-P3488<br>welcome to the MysQL monitor. commands end with ;or g. Your MysQL connection id is 47<br>Server version: 8.0.11 MysQL Community Server - GPL<br>Type ‘help;’or h’ for help. Type \c’ to clear the current input statement. mysql&gt; show databases;<br>I Database I employees<br>information schema 2rows in set (o.00 sec) mysql&gt;use employees<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed<br>mysql&gt;select count(o) from dept_emp;<br>1 count(0) 1 3316031<br>1 row in set(0.36 sec)<br>通过命令确认emp_sel用户已经拥有employees数据库的查询权限。分别使用REVOKE 命令、DROPROLE命令回收角色权限和删除角色，使用方法比较简单，读者可以自己尝试。 26.3其他安全设置选项<br>除了上面介绍的那些需要注意的安全隐患外，MySQL本身还带着一些选项，适当地使用<br>这些选项将会使数据库更加安全。 26.3.1密码插件<br>在MySQL8.0版本之前，PASSWORD函数生成的密码是41位；8.0以后，MySQL废弃了</p>
<p>≦ 490 ≧<br>472 第26章MySQL权限与安全<br>passwordO函数，默认改用caching_sha2_password插件进行加密，使用缓存解决连接时的延时问题。<br>MySQL5.7中查看PASSWORD函数的结果如下：<br>mysql&gt; SELECT PASSWORD(‘mypass’); 1PASSwORD(‘mypass’)<br>1*6C8989366EAF75BB670AD8EA7A7FC1176A95CEF4<br>MySQL8.0中执行的结果如下，可以看到PASSWORD函数已经被废弃。 mysql&gt; SELECT PASSWORD(mypass’）);<br>ERROR 1064 (42000):You have an error in your SQL syntax; check the manual that corresponds to your MysQL server version for the right syntax to use near (‘mypass’)’at line 1<br>MySQL8.0中查看用户默认的密码插件：<br>mysql&gt;sELECT User, Host, plugin from mysql.user; Iuser IHost 1plugin<br>emp 127.0.0.1 caching sha2 password1 emp localhost caching_sha2 _password<br>9 rows in set (o.00 sec)<br>结果显示，MySQL8.0默认密码插件为caching_sha2_password，MySQL8.0以前的密码插件为mysql_native_password。这样就会出现一个问题，当8.0以后的客户端连接8.0以前的客户端时，没有问题，因为新客户端可以理解新旧两种加密算法。但是反过来，当8.0以前的客户端需要连接8.0以后的服务器时，由于无法理解新的密码算法，发到服务器端的密码还是<br>旧的算法加密后的结果，于是导致在新的服务器上出现下面无法认证的情况： shell&gt; mysql -h localhost -u root<br>ERROR 2059 (Hy000):Authentication plugin ‘caching sha2 password cannot be loaded:&#x2F;usr&#x2F;local&#x2F; mysql&#x2F;Tib&#x2F;plugin&#x2F;caching_sha2_password.so:cannot open shared object file:No such file or directory<br>对于这个问题，可以采用以下办法解决。<br>（1）在服务器端用alteruser命令修改密码的加密方式，客户端可以进行正常连接： mysql&gt; alter user user‘@’host’ identified with mysql_native password By password’;<br>（2）在my.cnf的[mysqld]中增加默认密码认证插件参数并重启服务器，这样新的数据库<br>连接成功之后做的grant操作后生成的新密码全部变成旧的密码格式。 default authentication_plugin&#x3D;mysql_native_password<br>注意：这个参数只是为了支持8.0版本前的客户端才进行设置，但是这将使得新建或者修改的用<br>户密码全部变成旧的格式，降低了系统的安全性。<br>26.3.2safe-user-create<br>此参数如果启用，用户将不能用GRANT语句创建新用户，除非用户有mysql数据库中user<br>表的INSERT权限。如果想让用户具有授权权限来创建新用户，应给用户授予下面的权限： mysql &gt; GRANT INSERT（user) ON mysq7.user To user_name‘@’host_name’;<br>这样确保用户不能直接更改权限列，必须使用GRANT语句给其他用户授予该权限。以下例子描述了这个过程。</p>
<p>≦ 491 ≧<br>26.3其他安全设置选项 473<br>（1）用root创建用户emp，emp可以将权限授予其他用户：[mysq13307@loca1host ~]s mysql -uroot<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 64<br>Server version: 5.7.22-1og MysQL Community Server (GPL)<br>mysql&gt;grant select,insert on employees,* to emp@localhost with grant option;<br>Query ok,0 rows affected,2 warnings （o.o0 sec)（2）使用emp创建新用户成功：<br>mysql&gt;grant select on employees.* to emp@locaThost;<br>Query ok,0 rows affected,1 warning (0.00 sec)（3）用safe-user-create选项重启数据库：<br>[mysq13307@localhost bin]#.&#x2F;mysqld safe –safe-user-create &amp;[1]32422<br>Lmysq13307@localhost bin]# starting mysqld daemon with databases from &#x2F;var&#x2F;lib&#x2F;mysql<br>（4）重新用emp创建用户失败：[root@localhost bin]# mysql -uemp<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 2<br>Server version: 5.7.22-community-1og MysQL community Edition (GPL)<br>Type help;’or h for help. Type c’ to clear the buffer. mysql&gt; grant select on employees.* to‘emp1‘@’192.168’;<br>ERRoR 1410 (42000):You are not allowed to create a user with GRANT mysql&gt;&#x2F;exit<br>（5）用root登录，给emp赋予mysql数据库中user表的insert权限：[root@localhost bin]# mysql -uroot<br>welcome to the MysQL monitor. commands end with ; or g. Your MysQL connection id is 5<br>Server version:5.7.22-community-1og MysQL Community Edition (GPL) Type ‘help;or ‘h for help. Type \c’ to clear the buffer.<br>mysql&gt; grant insert on mysql.user to emp@localhost; Query ok,0 rows affected (o.o0 sec)<br>mysql&gt; exit Bye<br>（6）用emp重新登录，授权用户成功：[root@localhost bin]# mysq] -uemp<br>Welcome to the MysQL monitor. commands end with ;or  Your MysQL connection id is 7<br>Server version:5.7.22-community-log MysQL community Edition (GPL) Type help;or \h’ for help. Type cto clear the buffer.<br>mysql&gt; grant select on employees.* to *empl‘@localhost; Query oK,O rows affected (o.oo sec)<br>26.3.3表空间加密<br>从MySQL5.7开始，InnoDB表空间加密功能为每个表的表空间和一般表空间（general tablespace）提供静态数据加密功能。表空间加密使用双层加密密钥体系结构，包括主加密密钥和表空间密钥。当表空间被加密时，表空间密钥被加密并存储在表空间头部。当应用程序</p>
<p>≦ 492 ≧<br>474 第26章MySQL权限与安全<br>或经过身份验证的用户想要访问加密的表空间数据时，InnoDB使用主加密密钥来解密表空间密钥。<br>从MySQL8.0开始，又提供了重做日志（redolog）和回滚日志（undolog）的加密。与表空间数据一样，当重做日志和回滚日志数据写人磁盘时，将数据进行加密，而从磁盘读取日志数据时再进行解密，当日志数据被载人内存以后，数据就是已经被解密的了。如果要启用重做日志和回滚日志加密，可以配置innodb_redo_log_encrypt和innodb_undo_log_encrypt参数，加密生效后，只对新的日志有效，而旧的日志数据将保持原样不变，即不再被重新加密。<br>开启表空间加密将大大增强数据文件和日志文件的安全性。 26.3.4 skip-grant-tables<br>skip-grant-tables选项导致服务器根本不使用权限系统，从而给每个人以完全访问所有数据库的权力。通过执行mysqladmin flush-privileges或mysqladmin reload命令，或执行flush privileges语句，可以让一个正在运行的服务器再次开始使用授权表。<br>下面的例子演示了此参数的使用。<br>使用–skip-grant-tables启动数据库。<br>[mysq13307@localhost ~]s mysqld_safe –skip-grant-tables &amp;[1]15298<br>[mysql3307@localhost ~]s Starting mysqld daemon with databases from &#x2F;var&#x2F;lib&#x2F;mysql<br>此时没有权限的用户可以直接登录，而不需要密码。[mysq13307@localhost ~]s mysql -uemp_test<br>welcome to the MysQL monitor.Commands end with : or g Your MysQL connection id is 9<br>Server version:5.7.22-1og MysQL Community server (GPL) emp test@localhost:mysql 3307.sock [(none)]&gt;<br>O此时执行flushprivileges命令，重新使用权限系统。 mysql&gt;flush privileges;<br>Query oK, 0 rows affected (o.o1 sec)<br>退出后再次登录，将无法登录成功。[mysq13307@localhost ~]s mysql -uemp_test<br>ERRoR 1045 (28000): Access denied for user ‘emp_test‘@’localhost (using password:YEs) 26.3.5 skip-networking<br>在网络上不允许TCP&#x2F;IP连接，所有到数据库的连接必须经由命名管道（NamedPipe）共享内存（SharedMemory）或UNIX套接字（SOCKET）文件进行。这个选项适合应用和数据库共用一台服务器的情况，其他客户端将无法通过网络远程访问数据库，这样大大增强了数据库的安全性，但同时也带来了管理维护上的不方便，来看下面的例子。<br>服务器上打开此选项（默认关闭）并重启MySQL服务。[mysq1d]<br>skip-networking<br>port &#x3D;3307<br>远程客户端进行连接。</p>
<p>≦ 493 ≧<br>26.4小结 475<br>[mysq13307@loca1host ~]s mysql -emp -h192.168.7.55 -P3307 Enter password:<br>ERROR 2003 (HY000): Can’t connect to MySQL server on 192.168.7.55′(111)<br>关闭此选项后重启服务器。[mysq1d]<br>#skip-networking<br>port &#x3D;3307<br>远程客户端进行连接。<br>[mysq13307@1oca1host ~]s mysql -emp -h192.168.7.55 -P3307 -p Enter password:<br>welcome to the MysQl monitor. Commands end with ; or g. Your MySQL connection id is 4<br>Server version: 5.7.22-1og MysQL Community Server (GPL) 26.3.6skip-show-database<br>使用skip-show-database选项，只允许有showdatabases权限的用户执行showdatabases 语句，该语句显示所有数据库名。不使用该选项，允许所有用户执行showdatabases，但只显示用户有showdatabases权限或部分数据库权限的数据库名。下面的例子显示了启用此选项后 showdatabases的执行结果：<br>[mysq13307@locaThost ~]s mysqld safe –skip-show-database &amp;[1]15027<br>[mysq13307@localhost ~]s starting mysqld daemon with databases from &#x2F;var&#x2F;lib&#x2F;mysql<br>[mysq13307@loca1host ~jsmysq1 -uemp -h127.0.0.1 -P3307 -p Enter password:<br>welcome to the MysQL monitor. Commands end with ;or g. Your MysQL connection id is 4<br>Server version: 5.7.22-1og MysQL community Server (GPL) <a href="mailto:&#x65;&#x6d;&#112;&#64;&#49;&#50;&#x37;&#46;&#x30;&#x2e;&#48;&#46;&#49;">&#x65;&#x6d;&#112;&#64;&#49;&#50;&#x37;&#46;&#x30;&#x2e;&#48;&#46;&#49;</a>:3307 [(none)]&gt;show databases;<br>ERROR 1227 (42000): Access denied; you need (at least one of) the SHOW DATABASES privilege（s)<br>for this operation 26.4小结<br>权限和安全问题在任何数据库中都是非常重要的。本章重点介绍了MySQL中的权限管理以及可能存在的一些安全问题，并给出了很多例子加以详细说明。最后还讨论了MySQL 提供的一些安全方面的参数，用户可以根据实际情况选择使用。</p>
<p>≦ 494 ≧<br>第27章 MySQL监控<br>随着企业的发展壮大，在线服务器的数量越来越多，软硬件故障发生的概率也随之越来越高。这时，如果没有一个足够完善和强大的监控系统，当主机发生异常时，则可能无法及时发现和处理，从而造成业务的中断。尤其对于企业的核心业务系统，这将是不可承受之重。<br>因此，一个好的监控系统对企业来说正变得越来越重要。 27.1如何选择一个监控方案<br>在这里主要提出对两个方面的思考：第一，应该选择何种监控方式；第二，如何选择适合自己的监控工具。<br>27.1.1选择何种监控方式<br>常见的监控方式主要有以下3种：（1）自己写程序或者脚本进行监控；<br>（2）监控采用商业解决方案；（3）监控开源软件方案。<br>第一种方案，当机器很少时，可以通过写程序或者编写脚本的方式监控线上的服务器，但是随着业务量的增大，业务上需要监控的点变得越来越细化，需要部署的脚本也越来越多，通过脚本进行监控的方法基本上无法满足业务的需求，并且脚本的后期维护成本也很大。常常会看到企业开始初期，服务器上布满了大大小小的监控脚本。<br>第二种方案，选择一个商业的解决方案，通过第三方为企业实现一套完整的监控系统。采用这种方案的优点是能在短时间内搭建一套监控平台，并且平台有很受欢迎的展现方式，如报表、美观的用户界面等，但是也存在一定的缺点，比如说这套平台需要花费很高的成本，并且随着业务的发展可能需要监控的粒度越来越细，当前的系统无法更好地去扩展。<br>第三种方案，选择一套已有的开源工具，通过开源工具对企业的生产系统进行监控，选择开源工具的优势包括完全免费、定制能力强、完全可控、集中化管理、可视性好。但是开源工具也有一定的缺点，比如说需要花费大量时间阅读相关文档。</p>
<p>≦ 495 ≧<br>27.2常用的网络监控工具 477<br>27.1.2如何选择适合自己的监控工具<br>出于成本考虑，最终确定了开源的解决方案，但是在软件选型时我们需要选择的监控系统软件具备以下几项功能。<br>（1）监控系统必须具有对主机的监控，包括对主机的CPU、内存、网络、整体负载、相关进程数的监控等。<br>（2）监控系统必须具有对数据库的监控，主要包括对数据库的一些自身的性能指标进行监控，比如缓冲池的命中率、连接数等。<br>（3）监控系统要做到监控的实时性，监控系统需要具有相关触发报警的功能，当主机或者数据库发生异常时，要在第一时间进行短信报警、邮件报警等。<br>（4）在数据的表现形式上来讲，监控系统需要具备良好的图形展示的功能，当数据库发生异常时，数据库管理员能根据监控系统中异常时刻的趋势图迅速地定位到故障的产生原因。<br>（5）在协议的支持方面，监控系统客户端需要支持现有协议，如IPMI、SNMP等协议。（6）在数据存储方面，要充分了解监控系统监控数据的存取，包括以文件的形式存储、<br>用数据库的方式进行存储等，在部署监控系统时提前对数据进行规划。<br>（7）监控系统的部署和配置的复杂度、界面的友好性以及对中文的支持。<br>目前常见的开源监控系统包括Open-Falcon、Nagios、Zabbix、Ganglia等很多种，那么，这么多开源的监控系统，我们到底该选哪种呢？<br>还是要再次明确监控系统选择的目标：我们需要一套既能灵活地完成服务器各种监控信息的采集、分析、存储，又能支持快速的报警和信息发送的软件。那么上述哪些开源软件具备这些功能呢？<br>27.2常用的网络监控工具<br>下面将分别对Open-Falcon、Nagios、Zabbix这几个开源的网络监控工具进行简单的介绍。 27.2.1Open-Falcon简介<br>Open-Falcon是小米公司根据SRE、SA、DEVS的运维经验和反馈，结合业界众多互联网公司的监控经验而设计的一个分布式的监控系统。Open-Falcon后端使用Go语言开发，可自动发现并采集安装了Agent的机器的各种数据和指标，主动上报至Server端，不需要用户在 Server做任何配置，具有强大的可扩展性和灵活的数据采集能力。<br>Open-Falcon的架构如图27-1所示。<br>在图27-1中，在每台被监控的机器安装falcon-agent代理，falcon-agent会自动采集监控数据和指标，将数据上传至Transfer。Transfer接收到数据后，会检查和规整数据，再转发到多个后端系统去处理。当转发到每个后端业务系统，Transfer根据一致性hash算法，进行数据分片，来达到后端业务系统的水平扩展。Transfer将数据转发到Graph组件，Graph收到数据后，以Rrdtool的数据归档方式来存储，同时，Transfer也将数据转发到Judge，数据到达 Judge后，会触发相关策略的判定，来决定是否满足报警条件。如果满足条件，则会发送给</p>
<p>≦ 496 ≧<br>478 第27章MySQL监控 Alarm，Alarm再以邮件、短信、米聊等形式通知用户。<br>策略<br>统计信息上报 Heartbeat 加载Webportal<br>Dashboard<br>server MySQL<br>插件、特殊 T<br>采集项、IP 绘图，查询数据白名单下发<br>策略下发 聚合结果再次push到transfer<br>Falcon-agent transfer query aggregator<br>数据上报<br>proxy-gateway 个<br>致性has 致性hash 致性hash 聚合多个metric<br>数据上报<br>数据存储归档查询<br>Judge Graph 判定结果</p>
<blockquote>
<p>email<br>Alarm sms<br>米聊 callback<br>图27-1Open-Falco架构图<br>用户可以在Dashboard仪表盘查看关心的数据，Query组件通过Graph的rpc接口查询数据。由于Rrdtool在处理监控指标方面的效率非常高，即使查询一年的监控数据也能在秒级返回结果。<br>HeartbeatServer定期加载MySQL中的内容，分发Agent要执行的插件、要监控的进程、端口；Judge也会定期和HeartbeatServer保持沟通，来获取相关的报警策略。<br>Portal是一个Web项目，无状态，支持水平扩展。用户可以在Portal配置报警策略，并在MySQL中存储报警策略。<br>Open-Falcon具备以下几项监控功能。（1）网络监控。<br>（2）主机系统监控。<br>0 网络接口流量（进出口网卡流量）。<br>0 监控CPU负载、内存使用情况等。 o 监控磁盘的空间、磁盘使用率等。<br>内核参数、NTP偏移等。<br>（3）Open-Falcon常见的检测对象。<br>服务器资源：CPU、磁盘、内存、进程、端口等。服务器类型：Web、JVM、FTP、数据库、中间件。操作系统：Linux、Windows。<br>0 网络接口：流量、转发速度、丢包率。<br>设备运行状态：风扇、电源、温度。<br>0 机房运行环境：电流、电压、温湿度。</p>
</blockquote>
<p>≦ 497 ≧<br>27.2常用的网络监控工具 479<br>27.2.2Nagios简介<br>Nagios是一款用于系统和网络监控的应用程序。它可以在用户设定的条件下对主机和服务进行监控，当状态改变时发出相关告警信息。<br>Nagios通常由1个主程序（Nagios）、1个插件程序（Nagios-plugins）和4个可选的附件组件（NRPE、NSCA、NSClient++和NDOUtils）组成。Nagios的监控工作都是通过插件功能实现的，因此，Nagios和Nagios-plugins是服务器端工作所必需的组件。4个附件组件中的功能如下。<br>ONRPE：用来在监控的远程Linux&#x2F;UNIX主机上执行脚本插件，以实现对这些主机资源的监控。<br>ONSCA：用来让被监控的远程Linux&#x2F;UNIX主机主动将监控信息发送给Nagios服务器。 ONSClient++：安装在Windows主机上的组件，主要用来监控Windows主机。<br>ONDOUtils：用来将Nagios的配置信息和各Event产生的数据存入数据库，以实现这些数据的快速检索和处理。<br>这4个附件组件中，NRPE和NSClient++工作于客户端，NDOUtils工作于服务器端，而 NSCA则需要同时安装在服务器端和客户端。<br>Nagios的工作原理如图27-2所示。<br>send-nsca<br>web NSCA NRPE Linux&#x2F;Unix<br>SNMP<br>Nagios Nagios Daemon Plugins SNMPSwitch&#x2F;Router<br>SNMP Printer<br>NDOUtils<br>SNMP<br>Windows<br>NSClient+<br>Database<br>图27-2Nagios工作原理图<br>Nagios的功能是监控服务和主机，但是它自身并不包括这部分功能，所有的监控、检测功能都是通过各种插件来完成的。启动Nagios后，它会周期性地自动调用插件去检测服务器状态，同时Nagios会维持一个队列，所有插件返回来的状态信息都进入队列，Nagios每次都从队首开始读取信息，并进行处理后，把状态结果通过Web显示出来。Nagios提供了许多插件，利用这些插件可以方便地监控很多服务状态。安装完成后，在Nagios主目录下的&#x2F;libexec 里放有Nagios自带的可以使用的所有插件，如check_disk是检查磁盘空间的插件，check_load 是检查CPU负载的，等等。每一个插件可以通过运行.&#x2F;check_xxx-h来查看其使用方法和功能。 Nagios可以识别4种状态的返回信息，即0（OK）表示状态正常，1（WARNING）表示出现</p>
<p>≦ 498 ≧<br>480 第27章MySQL监控<br>一定的异常，2（CRITICAL）表示出现非常严重的错误，3（UNKNOWN）表示被监控的对象已经停止了。Nagios根据插件返回来的值来判断监控对象的状态，并通过Web显示出来，以供管理员及时发现故障。<br>Nagios支持的监控功能如下：<br>（1）网络监控服务（SMTP、POP3、HTTP、NNTP、PING等）；（2）监控主机资源（处理器负荷、磁盘利用等）；<br>（3）插件设计使得用户可以方便地扩展自己所需要定制的监控项；（4）并行服务检测机制；<br>（5）具备定义网络分层结构的能力，用“parent”主机定义来表达网络主机间的关系，这种关系可被用来发现和明晰主机岩机或不可达状态；<br>（6）具有快速的消息通知功能，当服务或者主机产生问题时能及时地将告警发送给相关业务负责人（可以通过E-mail、短信、用户定义方式），可高效地保证服务器的维护；<br>（7）具备定义事件句柄功能，它可以在主机或服务的事件发生时获取更多问题定位；（8）自动的日志回滚；<br>（9）可以支持并实现对主机的见余监控；<br>（10）友好的Web界面用于查看当前的网络状态、通知和故障历史、日志文件等。 27.2.3Zabbix简介<br>Zabbix是一个基于Web界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案，由一个国外的团队持续维护并且进行版本更新，可以自由下载使用，运作团队靠提供收费的技术支持赢利。Zabbix能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位&#x2F;解决存在的各种问题。<br>Zabbix通过C&#x2F;S模式采集数据，通过B&#x2F;S模式在Web端展示和配置。Zabbix由两部分构成：ZabbixServer与可选组件ZabbixAgent。<br>ZabbixAgent需要安装在被监视的目标服务器上，主要完成对硬件信息或与操作系统有关的内存、CPU等信息的收集。ZabbixAgent可以运行在Linux、Solaris、HP-UX、AIX、FreeBSD、 OpenBSD、OSX、Tru64&#x2F;OSF1、Windows等系统上。<br>ZabbixServer可以单独监视远程服务器的服务状态，同时也可以与ZabbixAgent配合，<br>可以轮询ZabbixAgent主动接收监视数 Zabbix体系结构<br>据，同时还可被动接收ZabbixAgent发送的数据，通过收集SNMP和Agent发送的数据，写人MySQL数据库，再通过<br>Apache等软件在Web前端显示，Zabbix Web Zabbix Serve Server需运行在LAMP（Linux+Apache+<br>MySQL+PHP）环境下，对硬件要求低。 ZabbixAgentLin<br>Zabbix的工作原理如图27-3所示。外部 ZabbixAgent负责数据收集操作，将脚本<br>定制的数据传送到ZabbixServer，Zabbix<br>图27-3Zabbix工作原理图<br>Server会把相关数据存人到MySQL数据</p>
<p>≦ 499 ≧<br>27.3Zabbix部署 481<br>库中。最终用户通过ZabbixWeb端查看数据，并且ZabbixWeb端具备报警等功能。<br>Zabbix的主要特点如下：<br>安装与配置简单，学习成本低；<br>支持多语言（包括中文）；免费开源；<br>0 自动发现服务器与网络设备；<br>O 分布式监视以及Web集中管理功能； 0 可以无Agent监视；<br>0 用户安全认证和柔软的授权方式；<br>通过Web界面设置或查看监视结果；<br>E-mail等通知功能。 Zabbix具有以下几项功能：<br>具备常见的商业监控软件所具备的功能（主机的性能监控、网络设备性能监控、数据库性能监控、FTP等通信协议的监控、多种告警方式、详细的报表图表绘制）。<br>支持自动发现网络设备和服务器。<br>支持分布式，能集中显示、管理分布式的监控点。<br>扩展性强，Server提供通用接口，可以自己开发完善各类监控。 27.2.4几种常见开源软件比较<br>Open-Falcon和Nagios、Zabbix的优缺点对比如下。<br>OOpen-Falcon：采集数据灵活。安装Agent后，不需要配置Server端，即可自动发现并采集数据；整个系统无核心单点，可以水平扩展，支持每个周期上亿次的数据采集；单机支持每分钟200万metric的上报和存储；采用rrdtool的数据归档策略，秒级返回上百个metric 一年的历史数据。它的缺点是组件太多，部署和监控有点烦琐；graph集群缩扩容时，历史数，据有损，历史数据无法迁移；系统权限控制不足，数据安全性较弱。<br>ONagios：适合监视大量服务器上面的大批服务是否正常，重点并不在图形化的监控，其集成的很多功能，例如报警，在绘图以及图形塑造方面精细度比较弱。<br>OZabbix：最大的优点是开源，无软件成本投入；对Server端的设备性能要求低，支持设备多，支持分布式集中管理，开放式接口，扩展性强，并且第三方插件percona-zabbix-templates 专门定制了对数据库的监控。其缺点是数据量太大时，对于数据库清理不是很方便。<br>通过以上论述，如果监控机器数量中等，对安全性要求高，可以采用Zabbix+ percona-zabbix-templates插件对数据库进行监控；如果监控机器数量多，监控系统放在内网，没有安全性顾虑，可以采用Open-Falcon+mymon对数据库进行日常监控。<br>出于篇幅考虑，本章将会详细介绍Zabbix+percona-zabbix-templates插件的使用。 27.3Zabbix部署<br>Zabbix监控环境部署如表27-1所示。</p>
<p>≦ 500 ≧<br>482 第27章MySQL监控<br>表27-1 Zabbix监控环境部署<br>角色 IP地址 主机名字 操作系统 用途 Zabbix Server 192.168.8.81 ip81 CentOS 6 Zabbix服务端 Zabbix Agent 192.168.7.83 ip83 CentOS 6 MySQL Server<br>27.3.1ZabbixServer软件安装<br>ZabbixServer软件安装大概需要以下几个步骤。（1）安装LAMP环境：<br>[root@ip81 <del>]#yum install mysql-server httpd php<br>（2）安装ZabbixWeb所需的依赖包：<br>[root@ip81 ~]#yum install gcc gcc-c++ autoconf php-mysql httpd-manual mod ssl mod perl mod auth_mysq1 php-gd php-xm1 php-mbstring php-1dap php-pear php-xmlrpc php-bcmath mysql-connector-odbc mysql-devel 1ibdbi-dbd-mysql net-snmp-devel curl-devel unixoDBC-devel openIPMI-devel java-devel 1ibssh2-devel.x86 64 open1dap open1ldap-devel<br>（3）创建Zabbix运行的用户：[root@ip81 ~]#groupadd zabbix<br>[root@ip81 -]#useradd -g zabbix zabbix（4）安装Zabbix Server:<br>[root@ip81</del>]#wget-c<a target="_blank" rel="noopener" href="https://sourceforge.net/projects/zabbix/files/ZABBIx%20Latest%20stable/">https://sourceforge.net/projects/zabbix/files/ZABBIx%20Latest%20stable/</a> 3.4.12&#x2F;zabbix-3.4.12.tar.gz&#x2F;down1oad<br>[root@ip81 <del>]#tar zxvf zabbix-3.4.12.tar.gz[root@ip81</del>]#cd zabbix-3.4.12<br>[root@ip81 ~]#export MYsQL _HoME&#x3D;&#x2F;home&#x2F;mysq1&#x2F;mysq1home[root@ip81 ~]#export C INCLUDE PATH&#x3D;SMYSQL HOME&#x2F;include[root@ip81 ~]#export LD LIBRARY_PATH&#x3D;SMYSQL HOME&#x2F;lib<br>[root@ip81]#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix –enable-server –enable-agent –enable-proxy –with-mysql&#x3D;&#x2F;usr&#x2F;bin&#x2F;mysql_config –with-net-snmp –with-libcurl –with-openipmi –with<br>-unixodbc–with-1dap—with-ssh2–enable-java[root@ip81 ~]#make &amp;&amp;make install<br>27.3.2ZabbixServer配置与启动<br>ZabbixServer安装配置和启动大概需要以下几个步骤。（1）创建Zabbix数据库和MySQL用户：<br>mysql&gt; create database zabbix character set utf8; Query ok, 1 row affected (0.05 sec)<br>mysql&gt; create user zabbix‘@’%identified by123456’; Query ok,0 rows affected (0.16 sec)<br>mysql&gt; grant all on zabbix.* tozabbix‘@’%’;<br>Query ok,O rows affected (0.03 sec) mysql&gt; flush privileges;<br>Query ok, 0 rows affected (0.04 sec)（2）导人Zabbix数据库初始数据：[root@ip81 ~]#cd database&#x2F;mysql&#x2F;<br>[root@ip81 ~]#mysql -s&#x2F;tmp&#x2F;mysql.sock zabbix&lt;schema.sq][root@ip81 ~]#mysq] -s&#x2F;tmp&#x2F;mysql.sock zabbix &lt;images.sql;[root@ip81 ~]#mysq] -s &#x2F;tmp&#x2F;mysql.sock zabbix &lt; data.sql;<br>（3）配置Zabbix配置文件。</p>
<p>≦ 501 ≧<br>27.3Zabbix部署 483<br>编辑ZabbixServer的配置文件&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_server.conf，修改以下参数： ListenPort&#x3D;10051<br>LogFile&#x3D; &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs&#x2F;zabbix server.1og PidFile&#x3D; &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs&#x2F;zabbix server.pid DBHost&#x3D;192.168.7.81<br>DBName&#x3D;zabbix DBUser&#x3D;zabbix<br>DBPassWord&#x3D;123456 DBPort&#x3D;3306<br>DBSocket&#x3D;&#x2F;tmp&#x2F;mysql.sock（4）配置Zabbix服务。<br>从安装目录复制zabbix_server脚本并编辑：[root@ip81 <del>]#cd zabbix-3.4.12<br>[root@ip81 ~]#cp misc&#x2F;init.d&#x2F;fedora&#x2F;core&#x2F;zabbix server &#x2F;etc&#x2F;init.d&#x2F;[root@ip81</del>]#mkdir -p&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs<br>[root@ip81 <del>]#chown -R zabbix:zabbix&#x2F;usr&#x2F;local&#x2F;zabbix<br>[root@ip81 ~]#vi &#x2F;etc&#x2F;init.d&#x2F;zabbix server[root@ip81 ~]#cat &#x2F;etc&#x2F;init.d&#x2F;zabbix server<br>BASEDIR&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix<br>（5）开启Zabbix安全限制。<br>调整防火墙规则（开放端口10051）：<br>[root@ip81</del>]#iptables -A INPuT -p tcp -m tcp –dport 10051 -j ACCEPT[root@ip81 ~]#service iptables save<br>Saving firewall rules to &#x2F;etc&#x2F;sysconfig&#x2F;iptables: ok（6）启动Zabbix Server：<br>[root@ip81 ~]#service zabbix server start<br>starting Zabbix Server:（7）停止ZabbixServer：<br>[root@ip81 ~]#service zabbix server stop Stopping Zabbix server:<br>（8）配置ZabbixServer开机自动启动：[root@ip81 ~]#chkconfig –add zabbix server<br>[root@ip81 ~]#chkconfig –level 35 zabbix server on 27.3.3配置ZabbixWeb服务端<br>配置ZabbixWeb服务大概需要以下几个步骤。<br>（1）将ZabbixWeb文件复制到ApacheWeb目录中。<br>将安装目录中的frontends复制到指定的Webroot目录中：[root@ip81 ~]#cd zabbix-3.4.12<br>[root@ip81 ~]#cp -ra frontends&#x2F;php&#x2F;*&#x2F;var&#x2F;www&#x2F;html&#x2F;[root@ip81 ~]#chown -R apache.apache &#x2F;var&#x2F;www&#x2F;html&#x2F;（2）Apache配置：<br>[root@ip81 ~]#cat &#x2F;etc&#x2F;httpd&#x2F;conf&#x2F;httpd.conf<br>ServerName 192.168.7.81:80（3）PHP配置。<br>&#x2F;etc&#x2F;php.ini配置如下，注意这里必须这样配置，否则Web界面安装检查会失败。</p>
<p>≦ 502 ≧<br>484 第27章MySQL监控<br>date.timezone &#x3D; Asia&#x2F;shanghai<br>memory_1imit&#x3D; 128M post max size &#x3D; 16M<br>max execution_time &#x3D; 300<br>max_input time &#x3D; 300 session.auto_start&#x3D;0<br>mbstring.func_overload &#x3D;2 开启httpd服务：<br>[root@ip81]#servicehttpdstart<br>配置httpd开机自动启动：<br>[root@ip81 ~]#chkconfig httpd on<br>（4）ZabbixWeb安装。<br>访问Web界面<a target="_blank" rel="noopener" href="http://192.168.7.81,进行zabbix相关的web配置,配置完成后使用默认用户名为admin(密码为zabbix)登录即可.zabbix的安装界面如图27-4所示./">http://192.168.7.81，进行Zabbix相关的Web配置，配置完成后使用默认用户名为admin（密码为zabbix）登录即可。Zabbix的安装界面如图27-4所示。</a><br>安装过程中的检查信息如图27-5所示，安装后的统计信息如图27-6所示，安装成功后的登录窗口如图27-7所示。<br>ZABBIX ZABBIX<br>Check of pre-requisites<br>宝香多品民客<br>Zabbix 3.4<br>a<br>图27-4Zabbix安装界面图27-5Zabbix安装前的环境检查<br>ZABBIX ZABBIX<br>zabbix<br>Sion in orsign in asgues<br>xNo<br>图27-6Zabbix安装成功输出图27-7Zabbix安装成功后的登录窗口<br>注意这里默认密码是“zabbix”，进人系统第一件事就是修改Zabbix的后台默认密码，可以通过Administration→Users→Admin→ChangePassword来修改。</p>
<p>≦ 503 ≧<br>27.3Zabbix部署 485<br>27.3.4ZabbixAgent安装和配置<br>安装ZabbixAgent大概需要以下几个步骤。（1）下载安装ZabbixAgent软件：<br>[root@ip83<del>]#wget -c <a target="_blank" rel="noopener" href="https://sourceforge.net/projects/zabbix/files/ZABBIx%20Latest%20stabTe/">https://sourceforge.net/projects/zabbix/files/ZABBIx%20Latest%20stabTe/</a> 3.4.12&#x2F;zabbix-3.4.12.tar.gz<br>[root@ip83</del>]#tar zxvf zabbix-3.4.12.tar.gz[root@ip83<del>]#cd zabbix-3.4.12<br>[root@ip83</del>]#.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix –enable-agent[root@ip83<del>]#make &amp;&amp;make instal]<br>[root@ip83</del>]#cp misc&#x2F;init.d&#x2F;fedora&#x2F;core&#x2F;zabbix agentd &#x2F;etc&#x2F;init.d&#x2F;（2）配置zabbix_agentd:<br>[root@ip83<del>]#groupadd zabbix<br>[root@ip83</del>]#useradd -g zabbix zabbix<br>[root@ip83<del>]#mkdir -p &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs<br>[root@ip83</del>]#chown zabbix:zabbix -R&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;[root@ip83<del>]#vi &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conf[root@ip83</del>]#cat &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conf<br>PidFile&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs&#x2F;zabbix agentd.pid LogFile&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;logs&#x2F;zabbix_agentd.1og<br>server&#x3D;192.168.7.81,127.0.0.1 ListenPort&#x3D;10050<br>ServerActive&#x3D;192.168.7.81,127.0.0.1<br>Hostname&#x3D;zabbix_agent83 Timeout&#x3D;15<br>Include&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conf.d&#x2F;<br>为了在本机测试zabbix_get命令，Server和ServerActive参数配置127.0.0.1的ip地址，否则会报错：<br>zabbix get[6248]:Checkaccessrestrictionsin Zabbix agent configuration<br>（3）配置ZabbixAgent系统服务启动脚本：<br>cat &#x2F;etc&#x2F;init.d&#x2F;zabbix_agentd#Zabbix-Directory<br>BASEDIR&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix<br>（4）防火墙设置。开启防火墙端口10050：<br>[root@ip83<del>]iptables -A INPuT -p tcp -m tcp –dport 10050 -j AccEPT<br>[root@ip83</del>]service iptables save（5）启动zabbix_agentd:<br>[root@ip83<del>]#&#x2F;etc&#x2F;init.d&#x2F;zabbix agentd start Starting Zabbix Agent:<br>（6）配置开机自动启动：<br>[root@ip83</del>]#chkconfig –add zabbix agentd<br>[root@ip83<del>]#chkconfig –level 35 zabbix agentd on<br>（7）测试ZabbixAgent。测试ZabbixAgent是否正常工作：<br>[root@ip83</del>]#&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;sbin&#x2F;zabbix agentd -c&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd. conf -t system.uptime<br>system.uptime[u丨37643579]</p>
<p>≦ 504 ≧<br>486 第27章MySQL监控 27.3.5PMP插件介绍和部署<br>PMP（PerconaMonitoringPluginsforZabbix）是一套比较完整的监控MySQL数据库的<br>Zabbix插件。该插件中包括丰富的监控项和触发器规则，通过和Zabbix客<br>zabbix_agentd.conf userparameter_percona_mysql.con<br>户端整合，可以完美地实现对MySQL 数据库的监控。<br>Zabbix使用PMP插件后的监控结构，如图27-8所示。<br>图27-8显示了PMP作为Zabbix 插件监控MySQL的整体架构，首先<br>Zabbix客户端zabbix_agentd会读取 图27-8Zabbix和PMP实现对MySQL监控<br>配置文件zabbix_agentd.conf，zabbix_agentd.conf 则会根据设置载入userparameter_percona_ mysql.conf文件，将Zabbix客户端和PMP插件实现挂接。PMP的主要功能是完成对数据库的相关信息收集和上传操作。对数据库信息的收集操作，主要通过zabbix_agentd传人的zabbix Key，在userparameter_percona_mysql.conf文件来读取相关配置信息，在收集过程中会调用插件自身的get_mysql_stats_wrapper.sh，通过 ss_get_mysql_stats.php收集数据，最终通过调用 zabbix_sender实现上传。<br>部署PMP插件大概需要以下几个步骤。<br>（1）安装和部署ZabbixServer软件、ZabbixWeb。（2）下载安装PMP软件包及其依赖包。<br>（3）通过ZabbixWeb导人PMP中所需要的模板文件。（4）在ZabbixWeb端创建HostGroup（主机组）。<br>（5）在ZabbixWeb端创建Host（注意Web端配置的Hostname必须与zabbixAgent配置中的hostname一致）。<br>（6）将模板关联到所创建的Host。<br>（7）安装和配置PMPAgent，将PMP整合到Zabbix中。（8）重启Zabbix客户端服务。<br>本章的开头部分已经介绍了ZabbixServer和客户端的部署，后面关于这两部分的内容将略过。<br>1.Percona-zabbix-templates下载及其依赖安装安装依赖的相关php包：<br>[root@ip83<del>]# yum insta11 -y php.x86 64 php-mysql.x86 64php-mysq]<br>下载rpm包并安装：<br>[root@ip83</del>]#wget <a target="_blank" rel="noopener" href="https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/6/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm">https://www.percona.com/downloads/percona-monitoring-plugins/percona-monitoring-plugins-1.1.8/binary/redhat/6/x86_64/percona-zabbix-templates-1.1.8-1.noarch.rpm</a><br>[root@ip83<del>]#1s-l percona-zabbix-templates-1.1.8-1.noarch.rpm<br>1 root root 28960 Jan 10 2018 percona-zabbix-templates-1.1.8-1.noarch.rpm<br>[root@ip83</del>]#rpm -ivh percona-zabbix-templates-1.1.8-1.noarch.rpm<br>warning: percona-zabbix-templates-1.1.8-1.noarch.rpm:Header V4 DsA&#x2F;sHAl Signature,key ID cd2efd2a: NOKEY<br>Preparing…#########技井######## 1pcbbxPTae##########################################</p>
<p>≦ 505 ≧<br>27.3Zabbix部署 487<br>Scripts are installed to &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts<br>Templates are installed to&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;templates<br>安装rpm包后，在&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts生成脚本，ZabbixAgent调用这些脚本来采集数据。<br>[root@ip83<del>]#11&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts total64<br>-rwxr-xr-x.1 root root 1251 Jan 10 2018 getmysql stats wrapper.sh-rwxr-xr-x.1 root root 60679 Jan 10 2018 ss get mysql_stats.php<br>在&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;templates生成xml模板，需要在ZabbixWeb端导入这个模板。<br>[root@ip83</del>]# 11 &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;templates total 284<br>1 root root 18866 Jan 10 2018 userparameter percona mysql.conf<br>rw-r–<br>-.1 root root 269258 Jan 10 2018 zabbix agent_template_percona_mysql_server ht<br>2.0.9-sver1.1.8.xml<br>2.ZabbixWeb端导入xml模板<br>将zabbix_agent_template_percona_mysql_server_ht_2.0.9-sverl,1.8.xml文件上传到WindowS。要导人模板，可以在ZabbixWeb中选择<br>Configuration→Templates，然后在“Import” ZABBIMonongenoryReporsConfguratonAds<br>栏下单击“浏览”按钮，选中所需要的XML 文件，单击“Import”按钮即可导人相应的监<br>OUp<br>控模板，如图27-9所示。<br>注意：percona官方提供xml模板，只适用于<br>Zabbix2.0，导入Zabbix3.0会报错。需要先将xml模板先导入Zabbix2.0，再选择导出模板，然后把导出的模板导入Zabbix3.0<br>在ZabbixWeb 中，选择Configuration→<br>Templates，可以查看刚才导人的模板，如图图27-9percona-zabbix-templates模板导入 27-10所示。<br>Aply<br>ns<br>图27-10 percona-zabbix-templates模板查看<br>percona-zabbix-templates中的模板带有丰富的Item项和Trigger项，基本上能覆盖MySQL 日常运维中的常用监控项。<br>3.修改php脚本参数<br>php脚本通过show命令，获取mysql参数和状态。下面配置连接mysql的用户名、密码、</p>
<p>≦ 506 ≧<br>488 第27章MySQL监控端口和soket文件：<br>[root@ip83<del>]#cd&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;[root@ip83 scripts]# vi ss get mysq]_stats.php<br>$mysql user &#x3D;’root’; $mysq1_pass&#x3D;’123456’; $mysq1_port&#x3D;3306;<br>$mysql_socket&#x3D;’&#x2F;tmp&#x2F;mysql.sock’;<br>执行命令测试php脚本能否采集数据：<br>[root@ip83</del>]#&#x2F;usr&#x2F;bin&#x2F;php-q&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;ss get mysql_stats.php–port 5306 –host localhost-items mm<br>mm:71702<br>看到mm：71702，表明php可以连接上mysql数据库了。 4.修改sh脚本参数<br>sh脚本通过showslave status命令，获取mysql从库io进程和sql进程状态；通过php脚本获取mysql的其他状态。在HOME&#x3D;<del>zabbixmysql之后添加连接mysql的用户名和socket文件：<br>[root@ip83</del>]# cd &#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;[root@ip83 scripts]# vi get mysql_stats wrapper.sh RES&#x3D;HoME&#x3D;<del>zabbix mysql -uroot -s&#x2F;tmp&#x2F;mysql.sock -e<br>在zabbix用户的</del>&#x2F;.my.cnf文件配置连接mysql的密码：[root@ip83<del>]# su - zabbix -c”vi ~&#x2F;.my.cnf”<br>[client] user&#x3D;root<br>password&#x3D;123456<br>sh 脚本需要在mysql_cacti_stats.txt之后添加“分号+mysql的端口号”，假设被监控的 MySQL实例端口为3306：<br>[root@ip83</del>]#cd&#x2F;var&#x2F;1ib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;[root@ip83 scripts]# vi get mysql stats wrapper.sh<br>&#x2F;tmp&#x2F;$HosT-mysql_cacti_stats.txt:3306 执行命令测试sh脚本能否采集数据：<br>[root@ip83<del>]#&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;get mysq]_stats wrapper.sh mm 71702<br>执行命令测试sh脚本能否采集io进程和sql进程的状态：<br>[root@ip83</del>]#&#x2F;var&#x2F;Tib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;getmysql _stats_wrapper.sh running-slave<br>从测试结果来看，sh脚本能正确采集到信息。 5.拷贝conf文件<br>将&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;templates下的conf文件复制到ZabbixInclude指定的目录：[root@ip83<del>]# cat &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conflgrep Includelgrep -v “#<br>IncTude&#x3D;&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix_agentd.conf.d&#x2F;[root@ip83</del>]# cd &#x2F;var&#x2F;1ib&#x2F;zabbix&#x2F;percona&#x2F;templates<br>[root@ip83<del>]# cp userparameter_percona mysql.conf &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conf.d&#x2F;<br>[root@ip83</del>]#11 &#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;etc&#x2F;zabbix agentd.conf.d&#x2F; total 20<br>-rw-r–r–. 1 root root 18866 Aug 27 08:35 userparameter percona mysql.conf<br>conf文件记录了Zabbix模板的key和查询脚本的对应关系，例如：[root@ip83~]# head -n 1 userparameter percona mysql.conf<br>UserParameter&#x3D;MysQL.Sort-scan,&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;get mysql stats wrapper.sh kt 如果采集项的key为“MySQL.Sort-scan”，那么agent执行的命令是&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;</p>
<p>≦ 507 ≧<br>27.3Zabbix部署 489<br>scripts&#x2F;get_mysql_stats_wrapper.sh kt<br>[root@ip83<del>]#&#x2F;var&#x2F;lib&#x2F;zabbix&#x2F;percona&#x2F;scripts&#x2F;getmysql_stats wrapper.sh kt 86<br>重启ZabbixAgentd，载人conf文件。<br>#&#x2F;etc&#x2F;init.d&#x2F;zabbix agentd restart 使用zabbix_get命令测试：<br>[root@ip83</del>]#&#x2F;usr&#x2F;local&#x2F;zabbix&#x2F;bin&#x2F;zabbix get-s127.0.0.1-p10050 -k”MysQL.Sort-scan” 86<br>结果显示，ZabbixAgent采集数据与直接执行sh脚本的结果一致。 27.3.6ZabbixWeb端操作<br>在ZabbixWeb中，要实现对被监控主机的监控大概需要以下几个步骤。（1）通过ZabbixWeb端创建监控数据库组。<br>通过Configuration→Hostgroups→Create host group→输入相关组名，如图27-11所示，创建“mysql database”组，该组主要是为了管理所有的MySQL数据库。<br>ZABBIX Mol Host groups<br>图27-11创建Zabbix监控组<br>（2）在Zabbix监控组中创建Zabbix监控主机。<br>创建Zabbix监控的主机，主机名为zabbix_agent83。在Configuration→Hosts→Createhost 中输人相关主机信息，如图27-12所示。<br>注意：ZabbixWeb添加的Hostname，必须与被监控主机zabbix_agentd.conf配置的Hostname<br>致，否则Zabbix无法采集数据。<br>（3）添加被监控主机所需的模板文件，如图27-13所示。<br>ZABBIX Hosts<br>ZABBIX<br>图27-12创建Zabbix被监控主机信息图27-13为监控的客户端配置模板文件</p>
<p>≦ 508 ≧<br>490 第27章MySQL监控<br>（4）查看监控端主机的监控状态，如图27-14所示。当主机的状态为Enabled，Availability 变为绿色时，代表该主机监控正常。<br>ZABBIX<br>Aoo<br>口 NO23<br>图27-14查看被监控主机的监控状态<br>（5）在ZabbixWeb中，选择Monitoring一Latest data，可以查看监控的具体情况，如图27-15 所示。<br>ZABBIXMontrngIn 8 Lalest data<br>201808-272237 2018-08-2721:23:48<br>图27-15Zabbix数据收集状况查看<br>通过相关输出信息，可以看见Agent端的数据库监控信息已经完全发送到了ZabbixServer端。（6）查看Zabbix绘制图形情况，这里选取连接数的绘图，单击Connections，如图27-16<br>所示。<br>ZABBIX Monto<br>ent83:Com O6 024<br>4<br>图27-16查看Zabbix趋势图<br>可以看到，在图27-16中，时间窗口可以任意拖动，窗口中显示最近一段时间的连接数</p>
<p>≦ 509 ≧<br>27.4性能医生orzdba 491<br>变化趋势。<br>27.4性能医生orzdba<br>Zabbix功能十分强大，可以监控数据库各个参数和性能指标，通过Zabbix可以查看较长时间的性能趋势图，但是Zabbix指标监控周期一般在1～3min，线上数据库性能急剧下降或者主机负载突然升高时，通过Zabbix可能无法很快地诊断问题。我们需要一个监控周期更短，可以实时分析数据库的当前状态的工具，这时orzdba将是一个很好的选择。<br>orzdba是淘宝工程师开发并开源的mysql监控工具，它使用Perl开发，用于实时收集Linux 主机和MySQL的性能数据。由于要收集主机数据，需要在MySQL实例所在主机运行orzdba。<br>orzdba的用法如下：<br>she77&gt;orzdaoptns.制片<br>option有很多选项，常用的选项如下。<br>-i–interval:收集信息间隔，单位为秒。-t,–time：输出结果打印当前时间。<br>-l,–load：打印主机负载。-c,–cpu:打印cpu信息。-S,–swap:打印 swap信息。<br>O-S,–socket:指定MySQL实例的socket文件。-com:打印每秒增删改查数量，即TPS和QPS。-hit：打印缓冲池命中率。<br>-innodb_rows：打印每秒增删改查的记录数。<br>-lazy:打印时间、主机负载、cpu信息、swap信息、TPS和QPS、缓冲池命中率。<br>27.4.1orzdba安装<br>由于orzdba用Perl语言开发，使用前需要安装Perl相关的包；orzdba本身不用安装，下载即可使用。需要安装的Perl依赖包如下：<br>yum install perl-Test-Simple.x86_64 yum install perl-Time-HiRes<br>yum install perl-Extutils-CBuilder yum install perl-Extutils-MakeMaker<br>yum install perl-DBD-MySQL yum install perl-DBI<br>安装Perl的version模块、File:LockFfile模块、class-Data-Inheritable模块和Module-Build模块<br>Perl依赖包安装后，在运行orzdba的用户下配置数据库root用户的密码。例如对应的用<br>户为mysql，root@localhost的密码为123456，编辑.my.cnf文件： she11&gt; vi &#x2F;home&#x2F;mysql&#x2F;.my.cnf<br>[client] user&#x3D;root<br>password&#x3D;123456<br>在&#x2F;etc&#x2F;hosts配置本机ip和主机的对应关系，例如本机ip为192.168.1.18，主机名为testos，<br>那么在&#x2F;etc&#x2F;hosts文件中增加下面一行： 192.168.1.18testos</p>
<p>≦ 510 ≧<br>492 第27章MySQL监控 27.4.2orzdba使用<br>完成配置后，orzdba使用非常简单，指定收集信息的模式和间隔即可。下面以lazy模式，每秒收集系统和数据库的性能数据：<br>[mysq13307@localhost bin]s perl orzdba -lazy-S&#x2F;tmp&#x2F;mysql_3391.sock-i 1<br>结果如图27-17所示，orzdba首先打印MySQL实例的DB信息和一些重要参数，帮助用户初步了解MySQL的配置情况。接着收集信息，并格式化输出。<br>time列是收集信息的当前时间，间隔为1s。<br>O1oad-avg列下的1m、5m、15m分别对应操作系统1min内、5min内和15min内的平均负载。从图27-17可知，15min、10min和1min内负载逐渐升高，此时主机负载呈上升趋势。<br>Ocpu-usage列下的usr、sys、idl、iow分别对应操作系统的用户cpu、系统cpu、空闲 cpu和io等待cpu占总cpu使用量的百分比。从图27-17可知，主要是用户使用cpu时间，使用率为13%<del>17%<br>ins、upd、del分别对应数据库每秒插入、更新和删除的sql数量。iud为增删改的总和，即TPS。在图27-17中，数据库的TPS为8</del>12。<br>max_connect_errors[10000] max_connections[10050] max_user_connections[10000]<br>open_files_limit[131072l sync_binlog[1] table_definition_cache[4096] table_open_cache[6144] thread_cache_size[256]<br>innodb_adaptive flushing[ONl innodb_adaptive_hash_index[ON] innodb_buffer_pooLsize[5G] innodb_file_per_table[ON] innodb_flush_Log_at_trx_commit[1] innodb_flush_methodIo_DIRECT] innodb_io_capacity[4eoo] innodb_lock_wait_timeout[1] innodb_log_buffer_size[64M]<br>QPS-<br>hitl<br>1352332113 电880000009 1614 121<br>1.19 0.67 221100.00 1.19 0.67&#x2F; 3 100.00<br>381<br>100.<br>1.05 0.671 81 100.00<br>00<br>1.18 1.05 0.671 100..00|<br>161513 2<br>8<br>156 100.001<br>图27-17 orzdba实时监控<br>Osel列对应数据库每秒查询的sql数量，即QPS。在图27-17中，数据库的QPS为9~13。 Olor列对应每秒innodb缓冲池的读次数（逻辑读请求数）。<br>Ohit列对应每秒缓冲池的命中率。图27-17结果显示，innodb缓冲池命中率都是100%，表明数据库innodb缓冲池大小足以装下当前的热数据。<br>orzdba使用简单，功能强大。可以自定义收集间隔，实时了解主机和MySQL的性能数据，<br>为分析和诊断问题提供了很多便利。 27.5小结<br>本章简单地介绍了常见的监控工具，并重点介绍了Zabbix和orzdba的安装和部署。由于篇幅有限，Zabbix的一些常见功能并没有详细介绍，如自动报警、自动发现监控主机、网络拓扑显示、分布式功能等。有兴趣的读者可以仔细阅读官方文档。</p>
<p>≦ 511 ≧<br>第28章 MySQL常见问题和应用技巧在MySQL日常开发或者维护工作中，用户经常会遇到各种各样的故障或者问题，比如密码丢失、表损坏等。本章总结了一些常见的问题，希望对读者在遇到类似问题时有所帮助。<br>28.1忘记MySQL的root密码<br>经常会有朋友或者同事问起，MySQL的root密码忘了，不知道改怎么办。其实解决方法很简单，下面介绍两种方法。<br>方法1：使用–skip-grant-tables选项，以无权限认证方式启动数据库实例，再登录数据库修改密码，以下是详细操作步骤。<br>（1）登录到数据库所在的服务器，手工kill掉MySQL进程： ki1l’cat &#x2F;mysql-data-directory&#x2F;hostname.pid’<br>其中，&#x2F;mysql-data-directory&#x2F;hostname.pid指的是MySQL数据目录下的pid文件，它记录了MySQL服务的进程号。<br>（2）使用–skip-grant-tables选项重启MySQL服务：<br>[mysq13307@1oca1host mysq1home]s.&#x2F;bin&#x2F;mysqld safe –defaults-fi1e&#x3D;&#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;my.cnf–user&#x3D;mysq13307–skip-grant-tabTes &amp;<br>[1]5647<br>[mysq13307@1oca1host mysq1home]s 2018-07-22T02:36:21.163410z mysqld safe Logging to &#x2F;data2&#x2F; mysq13307&#x2F;data&#x2F;error3307.1og.<br>2018-07-22T02:36:21.203452z mysqld safe Starting mysqld daemon with databases from &#x2F;data2&#x2F; mysq13307&#x2F;data<br>其中–skip-grant-tables选项前面曾经介绍过，意思是启动MySQL服务时跳过权限表认证。启动后，连接到MySQL的root将不需要口令。<br>（3）用空密码的root用户连接到MySQL，并且更改root口令：[mysq13307@localhost~]s mysq] -uroot<br>welcome to the MysQL monitor. Commands end with ;or \g. Your MysQL connection id is 5<br>Server version: 5.7.22-1og MysQL Community Server (GPL) mysql&gt; use mysql<br>Reading table information for completion of table and column names<br>You can turn off this feature to get a quicker startup with -A Database changed</p>
<p>≦ 512 ≧<br>494 第28章MySQL常见问题和应用技巧 mysql&gt; alter user root@’localhost’ identified by 123’；<br>ERROR 1290 (HY0o0): The MysQL server is running with the –skip-grant-tables option so it cannot execute this statement<br>此时，由于使用了–skip-grant-tables选项启动，直接使用“alteruser”命令更改密码失败。需要执行flushprivileges后再修改密码：<br>mysql&gt; flush privileges; Query ok,0 rows affected (1.o0 sec)<br>mysql&gt; alter user root@’1ocalhost’ identified by ‘123’; Query ok,o rows affected (o.oo sec)<br>（4）刷新权限表，使得权限认证重新生效： mysql&gt; flush privileges;<br>Query oK,O rows affected (o.00 sec)<br>（5）重新用root登录时，必须输人新口令：[mysq13307@localhost ~]s mysq]-uroot<br>ERROR 1045 (28000):Access denied for user‘root@localhost (using password:NO)[mysq13307@localhost ~]s mysq] -uroot -p123<br>mysql: [warning] using a password on the command line interface can be insecure.<br>welcome to the MysQL monitor. Commands end with ; or g. Your MySQL connection id is 6<br>server version: 5.7.22-1og MysQL Community Server (GPL) mysql&gt;<br>方法2：使用–init-file选项启动数据库实例，该参数指定数据库启动时执行包含sql语句的文件，以下是详细操作步骤。<br>（1）初始化sql文件，文件包含修改用户密码的 sql语句。<br>[mysq13307@localhost ~]$ vi &#x2F;tmp&#x2F;alter user.sq] alter user root@’localhost’ identified by 123;（2）使用–init-file选项重启MySQL服务：<br>[mysq13307@1oca1host mysqThome]s.&#x2F;bin&#x2F;mysq1d safe –defaults-file&#x3D;&#x2F;home&#x2F;mysq13307&#x2F;mysqThome&#x2F;my.cnf –user&#x3D;mysq13307 –init-file&#x3D;&#x2F;tmp&#x2F;alter_user.sql &amp;<br>[1]7481<br>[mysq13307@localhost mysq1home]s 2018-07-22T03:32:11.262410z mysqld safe Logging to&#x2F;data2&#x2F; mysq13307&#x2F;data&#x2F;error3307.1og<br>2018-07-22T03:32:11.262410z mysqld safe starting mysqld daemon with databases from &#x2F;data2&#x2F; mysq13307&#x2F;data<br>数据库启动时会执行-init-file选项后指定的sql文件。（3）用root登录数据库，输人新口令：<br>[mysq13307@localhost ]$mysq1 urootp123<br>mysql: [warning] using a password on the command line interface can be insecure.<br>welcome to the MysQL monitor. Commands end with ; or g. Your MysQL connection id is 9<br>Server version: 5.7.22-1og MysQL community Server (GPL) mysq1&gt;<br>以上两种方法都可以巧妙解决忘记MySQLroot密码的问题，读者可以选择任选其中一种。 28.2数据目录磁盘空间不足的问题<br>很多系统在正式上线后，随着数据量的不断增加，会发现数据目录下的可用空间越来越</p>
<p>≦ 513 ≧<br>28.3mysql.sock丢失后如何连接数据库 495<br>小，从而给数据库造成了安全隐患。对于这类问题，MySQL5.7新增通用表空间功能，它允许用户自定义数据文件的存放目录，多个表可以共用同一个通用表空间。下面来看一下具体的例子。<br>（1）登录到数据库，查看数据目录： mysql&gt; show variables like ‘datadir’; 1variable_name |value<br>I datadir 1&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;（2）在&#x2F;data盘创建通用表空间目录：<br>[root@1oca1host<del>]#mkdir-p &#x2F;data&#x2F;mysq13307&#x2F;data&#x2F;<br>[root@1oca1host</del>]#chown -Rmysq13307:mysq13307 &#x2F;data&#x2F;mysq13307&#x2F;data&#x2F;（3）创建通用表空间：<br>CREATE TABLESPACE general ts ADD datafile&#x2F;data&#x2F;mysq13307&#x2F;data&#x2F;general ts.ibd ENGINE&#x3D;InnoDB;<br>（4）查看通用表空间文件：<br>[root@1oca1host ~]# 11 &#x2F;data&#x2F;mysq13307&#x2F;data&#x2F; total 32<br>1 mysq13307 mysq13307 65536 Aug 28 21:19 general ts.ibd<br>（5）在通用表空间上，创建新表： mysql&gt; CREATE TABLEemployees（<br>emp noint（11) NOT NULL, birth date date NOT NULL,<br>first namevarchar(14) coLLATE utf8 unicode ci NOT NULL, last name Varchar(16) coLLATE utf8 unicode ci NOT NULL, genderenum(M’,F’) COLLATE utf8 unicode ci NOT NULL,<br>hire date  date NOT NULL, PRIMARY KEY (emp_no’),<br>KEYidx emp birth date(birth date)<br>）&#x2F;<em>!50100 TABLESPACE general_ts</em>&#x2F; ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8<br>unicode ci<br>Query ok,0 rows affected (o.o1 sec)<br>新建的表可以指定general_ts 通用表空间，不存储在MySQL数据目录。已存在的表，可<br>以用导出、重建表、导人的方法，将表迁移到通用表空间。 28.3mysgl.sock丢失后如何连接数据库<br>在MySQL服务器本机上连接数据库时，经常会出现mysql.sock不存在，导致无法连接的问题。这是因为如果指定localhost作为一个主机名，则mysqladmin默认使用UNIX套接字文件连接，而不是TCP&#x2F;IP。而这个套接字文件（一般命名为mysql.sock）经常会因为各种原因而被删除。通过–protocol&#x3D;TCP|SOCKET|PIPE|MEMORY}选项，用户可以显式地指定连接协议。下面演示了使用UNIX套接字失败后使用TCP协议连接成功的例子。<br>（1）UNIX套接字连接：<br>[mysq13307@localhost ~]smysq] -uroot –socket&#x3D;&#x2F;tmp&#x2F;mysql_3307.sock<br>ERROR 2002 (HY000): Can’t connect to 1ocal MysQL server through socket’&#x2F;tmp&#x2F;mysql 3307.sock’(2)（2）TCP连接：<br>[mysq13307@localhost ~]smysq] –protocol&#x3D;TCP-uroot-p-P3307 -hlocalhost Enter password:</p>
<p>≦ 514 ≧<br>496 第28章MySQL常见问题和应用技巧<br>welcome to the MysQL monitor.  commands end with ; or g. Your MysQL connection id is 14<br>server version: 5.7.22-1og MysQL Community Server (GPL) root@loca1host:3307 [(none)]&gt;<br>28.4从mysqldump文件抽取需要恢复的表<br>日常工作中，通常使用mysqldump备份一个或则多个db下的所有表，所有数据备份到同一个sql文件中。当恢复数据时，可以直接执行备份文件。如果只恢复备份文件中一个表，而且备份文件特别大，想通过手工编辑sql文件的方式，找到对应的sql语句，效率是非常低的。此时，可以使用sed命令抽取需要的sql语句，然后执行语句来恢复这个表。下面我们模拟一下整个过程。<br>（1）备份employees数据库：<br>[mysq13307@1oca1host tmp]s mysq1dump -uroot -s&#x2F;tmp&#x2F;mysq] 3307.sock employees &gt; emp1oyees.sq1[mysq13307@localhost tmp]s 1s -1trh employees.sql<br>-rw-rw-r–1 mysq13307 mysq13307 163m Aug 28 21:39 employees.sq1 （2）查看已备份的表和对应的开始行号：<br>[mysq13307@localhost tmp]s grep -nTable structure employees.sql<br>43:– Table structure for table departments 69:– Table structure for table dept emp 124:– Table structure for table dept manager 153:– Table structure for table employees 198:– Table structure for table salaries<br>340:– Table structure for table salaries history<br>368:– Table structure for table test 391:– Table structure for table titles<br>（3）结果显示，文件备份了8张表，如果想恢复salaries表，可以用sed命令抽取sql语句：<br>[mysq13307@localhost tmp]s sed -n ‘198,340 p emp1oyees.sql &gt; salaries.sq][mysq13307@localhost tmp]s 1s -1trh salaries.sq]<br>-rw-rw-r– 1 mysq13307 mysq13307 111m Aug 28 22:07 salaries.sql<br>其中，198代表salaries表起始行数，340代表下一个表的起始行数。（4）查看抽取的sql语句：<br>[mysq13307@localhost tmp]s more salaries.sq]<br>Table structure for table salaries DROP TABLE IF EXISTS salaries<br>&#x2F;*!40101 SET @saved cs_client &#x3D;@@character_set_client <em>&#x2F;;&#x2F;</em>!40101 SET character_set_client &#x3D; utf8 <em>&#x2F;:<br>CREATE TABLEsalaries（ emp_noint(11) NOT NULL, salary int（11) NOT NULL,<br>INSERT INTo salariesCemp no,salary,from date,to date) VALuES （10001,100,1986 06-26</em>1987-06-26)<br>（5）执行sql语句，恢复salaries表：<br>mysql&gt;source salaries.sql<br>到这里，salaries表的恢复就完成了。</p>
<p>≦ 515 ≧<br>28.5使用innobackupex备份恢复单表 497<br>28.5使用innobackupex备份恢复单表<br>在MySQL的数据量已经很大时，我们会考虑优先使用innobackupex工具来备份数据库，当然通常的做法仍然是全库备份，那么针对这种情况，如何进行单表恢复呢？下面我们模拟一下整个过程。<br>（1）备份前确认dept_emp表的数据量：<br>mysql&gt; select count(o) from dept_emp; 1count(o)1<br>3103091<br>1row in set (0.09 sec)<br>（2）开始innobackupex全量备份：<br>[mysq13307@loca1host employees]$ innobackupex–defau1ts-file&#x3D;&#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;my. cnf –no-timestamp–user&#x3D;root –password&#x3D;123–socket&#x3D;&#x2F;tmp&#x2F;mysq1_3307.sock &#x2F;home&#x2F;mysq13307&#x2F;tmp&#x2F; fullbackup<br>180828 23:01:14 innobackupex: Starting the backup operation<br>xtrabackup: Transaction log of 1sn (12965519373) to (12965519382) was copied. 180828 23:01:51 completed 0K!<br>看到“completedOK”，证明备份成功结束了。<br>（3）模拟dept_emp被误删： mysql&gt; drop table dept emp;<br>Query oK,0 rows affected (0.03 sec) mysql&gt; select count(o) from dept emp;<br>ERROR 1146 (42s02):Table‘employees.dept emp* doesn’t exist<br>（4）应用全备，需要加上–export选项，用于生成import table所需要的.exp文件：<br>[mysq13307@localhost employees]s innobackupex–defaults-file&#x3D;&#x2F;home&#x2F;mysq13307&#x2F;mysqlhome&#x2F;my.<br>-user&#x3D;root –password&#x3D;—use-memory&#x3D;256m–redo-only–apply-1og&#x2F;home&#x2F;mysq13307&#x2F;tmp&#x2F;<br>cnf<br>fullbackup –export<br>180828 23:06:26 innobackupex: starting the apply-1og operation<br>xtrabackup: export metadata of table ‘employees&#x2F;dept emp’ to file.&#x2F;employees&#x2F;dept_emp.exp(2indexes)<br>180828 23:06:27 completed oK!<br>看到“completedOK”，应用日志完成。查看dept_emp表相关文件：<br>[mysq13307@1oca1host empToyees]s cd &#x2F;home&#x2F;mysq13307&#x2F;tmp&#x2F;fu11backup&#x2F;employees[mysq13307@localhost employees]s 11 dept_emp*<br>-rw-rw-r– 1mysq13307 mysq73307 631 Aug 28 23:06 dept emp.cfg<br>1mysq13307 mysq13307 16384 Aug 28 23:06 dept_emp.exp-1 mysq13307 mysq13307 8676 Aug 2823:01 dept_emp.frm<br>-rw-r-<br>-rw-r–1 mysq13307 mysq13307 28311552 Aug 28 23:01 dept_emp.ibd<br>-1 mysq13307 mysq13307 887 Aug 28 23:01 dept emp_latest date.frm<br>（5）重新创建dept_emp表： mysql&gt; CREATE TABLEdept emp（<br>emp_noint(11) NOT NULL,<br>dept nochar(4） coLLATE utf8 unicode_ci NOT NULL, from date date NOT NULL,<br>-&gt; to date date NOT NULL,<br>PRIMARY KEY （emp_no,dept_no），</p>
<p>≦ 516 ≧<br>498 第28章MySQL常见问题和应用技巧<br>-&gt;KEYdept no（dept no）,<br>CONSTRAINTdept empibfk1FOREIGN KEY（emp_no）REFERENCESemployees（emp no)<br>ON DELETE CASCADE,<br>CONSTRAINTdept emp_ibfk2FOREIGN KEY（dept no）REFERENCESdepartments（dept<br>no） ON DELETE CASCADE<br>-&gt;) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci;<br>Query ok,0 rows affected (0.01 sec)（6）下线dept_emp表：<br>mysql&gt;ALTER TABLE dept emp DISCARD TABLESPACE; Query oK,0 rows affected (o.o2 sec)<br>（7）复制步骤（4）生成的dept_emp.exp和dept_emp.ibd文件到数据目录：[mysq13307@1oca1host emp1oyees]s cd &#x2F;home&#x2F;mysq13307&#x2F;tmp&#x2F;fu11backup&#x2F;emp1oyees<br>[mysq13307@loca1hostemp1oyees]$ cp dept_emp.exp dept_emp.ibd&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;employees&#x2F;（8）加载dept_emp表：<br>mysql&gt;ALTER TABLE dept_emp IMPORT TABLESPACE; Query oK,0 rows affected, 1 warning (0.32 sec)<br>（9）查看dept_emp表记录数： mysql&gt;select count(o) from dept emp;<br>1count(o）1 3103091<br>row in set (0.33 sec)<br>到这里，dept_emp表的恢复就完成了。<br>注意：如果备份文件比较大，需要考虑到磁盘空间问题以及恢复所用的时间。 28.6分析BINLOG，找出写的热点表<br>日常工作中，想找出线上写（增删改）的热点表。比较简单的方法是定时收集MySQL 内存统计值，然后计算差值。这种方法需要主动收集数据，而且时间点不够灵活。下面介绍一个解析BINLOG文件的方法，这样有两个好处：<br>不需要事先收集数据，统计的时间点也非常灵活；分析的维度可以精确到表、字段级别。<br>为了简化操作，推荐使用GitHub上一个分析统计BINLOG的工具，可以大大减少手工操作的工作量。下面看看怎么安装和使用这个工具。<br>（1）安装Perl:<br>[root@localhost ~]# yum install per]<br>（2）下载解压pasrebinlog脚本，：<br>[mysq13307@loca1host ~]s wget <a target="_blank" rel="noopener" href="https://codeload.github.com/wubx/mysql-binlog-statistic/zip/master[mysq13307@localhost">https://codeload.github.com/wubx/mysql-binlog-statistic/zip/master[mysq13307@localhost</a> ~]s unzip master<br>[mysql3307@localhost ~]s 11 mysql-binlog-statistic-master&#x2F;bin&#x2F;pasrebinlog<br>-rwxr-xr-x 1 mysq13307 mysq13307 1776Aug 14 2013 mysql-binlog-statistic-master&#x2F;bin&#x2F;pasrebin1og（3）查询MySQL数据库目录及BINLOG文件：<br>mysql&gt;show variables like%datadir%’; 1Variable name | Value</p>
<p>≦ 517 ≧<br>28.7在线DDL 499<br>1 datadir 1&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;1<br>1 row in set (o.00 sec) mysql&gt;show master logs;<br>ILog_name | File size | 1mysq1-bin.000052 1206401 1row in set (o.00 sec)<br>（4）修改pasrebinlog脚本参数：修改mysqlbinlog工具目录。<br>[mysq13307@localhost <del>]s which mysq1binlog ~&#x2F;mysq1home&#x2F;bin&#x2F;mysq1binlog<br>[mysq13307@localhost ~]s vi mysql-binlog-statistic-master&#x2F;bin&#x2F;pasrebinlog my Sbinlog &#x3D;”</del>&#x2F;mysq1home&#x2F;bin&#x2F;mysq1binlog<br>可以按照需求，增加解析BINLOG的限制条件，例如增加–start-datetime&#x3D;name，限定解析BINLOG的开始时间。<br>[mysq13307@localhost <del>]s vi mysql-binlog-statistic-master&#x2F;bin&#x2F;pasrebinlog<br>my Sbinlog &#x3D;</del>&#x2F;mysq1home&#x2F;bin&#x2F;mysq1binlog –start-datetime&#x3D;*2018-08-28 18:00:00′（5）开始解析BINLOG，统计表的变化：<br>[mysq13307@localhost ~]s perl mysql-binlog-statistic-master&#x2F;bin&#x2F;pasrebinlog &#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.000052<br>File&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.000052<br>Tableemployeesemployees: Type DELETE opt: 1024<br>Tableemployees.repl filter<br>Type INSERT opt: Type UPDATE opt: 1col:1<br>Tableemployees.repl normal Type INSERT opt:<br>Tableemployees.salaries Type DELETE opt:4047<br>结果显示，‘employees”‘employees表删除了1024条记录；‘employees”‘repl_filter表插人了 1条记录，更新了1条记录，操作更新第1列1次；‘employeesrepl_normal表插人了两条记录。表和写操作的关系一目了然，方便我们分析和优化数据库。<br>28.7 在线DDL<br>在MySQL5.6版本前，DDL操作（例如加字段、加索引）会阻塞写操作，如果对大表进行这些操作，会导致长时间无法写人数据，对业务的影响很大，几乎是不可接受的。直到5.6版本，MySQL开始提供在线DDL（OnlineDDL）功能，对于某些DDL操作来说，不再阻塞写操作。随后5.7版本和8.0版本都对在线DDL进行了优化，大大减少了DDL操作对业务的影响。<br>在MySQL5.6之前，操作DDL语句通常采取两种方式。</p>
<p>≦ 518 ≧<br>500 第28章MySQL常见问题和应用技巧<br>Ocopytable方式：新建与原表相同的临时表，在临时表上做DDL操作，同时锁定原表，此时原表只能读不能写。复制原表数据到临时表，复制完成后，通过rename命令用临时表替换原表。此方式比较消耗磁盘和CPU资源。<br>inplace方式：直接在原表上做操作，不再复制数据，效率更高，但是操作期间原表也是不可写的。<br>MySQL5.6以后，开始支持在线DDL。在线DDL操作虽然也是采用copy table和inplace 方式，但当采用inplace方式时，执行DDL语句期间，原表是可写的。这样将不再阻塞业务数据写入，增加数据库的可用性。<br>MySQL5.7对在线DDL进一步增强，支持tinyint、int、smallint和bigint类型位数的在线增大或减小；支持varchar类型在[0,255]以内或者255字节以上增加的在线操作，例如varchar 长度由10调到200，属于[0.255]以内的调整，支持在线操作，varchar类型长度由10调到300，跨越了[0,255]和255以上两个段，不支持在线操作；支持在线修改索引名字。<br>MySQL8.0中支持了快速增加表字段功能；增加了在线操作分区表的功能，例如在线增加分区、删除分区和重建分区。<br>在线DDL语法如下：<br>mySq&gt; ATter tabTe ,ALGORITHM[&#x3D;] {DEFAULT&#x2F;INPLACE&#x2F;COPY],LOCK [&#x3D;] DEFAULT&#x2F; NONE&#x2F; SHARED| EXCLUSIVE<br>前面已经对inplace和copy算法进行过介绍，inplace由于不用复制数据，所以相对来说，性能会好一些，但并不是所有的DDL操作都支持inplace方式。由于涉及内容太多，具体限制读者可以查看官方文档，这里不再赘述。<br>在线DDL一共有一下4个加锁方式。<br>ODEFAULT：由MySQL自动选择锁方式，优先选择锁定时间短的方式。<br>ONONE：不加锁，支持读写，效率最高。 OSHARED：支持读，不支持写。<br>OEXCLUSIVE：不支持读写，效率最低。<br>在线执行DDL语句的过程中，读者可以不指定ALGORITHM和LOCK，MySQL会根据代价和规则自动选择，即便人为指定LOCK模式为NONE，实际执行过程中也会申请锁，因为在线DDL操作在开始时，会短暂地申请排他元数据锁。如果此时DDL操作挂起，将会阻塞后续对该表的操作。下面来看一个具体的例子。<br>第一个会话，开启事务，查询departments表，申请共享锁： mysql&gt;start transaction;<br>mysql&gt;select * from departments;<br>第二个会话，为departments表增加新的字段：<br>mysq1&gt;ALTER TABLE departments ADD dept name Varchar(4O) ALGORITHM&#x3D;INPLACE,LOCK&#x3D;NONE:<br>第三个会话，查看线程运行情况： mysql &gt;show processlist\G<br>12.row<br>Id：133 user:root<br>Host:localhost db:employees<br>Command: Query Time:37</p>
<p>≦ 519 ≧<br>28.7在线DDL 501<br>State: waiting for table metadata lock<br>Info:ALTER TABLE departments ADD dept nameVarchar(4O) ALGORITHM&#x3D;INPLACE,LOCK&#x3D;NONE 因为第一个会话持有employees表的共享锁，第二个会话的DDL操作即便使用了inplace<br>算法和none锁，还是会挂起，State（状态）是Waitingfor tablemetadatalock。<br>第四个会话，查询departments表：<br>mysql&gt;select * from departments; 第三个会话，查看线程运行情况：<br>Id:133 User: root<br>Host:localhost db:employees<br>Command: Query Time:281<br>State: waiting for table metadata lock<br>Info: ALTER TABLE departments ADD dept nameVarchar(4O) ,ALGORITHM&#x3D;INPLACE,LOCK&#x3D;NONE<br>Id：136 User: root<br>Host:localhost db: employees<br>Command: Query Time:18<br>State: waiting for table metadata lock Info: select <em>from departments<br>DDL操作阻塞了第四个会话的查询请求，查询SQL的State也是Waitingfor tablemetadata lock。如果第一个会话的共享锁长时间不释放，后面的DDL操作和departments表的读写操作都会被阻塞，给数据库带来隐患。对于这种情况，一种办法是尽快提交第一个会话的事务；另一个办法是合理设置lock_wait_timeout的值，规定在lock_wait_timeout的时间后，DDL操作超时退出，department表后续的读写操作将不会被阻塞。<br>MySQL5.7版本后，可以开启performance shema统计，监控在线DDL的进度，下面来看一个示例。<br>开启PS统计：<br>mysql&gt;use performance_schema<br>mysql&gt;update setup_instruments set enabled &#x3D;YEs’ where name like ‘stage&#x2F;innodb&#x2F;alter%; Query ok, 0 rows affected (0.01 sec)<br>Rows matched:7 Changed:0 warnings:0<br>mysql&gt;update setup_consumers set enabled &#x3D; ‘YEs</em> where name like %stages%’; Query ok,3 rows affected (o.o0 sec)<br>Rows matched:3changed:3 warnings:0 修改表，添加一个新的字段：<br>mysql&gt;ALTER TABLE salaries ADD coLuMN emp_name Varchar(2O) AFTER salary;<br>由于salaries表记录数多，增加字段会持续比较长的时间；开启第二个会话，查看增加字段的进度：<br>mysql&gt;use performance_schema<br>mysql&gt;select event name, work completed, work estimated from events_ stages_current;<br>Ievent_name 1work compTeted I work estimated<br>Istage&#x2F;innodb&#x2F;alter table （read Pk and internal sort)1 19761 269321</p>
<p>≦ 520 ≧<br>502 第28章MySQL常见问题和应用技巧<br>1row in set (0.00 sec)<br>mysql&gt;select event_name, work_completed, work_estimated from events_ stages_current;<br>Ievent name 1work_completed l work estimated1 I stage&#x2F;innodb&#x2F;alter table (insert) 21869 273561 1 row in set (o.o0 sec)<br>mysql&gt;select event_name,work compTeted, work estimated from events stages current;<br>I event_name work completed work estimated Istage&#x2F;innodb&#x2F;alter table (flush) 258821 27083 1 row in set (0.00 sec)<br>event_name代表增加字段当前经历的阶段，work_estimated为MySQL预估总的工作量， work_completed为已完成的工作量，当work_completed与work_estimated相等后，DDL操作完成。通过监控work_completed与work_estimated的比值，可以估算DDL完成的百分比。<br>MySQL8.0版本对在线DDL的支持已经比较完善，但是实际使用过程中需要注意两个问题。第一是前面提到的，如果事务长时间持有表锁，再对该表进行DDL操作，那么DDL操作和后续的读写都会被阻塞；第二是在主库对大表进行在线DDL操作，主库需要较长时间才能完成DDL操作，从库一般也需要相同或者更长时间才能应用完DDL操作，这样将造成从<br>库极大的延迟。希望后续版本能完善在线DDL存在的问题，方便用户使用。 28.8小结<br>本章详细介绍了在MySQL中经常遇到的一些问题及其解决办法。对于实际应用来说，用户遇到的问题可能远远不止这些，希望读者在实践中能够多多总结，为管理和应用MySQL 积累更多的经验。</p>
<p>≦ 521 ≧<br>第29章 自动化运维系统的开发随着业务量的增长，MySQL实例的数量不断扩增，仅凭人力去手动维护大量的数据库实<br>例将会愈发困难。通过搭建数据库自动化运维平台将有效地提升部署与管理实例的效率，集中监控多实例的状态，能让DBA以最快速度响应并处理报警信息。<br>本章将介绍搭建一个MySQL自动化运维平台的基本流程，具体包括应用背景、框架选型、技术实践等，并将以实现MySQL自动化安装功能为例来教大家一步步搭建自己的自动化运维平台。<br>29.1MySQL自动化运维背景<br>在小规模的生产环境中，DBA常通过直连客户端的方式，通过命令行来执行管理数据库的操作。但是当MySQL实例数量不断增长时，仅凭人工去逐台登录服务器来完成诸如安装配置MySQL、部署监控等操作将会增加大量重复性的工作，同时也会增加配置出错的概率。在这种情况下，DBA通过编写定制化脚本，通过批量管理工具在多台服务器上执行命令或脚本，减少了重复性工作，在一定程度上提升了运维的效率。但这种方式也会出现如数据库信息统计困难、监控时效性差、脚本多版本难以管理等问题，或者从根本上说仍然是运维人员登录服务器进行操作，并没有实质上提升运维效率。<br>因此我们需要一个自动化运维平台，提供清晰简洁的可视化客户端界面，有一套后台系统管理资产信息与数据库信息，后台能调度管理所有脚本，从而完成MySQL部署与监控的工作，并能自动地收集数据库运行时的监控信息，将异常报警信息发送给运维人员。这样在MySQI 节点数量与压力高速增长时，运维仍能保证系统的稳定运行。下面介绍平台的基本架构。<br>如图29-1所示，一个MySQL自动化运维平台通常分为后台管理系统、任务调度系统、客户端三大部分。<br>（1）后台管理系统，也被称为CMDB（ConfigurationManagement Database），具体包括以下3个模块。<br>OCMDB数据库：存储了服务器的资产信息，MySQL部署信息与监控运行信息等系统的内部信息，使用的数据库和存储的内容依据业务内部逻辑制定。为保证数据的一致性与可靠性，系统仅通过API与CMDB数据库进行数据的交互。<br>O批量管理系统：通过批量的执行相同任务，完成管理多个MySQL实例的系统。系统可以直接在主机上执行指令，或是传递指令给任务调度系统调度执行，从而实现在一台主机</p>
<p>≦ 522 ≧<br>504 第29章自动化运维系统的开发上操控多台主机的功能。本章使用SaltStack做批量管理工具。<br>后台API：主要提供数据库信息的调度服务，CMDB数据库的信息都通过API来读取与存储。后台API提供了客户端，数据库和批量管理系统间的命令调度方法。本章使用 DjangoRESTFramework来完成API的开发。<br>CMDB数据库<br>后台管理系统 自<br>主机群<br>图29-1自动化运维平台组织结构<br>（2）任务调度系统，主要功能是帮助批量管理系统处理任务。由批量管理系统传递到任务调度系统的任务，由该系统进行队列分发，通过异步或定时的方式执行相关操作，完成诸如安装MySQL这类耗时较长的任务或MySQL运行状态的定期监控这类定时任务。本章选用 Celery作为任务调度的工具。<br>（3）客户端，提供了查看各类信息的可视化界面，如显示数据库信息、任务的调度状态、日志信息、监控信息等内容。本章选用Vue.js作为客户端开发的工具。<br>下面来详细介绍每个部分的系统架构设计和搭建方式。 29.2CMDB系统搭建<br>CMDB系统是整个平台的核心部分，支持系统中数据的调度与持久化，发送任务请求，管理平台上的所有服务器等功能，需要有较高的可靠性。下面我们逐个介绍组成CMDB系统的主要组件。<br>29.2.1CMDB数据库<br>CMDB数据库是自动化运维平台的数据基础，记录了系统所有必要的数据信息，如服务器信息、MySQL实例信息、监控信息、配置项、数据变动信息、任务调度信息等多项内容。为了保证配置库中数据与实际线上业务数据的一致性，CMDB数据库中信息只能通过API调度来实现修改。为了方便理解，本章以服务器和数据库信息两个配置表为例来介绍CMDB数据库，而在实际的应用中还需要记录配置信息、监控信息、任务信息等多种信息。服务器和数据库信息两表中记录的主要信息如下。<br>服务器信息表：至少需要记录服务器名称、网络信息、类型、状态等内容。<br>数据库信息表：至少需要记录数据库所属服务器、启动端口、版本、实例用户、配置文件信息、状态等内容。</p>
<p>≦ 523 ≧<br>29.2CMDB系统搭建 505<br>根据以上信息，设计出如图29-2所示的数据库类图。<br>在之后会使用Django-Model将数据库表结构抽象化为模型，并将模型序列化从而对数据<br>做增删改查操作，这部分将在后文的后台API设计章节中进行讨论。 29.2.2批量管理系统<br>对于大规模的MySQL集群管理，靠传统的手工逐台操作是低效且不现实的，通常的解决方案是使用批量运维工具。常用的批量管理工具有Puppet、SaltStack、Ansible等。其中SaltStack 是一款Python编写的，用于大规模批量管理服务器的工具，结合了消息队列服务ZeroMQ，支持在主节点（Master）执行命令来远程批量配置多个从节点（Minion），支持执行特定命令、传<br>输文件、安装服务、配置定时任务等常用操作，其基本的架构如图29-3所示。服务器信息据库信息<br>ZeroMQ<br>服务服型<br>星文件路校<br>创建时回<br>Minion Minion Minton<br>更新时间 Windows Linux OsX 图29-2CMDB数据库类图 图29-3SaltStack架构图下面详细介绍SaltStack的安装配置过程。<br>1.SaltStack安装与配置（1）Master节点配置。<br>Master节点是集群的控制中心，salt命令都是通过Master节点传到Minion节点上执行的。下例中选择了两台主机，Master：10.0.0.1和Slave：10.0.0.2（Minion1）来演示部署SaltStack 服务的流程。<br>在Master节点安装并配置salt-master。<br>[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#46;&#x30;&#x2e;&#49;">&#114;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#46;&#x30;&#x2e;&#49;</a><del>]#yum instal] -y epel-release<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#46;&#x31;">&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#46;&#x31;</a></del>]# yum install -y salt-master salt-minion<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;">&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;</a>~]#vi&#x2F;etc&#x2F;salt&#x2F;master cachedir:&#x2F;var&#x2F;cache&#x2F;salt<br>keep_jobs:24 file_roots: base:<br>&#x2F;srv&#x2F;salt&#x2F; dev:<br>&#x2F;srv&#x2F;salt&#x2F;dev&#x2F;services&#x2F;srv&#x2F;salt&#x2F;dev&#x2F;states prod:<br>&#x2F;srv&#x2F;salt&#x2F;prod&#x2F;services&#x2F;srv&#x2F;salt&#x2F;prod&#x2F;states<br>publish port:4505 ret port:4506<br>&#x2F;etc&#x2F;salt&#x2F;master是salt-master的默认配置文件，在每次修改后都需要重启该服务。在这里</p>
<p>≦ 524 ≧<br>506 第29章自动化运维系统的开发需要主要关注如上几个参数，并可根据需求进行修改。<br>cachedir:放置salt命令执行的缓存信息，大量的调用会使该目录存在过多缓存，可以更换存放路径。<br>Okeep_jobs：cachedir中保持缓存信息的时间，默认为24h。<br>file_roots：salt执行文件时默认的脚本所在地址，后文涉及的sls文件也在该目录中。 publish_port和ret_port：代表salt的消息发布系统端口和节点间通信端口，默认为4505<br>和4506，请避免这两个端口被占用。<br>配置完成后启动master服务：<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#46;&#x30;&#46;&#49;">&#114;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#46;&#x30;&#46;&#49;</a> <del>]# service salt-master start[<a href="mailto:&#x72;&#111;&#111;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#46;&#48;&#x2e;&#49;">&#x72;&#111;&#111;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#46;&#48;&#x2e;&#49;</a> ~]# service salt-master status salt-master.service - The Salt Master Server<br>Loaded:1oaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;salt-master.service; enabled;vendor preset: disabled) Active: active (running) since Mon 2018-07-16 19:30:59 cST; 3 weeks 6 days ago<br>可以看到服务已经正常启动。（2）Minion节点配置。<br>在Minion节点安装并配置salt-minion：[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#50;">&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#50;</a></del>]# yum install -y epel-release[<a href="mailto:&#x72;&#x6f;&#111;&#116;&#64;&#x31;&#48;&#x2e;&#x30;&#46;&#48;&#46;&#x32;">&#x72;&#x6f;&#111;&#116;&#64;&#x31;&#48;&#x2e;&#x30;&#46;&#48;&#46;&#x32;</a><del>]#yum install -y salt-minion[<a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#46;&#x32;">&#x72;&#111;&#111;&#116;&#64;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#46;&#x32;</a></del>]#vi&#x2F;etc&#x2F;salt&#x2F;minion<br>master: 10.0.0.1 id:Minionl<br>&#x2F;etc&#x2F;salt&#x2F;minion是salt-minion的默认配置文件，需要关注的参数为master和id。 Omaster:Master主机的IP或hostname。<br>Oid:Master向指定Minion发送指令时被指定Minion的标识id，可以根据业务关系配置为明了易读的字符串。<br>②配置完成后启动minion服务：<br>[<a href="mailto:&#114;&#x6f;&#111;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#x32;">&#114;&#x6f;&#111;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#x32;</a> <del>]# service salt-minion start[<a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#x30;&#x2e;&#x32;">&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#x30;&#x2e;&#x32;</a></del>]# service salt-minion status<br>Redirecting to &#x2F;bin&#x2F;systemctl status salt-minion.service salt-minion.service - The Salt Minion<br>Loaded:loaded (&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;salt-minion.service; enabled;vendor preset: disabled) Active: active (running) since Mon 2018-07-16 19:30:55 csT;3 weeks 6 days ago<br>启动后，为了配置Master和Minion节点间的互信关系，Minion会生成公私钥一对，并将公钥发送给Master。Master需要执行命令接受该minion-key来确认互信关系。<br>③配置互信关系如下：<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#x31;">&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#x31;</a> ~]# salt-key -L<br>Accepted Keys: Denied Keys: Unaccepted Keys: Minionl<br>Rejected Keys:<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;</a> ~]# salt-key -A -y<br>The following keys are going to be accepted:<br>unaccepted Keys: Minionl<br>Key for minion Minionl accepted.<br>配置完Minion1节点与Master节点的互信后，可以指定Minionl节点作为管理对象集，从Master节点发送test.ping指令，测试Master和Minion1节点间连接是否成功。</p>
<p>≦ 525 ≧<br>29.2CMDB系统搭建 507<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#48;&#46;&#48;&#x2e;&#x31;">&#114;&#x6f;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#48;&#46;&#48;&#x2e;&#x31;</a><del>]# salt -L Minion1 test.ping  Minionl:<br>True<br>在上面的例子中，在salt命令后指定了-L选项，以列表形式将SaltStack本次的管理对象集限定id为Minion1的节点，因此test.ping指令仅在Minionl节点上执行。除此之外，SaltStack<br>还支持如下的选择管理对象集的方式，可以方便地完成对多个Minion节点的连接测试。 salttest.ping&#x2F;&#x2F;选择所有Minion节点<br>saltMinion*test.ping&#x2F;&#x2F;根据Minion节点的id进行正则匹配 salt -L Minionl test.ping &#x2F;&#x2F;根据Minion节点的id列表匹配<br>salt -Gos:RedHattest.ping &#x2F;&#x2F;grains类型匹配 salt-s10.0.0.0&#x2F;24test.ping &#x2F;&#x2F;cIDRD配 2.SaltStack管理功能<br>在上文中部署并配置测试了SaltStack环境，下面介绍几种常用的管理功能。<br>（1）远程批量执行各类命令。执行特定命令：<br>[<a href="mailto:&#114;&#111;&#x6f;&#116;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#x31;">&#114;&#111;&#x6f;&#116;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#x31;</a></del>]# salt-run manage.up&#x2F;&#x2F; 检查所有存活Minion-Minionl<br>[<a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#x2e;&#x31;">&#114;&#111;&#111;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#x2e;&#x31;</a><del>]#saltMinion1 service.get all&#x2F;&#x2F; 获取Minion1上全部服务<br>[<a href="mailto:&#x72;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#x31;">&#x72;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#x31;</a></del>]# salt Minionl cmd.runuptime&#x2F;&#x2F; Minion1执行uptime命令，并返回结果 Minionl:<br>03:58:16up 435 days, 20:56,3 users<br>1oad average:0.50,0.59,0.48<br>②复制Master上文件salt:&#x2F;&#x2F;a.sh到Minion1的&#x2F;tmp下：<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#x31;&#48;&#46;&#48;&#x2e;&#48;&#46;&#49;">&#114;&#x6f;&#111;&#116;&#64;&#x31;&#48;&#46;&#48;&#x2e;&#48;&#46;&#49;</a> ]# salt Minionl cp.get file salt:&#x2F;&#x2F;a.sh &#x2F;tmp&#x2F;a.sh Minionl<br>&#x2F;tmp&#x2F;a.sh<br>其中salt:&#x2F;&#x2F;目录需要跟上文中Master配置的file_roots目录一致。要复制的文件必须指定 salt:&#x2F;&#x2F;参数，不能是Master上普通的目录，否则会报错。<br>③远程执行Master上的salt:&#x2F;&#x2F;a.sh脚本，a.sh的功能为打印第一个参数的内容：<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#48;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#48;&#46;&#x31;</a><del>]#more&#x2F;srv&#x2F;salt&#x2F;a.sh echo $1<br>[<a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#49;">&#114;&#x6f;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#49;</a></del>]# salt Minionl cmd.script salt:&#x2F;&#x2F;a.sh ‘a Minionl:<br>pid:<br>9368 retcode:<br>0 stderr: stdout:<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;">&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;</a>~]# salt Minion1 cmd.script salt:&#x2F;&#x2F;a.sh’a’runas&#x3D;mysql cwd&#x3D;&#x2F;home<br>远程脚本默认在Minion节点的&#x2F;tmp目录执行，可以增加runas和cwd参数修改执行用户和默认的Minion节点执行路径。<br>④部署定时任务：<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#46;&#x31;</a> ~]# salt Minion1 cron.set job root ‘o′****<br>0分执行命令，直接写入Minion的对应用户的crontab中 sh&#x2F;home&#x2F;a.sh每小时 Minionl:<br>通过以上介绍的几种命令，可以实现向Minion节点所在服务器批量地传输MySQL相关脚本、安装实例、部署对应的监控和定时备份脚本等基本功能。</p>
<p>≦ 526 ≧<br>508 第29章自动化运维系统的开发<br>（2）管理Minion节点系统数据。<br>这里主要介绍SaltStack的grains模块和pillar模块，前者用于从Master节点获取Minion 节点的系统数据，后者则用于从Master节点配置系统数据到Minion节点。<br>grains模块。<br>通过grains模块提供的一些方法，Master节点可以方便地获取到Minion节点的操作系统版本信息和设备型号信息等系统数据。但需要注意的是，这些系统数据是在Minion节点的 salt-minion服务启动时收集到并保存在各自&#x2F;etc&#x2F;salt&#x2F;grains中的静态数据，直到salt-minion服务下一次重启时才会再次进行更新，因此grains模块更适合用于资产管理。<br>[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#49;">&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#49;</a><del>]# salt Minion1 grains.item os&#x2F;&#x2F;查看Minion1的os信息 Minionl:<br>RedHat<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#49;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#49;</a></del>]#saltMinionlgrains.items&#x2F;&#x2F;查看Minion1的所有服务器属性 Minionl:<br>SSDS:<br>biosreleasedate:<br>04&#x2F;05&#x2F;2016 biosversion:<br>6.00 cpu_flags:<br>通过在Minion节点修改配置文件，或者在Master节点进行指定，可以对指定的Minion节点新增自定义的系统数据项。同样需要重启salt-minion服务后才可以获取到新的系统数据项。[<a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#46;&#x32;">&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#46;&#x32;</a><del>]#vi&#x2F;etc&#x2F;salt&#x2F;minion<br>grains: roles:<br>-Database<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x32;">&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x32;</a> ~]# service salt-minion restart[<a href="mailto:&#114;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#49;">&#114;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#49;</a></del>]# salt Minionl grains.item roles Minionl:<br>Database<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#46;&#x30;&#46;&#x30;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#46;&#x30;&#46;&#x30;&#46;&#x31;</a> <del>]# salt Minionl grains.setval environment’dev Minionl:<br>environment:<br>dev<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;</a> ~]# salt Minionl grains.item environment Minionl:<br>environment : pillar模块。<br>如上所述，grains模块的信息保存在各个Minion节点上，而pillar模块的信息则由Master 节点进行配置并存储在Master节点的&#x2F;srv&#x2F;pillar目录中。pillar模块的信息仅对指定的Minion 可读，因此更适用于一些动态的、比较敏感的数据。下面的例子演示了如何使用pillar来保存 Minionl节点的用户名和密码。<br>①首先建立一个top.sls文件，作为pillar的入口文件。[<a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#46;&#x30;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#x31;&#48;&#x2e;&#x30;&#46;&#x30;&#46;&#x31;</a> ~]# mkdir &#x2F;srv&#x2F;pi1lar<br>[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#x31;">&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#x31;</a></del>1#vi &#x2F;srv&#x2F;pillar&#x2F;top.sls base:<br>Minionl:<br>-minionl<br>②配置对应的minionl.sls文件，里面写人测试的用户名和密码信息。</p>
<p>≦ 527 ≧<br>29.2CMDB系统搭建 509<br>[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#x31;">&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#x31;</a>]#vi &#x2F;srv&#x2F;pi1lar&#x2F;minion1.sls<br>db user: username db passwd: passwd<br>③刷新Master的pillar配置来应用新的配置内容，之后查询pillar信息。[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#49;">&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#49;</a><del>]# salt’*′saltutil.refresh pillar<br>[<a href="mailto:&#114;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#x2e;&#49;">&#114;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#x2e;&#49;</a></del>]# salt Minion1 pillar.items Minionl:<br>dbuser:<br>username db_passwd: passwd<br>pillar模块的配置主要通过SLS（SaltState）文件来完成，实际上SLS文件作为SaltStack 的配置文件能够完成的工作远不止如此。下面通过安装MySQL实例详细介绍一下SaltStack 中 SLS文件的应用。<br>3.利用SLS文件安装MySQL实例<br>SLS是SaltStack的配置文件，文件存放于Master端，用途是配置Minion端的系统状态，记录的数据格式为YAML（一种简易的标记性语言）。Minion通过从Master上拉取文件来保持配置、服务的一致性，利用此特性可以很方便地为所有Minion安装MySQL实例。下面以源码安装MySQL为例来介绍流程。<br>（1）将安装过程涉及的配置文件和安装文件全部放在file_roots下，在本例中为默认的路径&#x2F;srv&#x2F;salt。安装前的目录树如下：<br>top.sls&#x2F;&#x2F;入口文件 mysql<br>files&#x2F;&#x2F;存放安装配置文件<br>my.cnf&#x2F;&#x2F;数据库配置文件 mysq1-5.6.34.tar.gz&#x2F;&#x2F;安装源码 mysq1d 数据库启动文件<br>init.sh&#x2F;&#x2F;配置功能文件 init.sls&#x2F;&#x2F;环境配置文件 install.sls&#x2F;&#x2F;安装文件<br>（2）top.sls是配置管理的人口文件，从base标签开始解析，下一级是操作的目标Minion 节点，可以通过正则、grains、分组名等各种方式进行匹配，再下一级是要执行的SaltState 文件，默认扩展名为.sls。top.sls文件内容如下：<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;">&#114;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;</a> salt]# cat top.sls base:<br>Minionl:<br>-mysql.init-mysql.instal1<br>人口文件要执行的目标Minion是Minion1，Minion1上要执行的SLS文件为$file_roots&#x2F; mysql目录下的init.sls和install.sls。<br>（3）init.sls为环境配置文件，内容如下：[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#49;">&#114;&#x6f;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#49;</a> salt]# cat mysql&#x2F;init.s1s pkg-init:<br>pkg.installed: names: gcc<br>-gcc-c++ glibc make cmake</p>
<p>≦ 528 ≧<br>510 第29章自动化运维系统的开发<br>autoconf 1ibxm12<br>1ibxm12-devel 21ib<br>zlib-devel Tibcurl<br>-1ibcurl-devel openss1<br>openssl-devel ncurses<br>-ncurses-devel libtool<br>其中pkg-init为自定义的方法名，其他模块可以直接通过方法名称来调用该方法。 pkg.installed为SaltStack的内部函数，检查包是否被安装以及包的版本是否正确。如果包不存在，则会被安装。names作为可选参数，指定了所有待检查的包名。<br>（4）install.sls为安装文件，指定了Minion端的脚本调用和命令执行流程以及相关配置文件目录，内容如下：<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#x31;</a> salt]# cat mysq1&#x2F;install.sls<br>include：#包括了上文中的环境配置脚本-mysql.init<br>mysql-source-install:<br>file.managed：#传输源文件到Minion<br>name:&#x2F;data&#x2F;mysq1-5.6.34.tar.gz#Minion端文件存放位置<br>-source:salt:&#x2F;&#x2F;mysq1&#x2F;fi1es&#x2F;mysq1-5.6.34.tar.gz #源文件位置<br>user: root-group: root-mode:755<br>cmd.run：#执行解压源码与安装服务功能<br>name:cd &#x2F;data &amp;&amp; tar xf mysq1-5.6.34.tar.gz &amp;&amp; cd mysql-5.6.34 &amp;&amp; cmake -DCMAkE INSTALL<br>PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql -DMYSQL DATADIR&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data -DWITH_MYISAM STORAGE ENGINE&#x3D;1-DWITH_INNOBASE _STORAGE ENGINE&#x3D;1 -DWITH MEMORY STORAGE ENGINE&#x3D;1 -DWITH READLINE&#x3D;1 -DMYSQL UNIX ADDR&#x3D;&#x2F;var&#x2F;1ib&#x2F;mysq1&#x2F;mysql.sock -DMYSQL_TCP_PORT&#x3D;3306-DENABLED_LOCAL INFILE&#x3D;1 -DWITH_PARTITION STORAGE_ENGINE&#x3D;1 -DEXTRA CHARSETS&#x3D;al1 -DDEFAULT _CHARSET&#x3D;utf8 -DDEFAULT_COLLATION&#x3D;utf8_general ci &amp;&amp; make &amp;&amp; make install<br>-unless：test -d&#x2F;usr&#x2F;local&#x2F;mysq1#判断条件若为真，则不执行该模块 mysql-init:<br>file.managed：#传输配置文件脚本 name: &#x2F;data&#x2F;init.sh<br>-source: salt:&#x2F;&#x2F;mysql&#x2F;init.sh<br>-user: root group: root-mode:755<br>cmd.script：#执行脚本-name:&#x2F;data&#x2F;init.sh<br>require：#执行配置文件脚本时，需要mysq1-source-install先执行成功 cmd: mysql-source-install<br>mysql-config:<br>file.managed：#传输my.cnf文件-name:&#x2F;etc&#x2F;my.cnf<br>source: salt:&#x2F;&#x2F;mysql&#x2F;files&#x2F;my.cnf<br>user: root-group: root-mode:644-require:<br>-file: mysql-init<br>mysql-service:<br>file.managed：#传输mysq1d文件-name: &#x2F;etc&#x2F;init.d&#x2F;mysqld<br>source: salt:&#x2F;&#x2F;mysq1&#x2F;files&#x2F;mysq1d<br>user: root group: root</p>
<p>≦ 529 ≧<br>29.2CMDB系统搭建 511<br>-mode:755<br>cmd.run：#添加启动项<br>-name:chkconfig –add mysqld<br>-unless: chkconfig –list Igrep mysqld require:<br>-file:mysql-service service.running：#启动服务<br>name:mysqld require:<br>-cmd:mysql-service<br>（5）在install.sls中调用了init.sh配置文件，用于完成MySQL服务安装后的配置用户组，初始化数据等工作：<br>[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#49;">&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#49;</a> salt]# cat mysql&#x2F;init.sh#!&#x2F;bin&#x2F;bash<br>groupadd mysq1<br>useradd -r -g mysql mysql<br>chown mysql:mysq1 &#x2F;usr&#x2F;local&#x2F;mysql&#x2F;-R<br>1n-sv&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin&#x2F;mysql&#x2F;usr&#x2F;bin<br>&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;scripts&#x2F;mysql install db –user&#x3D;mysql –basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql –datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data<br>在上述的几个文件中，Master节点的SLS文件中定义了编译安装MySQL的整体流程，接下来在Master节点执行SlatStack的state.highstate命令，使指定Minion节点（Minionl）的<br>环境生效，即完成了Minion节点的MySQL服务的搭建。[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#49;&#48;&#46;&#48;&#46;&#48;&#46;&#49;">&#114;&#111;&#111;&#116;&#x40;&#49;&#48;&#46;&#48;&#46;&#48;&#46;&#49;</a> salt]# salt Minion1 state.highstate<br>编译安装耗时较长，需要耐心等待结果返回。安装完成后，在Minion节点可以查看到 MySQL实例已经启动。<br>[<a href="mailto:&#x72;&#111;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x32;">&#x72;&#111;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x32;</a>~]#ps-ef1grep mysq1<br>mysql 4981 4801 920:33pts&#x2F;100:00:00&#x2F;usr&#x2F;local&#x2F;mysq1&#x2F;bin&#x2F;mysqld –basedir&#x3D;&#x2F;usr&#x2F; 1ocal&#x2F;mysql–datadir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data –plugin-dir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysq1&#x2F;lib&#x2F;plugin –user&#x3D;mysql-1og-error&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;Minion1.err –pid-file&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;data&#x2F;Minion1.pid socket&#x3D;&#x2F;tmp&#x2F;mysq13306.sock–port&#x3D;3306<br>在29.5节中也将采用如上的流程来安装MySQL实例。 29.2.3后台API<br>后台API（ApplicationProgrammingInterface）是系统中最核心的部分之一，它连接了客户端、后台数据库和批量管理系统这三者，是传输数据和请求命令的唯一途径，因此后台API 的可用性和接口的丰富性至关重要。<br>DjangoRestFramework是基于Django的扩展框架，在Django的基础上提供了规范的 REST（RepresentationalStateTransfer）API模板，通过序列化的方式提供了数据的验证和渲染功能，并拥有直观的接口调试界面。这里选用DjangoRestFramework作为CMDB系统的后台API框架。下面将介绍功能的搭建和具体实现。<br>1.DjangoRestFramework开发环境准备<br>（1）首先需要准备Python3和pip环境，并在此基础上安装djangorestframework模块。[<a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;">&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;</a> backend]# pip install django<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#48;&#46;&#48;&#x2e;&#x31;</a> backend]# pip install djangorestframework<br>（2）选定一个开发目录，本例中为&#x2F;data&#x2F;backend，新建cmdb项目，并在该项目目录中部署dbms应用。</p>
<p>≦ 530 ≧<br>512 第29章自动化运维系统的开发[<a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#46;&#48;&#x2e;&#48;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#46;&#48;&#x2e;&#48;&#46;&#x31;</a> backend]# django-admin.py startproject cmdb[<a href="mailto:&#x72;&#111;&#111;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#x30;&#x2e;&#x31;">&#x72;&#111;&#111;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#x30;&#x2e;&#x31;</a> backend]# cd cmdb<br>[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#x2e;&#49;">&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#x2e;&#49;</a> cmdb]# django-admin.py startapp dbms 应用创建好之后，开发目录的目录树如下所示：[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#46;&#48;&#46;&#48;&#x2e;&#49;">&#x72;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#46;&#48;&#46;&#48;&#x2e;&#49;</a> cmdb]# tree<br>cmdb<br>init.py settings.py urls.py wsgi.py<br>admin.py apps.py init.py migrations<br>init.py<br>models.py tests.py views.py<br>serializers.py manage.py<br>需要关注以下几个文件。<br>settings.py：项目配置文件，包含项目的应用信息、权限管理、数据库连接串等。 models.py:模型层文件，完成数据到代码间的ORM（ObjectRelationalMapping），包含了CMDB系统的数据库的抽象映射关系。<br>serializers.py：序列化文件，主要完成数据结构的转换与调整工作。<br>○views.py：视图层文件，主要完成请求处理函数的定义，并实现请求的路由和 Response.<br>urls.py：路由配置文件，定义了请求url和视图层处理函数之间的映射关系。 2.搭建CMDB系统的后台API<br>在上文中，一个基本的DjangoRestFramework开发环境已准备好，接下来我们会逐一介绍如何完善上述文件的代码，实现CMDB系统的后台API的服务搭建。下面以服务器资产信<br>息管理为例，详细介绍如何搭建一个符合REST规范的接口服务。（1）修改cmdb&#x2F;settings.py，为cmdb项目添加基本的配置信息。[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;</a> cmdb]# vi settings.py<br>#为项目添加dbms应用 INSTALLED APPS &#x3D;<br>‘rest_framework’,’dbms’<br>#设置登录用户才可访问接口 REST FRAMEWORK &#x3D;<br>‘DEFAULT PERMISSION CLASSES’:<br>rest framework.permi ssions.IsAdminuser<br>#数据库连接串信息 DATABASES &#x3D;<br>‘default’:<br>ENGINE’:django.db.backends.mysql,<br>NAME’XXX’’USER’:xXX’,</p>
<p>≦ 531 ≧<br>29.2CMDB系统搭建 513<br>‘PASSWORD’: xxX,’HOST10.0.0.2,’PORT’:3306,<br>本例中只给出了其中部分配置项，感兴趣的读者可以参考官方文档获取更多配置项的细节（<a target="_blank" rel="noopener" href="https://www.django-rest-framework.org/">https://www.django-rest-framework.org</a>)<br>另外，由于Django的MySQL驱动识别问题，在Python3环境下需要在安装了pymysql<br>模块的基础上修改项目的_init_·Py文件解决兼容性问题：[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#x30;&#x2e;&#x30;&#46;&#x31;">&#x72;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#x2e;&#x30;&#x2e;&#x30;&#46;&#x31;</a> cmdb]# pip install pymysq]<br>[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#49;">&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#x30;&#46;&#49;</a> cmdb]#viinit.py import pymysql<br>pymysql.install as MysQLdbO<br>（2）修改dbms&#x2F;models.py，初步实现模型层的设计，定义一个用于记录服务器基本信息<br>的表单结构，包括各个字段的数据类型、默认值等信息。[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;">&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;</a> dbms]# vi models.py<br>from django.db import models from datetime import datetime<br>class TbserverInfo(models .Mode1):<br>salt_id &#x3D; models.charField（max_length&#x3D;20,verbose_name&#x3D;”服务器 SALT ID”)<br>ip&#x3D;mode1s.charFie1d（max length&#x3D;20，verbose_name&#x3D;”服务器IP”) ssh_port &#x3D;models.IntegerField(verbose name&#x3D;”登录端口”)<br>server_type &#x3D; models.charField（max_1ength&#x3D;10,verbose_name&#x3D;”服务器类型) status &#x3D;models.IntegerField（verbose name&#x3D;“服务器状态”)<br>create_time &#x3D; models.DateTimeField（default&#x3D;datetime.now,verbose_name&#x3D;”创建时间”) update time &#x3D; models.DateTimeField(null&#x3D;True,verbose name&#x3D;“更新时间”)<br>（3）修改dbms&#x2F;serializers.py，对模型层定义的表单模型进行序列化。序列化是DjangoREST Framework的最大特点，能将Python的数据结构转换为JSON或XML等格式，并保存转换后的数据。下例中fields属性设置为all，代表序列化所有字段，也可设置为包含模型中部分<br>字段名的列表，从而序列化指定的字段。[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#49;">&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#48;&#x2e;&#x30;&#x2e;&#x30;&#x2e;&#49;</a> dbms]# vi serializers.py from rest framework import serializers from .models import TbserverInfo<br>class serverInfoserializer(serializers.Modelserializer):<br>class Meta<br>model &#x3D; TbserverInfo fields&#x3D;”all<br>（4）修改dbms&#x2F;views.py，借助DjangoRESTFramework的mixins方法完成视图层的设计。[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#46;&#x30;&#x2e;&#49;">&#114;&#111;&#x6f;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#46;&#x30;&#x2e;&#49;</a> dbms]# vi views.py<br>from rest framework import viewsets, mixins<br>from rest_framework.permissions import Isauthenticated<br>from .serializers import serverInfoserializer from .models import TbserverInfo<br>class ServerViewSet（mixins.ListModeMixin,mixins.createModeMixin,mixins.UpdateModelmixin, mixins.RetrieveModelMixin,viewsets.GenericviewSet)<br>queryset &#x3D; TbserverInfo.objects.all() serializer class &#x3D; ServerInfoserializer<br>此处创建的ServerViewSet类通过继承关系，可以调用mixins中的ListModelMixin、 CreateModelMixin、UpdateModeIMixin等方法，简单地实现了对服务器基本信息表单的读取、插人和已有记录更新功能，极大地简化了开发流程。当然，也可以通过重写mixins的create</p>
<p>≦ 532 ≧<br>514 第29章自动化运维系统的开发<br>方法来对具体的POST请求的响应方法进行定制，或者自定义其他mixins中没有的方法来实现其他请求响应方法。<br>（5）修改cmdb&#x2F;urls.py，完成路由层的定义。[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#48;&#46;&#x30;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#48;&#46;&#x30;&#46;&#x31;</a> cmdb]# vi ur1s.py<br>from django.conf.urls import url,include<br>from rest_framework import routers from dbms import views<br>router &#x3D; routers.DefaultRouterO)<br>router.register(r’server’,views.serverviewset) urlpatterns &#x3D;[<br>url（r’api&#x2F;‘,include(router.urls）),<br>ur1（r’Aapi-auth&#x2F;‘,include(‘rest_framework.urls’,namespace&#x3D;′rest framework’)<br>以上代码表示所有访问api&#x2F;节点的请求都路由到router.urls中处理，而router定义了server 路由前缀，对应的是views.ServerViewSet这一视图集合，即可以通过访问api&#x2F;server来请求视图下的方法。<br>上述代码中完成了模型定义、序列化方法定义，以及响应方法和路由的定义，接下来通过下述命令将模型导人到数据库，并在默认的8000端口启动服务。<br>[<a href="mailto:&#x72;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;">&#x72;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;</a> cmdb]#python manage.py makemigrations #记录对models.py的改动<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;</a> cmdb]# python manage.py migrate#将改动同步到数据库[<a href="mailto:&#114;&#111;&#111;&#x74;&#x40;&#x31;&#x30;&#46;&#x30;&#46;&#x30;&#x2e;&#49;">&#114;&#111;&#111;&#x74;&#x40;&#x31;&#x30;&#46;&#x30;&#46;&#x30;&#x2e;&#49;</a> cmdb]# python manage.py runserver<br>访问<a target="_blank" rel="noopener" href="http://127.0.0.1:8000/api-auth/login/%E6%9D%A5%E7%99%BB%E5%BD%95%E7%B3%BB%E7%BB%9F%EF%BC%8C%E7%99%BB%E5%BD%95%E6%88%90%E5%8A%9F%E5%90%8E%E8%AE%BF%E9%97%AEhttp://127.0.0.1:8000/">http://127.0.0.1:8000/api-auth/login/来登录系统，登录成功后访问http://127.0.0.1:8000/</a> apilserver&#x2F;即可查看到服务器列表页，获取已录人数据库的服务器信息。<br>DjangoRestFramework提供了非常友好的可视化界面用于接口调试，如图29-4所示。通过该页面下方提供的表单录人一条服务器信息，再次刷新该接口可以看到数据已录人，如图 29-5所示。当然除了直接在该调试界面提交数据之外，也可以直接构建POST请求来访问接口，例如，在后文的客户端搭建中将使用axios访问接口来实现各类功能。<br>ApiRootServer<br>Server List OPTIONSGET<br>服务器SALTID<br>服务器IP 登陆鸽口<br>图29-4服务器列表页1</p>
<p>≦ 533 ≧<br>29.3任务调度系统 515<br>Server List<br>图29-5 服务器列表页2<br>29.3任务调度系统<br>MySQL自动化运维平台需要处理大量的高并发任务，其中不仅包括长耗时的实例安装任务，还包括定时类的多实例监控任务等，因此任务调度系统尤为关键。这里选用Celery作为<br>任务调度系统的技术框架。 29.3.1Celery安装<br>Celery是基于Python开发一个分布式任务调度模块，支持耗时较长任务的异步并行执行，并提供定时任务调度功能，因此很适合辅助MySQL自动化运维平台完成各类任务的队列分发和消息处理。下面将介绍基于Celery搭建任务调度系统的具体实现，并简介Celery的监控管理工具Flower。<br>Celery的调度流程包括任务队列、消息中间件、任务执行者和持久化数据四大部分，如图29-6所示。各个功能简介如下。<br>异步任务 AsyncTask<br>消息中间件任务执行者持久化数据 Broker Worker Backend<br>定时任务 Celery Beat<br>图29-6Celery调度流程图<br>1.任务队列（Producer）<br>任务队列包括异步任务（AsyncTask）和定时任务（CeleryBeat）两部分，Celery在接收到任务后直接发送到消息中间件中等待处理，两种任务的处理流程分别如下。<br>（1）异步任务包括直接API调用，django-celery中的请求等，可以将一段逻辑代码发送到消息中间件排队等待处理。系统中可以存在多个异步任务请求并行发送任务。<br>（2）定时任务以独立的进程存在，通过读取配置文件中的内容，周期性地将执行任务的请求发送到消息中间件来完成调度。系统中只能有一个定时任务调度者。<br>发送异步消息或定时任务请求都需要安装Celery模块，由于后台API项目基于Django，这里同时安装上集成模块django-celery。</p>
<p>≦ 534 ≧<br>516 第29章自动化运维系统的开发<br>[<a href="mailto:&#114;&#x6f;&#111;&#x74;&#x40;&#x31;&#x30;&#46;&#x30;&#x2e;&#x30;&#x2e;&#49;">&#114;&#x6f;&#111;&#x74;&#x40;&#x31;&#x30;&#46;&#x30;&#x2e;&#x30;&#x2e;&#49;</a>~]#pip install celery[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;">&#x72;&#111;&#x6f;&#116;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;</a> ~]# pip install django-celery<br>2.消息中间件（Broker）<br>消息中间件负责接收任务队列发送过来的任务处理消息，在队列中排序并将任务逐个发送给空闲的任务执行者。因为任务处理是基于消息的，所以需要选择RabbitMQ、Redis等作为消息队列。本章选择Celery推荐的RabbitMQ，安装和启动命令如下：<br>[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#48;&#46;&#x30;&#x2e;&#x30;&#x2e;&#x31;">&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#48;&#46;&#x30;&#x2e;&#x30;&#x2e;&#x31;</a> ~]# yum install -y rabbitmq-server[<a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#46;&#49;">&#114;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#46;&#49;</a> ~]# service rabbitmq-server start[<a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;">&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;</a> ~]# rabbitmqctl start app<br>Starting <a href="mailto:&#110;&#111;&#100;&#101;&#x72;&#x61;&#98;&#x62;&#105;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#x31;">&#110;&#111;&#100;&#101;&#x72;&#x61;&#98;&#x62;&#105;&#x74;&#64;&#x31;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#x31;</a>..done<br>这样RabbitMQ便启动了，默认监听端口为5672。 3.任务执行者（Worker）<br>任务执行者是操作系统中的一组进程，它实时监控消息中间件发来的任务处理请求，并完成任务的处理。Worker可通过Celery直接启动，支持分布式部署和横向扩展，可以在多个节点增加Worker的数量来增加系统的高可用性。在分布式系统中，可以在不同节点上分配执行不同任务类型的Worker来达到模块化的目的。<br>4.持久化数据（Backend）<br>Celery支持将任务处理过程中的状态信息及结果保存，包括任务的执行结果、异常信息、执行参数和起止时间等内容。在生产项目中我们推荐选用CMDB数据库做Backend。为了方<br>便测试，本节我们选用RabbitMQ作为Backend。 29.3.2Celery任务部署<br>本节以安装MySQL为例，对Celery的异步任务和定时任务的部署调度进行介绍。 1.异步任务调度<br>（1）配置任务文件。指定消息中间件和Celery任务队列的进程名称。借助app.task装饰<br>器，将install_mysql函数注册为一个可以被异步执行的任务。[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#x30;&#x2e;&#49;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#x30;&#x2e;&#49;</a> ~]#vi install.py<br>from celery import celery import time<br>#配置上文中的RabbitMQ作为消息中间件<br>broker &#x3D;amqp:&#x2F;&#x2F;guest@1oca1host:5672&#x2F;&#x2F;#启动一个名为instal1的celery进程作为任务队列<br>app &#x3D; celery(‘install’,broker&#x3D;broker,backend&#x3D;broker)#配置路由<br>app.conf.CELERY_ROUTES &#x3D;<br>“install.install mysql”:<br>“queue”:“long”<br>@app.task<br>def install mysql(**kwargs):<br>time.s1eep（10）#模拟安装MysQL过程 return o</p>
<p>≦ 535 ≧<br>29.3任务调度系统 517<br>（2）启动Worker：<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#x30;&#46;&#x31;">&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#x30;&#46;&#x31;</a> <del>]#celery worker-A instal-Qlong –loglevel&#x3D;infon query<br>其中-A参数指定了Celery进程的名称。-Q代表Worker接受指定名称路由的任务，在实际项目中我们需要指定多个路由名称用以区分定时任务或耗时较长的异步任务。–loglevel则<br>代表worker的日志级别。-n指定了该Worker的名称。启动Worker后我们执行任务。（3）执行异步任务：<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x30;&#46;&#x30;&#x2e;&#48;&#x2e;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#x30;&#46;&#x30;&#x2e;&#48;&#x2e;&#x31;</a></del>]#python</p>
<blockquote>
<blockquote>
<blockquote>
<p>from install import install mysql &gt;&gt;&gt; res &#x3D;install _mysq1.delay(a&#x3D;1)<br>res.ready） #任务尚未完成 False<br>res.ready） #任务已经完成 True<br>res.get） #获取任务结果<br>经过测试可以看到，10s后返回了任务执行结果，而且该任务也并未阻塞命令行中的其他功能的执行。另外，在本例中开启Worker时指定了info级别的日志，因此也可以通过Worker 端的日志来查看任务的执行情况。<br>[tasks]<br>install.install mysql<br>[2018-10-10 18:16:03,809: INFo&#x2F;MainProcess] connected to amqp:&#x2F;&#x2F;guest:<strong>@127.0.0.1:5672&#x2F;&#x2F;<br>[2018-10-10 18:16:03,822:INFo&#x2F;MainProcess] mingle: searching for neighbors[2018-10-10 18:16:04,836: INFo&#x2F;MainProcess] ming1e:sync with 3 nodes<br>[2018-10-10 18:16:04,836:INFo&#x2F;MainProcess] mingle: sync complete[2018-10-10 18:16:04,851:WARNING&#x2F;MainProcess] celery@insta1l ready.<br>[2018-10-10 18:16:18,979: INFo&#x2F;MainProcess] Received task: install.install_mysql[9e891484-ac08-4d28-9c48-f44551be49b1]<br>[2018-10-10 18:16:29,004:INF0&#x2F;MainProcess] Task install.install mysq][9e891484-ac08-4d28-9c48-f44551be49b1] succeeded in 10.022355429828167s:0<br>2.定时任务调度<br>CeleryBeat进程能够周期性的调度已有任务，实现定时任务部署的功能。下面详细介绍如何将上述MySQL安装任务配置为定时调度任务。<br>（1）在已有任务的任务文件中，添加以下周期调度的相关代码，指定调度的任务名称（install.install_mysql）和触发周期（一分钟一次）。<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#46;&#x30;&#46;&#x31;">&#114;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#46;&#x30;&#46;&#x31;</a> ~]# vi install.py from datetime import timedelta<br>app.conf.update(CELERYBEAT SCHEDULE &#x3D;<br>‘check mysql’:<br>‘task’:’install.install mysql’,’schedule’:timedelta(seconds&#x3D;60),’args’: None<br>3)<br>（2）重启Worker后，再将CeleryBeat进程启动，即完成了定时任务的配置和周期性调度。[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;</a> ~]# celery beat -A instal]<br>celery beat v3.1.26.post2 （Cipater) is starting. Configuration -&gt;<br>broker -&gt; amqp:&#x2F;&#x2F;guest:</strong>@loca1host:5672&#x2F;&#x2F; loader -&gt; celery.loaders.app.AppLoader </p>
</blockquote>
</blockquote>
</blockquote>
<p>≦ 536 ≧<br>518 第29章自动化运维系统的开发<br>.scheduler -&gt; celery.beat.PersistentScheduler<br>.db -&gt; celerybeat-schedule logfile -&gt;[stderr]@%INFO.maxinterval -&gt; now (Os)<br>[2018-10-10 19:13:25,889: INFo&#x2F;MainProcess] beat: Starting..<br>[2018-10-10 19:13:25,908: INFo&#x2F;MainProcess] scheduler: Sending due task check mysql insta1].install mysql)<br>[2018-10-10 19:14:25,908:INFo&#x2F;MainProcess] Scheduler: Sending due task check mysql (instal].install_mysql)<br>worker Log Info:<br>[2018-10-10 19:13:29,041: INFo&#x2F;MainProcess] Received task: insta11.install mysq][ad48db14-bd08-4505-9d3c-d442f3f920b4]<br>[2018-10-10 19:13:33,212: INFo&#x2F;MainProcess] Events of group {task} enabled by remote<br>[2018-10-10 19:13:39,072: INF0&#x2F;MainProcess] Task insta11.instal1 mysq1[ad48db14-bd08-4505-9d3c-d442f3f920b4] succeeded in 10.02820060774684s:0<br>[2018-10-10 19:14:25,910:INFo&#x2F;MainProcess] Received task:install.install mysq1[bbd6d7e3-e12c-4ddb-aaf6-ff93631bfdf6]<br>[2018-10-10 19:14:35,943:INFo&#x2F;MainProcess] Task instal1.instal1_mysq1[bbd6d7e3-e12c-4ddb-aaf6<br>-ff93631bfdf6] succeeded in 10.030340616591275s:0 29.3.3Flower监控<br>前面对Celery的架构和调度配置进行了介绍。本节将介绍一款基于Web端的Celery的监控和管理工具Flower。<br>Flower支持对Celery事件进行实时监控，包括查看任务进程与历史、显示任务的详细信息、统计事件执行频率等功能。同时Flower还可以远程控制Celery，包括启动关闭Worker、控制进程池大小、撤销或终止任务等，并提供了API来调度这些功能。</p>
<p>Flower的安装部署非常简单，在5555端口启动Flower，默认选择RabbitMQ作为Broker：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@10.0.0.1 ~]# pip install flower[root@10.0.0.1~]# flower --port=5555</span><br><span class="line">[1 181010 19:24:31 command:139] visit me at http://loca1host:5555</span><br><span class="line">[I 181010 19:24:31 command:144] Broker:amqp://guest:**@1oca1host:5672//[1 181010 19:24:31 command:147] Registered tasks:</span><br><span class="line">[&#x27;celery.backend cleanup&#x27;</span><br><span class="line">&#x27;celery.chain&#x27;,&#x27;celery.chord&#x27;,</span><br><span class="line">&#x27;celery.chord unlock，</span><br><span class="line">&#x27;celery.chunks&#x27;,&#x27;celery.group&#x27;,&#x27;celery.map&#x27;,&#x27;celery.starmap&#x27;]</span><br><span class="line">[I 181010 19:24:31 mixins:231] connected to amqp://guest:**@127.0.0.1:5672//</span><br></pre></td></tr></table></figure>

<p>服务启动后，登录h ttp:&#x2F;&#x2F;127.0.0.1:5555即可访问Flower的Web界面，如图29-7所示。<br>Fiower C<br>On 0.4024:06 onim 3 04024015<br>04:024日16 04:024.016<br>图29-7Flower界面<br>在Tasks菜单中，可以查看每个任务的名称、参数、执行状态、结果、起止时间、执行</p>
<p>≦ 537 ≧<br>29.4客户端搭建 519<br>时间，以及Worker名称等内容，可以说是记录了Celery调度的完整运行状态。打开CeleryBeat 进程，可以观察到celery@install这个Worker的详细信息，如图29-8所示。<br>FlowerDia<br>Lagod<br>GARIO 2018-10-0113147 2018-10-10113141747<br>EESS SESS<br>图29-8Flower任务执行详情<br>在29.5节中，将继续使用Flower监控任务执行情况。 29.4客户端搭建<br>客户端在此主要指Web客户端，是在浏览器端可视化的界面。本章选择Vue.js作为MySQL 自动化运维平台的客户端开发框架，实现对CMDB数据库信息和实例部署维护等任务调度情况的可视化展示。<br>29.4.1Vue.js简介<br>Vuejs是一套用于构建用户界面的渐进式框架，可以构建复杂的单页应用。选用Vue.js 主要由于下面两大特性。<br>1．响应式数据绑定<br>Vue.js采用如图29-9所示的MVVM模型（Model-View-ViewModel），双向绑定JavaScript 数据和HTML数据，只要一方数据更新，另一方也会随之更新，这将复杂的前端数据显示与更新自动化，有效地提高了开发效率。MVVM模型中，View指代页面展示视图，Model指代模型数据，ViewModel通过DOMlisteners和DataBindings这两个工具，分别实现Model和 DOM层之间数据的双向交换。<br>2.组件化<br>Vuejs采用组件化思想将应用界面的每个模块都抽象为一个组件，每个组件的作用域各自独立，通过定义事件完成组件之间的通信，实现复杂业务需求的拆分化简。如图29-10所示，一个单页应用拆分为一个由样式与功能各异的组件构成的组件树，每个组件都是一个拥有预定义选项的Vue实例。<br>DOM Plain JavaScript<br>vue Objects<br>图29-9Vue.js的MVVM模式图29-10Vue组件化框架</p>
<p>≦ 538 ≧<br>520 第29章自动化运维系统的开发<br>此外，Vue.js也具有很强的扩展性，支持路由、AJAX、数据流等多种功能，感兴趣的读者可以前往官方网站详细了解。下面将演示使用Vue脚手架搭建项目的实战流程，构建请求<br>至后台API，完成CMDB数据的显示。 29.4.2Vue项目搭建<br>1.搭建Vue.js开发环境<br>Vue-cli是Vue.js的脚手架工具，可以帮助用户直接生成一个可运行的Vue项目，具体搭建流程如下：<br>（1）安装Node.js与Vue-cli。<br>[<a href="mailto:&#114;&#111;&#111;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#46;&#49;">&#114;&#111;&#111;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#46;&#49;</a> <del>]# yum instal1 -y nodejs[<a href="mailto:&#114;&#111;&#x6f;&#116;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#x31;">&#114;&#111;&#x6f;&#116;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#x30;&#46;&#x31;</a></del>]# npm install -g vue-cli<br>（2）部署项目，初始化了一个名为vue_tutorial的项目。<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#46;&#x31;">&#114;&#111;&#111;&#116;&#x40;&#x31;&#48;&#46;&#48;&#46;&#48;&#46;&#x31;</a> <del>]# vue init webpack vue tutorial?Project name vue tutorial<br>？ Project description vue tutorial?Author Mikuru<br>?Vue build standalone？Install vue-router? Yes<br>?use EsLint to lint your code? Yes？Pick an ESLint preset Standard?Set up unit tests No<br>? Setup e2e tests with Nightwatch? No<br>?should we run npm install for you after the project has been created? (recommended) npm<br>vue-cli , Generated “vue tutorial”.#Project initialization finished!#<br>To get started: cd vue_tutorial npm run dev<br>vue_tutorial项目创建好之后，项目的目录树如下，之后开发的主要工程文件都放置在src 目录中。<br>[<a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;">&#114;&#111;&#111;&#x74;&#64;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;</a></del>]# cd vue_tutorial&#x2F;<br>[<a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#49;&#48;&#46;&#48;&#x2e;&#x30;&#46;&#49;">&#x72;&#111;&#111;&#116;&#64;&#49;&#48;&#46;&#48;&#x2e;&#x30;&#46;&#49;</a> vue tutorial]# tree -al 1<br>babelrc<br>build#存放webpack信息 config#存放各种环境配置信息<br>.editorconfig eslintignore eslintrc.js gitignore index.html<br>node_modules #npm所安装的各种依赖<br>package.json #node modules 中依赖的包名<br>postcssrc.js README.md<br>src #放置vue工程文件 static#静态文件存放位置<br>src工程目录树如下，其中main.js是程序的入口文件，负责各个Vue组件和路由的注册， App.vue和index.js则分别是项目的入口文件和根路由文件。</p>
<p>≦ 539 ≧<br>29.4客户端搭建 521<br>[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#46;&#49;">&#x72;&#111;&#x6f;&#116;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#46;&#49;</a> src]# tree<br>App.vue assets<br>logo.png<br>components #组件库目录<br>He1loworld.vue #Vue文件，也是主界面显示的文件内容<br>main.js router<br>index.js#根路由文件<br>（3）启动项目服务。<br>[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#48;&#x2e;&#48;&#46;&#49;">&#x72;&#111;&#x6f;&#116;&#x40;&#x31;&#48;&#46;&#48;&#x2e;&#48;&#46;&#49;</a> vue_tutorial]# npm run dev &gt;<a href="mailto:&#x76;&#x75;&#x65;&#x5f;&#x74;&#117;&#116;&#111;&#114;&#105;&#x61;&#108;&#64;&#49;&#46;&#48;&#46;&#48;">&#x76;&#x75;&#x65;&#x5f;&#x74;&#117;&#116;&#111;&#114;&#105;&#x61;&#108;&#64;&#49;&#46;&#48;&#46;&#48;</a> dev &#x2F;root&#x2F;vue tutorial</p>
<blockquote>
<p>webpack-dev-server –inline –progress –config build&#x2F;webpack.dev.conf.js DONE Compiled successfu1ly in 5226ms 3:58:38 PM<br>Your application is running here: <a target="_blank" rel="noopener" href="http://localhost:8080/">http://localhost:8080</a><br>服务默认在本地8080端口上，通过浏览器访问<a href="http://localhost:8080，可以看到Vue应用主页如图29-11所示。至此，一个Vue.js开发环境已经搭建好。">http://localhost:8080，可以看到Vue应用主页如图29-11所示。至此，一个Vue.js开发环境已经搭建好。</a><br>cG<br>Welcome toYour Vue.jsApp<br>Essential Links<br>图29-11Vue应用主页<br>2.实现一个功能组件<br>项目搭建好后，下面介绍如何增加一个数据双向绑定的组件。（1）在路由文件index.js 添加路由test，指向Test.vue文件。<br>[<a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;">&#114;&#x6f;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#x2e;&#49;</a> src]# vi router&#x2F;index.js import vue from ‘vue<br>import Router from ‘vue-router’<br>import Helloworid from@&#x2F;components&#x2F;Helloworld<br>import Test from‘@&#x2F;components&#x2F;Test Vue.use(Router)<br>export default new RouterCt routes:<br>path:’&#x2F;‘.<br>name:’Helloworld’, component:Helloworld<br>path:’&#x2F;test’,<br>name:’Test’, component: Test</p>
</blockquote>
<p>≦ 540 ≧<br>522 第29章自动化运维系统的开发<br>（2）创建Test.vue文件，增加结构层（DOM）行为逻辑层（JavaScript）和样式层（CSS）代码，实现了简易的输人框和DOM数据的双向绑定功能。<br>[<a href="mailto:&#x72;&#111;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x31;">&#x72;&#111;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x31;</a> src]# vi components&#x2F;Test.vue <template></p>
<div id="test">
<p></p>
<input v-model="message"/>
</div> </template>
<script>
export default name:'Test'
data  return 
message'test
</script> <style> </style>
Vue-cli默认为热更新加载代码，直接访问http://localhost:8080/#/test，即可以看到刚才添加的组件页面，如图29-12所示。
此时输入框中的值和DOM数据已经进行了双向绑定，当修改输人框的值时，DOM中的值会同步发生变化。同样，在控制台中修改DOM中的值，输入框中的值也会随之同步，如图29-13所示。
test testtest
test testtst
图29-12Test.vue界面图29-13修改内容后DOM发生变化
此外，Vue在模板层还提供了大量其他功能，例如条件渲染、列表渲染、自定义事件处理、组件绑定等。在29.5节中会涉及这些功能，感兴趣的读者请查阅官方文档进行了解和学习。
3.Vue 构建前后端交互请求
在CMDB系统中，我们使用DjangoRestFramework实现了数据调度的API，客户端需要调用这些API来完成数据的读取与修改。这里我们选用官方推荐的axios作为后端请求的工具。 axios是一个基于promise的HTTP库，可以在浏览器中创建XMLHTTPRequests来请求后端 API，支持各种类型数据的转换，同时也支持拦截器和防跨域请求等。下面我们逐步介绍使用 axios完成前后端请求的流程：
（1）安装axios。
[root@10.0.0.1 vue tutorial]#npm installaxios
（2）在Test.vue文件中添加mounted方法，通过axios请求后台API的 server接口，并将数据显示在文本框中。
[root@10.0.0.1 vue tutorial]# vi src/components/Test.vue

<p>≦ 541 ≧<br>29.4客户端搭建 523</p>
<script>
import axios from 'axios
export default name:'Test'
data  return
message:'test'}，
mounted () { axios
get('http://10.0.0.1:8000/api/server)
.then(response => (this.message = response))
</script>
<p>完成后刷新页面，发现数据并没有被加载，查看网页日志会发现如下错误。<br>GET <a target="_blank" rel="noopener" href="http://10.0.0.1:8000/api/serVer">http://10.0.0.1:8000/api/serVer</a> net::ERR CONNECTION_TIMED_OUT Uncaught (in promise) Error: Network Error<br>at createError (createError.js?16d0:16)<br>at XMLHttpRequest.handleError (xhr.js?ec6c:87)<br>发现问题是请求被拒绝，这就涉及了前后端的跨域问题。出于安全性考虑，后端的项目需要增加跨域访问许可才能接收并处理请求，因此需要修改后端API配置。<br>（3）后台API项目安装django-cors-middleware，并修改配置文件。[<a href="mailto:&#x72;&#111;&#111;&#x74;&#x40;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;">&#x72;&#111;&#111;&#x74;&#x40;&#49;&#x30;&#x2e;&#48;&#x2e;&#48;&#46;&#x31;</a> cmdb]# pip insta1l django-cors-middleware<br>[<a href="mailto:&#114;&#111;&#x6f;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#x2e;&#x31;">&#114;&#111;&#x6f;&#116;&#x40;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#x2e;&#x31;</a> cmdb]# vim cmdb&#x2F;settings.py INSTALLED_APPS&#x3D;[<br>corsheaders’ MIDDLEWARE &#x3D;[<br>corsheaders.middTeware.corsMiddleware CORS ORIGIN ALLOW ALL&#x3D; True<br>为了解决前后端的跨域问题，只有增加了跨域访问许可后，后台API才会接收并处理前端发过来的请求。需要注意的是，本例中开通了内网中所有服务器访问API的权限，出于安全方面的考虑，请不要在生产环境中这样配置。<br>（4）调整客户端的配置文件，此处修改的是dev环境的。[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#x31;">&#114;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#x31;</a> vue tutorial]# vim config&#x2F;index.js<br>module.exports &#x3D;{ dev:<br>assetssubDirectory:’static<br>assetspublicPath: proxyTable:<br>&#x2F;api’:<br>target:’<a target="_blank" rel="noopener" href="http://10.0.0.1:8000/api">http://10.0.0.1:8000/api</a>‘, pathRewrite:{<br>&#x2F;api*：&#x2F;<br>（5）再次修改Test.vue文件的接口访问部分，刷新<a target="_blank" rel="noopener" href="http://localhost:8080/#/test%EF%BC%8C%E5%B7%B2%E7%BB%8F%E5%8F%AF%E7%9C%8B%E5%88%B0%E5%A6%82%E5%9B%BE29-14%E6%89%80%E7%A4%BA%E7%9A%84%E7%95%8C%E9%9D%A2%E3%80%82">http://localhost:8080/#/test，已经可看到如图29-14所示的界面。</a><br>[<a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;">&#114;&#111;&#111;&#x74;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;</a> vue tutorial]#vim src&#x2F;components&#x2F;Test.vue mountedO</p>
<p>≦ 542 ≧<br>524 第29章自动化运维系统的开发<br>axios<br>get(‘&#x2F;api&#x2F;server&#x2F;‘)<br>.then(response &#x3D;&gt;（this.message &#x3D; response))<br>{“data[[d”1.“salid”“Minion1”p“10002”“ssh_pot”22server ype“Enty”name”“测t机1,“create time”“2018-09-07T022130369140Z“update time”null}] ptions“SAMEORIGIN”x-powered-by“Express“alow“GETPOSTHEAD OPTIONSconten-type”“application&#x2F;jsonconection“keep-alivecontentleng“166）conig{“transfomRequest“lransfomResponse”0.timeour0.srfCookieNameXSRF-TOKEN”xsrfHeaderName“XXSRF.TOKEN”maxContenlLength-1headers(Accept<br>“application&#x2F;json,text&#x2F;plain,},methodget“urapi&#x2F;server},reques0）<br>[object Objec]<br>图29-14axios请求API获取的全部信息<br>很明显这并不是我们想要的，我们只需要显示data中的信息，并且需要更清晰的数据格式。<br>（6）进一步修改Test.vue文件，添加清晰的DOM样式和异常处理方法。再次刷新页面，如图29-15所示。<br>[<a href="mailto:&#x72;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;">&#x72;&#111;&#x6f;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#49;</a> vue_tutorial]# vim src&#x2F;components&#x2F;Test.vue <template></p>
<div id="test">
<h1>服务器信息</h1>
<section v-if="error"> <p>读取服务器信息出错</p> </section>
<section v-else>
<div v-for="i in message":key="i">
<div v-for="（key，item) in i":key="key"”>[item }}：
</div> </div> </section>
</div> </template>
<script>
import axios from 'axios'
export default name:'test',
dataO return
message: null, error:false
mounted O axios
get(/api/server/') then(response =>
this.message = response.data)
catch(error => console.log（error) this.error = true 3)
}
</script> <style> </style>
图29-15中得到了一个较为清晰的显示结果，但仍与需要的样式不同，主要原因是我们

<p>≦ 543 ≧<br>29.5自动化运维平台实战 525<br>并没有修改Vue文件中的 style，即CSS 配置。读者可以<br>id:1<br>进一步为Test.vue 添加CSS配置部分，以实现更复杂的 salt id:Minion1 样式。由于篇幅限制，在29.5节中将不会讨论样式配置 ip10002<br>ssh_port22 server_type:Entity<br>相关的内容。 create_time:2018-09-07T02:21:30.369140Z<br>name：测试机1 update_time:<br>29.5自动化运维平台实战 图29-15修改后的axios请求结果<br>结合上文中所提到的技术框架和技术要点，本节将带领大家从头部署一套完整的MySQL 自动化运维平台。<br>29.5.1搭建CMDB<br>在前文中我们已经搭好了SaltStack管理环境和后台API项目，在此基础之上进行整个系统的开发。<br>1．搭建CMDB数据库<br>修改models.py，设置服务器和MySQL的主要属性，保存文件并将数据模型同步至数据库。[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x31;">&#114;&#x6f;&#111;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#x2e;&#48;&#x2e;&#x31;</a> cmdb]#vi dbms&#x2F;mode1s.py<br>from django.db import models from datetime import datetime<br>#服务器信息<br>class TbserverInfo(models.Model):<br>SERVER TYPE&#x3D;（<br>（”Entity”，“实体机”），（”KVM”，“虚拟机”），<br>salt id &#x3D; models.charField（max 1ength&#x3D;20,verbose name&#x3D;”服务器 SALT ID”)<br>ip&#x3D;models.charField（max length&#x3D;20，verbose name&#x3D;”服务器IP”) ssh_port &#x3D;models.IntegerField（verbose _name&#x3D;”登录端口”)<br>server_type &#x3D;models.charField（max length&#x3D;10,choices&#x3D; SERVER TYPE，verbose_name&#x3D;服务器类型) status &#x3D; models.IntegerField（verbose_name&#x3D;”服务器状态”)<br>create_time &#x3D; models.DateTimeField（default&#x3D;datetime.now,verbose name&#x3D;”创建时间”)<br>update_time &#x3D; models.DateTimeField（null&#x3D;True,verbose _name&#x3D;“更新时间”) class Meta:<br>verbose_name&#x3D;“服务器信息”<br>verbose_name_plural &#x3D; verbose name db table &#x3D;”tb_server_info”<br>#数据库信息<br>class TbMysqlInfo(models.Model):<br>server &#x3D;models.Foreignkey（TbserverInfo,on delete&#x3D;models.CAsCADE，verbose_name&#x3D;“所属服务器） port &#x3D; models.IntegerField(verbose_name&#x3D;”数据库端口”)<br>version &#x3D; models.charFie1d（max length&#x3D;50,verbose_name&#x3D;”版本”)<br>instance_user &#x3D; models.charField（max_1ength&#x3D;20,verbose_name&#x3D;”实例用户”) cnf path &#x3D; models.charField（max_1ength&#x3D;100,verbose name&#x3D;“配置文件路径”) status &#x3D; models.IntegerField（default&#x3D;o，verbose_name&#x3D;“数据库状态)<br>create_time &#x3D; models.DateTimeField（default&#x3D;datetime.now,verbose name&#x3D;”创建时间”)<br>update _time &#x3D;models.DateTimeField（null&#x3D;True,verbose name&#x3D;”更新时间”) class Meta:<br>verbose_name&#x3D;“数据库信息”<br>verbose _name plural &#x3D; verbose _name db table &#x3D;”tb_mysql info”<br>#同步数据库</p>
<p>≦ 544 ≧<br>526 第29章自动化运维系统的开发<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#46;&#x30;&#x2e;&#x30;&#46;&#49;">&#114;&#111;&#111;&#116;&#x40;&#x31;&#x30;&#46;&#x30;&#x2e;&#x30;&#46;&#49;</a> cmdb]# python manage.py makemigrations[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#x6f;&#46;&#x30;&#46;&#x31;">&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#x6f;&#46;&#x30;&#46;&#x31;</a> cmdb]# python manage.py migrate<br>2.后台API搭建<br>根据建好的数据模型序列化数据，完成视图层和路由的配置。<br>[<a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#x2e;&#49;">&#114;&#111;&#111;&#x74;&#64;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#x2e;&#49;</a> cmdb]#vi dbms&#x2F;serializers.py from rest framework import serializers<br>from .models import TbserverInfo,TbMysqlInfo#序列化数据库信息<br>class MysqlInfoserializer(serializers.Modelserializer):<br>ip &#x3D; serializers.charField(source&#x3D;server.ip’)<br>salt id &#x3D; serializers.charField(source&#x3D;server.salt id’) class Meta:<br>mode1 &#x3D; TbMysq1Info fields &#x3D;”all”<br>#序列化服务器信息<br>class serverInfoserializer(serializers.Modelserializer):<br>instances &#x3D; MysqlInfoserializer(many&#x3D;True, read only&#x3D;True) class Meta:<br>model &#x3D; TbserverInfo fields&#x3D;“all ”<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#46;&#x30;&#46;&#x31;">&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#48;&#x2e;&#48;&#46;&#x30;&#46;&#x31;</a> cmdb]# vi dbms&#x2F;views.py<br>from rest framework import viewsets,mixins<br>from .serializers import serverInfoserializer,MysqlInfoserializer<br>from .models import TbserverInfo, TbMysqlInfo#服务器视图<br>class ServerViewSet(mixins.ListModelmixin, mixins.CreateModelmixin, mixins.UpdateModelmixin, mixins.RetrieveModelMixin,viewsets.GenericviewSet):<br>queryset &#x3D; TbserverInfo.objects.all0 serializer_class &#x3D; serverInfoserializer#增加过滤字段选项<br>filter_fields &#x3D;(‘salt id’,ip’,server_type’,status’)#数据库视图<br>class MysqlviewSet(mixins.ListModelMixin,mixins.CreateModelMixin,mixins.UpdateModelMixin, mixins.RetrieveModelmixin,viewsets.GenericviewSet):<br>queryset &#x3D; TbMysqlInfo.objects.allO serializer_class &#x3D; MysqlInfoserializer filter fields &#x3D;(‘server,status’)<br>[<a href="mailto:&#x72;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#46;&#49;">&#x72;&#111;&#111;&#116;&#x40;&#49;&#x30;&#x2e;&#x30;&#x2e;&#48;&#46;&#49;</a> cmdb]# vi cmdb&#x2F;ur1s.py from django.conf.uris import url, include<br>from django.contrib import admin from rest_framework import routers from dbms import views<br>router &#x3D; routers.DefaultRouter<br>router.register(r’server’,views.serverviewset) router.register(rmysql’,views.MysqlviewSet)<br>urlpatterns &#x3D;<br>url(radmin&#x2F;‘,admin.site.urls),<br>ur1（rapi&#x2F;‘,include(router.urls)),<br>url(r’^api-auth&#x2F;‘, include(‘rest framework.urls’, namespace&#x3D;’rest_ framework’)), 3.完成分页和过滤器配置<br>分页的主要作用是能让API返回限制长度的并且排序后的数据，而过滤器则可以为视图增加过滤字段用作查询条件。下面增加一个func.py文件来完成相关的配置。</p>
<p>≦ 545 ≧<br>29.5自动化运维平台实战 527<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#46;&#x30;&#x2e;&#49;</a> cmdb]# pip install djangorestframework-filters[<a href="mailto:&#x72;&#x6f;&#111;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#x2e;&#x30;&#x2e;&#x31;">&#x72;&#x6f;&#111;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#x2e;&#x30;&#x2e;&#x31;</a> cmdb]# vi dbms&#x2F;func.py<br>from rest framework.pagination import PageNumberPagination#分页信息配置，限制默认每页长度为10条数据，最多100条<br>class StandardResultsSetpagination(PageNumberpagination):<br>page_size &#x3D; 10<br>page_size_query_param &#x3D;’limit max page size &#x3D; 100<br>[<a href="mailto:&#114;&#111;&#111;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#49;">&#114;&#111;&#111;&#116;&#64;&#49;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#49;</a> cmdb]# vi cmdb&#x2F;settings.py#配置过滤器信息<br>INSTALLED APPS&#x3D;<br>“django_filters REST_FRAMEWORK&#x3D;<br>DEFAULT FILTER BACKENDs:(‘django _filters.rest framework.DjangoFilterBackend,)<br>DEFAULT PAGINATION CLASs’:dbms.function.StandardResultsSetPagination，这样数据配置相关的API已经完成了，之后将加人MySQL的安装功能。 4.安装MySQL功能的实现<br>上文中主要完成了服务器和数据库的数据调度的API，还需要增加安装MySQL的接口。具体操作需要首先配置前文提到的MySQL安装代码，然后通过调用SaltStack的PythonAPI 来完成该逻辑。<br>根据需求，客户端会通过POST请求将创建一个MySQL实例的参数发送给&#x2F;api&#x2F;server&#x2F;install&#x2F; 接口，接口启动一个SaltStack的本地客户端，通过cmd方法让本机的salt-master客户端来提交state.highstate请求。如果salt请求成功执行，则需要调用objects.saveO方法存储数据库信息在CMDB中。<br>[<a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#48;&#46;&#x30;&#x2e;&#x31;">&#x72;&#x6f;&#111;&#x74;&#x40;&#x31;&#48;&#46;&#48;&#46;&#x30;&#x2e;&#x31;</a> cmdb]# vi dbms&#x2F;views.py from.func import install mysql<br>from rest _framework.response import Response<br>from rest framework import status class MysqlviewSet(.)<br>#增加路由，匹配insta11接口，仅允许POST请求@action（methods&#x3D;[‘post’], detail&#x3D;False) def install(self,request):<br>data &#x3D; request.data#执行安装任务<br>install _mysql(infos&#x3D;data)<br>return Response(‘success’, status&#x3D;status.HTTP _200 oK)[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#x2e;&#x30;&#46;&#x31;">&#114;&#111;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#48;&#x2e;&#x30;&#46;&#x31;</a> cmdb]# vi dbms&#x2F;func.py<br>from .models import TbMysqlInfo import salt.client<br>def install mysql(**kwargs):<br>#根据客户端的传参来获取服务器的saltid<br>salt id &#x3D; TbserverInfo.objects.values_list(‘salt id,flat&#x3D;True).get(pk&#x3D;kwargs’infos]<br>[‘server_id’])<br>#启动本地客户端，通过cmd.run方法执行了state.highstate命令，来完成数据库的安装工作 res&#x3D; salt.client.LocalclientO.cmd(kwargssalt id][o],<br>“state.highstate”, show_timeout&#x3D;True,</p>
<p>≦ 546 ≧<br>528 第29章自动化运维系统的开发<br>if res[salt id]:<br>#安装成功，需要存储安装好的数据库信息<br>return TbMysqlInfo.objects.create(*<em>kwargs[‘infos’]) else:<br>raise Exception(‘failure’)<br>以上就是数据库安装和信息保存的后台API的调度实现。 29.5.2搭建任务调度平台<br>针对上面耗时较长的MySQL安装功能，可以将这个安装任务配置成异步任务。这里通<br>过Celery的扩展Django-celery模块来配置该任务，具体步骤如下。（1）配置Django-celery并同步数据库。<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#49;&#x30;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#x40;&#49;&#x30;&#46;&#x30;&#x2e;&#48;&#x2e;&#49;</a> cmdb]# pip instal1 django-celery # 安装django-celery<br>[<a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#x30;&#x2e;&#x31;">&#114;&#x6f;&#111;&#x74;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#x30;&#x2e;&#x31;</a> cmdb]# vi cmdb&#x2F;settings.py#配置app<br>INSTALLED APPS&#x3D;<br>‘djcelery’,<br>from celery.schedules import crontab from datetime import timedelta<br>BROKER URL &#x3D;’amqp:&#x2F;&#x2F;guest@loca1host:5672&#x2F;&#x2F;‘#Broker配置 CELERY RESULT BACKEND &#x3D;’database</em><br>#数据库配置为djcelery，与Django项目位于相同数据<br>CELERYBEAT SCHEDULER &#x3D;’djcelery.schedulers.DatabaseScheduler<br>CELERY_TIMEZONE &#x3D;Asia&#x2F;Shanghai#配置时区 CELERY ENABLE UTC&#x3D; False<br>CELERY IMPORTs&#x3D;（’dbms.views，dbms.func，）#配置celery任务路径 from celery import celery, platforms<br>platforms.CFORCE RooT&#x3D;True#允许root用户调度celery，在生产环境中不推荐 import djcelery<br>djcelery.setup_loader#启动 django-celery#同步django-celery自带数据模板信息到数据库中<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x30;&#46;&#48;&#x2e;&#48;&#46;&#x31;</a> cmdb]# python manage.py makemigrations[<a href="mailto:&#x72;&#x6f;&#111;&#116;&#64;&#49;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;">&#x72;&#x6f;&#111;&#116;&#64;&#49;&#48;&#46;&#x30;&#46;&#48;&#x2e;&#49;</a> cmdb]# python manage.py migrate<br>以上配置将django-celery的Broker和Backend信息配置到了Django中，配置完成后将表结构同步至数据库。<br>（2）修改MySQL安装任务为异步调度任务，修改MysqlViewSet视图和install_mysql方法。[<a href="mailto:&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#x31;">&#114;&#x6f;&#111;&#116;&#64;&#x31;&#x30;&#x2e;&#48;&#46;&#x30;&#46;&#x31;</a> cmdb]# vi dbms&#x2F;views.py<br>#signature是celery的自带方法，允许将任务名称和参数传递给celery执行，支持异步和同步执行<br>from celery import signature class Mysqlviewset()<br>@action(methods&#x3D;[‘post’],detail&#x3D;False) def install(self, request):<br>data &#x3D; request.data<br>#将直接install_mysq1的调用改为signature任务，并通过delay方法来异步执行<br>signature(‘install mysql,kwargs&#x3D;{‘infos:data}).delay() return Response(‘success’,status&#x3D;status.HTTP_200 oK)<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#48;&#x2e;&#x30;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#48;&#x2e;&#x30;&#46;&#x31;</a> cmdb]# vi dbms&#x2F;func.py from celery.decorators import task</p>
<p>≦ 547 ≧<br>29.5自动化运维平台实战 529<br>#只要在方法前加上task标识即可@task(name&#x3D;’install mysql’) def install mysq1(**kwargs):<br>salt id &#x3D; TbserverInfo.objects.values list(‘salt id’,flat&#x3D;True).get(pk&#x3D;kwargs[infos]<br>[‘server_id’])<br>res &#x3D; salt.client.Localclient).cmd(salt_id,<br>“state.highstate”, show_timeout&#x3D;True, D<br>if res[salt id]:<br>return TbmysqlInfo.objects.create(*<em>kwargs[‘infos’]) else:<br>raise Exception<br>这样便完成了任务调度系统的编写。（3）启动后台服务。<br>上文完成了CMDB系统和任务调度系统的搭建，现在启动后台服务。[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#49;">&#114;&#111;&#x6f;&#x74;&#x40;&#49;&#x30;&#46;&#x30;&#46;&#x30;&#46;&#49;</a> backend]# python manage.py runserver<br>[<a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#46;&#48;&#46;&#x31;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#49;&#48;&#46;&#x30;&#46;&#48;&#46;&#x31;</a> backend]# python manage.py celery worker -n instal] 29.5.3搭建客户端<br>对客户端而言，需要至少完成两个页面来显示系统内容，分别是MySQL信息的展示页和MySQL安装页面。同时我们也需要构建相应的请求访问CMDB，来完成与后台的数据交互。由于篇幅限制，本节将仅演示安装页对应的Vue文件和axios跨域请求文件的部分内容，更多页面文件与样式可以参考Vue的相关文档。<br>根据上文中关于Vue的介绍，首先需要完成路由到Vue组件的配置，之后编写组件，即数据库安装页面，并在页面中加人axios请求方法，最后编写数据请求连通后端，完成数据库安装的异步调度任务。下面将逐条介绍安装流程。<br>（1）客户端路由配置。<br>[<a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#46;&#49;">&#114;&#111;&#x6f;&#x74;&#64;&#49;&#48;&#46;&#x30;&#x2e;&#48;&#46;&#49;</a> src]# vi router&#x2F;index.js&#x2F;&#x2F;引用vue组件<br>import Install from‘@&#x2F;components&#x2F;install<br>import Mysql from @&#x2F;components&#x2F;mysql 7&#x2F;定义路由<br>export default new Router（t<br>routes:[ t<br>path:’&#x2F;install’, name:Install’, component: Install 3,<br>path:</em>&#x2F;mysql’, name:’Mysql’, component: Mysql<br>3<br>（2）安装页文件配置。这里使用了Element-UI作为UI（UserInterface）视觉框架。<br>[<a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#48;&#46;&#49;">&#114;&#x6f;&#x6f;&#116;&#x40;&#x31;&#x30;&#x2e;&#x30;&#46;&#48;&#46;&#49;</a> src]# vi src&#x2F;components&#x2F;install.vue <template></p>
<div class="app-container">
<el-form ref="mysql":model="mysql"1abel-width="140px">

<p>≦ 548 ≧<br>530 第29章自动化运维系统的开发<br><el-form-item label="SALT ID"><br><el-select clearable class="filter-item" v-model="mysql.server_id"><br>&lt;el-option v-for&#x3D;”item in salt id list”:key&#x3D;”item.id”:label&#x3D;”item.salt id”:value&#x3D;”item.id”&gt;<br></el-option> </el-select> </el-form-item><br>&lt;el-form-itemTabel&#x3D;”版本”&gt;<br><el-radio-group v-model="mysql.version"><br>&lt;el-radio1abel&#x3D;”5.6.34”value&#x3D;”5.6.34”&#x2F;&gt; &lt;e1-radio1abe1&#x3D;”5.7.17”value&#x3D;”5.7.17”&#x2F;&gt;<br></el-radio-group> </el-form-item><br>&lt;el-form-itemlabel&#x3D;”端口”&gt;<br><el-input v-model="mysql.port"/> </el-form-item><br>&lt;el-form-itemlabel&#x3D;”实例用户”&gt;<br><el-input v-model="mysql.instance user"/> </el-form-item><br>&lt;el-form-item 1abel&#x3D;”配置文件路径”&gt;<br><el-input v-model="mysql.cnf_path"/><br></el-form-item> <el-form-item><br>&lt;el-button type&#x3D;”primary” @click&#x3D;”onsubmit”&gt;创建</el-button> &lt;el-button @click&#x3D;”oncancel”&gt;重置</el-button><br></el-form-item> </el-form></p>
</div> </template>
<script>
//引用了安装方法
import{createMysql, serverList } from‘@/api/mysql
export default name:Mysql',
data(）[ return mysql:
server_id:, version: port:..
instance user: cnf path:,},
salt id list:undefined 子
created()
//默认请求所有服务器节点
serverListO.then(response =>
this.salt_id list=response.data.results
3) 子，
methods:
onSubmitO
//提交安装数据库表单
createMysq1(this.mysql).then(response =>[
alert（安装命令已经发出'）)
（3）axios请求页，这里仅定义了接口，在src/utils/request中创建axios请求。
[root@10.0.0.1 src]# vi api/mysql.js//将axios请求封装到单独的文件
import request from '@/utils/request'//请求全部MySQL信息

<p>≦ 549 ≧<br>29.5自动化运维平台实战 531<br>export function mysqllist(query)[ return request（t<br>url:&#x2F;api&#x2F;mysql&#x2F;‘,<br>method:’get’, params: query<br>3) 子<br>&#x2F;&#x2F;请求全部服务器信息<br>export function serverList(query)  return request(f<br>url:&#x2F;api&#x2F;server&#x2F;‘,<br>method:’get’， params: query<br>)}<br>&#x2F;&#x2F;数据库安装接口<br>export function createMysql(data){ return request（t<br>url:&#x2F;api&#x2F;mysql&#x2F;install&#x2F;‘, method:’post’，<br>data)<br>（4）创建axios请求并配置拦截器。[<a href="mailto:&#x72;&#111;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#x31;">&#x72;&#111;&#111;&#x74;&#64;&#49;&#x30;&#x2e;&#x30;&#x2e;&#x30;&#46;&#x31;</a> src]# vi utils&#x2F;request.js import axios from ‘axios’<br>import {Message } fromelement-ui’<br>&#x2F;&#x2F;设置axios请求超时时间为10000ms const service &#x3D; axios.create（<br>timeout:10000 3)<br>&#x2F;&#x2F;配置拦截器，通过JsoNwebToken传递消息<br>service.interceptors.request.use( config &#x3D;&gt;{<br>if(store.getters.token）<br>config.headers.Authorization &#x3D;JwT ${store.getters.token} 了<br>return config},<br>error &#x3D;&gt;{<br>Promise.reject(error)}<br>service.interceptors.response.use( response&#x3D;&gt;{<br>return response},<br>error &#x3D;&gt;{ Message(<br>message: error.message, type:’error,<br>duration:5*1000 3)<br>return Promise.reject(error)}<br>export default service<br>（5）以上内容完成后启动服务。<br>[<a href="mailto:&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;">&#114;&#x6f;&#111;&#116;&#x40;&#x31;&#x30;&#x2e;&#48;&#46;&#48;&#x2e;&#49;</a> frontend]# npm run dev<br>至此项目就已经准备完成，下面来实践操作一下安装流程。</p>
<p>≦ 550 ≧<br>532 第29章自动化运维系统的开发 29.5.4项目演示<br>在浏览器端访问<a target="_blank" rel="noopener" href="http://localhost:8080/#/install/mysql%EF%BC%8C%E7%99%BB%E5%BD%95%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%9F%A5%E7%9C%8B%E5%AE%89%E8%A3%85%E7%95%8C%E9%9D%A2%EF%BC%8C%E5%A6%82%E5%9B%BE29-16">http://localhost:8080/#/install/mysql，登录客户端查看安装界面，如图29-16</a> 所示。<br>填写数据库信息，单击创建提交请求至后台API，如图29-17所示。<br>图29-16安装MySQL客户端界面 图29-17提交安装MySQL请求<br>等待一段时间后，登录http:&#x2F;localhost:5555，即前文提到的Flower系统查看任务状态，如图29-18所示。<br>caley@na 038:033031<br>infos<br>2208b08<br>2051<br>instal_mysgl 0c71436d SUCESS<br>图29-18Flower界面显示任务状态<br>任务完成后登录客户端，访问<a target="_blank" rel="noopener" href="http://localhost:8080/#/mysql%E6%9F%A5%E7%9C%8B%E5%B7%B2%E7%BB%8F%E5%AE%89%E8%A3%85%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%EF%BC%8C%E5%A6%82%E5%9B%BE29-19%E6%89%80%E7%A4%BA%E3%80%82">http://localhost:8080/#/mysql查看已经安装的数据库，如图29-19所示。</a><br>8<br>D<br>图29-19客户端显示数据库情况<br>数据库已安装完成。至此安装功能演示完毕。 29.6小结<br>本章从技术架构讲起，逐个介绍了搭建MySQL自动化运维平台所用到的技术，并完成了一个安装MySQL单实例的简易流程。<br>目前，搭建一套数据库的自动化运维平台来完成运维工作，已经是行业中运维技术的主要发展方向。搭建平台时可用到的技术种类繁多，读者不必拘泥于某种技术上，可根据业务的需求和本章中提到的技术思想与架构自行完成平台的搭建。<br>由于篇幅限制，本章仅介绍了一个自动化运维平台所用到的基本技术，详细的代码设计和技术要点还请读者自行参考相关的文档。</p>
<p>≦ 551 ≧<br>5<br>第五部分架构篇<br>P&amp;R</p>
<p>≦ 552 ≧<br>第30章 MySQL复制<br>复制是指将主数据库的DDL和DML操作通过二进制日志传到复制服务器（也叫作从库）上，然后在从库上对这些日志重新执行（也叫作重做），从而使得从库和主库的数据保持同步。<br>MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他服务器的主库，实现链状的复制。<br>MySQL复制的优点主要包括以下3个方面：<br>如果主库出现问题，可以快速切换到从库提供服务；<br>可以在从库上执行查询操作，降低主库的访问压力； 0<br>可以在从库上执行备份，以避免备份期间影响主库的服务。<br>注意：如果主从库之间存在延迟，在从库上进行的查询操作需要考虑到这些数据的差异。 30.1复制概述<br>MySQL的复制原理大致如下。<br>（1）首先，MySQL主库在事务提交时会把数据变更作为事件（Event）记录在二进制日志文件（BINLOG）中；MySQL主库上的sync_binlog参数控制BINLOG日志刷新到磁盘。<br>（2）从库请求主库的BINLOG事件，并通过主库上的BINLOGDump线程将需要的数据发送给从库的IO线程，然后从库将接收到的数据写人中继日志RelayLog，之后从库根据中继日志RelayLog重做数据变更操作，通过逻辑复制以此来达到主库和从库的数据一致。<br>MySQL通过3个线程来完成主从库间的数据复制：其中BINLOGDump线程跑在主库上，<br>IO线程和SQL线程跑在从库上。当在 Master 从库连接主库 Slave 从库上启动复制（Start Slave）时，首<br>先创建I&#x2F;O线程连接主库，主库随后创 1&#x2F;0线程向主Master Slave<br>建BINLOGDump线程读取数据库事 Database 库要求数据 Database<br>VO<br>件并发送给I&#x2F;O线程，I&#x2F;O线程获取到 DML<br>SQL线程应用中继<br>事件数据后更新到从库的中继日志 Commands BinlogDump线程读取数日志中的事件 RelayLog中，之后从库上的SQL线程据库事件并把数据发给 SQL<br>1&#x2F;0线程<br>读取中继日志RelayLog中更新的数据 BINLOG Dump 1&#x2F;0 库事件并应用，如图30-1所示。<br>图30-1MySQL复制流程</p>
<p>≦ 553 ≧<br>30.1复制概述 535<br>可以通过showprocesslist命令在主库上查看BINLOGDump线程，从BINLOGDump线<br>程的状态可以看到，主库将从库需要的BINLOG发送给从库： mysql&gt; show processlist\G;<br>row<br>Id:20 User: repl<br>Host:10.120.240.251:51231 db: NULL<br>Command: Binlog Dump Time: 1984661<br>state: Master has sent all binlog to slave; waiting for more updates Info: NULL<br>安**会<br>Id：55 user: root<br>Host: localhost<br>db：NULL Command: sleep Time:531 State:<br>Info: NULL<br>2rows in set(0.00 sec)<br>同样地，在从库上通过showprocesslist可以看到Slave的IO线程和SQL线程，I&#x2F;O线程等待主库上的BINLOGDump线程发送事件并更新到中继日志RelayLog，SQL线程读取中继<br>日志RelayLog并应用变更到数据库： mysql&gt; show processlist\G;<br>Id:5<br>User: system user Host:<br>db：NULL Command: connect<br>Time:1986092<br>State: waiting for master to send event Info: NULL<br>2. row 会<br>Id:6<br>User: system user Host:<br>db：NULL Command: connect<br>Time:277789<br>State: slave has read all relay log; waiting for more updates Info: NULL<br>#会 ★会会会<br>Id:7<br>User: system user Host:<br>db:NULL Command: Connect Time:277789<br>State: waiting for an event from coordinator<br>Info: NULL Id：8<br>User: system user Host:<br>db:NULL Command: Connect Time:1986092<br>State: Waiting for an event from coordinator Info: NULL<br>4rows in set (o.00 sec) ERROR:<br>No query specified</p>
<p>≦ 554 ≧<br>536 第30章MySQL复制<br>注意：WaitingforaneventfromCoordinator涉及多线程复制。<br>以上是MySQL传统的复制流程，但复制是异步的，从库上的数据和主库存在一定的延迟。 30.1.1复制中的各类文件<br>从MySQL复制流程可以看到复制过程中涉及两类非常重要的日志文件：二进制日志文件（BINLOG）和中继日志文件（RelayLog）。<br>二进制日志文件（BINLOG）会把MySQL中的所有数据修改操作以二进制的形式记录到日志文件中，包括Create、Drop、Insert、Update、Delete操作等，但二进制日志文件（BINLOG）不会记录Select操作，因为Select操作并不修改数据。<br>可以通过showvariables查看BINLOG的格式，BINLOG支持Statement、Row、Mixed<br>这3种格式，也对应了MySQL的3种复制技术（会在30.1.1节中详细讨论）： mysql&gt; show variables like binlog format’;<br>|variable name | value | 1binlog format | Row 1 row in set (0.00 sec)<br>中继日志文件RelayLog的文件格式、内容和二进制日志文件BINLOG一样，唯一的区别在于从库上的SQL线程在执行完当前中继日志文件RelayLog中的事件之后，SQL线程会自动删除当前中继日志文件RelayLog，避免从库上的中继日志文件RelayLog占用过多的磁盘空间（可以通过参数relay_log_purge改变这个行为，默认开启，在MySQL8.0以后，BINLOG 文件也可以通过设置参数binlog_expire_logs_seconds来自动删除过期文件）。<br>为了保证从库Crash重启之后，从库的I&#x2F;O线程和SQL线程仍然能够知道从哪里开始复制，从库上默认还会创建两个日志文件master.info和relay-log.info用来保存复制的进度。<br>注意：可以通过设置参数–master-info-repository和–relay-log-info-repository将“FILE”修改为<br>“TABLE”，创建出来的表默认是Innodb存储引擎，实际在线上应用中，通常设置为“TABLE”，这样能与变更的事务保持一致性，使意外故障的恢复更高效。从MySQL8.0.2 以后，这两个参数的默认值为“TABLE”。<br>master.info和relay-log.info这两个文件在磁盘上分别记录了从库的IO线程当前读取主库二进制日志BINLOG的进度和SQL线程应用中继日志RelayLog的进度。例如，通过showslave status命令能够看到当前从库复制的状态，如图30-2所示。<br>其中master.info记录的是I&#x2F;O线程连接主库的一些参数，主要介绍showslave status显示的以下5项内容。<br>MasterHost:主库的IP。<br>MasterUser：主库上，主从复制使用的用户账号。 MasterPort:主库MySQL的端口号。<br>OMaster_Log_File：从库的I&#x2F;O线程当前正在读取的主库BINLOG的文件名。 ORead_Master_Log_Pos:从库I&#x2F;O线程当前读取到的位置。<br>而relay-log.info记录的是SQL线程应用中继日志RelayLog的一些参数，主要介绍show slavestatus显示的以下4项内容。</p>
<p>≦ 555 ≧<br>30.1复制概述 537<br>ORelay_Log_File:从库SQL线程正在读取和应用的中继日志RelayLog的文件名。 ORelay_Log_Pos:从库SQL线程正在读取并应用的中继日志RelayLog的位置。<br>ORelay_Master_Log_File:从库SQL线程正在读取和应用的RelayLog对应于主库 BINLOG的文件名。<br>OExec_Master_Log_Pos:中继日志RelayLog中Relay_Log_Pos位置对应于主库Binlog 的位置。<br>mysql&gt;show slave status\G<br>1.row***<br>市<em>市</em>本心<br>slave_Io_state:waiting for master to send event Master_Host:192.168.7.83&#x3D;主库IP<br>Master_user:repl ■主库上用于主从复制的用户账号<br>Master_Port:3331 ■主库MySQL端口 Connect_Retry:60<br>Master_Log_File:ip83-bin.000003从库I&#x2F;0线程当前读取主库Binlog文件名 Read_Master_Log_Pos:8023 ■从库I&#x2F;0线程读取主库Bin1og的位置<br>Relay_Log_File:bjurs28-relay-bin.000004 SQL线程正在应用的Relay Log Relay_Log_Pos:210 SQL线程正在应用RelayLog的位置<br>Read_Master_Log_File:ip83-bin.000003 SQL线程正在应用的RelayLog对应的Binlog<br>slave_Io_Running:Yes Slave_SQL_Running:Yes Replicate_Do_DB:<br>Replicate_lgnore_DB: relay-Replicate_Do_Table:<br>Replicate_lgnore_Table: Replicate_wild_Do_Table:<br>Replicate_wild_lgnore_Table:<br>Last_Errno:0 Last_Error: Skip_Counter:0<br>Exec_Master_Log_Pos:8023 SQL线程正在应用RelayLog的位置对应于主库<br>Binlog的位置<br>图30-2MySQL从库复制中的状态值<br>30.1.23种复制方式<br>二进制日志文件BINLOG的格式有以下3种。<br>OStatement:基于SQL语句级别的BINLOG，每条修改数据的SQL都会保存到BINLOG里。 Row：基于行级别，记录每一行数据的变化，也就是将每行数据的变化都记录到<br>BINLOG里面，记录得非常详细，但是并不记录原始SQL；在复制的时候，并不会因为存储过程或触发器导致主从库数据不一致的问题，但是记录的日志量较Statement格式要大得多。<br>OMixed:混合Statement和Row模式，默认情况下采用Statement模式记录，某些情况下会切换到Row模式，例如SQL中包含与时间、用户相关的函数等。<br>同时也对应了MySQL复制的3种技术。<br>Obinlog_format&#x3D;Statement:基于SQL语句的复制，也叫作Statement-BasedReplication（SBR），MySQL5.1.4或之前版本仅提供基于SQL语句的复制。<br>Obinlog_format&#x3D;Row：基于行的复制，也叫作Row-Based Replication（RBR）。<br>Obinlog_format&#x3D;Mixed：混合复制模式，混合了基于SQL语句的复制和基于行的复制。注意：对于MySQL5.7.6之前的版本，MySQL的默认设置是基于SQL语句的复制，从MySQL5.7.7</p>
<p>≦ 556 ≧<br>538 第30章MySQL复制<br>开始之后的版本，MySQL的默认设置变更为基于Row的复制。<br>下面通过例子来看Statement格式和Row格式的区别，这里以Update操作为例。在 Statement格式下，BINLOG记录的是原始操作SQL：<br>mysql&gt; show variables like ‘binlog format’; |Variable_name |value<br>|binlog format丨 STATEMENT| 1 row in set (o.00 sec)<br>mysql&gt; update salaries set salary &#x3D; salary + 10 where emp no&#x3D;10001; Query ok, 17 rows affected (0.05 sec)<br>Rows matched:17 changed:17 Warnings:0<br>通过showbinlogevents命令查看到Update操作在BINLOG日志文件mysql-bin.000013 中对应的开始位置为308：<br>mysql&gt; show binlog events inmysql-bin.000013 from 154\G; Log_name : mysql-bin.000013<br>POS:154<br>Event type: Anonymous Gtid<br>Server_id:7237 End_log pos:219<br>Info:SET @@SESSION.GTID NEXT&#x3D;’ANONYMOUS<br>武会会业会<br>Log_name :mysq1-bin.000013<br>POS:219<br>Event type:Query server_id:7237 End 1og pos:308<br>Info:BEGIN<br>Log name:mysq1-bin.000013<br>Pos:308<br>Event_type: Query server_id:7237 End log pos:451<br>Info: use employees;update salaries set salary &#x3D; salary + 10 where emp no&#x3D;10001<br>4.row<br>Log_name : mysq1-bin.000013<br>POS:451<br>Event_type:xid server_id:7237 End_1og pos:482<br>Info:COMMIT&#x2F;<em>xid&#x3D;19230</em>&#x2F;<br>4rows in set (0.00 sec) ERROR:<br>No query specified<br>通过mysqlbinlog工具分析对应的BINLOG日志，会发现在Statement模式下，BINLOG 日志文件中（从308位置开始）记录了实际发生的SQL：<br>BEGIN&#x2F;<em>1</em>&#x2F;#at 308<br>#180720 10:47:23 server id 7237 end 1og_pos 451 CRC32 0xddf78e5c Query thread id&#x3D;179 exec_time&#x3D;0 error_code&#x3D;0 use employees&#x2F;<em>!</em>&#x2F;:<br>SET TIMESTAMP&#x3D;1532054843&#x2F;<em>!</em>&#x2F;;<br>update salaries set salary &#x3D; salary + 10 where emp_no&#x3D;10001&#x2F;<em>1</em>&#x2F;；<br>调整BINLOG格式为Row，再做一个update操作检查一下：</p>
<p>≦ 557 ≧<br>30.1复制概述 539<br>mysql&gt; show variables like binlog format’;<br>| Variable name I value | I binlog format | Row 1 row in set (0.00 sec)<br>mysql&gt; update salaries set salary &#x3D; salary - 10 where emp no&#x3D;10001; Query ok, 17 rows affected (0.01 sec)<br>Rows matched: 17changed:17 warnings:0<br>同样地，通过showbinlogevents命令查看到Update操作在BINLOG日志文件mysql-bin.000013中对应开始位置为624：<br>mysql&gt; show binlog events in mysql-bin.000013’ from 547\G;<br>Log name: mysql-bin.000013 POS:547<br>Event_type: Query server_id:7237 End_1og_pos:624<br>Info:BEGIN 业会会会<br>Log_name : mysq1-bin.000013<br>POS:624<br>Event_type: Table map<br>Server_id: 7237 End_1og_pos : 683<br>Info: table id: 119 (employees.salaries) Log name : mysql-bin.000013<br>Pos:683<br>Event type: update rows<br>Server id : 7237 End log pos:1229<br>Info: table id: 119 flags:STMT END_F<br>Log_name : mysq1-bin.000013 Pos:1229<br>Event_type : xid Server_id : 7237 End_log pos:1260<br>Info:cOMMIT&#x2F;<em>xid&#x3D;19270</em>&#x2F;<br>4 rows in set (0.00 sec)<br>此时再通过mysqlbinlog检查对应的BINLOG日志文件： $ mysqTbinlog -vv mysql-bin.000013 –start-position&#x3D;624&#x2F;<em>150530 SET @@SESSION.PSEUDO SLAVE MODE&#x3D;1</em>&#x2F;;<br>&#x2F;<em>!50OO3 SET @OLD_ COMPLETION_TYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER&#x2F;<em>I</em>&#x2F;;#at4<br>#180720 10:35:26 server id 7237 end log pos 123 CRc32 0x61381108 Start:binlog v 4, server v 5.7.22-1og created 180720 10:35:26<br>#warning: this binlog is either in use or was not closed properly. BINLOG’<br>bkpRwW9FHAAAdWAAAHSAAAABAAQANS43LjIyLWXVZWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXWAEGggAAAAICAgCAAAACgoKKioAEjQA<br>AQgROGE&#x3D;&#x2F;*1#&#x2F;:#at624<br>#180720 15:00:40 server id 7237 end 1og pos 683 cRc32 0x02e5f4a8 Table map:employees.salariesmapped to number 119<br>#at683<br>#180720 15:00:40 server id 7237 end 1og pos 1229 cRc32 0x449318e0 Update_rows: table id<br>119 flags: STMT END_F BINLOG</p>
<p>≦ 558 ≧<br>540 第30章MySQL复制<br>mIhRwxNFHAAAOWAAAKsCAAAAAHCAAAAAAAEACWVtcGXVeWV1cWAIc2FsYXJpZXMABAMDCgoAAKj0 5QI&#x3D;<br>mIhRwx9FHAAAIgIAAMOEAAAAAHcAAAAAAAEAAgAE&#x2F;&#x2F; &#x2F;wEScAAN&#x2F;qAADahA&#x2F;ahg&#x2F;wEScAANXqAADa hA&#x2F;ahg&#x2F;wEScAAKDyAADahg&#x2F;ZiA&#x2F;wEScAAJbyAADahg&#x2F;ZiA&#x2F;wEScAACQCAQDziA&#x2F;zig&#x2F;wEScAABoC AQDziA&#x2F;zig&#x2F;wEScAAC4EAQDzig&#x2F;ZjA&#x2F;wEScAAcQEAQDzig&#x2F;zjA&#x2F;wEScAAJsFAQDzjA&#x2F;Zjg&#x2F;wEScA AJEFAQDZjA&#x2F;Zjg&#x2F;wEScAAJAVAQDZjg&#x2F;YkA&#x2F;wEScAAIYVAQDZjg&#x2F;YkA&#x2F;wEScAAGciAQDYkA&#x2F;Ykg&#x2F;w ESCAAFOiAQDYkA&#x2F;Ykg&#x2F;WESCAACAmAQDYkg&#x2F;Y1A&#x2F;WESCAABYmAQDYkg&#x2F;Y1A&#x2F;WEScAAOQoAQDYTA&#x2F;Y 1g&#x2F;wEScAANooAQDY1A&#x2F;Y1g&#x2F;WEScAAF4sAQDY1g&#x2F;XmA&#x2F;wEScAAFQsAQDY1g&#x2F;XmA&#x2F;WEScAAJc4AQDx mA&#x2F;xmg&#x2F;wEScAAI04AQDxmA&#x2F;Xmg&#x2F;wEScAAIs8AQDXmg&#x2F;XnA&#x2F;wEScAAIE8AQDxmg&#x2F;xnA&#x2F;wEScAANM8 AQDXnA&#x2F;Xng&#x2F;wEScAAMk8AQDXnA&#x2F;Xng&#x2F;wEScAAL9LAQDXng&#x2F;WoA&#x2F;wEScAALVLAQDXng&#x2F;WoA&#x2F;wEScA AIJMAQDWoA&#x2F;Wog&#x2F;wEScAAHhMAQDWoA&#x2F;Wog&#x2F;wEScAAHNMAQDWog&#x2F;WpA&#x2F;wEScAAG1MAQDWog&#x2F;WpA&#x2F;w<br>EScAAIhbAQDWpA8hHk7wEScAAH5bAQDWpA8hHk7gGJNE&#x2F;<em>1</em>&#x2F;;<br>###UPDATEemployeessalaries###WHERE<br>###@1&#x3D;10001 &#x2F;*INT meta&#x3D;0 nullable&#x3D;0 is_nul1&#x3D;0 *&#x2F;###@2&#x3D;60127 &#x2F;*INT meta&#x3D;0nu11ab1e&#x3D;0 is_nu11&#x3D;0 *&#x2F;<br>###@3&#x3D;1986:06:26′&#x2F;<em>DATE meta&#x3D;0 nu1lable&#x3D;0 is_nu11&#x3D;0</em>&#x2F;###@4&#x3D;1987:06:26′&#x2F;*DATE meta&#x3D;0 nu11ab1e&#x3D;0 is nu11&#x3D;0 *&#x2F;###SET<br>###@1&#x3D;10001 &#x2F;*INT meta&#x3D;0 nullable&#x3D;0 is nu11&#x3D;0 *&#x2F;###@2&#x3D;60117 &#x2F;<em>INT meta&#x3D;0 nu11able&#x3D;0 is nu11&#x3D;0</em><br>###@3&#x3D;’1986:06:26′&#x2F;<em>DATE meta&#x3D;0nu11ab1e&#x3D;0 is_nu11&#x3D;0</em>&#x2F;###@4&#x3D;1987:06:26′&#x2F;*DATE meta&#x3D;0 nu11ab1e&#x3D;0 is_nu11&#x3D;0 *&#x2F;<br>能够清晰地看到，在binlog_format设置为Row格式时，MySQL实际上在BINLOG中逐行记录数据的变更，Row格式比Statement格式更能保证从库数据的一致性（复制的是记录，而不是单纯的操作SQL）。当然，Row格式下的BINLOG的日志量很可能会增大非常多，在设置时需要考虑到磁盘空间问题。<br>30.1.3复制的4种常见架构<br>复制的4种常见架构有一主多从复制架构、多级复制架构、双主（DualMaster）复制架构和多源（Multi-Source）复制架构。 一主多从<br>1.一主多从复制架构 Web Client Web Client Web Client Web Client 在主库读取请求压力非常大的场景<br>下，可以通过配置一主多从复制架构实现 Write Request 读写分离，把大量对实时性要求不是特别<br>Master<br>高的读请求通过负载均衡分布到多个从库 Replication 上，降低主库的读取压力，如图30-3所示。 Slavel Slave2 Slave3 在主库出现异常岩机的情况下，可以<br>把一个从库切换为主库继续提供服务。<br>2.多级复制架构 LVS&#x2F;负载均衡 Read Request 一主多从的架构能够解决大部分读请 Web Client<br>Web Client Web Client Web Client]<br>求压力特别大的场景的需求，考虑到<br>MySQL的复制需要主库发送BINLOG日志图30-3MySQL一主多从复制架构<br>到从库的I&#x2F;O线程，主库的IO压力和网络压力会随着从库的增加而增长（每个从库都会在主库上有一个独立的BINLOGDump线程来发送事件），而多级复制架构解决了一主多从场景下，主库额外的I&#x2F;O和网络压力。MySQL的多级复制架构如图30-4所示。</p>
<p>≦ 559 ≧<br>30.1复制概述 541<br>对比一主多从的架构图，多级复制仅 多级复制仅是在主库Master1复制到从库Slavel、 Web Client Web Client Web Client Web Client Slave2、Slave3的中间增加一个二级主库<br>Write Request<br>Master2，这样，主库Master1只需要给一个从库Master2发送BINLOG日志即可，<br>Replication<br>减轻了主库Masterl的压力。二级主库<br>Master2<br>Master2再发送BINLOG日志给所有从库 Replication Slavel、Slave2和Slave3的I&#x2F;O线程。<br>多级复制解决了一主多从场景下，主 Slavel Slave2 Slave3 库的I&#x2F;O负载和网络压力，当然也有缺点：<br>MySQL的传统复制是异步的，多级复制 LVS&#x2F;负载均衡<br>场景下主库的数据是经历两次复制才到 Read Request 达从库Slavel、Slave2、Slave3的，期间<br>Web Client Web Client Web Client Web Client<br>的延迟要比一主多从复制场景下只经历<br>一次复制的还大。 图30-4MySQL多级复制架构<br>可以通过在二级主库Master2上选择表引擎为BLACKHOLE来降低多级复制的延迟。顾名思义，BLACKHOLE引擎是一个“黑洞”引引擎，写人BLACKHOLE表的数据并不会写回到磁盘上，BLACKHOLE表永远都是一个空表，INSERT&#x2F;UPDATE&#x2F;DELETE操作仅仅在BINLOG 中记录事件。<br>mysql&gt; CREATE TABLE blackhoTe（i INT,c CHAR(10)) ENGINE &#x3D; BLACKHOLE； Query ok,0 rows affected (o.04 sec)<br>mysq1&gt; INsERT INTo blackhole VALuES(1,record one’),(2,record two’）；<br>Query ok, 2 rows affected (o.oo sec) Records:2Duplicates:0warnings:0<br>mysql&gt; select * from blackhole; Empty set (0.00 sec)<br>BLACKHOLE引擎非常适合二级主库Master2的场景：Master2并不承担读写请求，仅仅负责将BINLOG日志尽快传送给从库。<br>3.双主（Dual Master）复制架构<br>双主（DualMaster）复制架构适用于DBA做维护时需要主从切换的场景（也可以考虑使<br>用高可用方案，具体参考第31章），通过 双主复制双主复制架构避免了重复搭建从库的麻<br>Web Client Web Client WebClient Web Client<br>烦，双主复制架构如图30-5所示。<br>主库Master1和Master2互为主从，所<br>Write&#x2F;ReadRequest<br>有WebClient的写请求都访问主库Masterl，<br>浮动虚拟IP等技术<br>而读请求可以选择访问主库Masterl或 Read Request<br>Write&#x2F;Read Request<br>Master2。假如，DBA需要做日常维护操<br>作，为了避免影响服务，需进行以下操作。 Masterl Replication Master2<br>首先，在Masterl库上停止Slave<br>线程（STOPSLAVE），避免后续对Master2 Replication<br>库的维护操作被实时复制到Master1库上图30-5MySQL双主复制架构</p>
<p>≦ 560 ≧<br>542 第30章MySQL复制对服务造成影响。<br>O其次，在Master2库上停止Slave线程（STOPSLAVE），开始日常维护操作，例如修改varchar字段长度从10增加到300。<br>O然后，在Master2库上完成维护操作之后，打开Master2库上的Slave线程（START SLAVE），让Master2库的数据和Master1库同步，同步完成后，把应用的读写操作切换到Master2 库上。<br>O最后，确认Masterl库上无应用访问后，打开Master1库的Slave线程（STARTSLAVE）<br>即可。 双主-级联复制通过双主复制架构能够大大减<br>轻一主多从架构下对主库进行维护 Web Client Web Client Web Client Web Client 带来的额外搭建从库的工作。<br>当然双主复制还能和主从复制 Write&#x2F;Read Request 联合起来使用：在Master2库下配置 浮动虚拟IP等技术<br>Read Request<br>从库Slavel、Slave2等，这样既可通 Write&#x2F;Read Request 过从库Slave1等来分担读取压力，<br>Masterl Master2<br>同时在DBA做维护的同时，避免了 Replication<br>重建从库的额外工作，但需要注意从 Replication<br>库的复制延迟。MySQL的双主多级 Slavel Slave2 复制架构如图30-6所示。<br>由于MySQL的BINLOG中会记图30-6MySQL双主多级复制架构<br>录事件初始发生的server id，以Master1上的BINLOG为例：#at282<br>#180720 16:16:40 server id 7237 end_1og_pos 341 cRc32 0x1e63cedf Table_map:employees<br>.salariesmapped to number 165#at580<br>#180720 16:17:27 server id 7238 end_log_pos 639 cRC32 0x02604abb Table_map:employees salariesmapped to number 165<br>MySQL只应用和自己ServerID不同的BINLOG日志。从上面的数据中可以看到ServerID 有两个，分别为7237和7238，其中7237代表是自身实例，7238表示另一个实例。这段数据表明该实例自身执行了一些事务，又通过复制，执行了ServerID为7238所执行过的事务， MySQL就这样通过判断BINLOG事件中的不同ServerID即可判断当前库是否是事件发生的初始发生Server，所以双主复制加上级联复制也不会出现循环复制。<br>4.多源（Multi-Source）复制架构<br>多源（Multi-Source）复制架构适合于复杂的业务需求，既可以支撑OLTP（联机事务处理），也可以满足OLAP（联机分析处理）。MySQL的多源复制架构如图30-7所示。<br>Slave1是主库Master1的单独从库，Slave2是主库Master2单独从库，Slave3是主库Masterl 和Master2的共用从库。WebClient客户端分业务，将不同的写请求发往主库Masterl或者 Master2，而针对线上的读请求优先访问各自的单独从库。因主库Master1和Master2都只有线上的部分数据，不能提供全量数据；针对OLAP的业务需求，Slave3能很好地提供数据，省去合并数据的烦恼。</p>
<p>≦ 561 ≧<br>30.2复制搭建 543<br>多源复制<br>Web Client Web Client Web Client Web Client<br>WriteRequeste Write Request<br>Read Request Read Request<br>Master2<br>Slave3 Slave2+<br>Read Request<br>Web Client Web Cliente Web Client Web Cliente<br>图30-7MySQL多源复制架构<br>另外，共用从库还能作为Slave1和Slave2的备机，随时可以接替其工作，且节省购机成本（因高可用MHA需要一主两从，此部分内容可参见第31章）。<br>此方案的缺点也一目了然，那就是Master1和Master2如果有数据冲突，共用从库Slave3 将会发生数据混乱。复制过程中可以显式定义通道（Channel），通过执行show slave status可<br>以看到该复制线程正在使用哪个通道，后续的操作都将围绕该通道执行。 mysql&gt; show slave status\G;<br>Channe1 Name:channe1 3305 Channel _Name:channe1 3307<br>2rows in set (o.o0 sec) 30.2复制搭建<br>30.1节主要介绍了MySQL的复制原理和常见的复制架构。本节将介绍如何一步步搭建复制环境。<br>30.2.1异步复制<br>MySQL的复制默认是异步的，主从复制至少需要两个MySQL服务，这些MySQL服务可以分布在不同的服务器上，也可以在同一台服务器上。主从复制配置的步骤比较简单，下面进行详细介绍。<br>（1）确保主从库上安装了相同版本的数据库。因为主从库的角色可能会互换，同时减少问题出现的概率，所以在可能的情况下推荐安装最新的稳定版本。<br>（2）在主库上，设置一个复制使用的账户，并授予REPLICATIONSLAVE权限。这里创建一个复制用户rep1，允许IP为10.120.240.251的主机进行连接，在MySQL5.7和8.0中，</p>
<p>≦ 562 ≧<br>544 第30章MySQL复制创建命令有所不同。<br>MySQL5.7可以用下面两种方式创建：<br>mysql&gt; GRANT REPLICATION SLAVE ON **<a href="mailto:&#84;&#x4f;&#x72;&#101;&#x70;&#108;&#64;&#49;&#x30;&#x2e;&#x31;&#x32;&#x30;&#x2e;&#x32;&#52;&#48;&#46;&#x32;&#53;&#x31;&#73;&#68;&#x45;&#78;&#x54;&#73;&#70;&#73;&#x45;&#x44;">&#84;&#x4f;&#x72;&#101;&#x70;&#108;&#64;&#49;&#x30;&#x2e;&#x31;&#x32;&#x30;&#x2e;&#x32;&#52;&#48;&#46;&#x32;&#53;&#x31;&#73;&#68;&#x45;&#78;&#x54;&#73;&#70;&#73;&#x45;&#x44;</a> BYrep1’;<br>Query oK,O rows affected (o.o0 sec) 或者：<br>mysql&gt; Create user repl‘@’10.120.240.251 IDENTIFIED WITH mysql native passWord BY  rep1′; Query ok,O rows affected (o.o0 sec)<br>mySq1&gt; GRANT REPLICATION SLAVE ON *<em>TO</em><a href="mailto:&#x72;&#x65;&#x70;&#x31;&#64;&#x31;&#48;&#46;&#49;&#x32;&#48;&#x2e;&#50;&#x34;&#x30;&#46;&#50;&#x35;&#49;">&#x72;&#x65;&#x70;&#x31;&#64;&#x31;&#48;&#46;&#49;&#x32;&#48;&#x2e;&#50;&#x34;&#x30;&#46;&#50;&#x35;&#49;</a>; Query oK,O rows affected (o.o0 sec)<br>MySQL8.0中可以沿用上面的第二种方式，也可以使用下面的方式创建：<br>mysql&gt; Create user repl‘@10.120.240.251 IDENTIFIED WITH BY repl’; Query ok, 0 rows affected (o.o0 sec)<br>mySq1&gt; GRANT REPLICATION SLAVE ON **<a href="mailto:&#84;&#x4f;&#114;&#101;&#112;&#49;&#64;&#49;&#x30;&#46;&#49;&#50;&#x30;&#46;&#50;&#x34;&#x30;&#x2e;&#x32;&#x35;&#x31;">&#84;&#x4f;&#114;&#101;&#112;&#49;&#64;&#49;&#x30;&#46;&#49;&#50;&#x30;&#46;&#50;&#x34;&#x30;&#x2e;&#x32;&#x35;&#x31;</a>; Query ok,0 rows affected (o.o0 sec)<br>以上代码使用了MySQL8.0的默认认证方式caching_sha2_password，执行前需要在配置<br>文件my.cnf中添加如下内容，然后重启MySQL实例：[mysq1d]<br>default_authentication plugin&#x3D;caching_sha2_password<br>（3）修改主数据库服务器的配置文件my.cnf，开启BINLOG，并设置server-id的值。这两个参数的修改需要重新启动数据库服务才能生效。<br>在my.cnf中修改如下：<br>[mysq1d]1og-bin&#x3D;&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin server-id&#x3D;7237<br>（4）在主库上，设置读锁定有效，这个操作是为了确保没有数据库操作，以便获得一个一致性的快照：<br>mysql&gt; flush tables with read lock; Query ok,O rows affected (o.o0 sec)<br>（5）然后得到主库上当前的二进制日志名和偏移量值。这个操作的目的是为了在从数据库启动以后，从这个点开始进行数据的恢复（如果已经启用了GTID模式，可以跳过该步骤，关于GTID，详见下文）。<br>mysql&gt; show master status;<br>File IPosition I Binlog Do DB | Binlog Ignore DB | Executed Gtid Set<br>1mysq1-bin.0000131 23981 1row in set (0.00 sec)<br>（6）现在主数据库服务器已经停止了更新操作，需要生成主数据库的备份，备份的方式有很多种，可以直接在操作系统下复制全部的数据文件到从数据库服务器上，也可以通过 mysqldump导出数据或者使用xtrabackup等热备份工具进行数据库的备份，这些备份操作的步骤已经在第25章中有详细介绍，这里就不再一一说明。如果主数据库的服务可以停止，那么直接复制数据文件应该是最快的生成快照的方法。<br>（7）主数据库的备份完毕后，可以恢复写操作，剩下的操作只需要在从库上执行： mysql&gt; unlock tables;<br>Query oK,O rows affected (o.o0 sec)<br>（8）将主数据库的一致性备份恢复到从数据库上。如果是使用.tar打包的文件包，只需要</p>
<p>≦ 563 ≧<br>30.2复制搭建 545<br>解开到相应的目录即可。<br>（9）修改从数据库的配置文件my.cnf，增加server-id参数。注意server-id的值必须是唯一的，不能和主数据库的配置相同，如果有多个从数据库服务器，每个从数据库服务器必须有自己唯一的server-id值（如果已经启用了GTID模式，同时删除datadir目录下的auto.cnf 文件，避免与主库有相同的UUID，关于GTID，详见下文）。<br>在my.cnf中修改如下：[mysqld]<br>server-id&#x3D;7238<br>MySQL数据目录下的auto.cnf文件内容如下：[mysq13489@hz _10 120_240 251 data]$ cat auto.cnf[auto]<br>server-uuid&#x3D;7c63d434-6edd-11e8-b378-0024e869b4d5<br>（10）在从库上，使用–skip-slave-start选项启动从数据库，这样不会立即启动从数据库服务上的复制进程，方便对从数据库的服务进行进一步的配置：<br>[mysq13308@hz_10_120_240_251 mysq1home]s.&#x2F;bin&#x2F;mysq1d safe –defau1ts-fi1e&#x3D;&#x2F;home&#x2F;mysq13308&#x2F; mysq1home&#x2F;my.cnf –user&#x3D;mysq13308 –skip-slave-start &amp;<br>（11）对从数据库服务器做相应设置，指定复制使用的用户，主数据库服务器的IP、端口以及开始执行复制的日志文件和位置等，具体代码如下（如果已经启用了GTID模式，不需要指定复制的日志文件和位置，可以指定MASTER_AUTO_POSITION&#x3D;1，即自动发现复制起<br>始点，关于GTID，详见下文）： mysql&gt; CHANGE MASTER TO </p>
<blockquote>
<p>MASTER HoST&#x3D;’master_host_name’,<br>-&gt; MAsTER UsER&#x3D;replication user name’<br>-&gt;MASTER PAsSWORD&#x3D;’replication_password’， &gt;MASTER LOG FILE&#x3D;’recorded log file name’ &gt;MASTER LOG POS&#x3D;recorded_log position;<br>举例说明如下：<br>mysql&gt; CHANGE MASTER To<br>-&gt;MASTER HOST&#x3D;10.120.240.251，<br>-&gt; MASTER_PORT&#x3D;3307,-&gt; MASTER USER&#x3D;’repl’<br>-&gt; MASTER_PASSWORD&#x3D;’rep1<br>-&gt; MASTER_LOG_FILE&#x3D;*mysq1-bin.000013-&gt; MASTER_LOG_POS&#x3D;2398;<br>Query oK, 0 rows affected (0.10 sec)<br>如果想显式定义通道（Channel），详见如下： mysql&gt; CHANGE MASTER TO<br>-&gt;MASTER HOST&#x3D;10.120.240.251<br>-&gt;MASTER_PORT&#x3D;3307, &gt;MASTER USER&#x3D;’repl<br>-&gt; MASTER PASSWORD&#x3D;’repl<br>-&gt; MASTER LOG_FILE&#x3D;’mysq1-bin.000013-&gt; MASTER_LOG_POS&#x3D;2398<br>-&gt;FOR CHANNEL channe1 3307’；<br>Query ok,0 rows affected (0.10 sec)（12）在从库上，启动slave线程： mysql&gt; start slave;<br>Query oK, Orows affected (o.o0 sec)<br>注意：如果使用了MySQL8.0默认的认证方式caching_sha2_password，可以在STARTSLAVE时<br>指定DEFAULT_AUTH&#x3D;caching_sha2_password’，详见如下：</p>
</blockquote>
<p>≦ 564 ≧<br>546 第30章MySQL复制 mysql&gt; start slave DEFAULT AUTH&#x3D;caching sha2 password’； Query oK,O rows affected (o.o0 sec)<br>（13）这时slave上执行showprocesslist命令将显示类似如下的进程： root@localhost:mysql_3308.sock [(none)]&gt;show processlist\G;<br>Id:1<br>User: event scheduler<br>Host: localhost db：NULL<br>Command: Daemon<br>Time: 3544378<br>State: waiting on empty queue Info: NULL<br>*2.row<br>Id:51<br>User: system user<br>Host. db:NULL Command: connect Time:341636<br>State: waiting for master to send event<br>Info: NULL Id:52<br>user: system user Host:<br>db:NULL Command: Connect<br>Time:15017<br>State: slave has read all relay log; waiting for more updates Info: NULL<br>这表明slave已经连接上master，并开始接受并执行日志。<br>（14）也可以测试复制服务的正确性，在主数据库上执行一个更新操作，观察是否同步到了从库。在主数据库上的employees数据库中操作一张表：<br>mysql&gt; update salaries set salary&#x3D;100 where emp_no&#x3D;10001 and salary&#x3D;60117; Query ok, 1 row affected (0.o1 sec)<br>Rows matched:1changed:1warnings:0（15）在从数据库上检查数据是否同步：<br>mysql&gt; select * from salaries where emp_no&#x3D;10001 and salary&#x3D;100;<br>Iemp_no l salary I from date to _date<br>10001 1 100 11986-06-2611987-06-26 1 row in set (o.o0 sec)<br>可以看到数据可以正确同步到从数据库上，主从复制服务配置成功完成。<br>MySQL主从异步复制是最常见和最简单的复制场景。数据的完整性依赖于主库BINLOG 的不丢失，只要主库的BINLOG不丢失，那么就算主库岩机了，我们还可以通过BINLOG把丢失的部分数据通过手工同步到从库上去。<br>注意：主库宕机的情况下，DBA可以通过mysqlbinlog工具手工访问主库binlog，抽取缺失的日志<br>并同步到从库上去；也可以通过配置高可用MHA架构来自动抽取缺失的数据补全从库，高可用的MHA架构会在其他章节介绍，或者启用GlobalTransaction Identifiers（GTID）来自动抽取缺失Binlog到从库，此部分内容详见30.3节。<br>MySQL在BINLOG中记录事务（或SQL语句），也就是说对于支持事务的引擎（例如</p>
<p>≦ 565 ≧<br>30.2复制搭建 547<br>InnoDB）来说，每个事务提交时都需要写BINLOG；对于不支持事务的引擎（例如MyISAM）来说，每个SQL语句执行完成时，都需要写BINLOG。为了保证Binlog的安全，MySQL引<br>人sync_binlog参数来控制BINLOG刷新到磁盘的频率。 mysql&gt; show variables like ‘sync binlog；<br>I Variable name | value | |sync binlog<br>1 row in set (0.10 sec)<br>O在默认情况下，sync_binlog&#x3D;1，表示事务提交之前，MySQL都需要先把BINLOG刷新到磁盘，这样的话，即便出现数据库主机操作系统崩溃或者主机突然掉电的情况，系统最多损失prepared状态的事务；设置sync_binlog-l，尽可能保证数据安全。<br>Osync_binlog&#x3D;0，表示MySQL不控制binlog的刷新，由文件系统自己控制文件系统缓存的刷新。<br>Osync_binlog&#x3D;N，如果N不等于0或者1，刷新方式同sync_binlog&#x3D;1类似，只不过此时会延长刷新频率至N次binlog提交组之后。<br>以上是传统的异步复制搭建过程，相信大家对其并不陌生，在MySQL5.7的并行复制技术到来之前，为人病最多的还是效率问题，slave延迟是个顽疾，虽然之前已经出现了schema 级别的并行复制，但实际效果并不好，接下来详细介绍一下MySQL5.7中的并行复制（也称为多线程复制）。<br>30.2.2多线程复制<br>在MySQL5.7中，带来了全新的多线程复制技术，解决了当master同一个schema下的数据发生了变更，从库不能并发应用的问题，同时也真正将binlog组提交的优势充分发挥出来，保障了从库并发应用RelayLog的能力，接下来还是一步步地介绍多线程复制环境的搭建过程（在30.2.1节的基础上继续操作）。<br>（1）在从库上确认以下参数的配置。<br>mysql&gt; show variables 1ike slave paralle1%’;<br>| Variable name |Value<br>1slave_parallel type LOGICAL_CLOCK<br>|slave_parallel_workers |8 2 rows in set (o.00 sec)<br>mysql&gt; show variables like %repository’;<br>1variablename 1value|<br>I master_info repository TABLE Irelay_log info_repository TABLE<br>2rows in set (0.01 sec)<br>mysql&gt; show variables like relay log_recovery’;<br>1variable_name |value|</p>
<p>≦ 566 ≧<br>548 第30章MySQL复制<br>I relay_log_recovery | on 1 row in set (o.00 sec)<br>mysql&gt; show variables like slave preserve commit order’; I Variable _name value<br>I slave preserve_commit order I oN 1 row in set (0.01 sec)<br>参数slave_parallel_type默认是DATABASE，兼容以前不同schema的并行复制， LOGICAL_CLOCK是表示逻辑时间戳，即多线程复制依赖主库commit时刻的时间戳，从 BINLOG中的last_committed和sequence_number可以来判断，相同last_committed作为一组事务，可以并行执行（不同的last_committed有时也是可以并行执行的，参见下文）。<br>参数slave_parallel_workers默认值为0，表示禁用多线程复制；当设置该值大于1的时候，例如 slave_parallel_workers&#x3D;8，表示有8个线程执行应用。如果要修改该参数值，可参考如下示例：<br>mysql&gt; set global slave parallel workers&#x3D;8； Query ok,O rows affected (o.oo sec)<br>mysql&gt; stop slave for channel channel 3307’; Query ok,O rows affected (o.o0 sec)<br>mysql&gt; start slave for channel ‘channel 3307’; Query oK,0 rows affected (0.02 sec)<br>参数slave_preserve_commit_order默认值为OFF，即表示复制应用的过程中，不保留主库事务提交的顺序性，例如主库并发提交了事务t1、t2、t3、t4，但从库应用过程中，提交顺序可能是t2、t3、tl、t4，如果从库也会有业务端访问，需要考虑是否要设置为ON，以此来保证和主库事务提交顺序的一致性。<br>参数relay_log_recovery、master_info_repository、relay_log_info_repository这样设置，则是为了考虑在多线程复制场景下，从库一旦crash，可以保障recovery时数据可恢复。<br>（2）验证多线程复制，以下示例中Master启动了3个session： Sessionl<br>mysql&gt; start transaction;<br>Query ok,0 rows affected (o.oo sec)<br>mysql&gt; update salaries set salary&#x3D;100 where emp no&#x3D;10001 and salary&#x3D;60117; Query ok, 1 row affected (0.00 sec)<br>Rows matched:1changed:1 warnings:0 Session2:<br>mysql&gt; start transaction;<br>Query ok,0 rows affected (0.00 sec)<br>mysql&gt; update salaries set salary&#x3D;200 where emp no&#x3D;10001 and salary&#x3D;62102; Query ok, 1 row affected (0.o0 sec)<br>Rows matched:1changed:1warnings:0 Session3:<br>mysql&gt; start transaction;<br>Query ok,0 rows affected (o.oo sec)<br>mysql&gt; update salaries set salary&#x3D;300 where emp_no&#x3D;10001 and salary&#x3D;66074; Query ok, 1 row affected (0.00 sec)<br>Rows matched:1Changed:1warnings:0<br>Session3: commit;</p>
<p>≦ 567 ≧<br>30.2复制搭建 549<br>Session2: Commit;<br>Sessionl: Commit;<br>用mysqlbinlog工具解析BINLOG，如下所示。<br>#180730 17:06:26 server id 7237 end 1og_pos 1270 cRc32 0x86e1a095 Anonymous_GTID last_committed&#x3D;4 sequence_number&#x3D;5rbr_only&#x3D;yes<br>###UPDATEemployees#salaries###WHERE<br>###@2&#x3D;66074&#x2F;<em>INT meta&#x3D;0nu11able&#x3D;0 is_nu11&#x3D;0</em>&#x2F;###SET<br>###@2&#x3D;300&#x2F;*INT meta&#x3D;0nu1lable&#x3D;0isnu11&#x3D;0&#x2F;<br>#180730 17:06:27 server id 7237 end 1og pos 1568 cRc32 0xf28f52d2 Anonymous GTID last_committed&#x3D;4 sequence_number&#x3D;6rbr_only&#x3D;yes<br>###uPDATE employeessalaries###SET<br>@2&#x3D;200&#x2F;<em>INT meta&#x3D;0nu1lable&#x3D;0 is_nu11&#x3D;0</em>&#x2F;###<br>#180730 17:06:27 server id 7237 end 1og_ pos 1866 cRc32 0xadba61fd Anonymous_GTID last_committed&#x3D;4 sequence_number&#x3D;7 rbr_only&#x3D;yes<br>###UPDATEemployeessalaries###SET<br>###@2&#x3D;100&#x2F;<em>INT meta&#x3D;0 nu1lable&#x3D;0isnu11&#x3D;0</em>&#x2F;<br>以上的last_committed的值是一样的，都是4，作为一组事务，表明从库应用的时候是可以并发执行的。<br>在MySQL8.0中，多线程复制又进行了技术更新，引人了writeset的概念，而在之前的版本中，如果主库的同一个会话顺序执行多个不同相关对象的事务，例如，先执行了UpdateA 表的数据，又执行了UpdateB表的数据，那么BINLOG在复制到从库后，这两个事务是不能并行执行的，writeset的到来，突破了这个限制。下面进行详细介绍。<br>（1）准备好主从复制环境（以下使用了MySQL8.0.11版本），此过程可参考上文描述。（2）主库执行事务前，确认以下两个参数。<br>mysql&gt; show variables like ‘transaction write set extraction’;<br>1Variable name 1value<br>| transaction write_set extraction l xxHasH64 1 1 row in set (0.01 sec)<br>mysql&gt; show variables like binlog transaction_dependency_tracking’；<br>IVariable_name value Ibinlog transaction dependency_tracking | coMMIT oRDER1<br>以上第一个参数transaction_write_set_extraction是启用写集（writeset）的前提条件，定义了事务中写集的算法，默认是OFF，即关闭状态，表示不启用writeset，但从MySQL8.0.2以后，该参数的默认值已经变更为XXHASH64。<br>以上第二个参数binlog_transaction_dependency_tracking，表示从库并发执行的依赖信息</p>
<p>≦ 568 ≧<br>550 第30章MySQL复制<br>源，即当主库执行事务，产生BINLOG后，这些事务能否在开启多线程复制的从库并发执行。该参数有3个可选值，分别为COMMIT_ORDER、WRITESET和WRITESET_SESSION，默认值是COMMIT_ORDER。<br>OCOMMIT_ORDER：表示依赖信息由主库提交时的时间戳产生，即5.7版本的默认行为。 OWRITESET：表示依赖信息由主库的write set产生，任何写入不同元组的事务能够并<br>发执行，可以简单理解为，当主库的同一个会话更新不同记录时（同一个表或不同表），从库也可以并行执行。这里有一个特殊情况，如果被更新的表不包括主键或者包含了外键，即便设置了WRITESET，也等同于参数值COMMIT_ORDER。<br>OWRITESETSESSION：与WRITESET类似，只不过此时又多了一个约束，即使多个操作间数据并无冲突，但如果这些操作发生在同一会话中，也等同于参数值COMMIT_ORDER。<br>这些参数值初次接触可能觉得有些难以理解，下面会通过样例进行说明。（3）在主库上新建一个会话，并顺序执行以下两个事务。<br>mysql&gt; update employees.dept_emp set to date&#x3D;’9999-02-02’ 1imit 3；<br>Query oK, 3 rows affected (o.o0 sec) Rows matched:3changed:3warnings:0<br>mysql&gt; update employees.salaries set salary&#x3D;100 1imit 3; Query ok,3 rows affected (0.20 sec)<br>Rows matched:3changed:3 warnings:0<br>（4）在主库查看此时产生的BINLOG数据。<br>[mysq13308@hz 10 120 240 251 data]s mysq7binlog-vvv mysq]-bin.000008 &gt; mysq1-bin.000008.1og[mysq13308@hz 10 120 240 251 data]s cat mysql-bin.000008.1oglgrep “1ast commit”<br>#181119 18:29:35 server id 7238 end log pos 1033 CRC32 0xd9819f9d GTID last_committed&#x3D; sequence_number&#x3D;3 rbr only&#x3D;yes<br>#181i19 18:29:48 server id 7238 end 1og pos 1399 cRc32 0x7722ed70 last_committed<br>GTID<br>3sequence_number&#x3D;4rbr only&#x3D;yes<br>可以看到，此时生成的BINLOG数据依赖的主库的时间戳，last_commited不一致，没有在一个组内，在从库不能并发执行。<br>（5）修改主库的参数binlog_transaction_dependency_tracking变更为WRITESET。<br>mysql&gt; set global binlog transaction dependency <em>tracking&#x3D;wRITEsET’； Query ok, o rows affected (o.oo sec)<br>mysql&gt; show variables like binlog transaction dependency tracking’;<br>I Variable name value<br>I binlog</em> transaction_dependency_tracking I WRITESET 1row in set (0.01 sec)<br>注意：当参数binlog_transaction_dependency_tracking 变更为WRITESET后，参数transaction<br>write_set_extraction不能变更为其他值，如下所示。<br>mysql&gt; set transaction write_set extraction&#x3D;off;<br>ERRor 1221 (Hy0oo): Incorrect usage of transaction write set extraction (changed) and binlog transaction dependency_tracking （!&#x3D; coMMIT oRDER)<br>（6）主库上创建一个新会话，并顺序执行以下两个事务。<br>mysq1&gt; update emp1oyees.dept emp set to date&#x3D;9999-02-011imit 3；m Query ok,3 rows affected (0.94 sec)<br>Rows matched:3changed:3 warnings:0<br>mysql&gt; update employees.salaries set salary&#x3D;200 limit 3;</p>
<p>≦ 569 ≧<br>30.2复制搭建 551<br>Query ok,3 rows affected (0.38 sec)<br>Rows matched:3changed:3warnings:0（7）在主库查看此时的BINLOG数据。<br>[mysq13488@hz 10 120 240 251 data]s mysq1binlog -vvv mysq1-bin.000028&gt; mysq1-bin.000028.1og[mysq13488@hz 10 120 240 251 data]s cat mysql-bin.000028.1og lgrep last_committed”<br>#181119 17:25:22 server id 7237 end_1og_pos 270 cRC32 0xfa82c8fb last_committed<br>GTID<br>sequence_number&#x3D;1rbr_only&#x3D;yesoriginal committed timestamp&#x3D;1542619522970168<br>&#x3D;0<br>immediate_commit_timestamp&#x3D;1542619522970168 transaction_1ength&#x3D;385<br>#181119 17:25:35 server id 7237 end 1og pos 655 CRc32 0x111c59d1 GTID last_committed<br>sequence_number&#x3D;2rbr_only&#x3D;yes original_committed_timestamp&#x3D;1542619535667730 immediate commit timestamp&#x3D;1542619535667730transaction_length&#x3D;374<br>可以看到，虽然已经将参数设置正确，但并没有得到想要的效果（仍然没有在同一个组），这是为什么呢？<br>（8）查看会话中的事务涉及的两个表结构，具体如下： mysql&gt; show create table salaries;<br>|salaries|CREATE TABLEsalaries（<br>emp noint（11) NOT NULL, salaryint(11) NOT NULL, from date date NOT NULL, to date date NOT NULL,<br>PRIMARY KEY（emp_no，from_date),<br>CONSTRAINTsalaries_ibfk 1FOREIGN KEY (emp_no) REFERENCESemployees(emp_no）ON<br>DELETE CASCADE<br>)ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode_ci1 mysql&gt; show create table employees.dept emp;<br>|dept emp I CREATE TABLE dept emp（ emp no int(i1) NOT NULL,<br>dept nochar(4) cOLLATE utf8 unicode_ci NOT NULL,<br>from date  date NOT NULL, to date date NOT NULL,<br>PRIMARY KEY（emp no，dept_no）， KEYdeptno（dept no），<br>CONSTRAINTdept_emp_ibfk1FOREIGN KEY Cemp_no) REFERENCES employeesCemp_no） ON DELETE CASCADE,<br>CONSTRAINTdept_emp_ibfk2FOREIGN KEY (dept_no) REFERENCESdepartments(deptno)<br>ON DELETE CASCADE<br>) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8 unicode ci<br>可以看到这两个表都涉及外键，就是这个原因将导致复制不能被并发执行。接下来，删除掉这些外键约束，代码如下：<br>mysql&gt; alter table employees.salaries DROP FOREIGN KEY salaries ibfk 1；<br>Query ok,0 rows affected (0.11 sec) Records:ODuplicates:OWarnings:0<br>mysql&gt; alter table employees.dept emp drop FOREIGN KEY dept emp_ibfk 1;<br>Query oK,0 rows affected (0.19 sec) Records:0Duplicates:0warnings:0<br>mysql&gt; alter table employees.dept emp drop FOREIGN KEY dept emp_ibfk 2;<br>Query ok,0 rows affected (0.03 sec) Records:0 Duplicates:Owarnings:0<br>（9）在主库上再次顺序执行以下两个事务。<br>mysql&gt; update emp1oyees.dept emp set to date&#x3D;’9999-01-011imit 3; Query ok, 3 rows affected (0.06 sec)<br>Rows matched:3 changed:3 warnings:0<br>mysql&gt; update employees.salaries set salary&#x3D;100 1imit 3; Query 0k,3 rows affected (0.01 sec)<br>Rows matched:3changed:3warnings:0<br>（10）在主库查看此次生成的BINLOG，具体如下：</p>
<p>≦ 570 ≧<br>552 第30章MySQL复制<br>[mysq13488@hz_10 120 240 251 data]s mysq1binlog -vvv mysq1-bin.000028 &gt; mysq1-bin.000028.1og[mysq13488@hz_10 120 240 251 data]s<br>[mysq13488@hz 10 120 240 251 data]s cat mysql-bin.000028.1og Igrep 1ast committed<br>#181119 17:26:50 server id 7237 end log pos 1475 cRC32 0xb55ff777 last_committed&#x3D;<br>GTID<br>sequence_number&#x3D;5rbr_only&#x3D;yesoriginal_committed_timestamp&#x3D;1542619610265407 4<br>immediate_commit_timestamp&#x3D;1542619610265407 transaction_length&#x3D;385<br>#181119 17:26:57 server id 7237 end 1og pos 1860 cRc32 0x30ea5e65 GTIDlast_committed&#x3D;<br>sequence_number&#x3D;6rbr only&#x3D;yes original_committed_timestamp&#x3D;1542619617335538 immediate_commit timestamp&#x3D;1542619617335538transaction_1ength&#x3D;374<br>注意：实际业务场景可能比较复杂，如下所示，在经历过反复验证之后，发现在同一个会话中<br>顺序执行上面的这两个事务（每次更新之前更改事务1和事务2的条件，使其不会更新相同记录，例如第一次，事务1:updateAwhereid&#x3D;1，事务2:updateBwhereid&#x3D;1；第二次，事务1:updateAwhereid&#x3D;2，事务2:updateBwhereid&#x3D;2），得到的last_committed 也可能不同，类似如下情况，即last_committed的值是交叠相同的。事务1执行了两次， last_committed的值都是28；事务2执行了两次，last_committed的值都是29，但事务1 与事务2不属于同一个组（last_committed不相等），此时可以通过last_committed与 sequence_number进行比较，如果last_committed（28和29）的值&lt;min（sequence_number）的值（32），表明数据之间不冲突，即从库仍然可以并行执行。<br>第一次，事务1：<br>#181212 16:20:06 server id 7237 end 1og_pos 10041 cRc32 0x1a02766e GTID<br>last_commi tted&#x3D;28 sequence_number&#x3D;32rbr_only&#x3D;yesoriginal_committed timestamp&#x3D; 1544602806172592immediate_commit_timestamp&#x3D;1544602806172592transaction_length&#x3D;320<br>第一次，事务2：<br>#181212 16:20:09 server id 7237 end 1og pos 10361 cRc32 0xd9147b9a GTID<br>last_committed&#x3D;29 sequence_number&#x3D;33rbr only&#x3D;yes original_committed timestamp&#x3D; 1544602809135136 immediate_commit_timestamp&#x3D;1544602809135136 transaction length&#x3D;320<br>第二次，事务1：<br>#181212 16:21:02 server id 7237 end 1og pos 10681 cRc32 0xacf051bb GTID<br>last_committed&#x3D;28sequence_number&#x3D;34rbr_only&#x3D;yes original_committed timestamp&#x3D; 1544602862252860 immediate_commit_timestamp&#x3D;1544602862252860 transaction_length&#x3D;320<br>第二次，事务2：<br>#181212 16:21:05 server id 7237 end 1og pos 11001 cRc32 0x0fa69c25 GTID<br>last_committed<br>sequence_number&#x3D;35rbr_only&#x3D;yes original_committed_timestamp&#x3D;1544602865816208 29<br>immediate commit timestamp&#x3D;1544602865816208 transaction length&#x3D;320<br>从试验结果来看，符合预期，从库可以并发应用RelayLog数据（这涉及多线程复制的实现机制Commit-Parent-Based、Lock-Based，由于内容晦涩，在此不再深人讨论）。<br>接下来再验证一下如果将参数binlog_transaction_dependency_tracking的值，变更为 WRITESET_SESSION，会有什么样的结果？<br>（1）首先，确认主库设置以下参数值。<br>mysql&gt; set global binlog transaction <em>dependency_tracking&#x3D;’wRITEsET SESsIoN’; Query ok, 0 rows affected (o.o0 sec)<br>mysql&gt; show variables like ‘binlog</em> transaction_dependency_tracking’;<br>IVariable name |value<br>Ibinlog transaction dependency_tracking I wRITEsET _SESSIoN 1row in set (o.00 sec)<br>mysql&gt; show variables like ‘transaction write set extraction’:</p>
<p>≦ 571 ≧<br>30.2复制搭建 553<br>| Variable_name |value<br>Itransaction write set extraction | xxHAsH64 1row in set (0.o0 sec)<br>（2）主库上创建一个新会话，并顺序执行以下两个事务。 mysql&gt; update employees.salaries set salary&#x3D;100 1imit 3； Query oK,3 rows affected (0.09 sec)<br>Rows matched:3changed:3warnings:0<br>mysql&gt; update employees.dept emp set to date&#x3D;’9999-02-01’ limit 3; Query oK, 3 rows affected (0.06 sec)<br>Rows matched:3changed:3 warnings:0（3）在主库查看BINLOG日志。<br>[mysq13488@hz 10_120 240 251 data]s mysq1binlog -vv mysq1-bin.000029 &gt; mysq1-bin.000029.1og[mysq13488@hz 10 120 240 251 data]$<br>[mysq13488@hz 10_120_240_251 data]s cat mysq1-bin.000029.1og 1grep “1ast committed”<br>#181119 22:38:54 server id 7237 end 1og_pos 270 cRc32 0x8d5d169d GTID last_committed sequence_number&#x3D;1rbr only&#x3D;yes origina1_committed_timestamp&#x3D;1542638334826576<br>immediate_commit timestamp&#x3D;1542638334826576transaction_length&#x3D;374<br>#181119 22:39:06 server id 7237 end 1og pos 644 CRc32 0x58131898 last_committed<br>GTID<br>sequence_number&#x3D;2rbr_only&#x3D;yes original_commi tted timestamp&#x3D;1542638346404263 immediate commit timestamp&#x3D;1542638346404263  transaction_length&#x3D;385<br>可以看出，在将参数的值从WRITESET变更为WRITESET_SESSION之后，应用相同的试验内容，即主库在同一个会话对不同对象执行数据变更，但从库将不能并发应用。<br>（4）主库上再创建一个新会话，并在每一个会话分别执行一个事务。 sessionl:<br>mysql&gt; update employees.salaries set salary&#x3D;200 1imit 3; Query ok, 3 rows affected (o.09 sec)<br>Rows matched:3 Changed:3 warnings:0 session2:<br>mysql&gt; update employees.dept emp set to date&#x3D;’9999-01-01’1imit 3; Query Ok,3rows affected (0.06 sec)<br>Rowsmatched:3Changed:3warnings:0（5）查看主库上的BINLOG。<br>[mysq13488@hz 10_120_240 251 data]$ cat mysq1-bin.000029.1og lgrep 1ast_committed<br>#181119 22:47:19 server id 7237 end 1og pos 1029 cRC32 0x8aee409e GTID last_committed sequence_number&#x3D;3rbr only&#x3D;yes original_committed timestamp&#x3D;1542638839795133 &#x3D;2<br>immediate_commit_timestamp&#x3D;1542638839795133 transaction_length&#x3D;374<br>#181119 22:47:28 server id 7237 end 1og pos 1403 cRc32 0x43e79ebc last_committed<br>GTID<br>sequence_number&#x3D;4 rbr only&#x3D;yes original_committed_timestamp&#x3D;1542638848568232 immediate commit timestamp&#x3D;1542638848568232transaction_1ength&#x3D;385<br>可以看出，主库产生的BINLOG是符合预期的。 30.2.3增强半同步复制<br>前面介绍的复制是异步操作，主库和从库的数据之间难免会存在一定的延迟，这样存在一个隐患：当在主库上写人一个事务并提交成功，而从库尚未得到主库的BINLOG日志时，主库由于磁盘损坏、内存故障、断电等原因意外岩机，导致主库上该事务BINLOG丢失，此时从库就会损失这个事务，从而造成主从不一致。<br>为了解决这个问题，从MySQL5.5开始，引人了半同步复制机制，此时的技术暂且称之为传统的半同步复制，因该技术发展到MySQL5.7后，已经演变为增强半同步复制（也称为无损复制）。在异步复制时，主库执行Commit提交操作并写入BINLOG日志后即可成功返回</p>
<p>≦ 572 ≧<br>554 第30章MySQL复制<br>客户端，无须等待BINLOG日志传送给从库，如图30-8所示。<br>而半同步复制时，为了保证主库上的每一个BINLOG事务都能够被可靠地复制到从库上，主库在每次事务成功提<br>交时，并不及时反馈给前端应用用户， rela loappbinlocot 而是等待至少一个从库（详见参数rpl_ rela loabilo<br>la<br>semi_sync_master_wait for_slave_count)<br>也接收到BINLOG事务并成功写人中继 图30-8MySQL的异步复制<br>日志后，主库才返回Commit操作成功给客户端（不管是传统的半同步复制，还是增强的半同步复制，目的都是一样的，只不过两种方式在一个细微地方不同，详见下文）。<br>半同步复制保证了事务成功提交后，至少有两份日志记录，一份在主库的BINLOG日志上，另一份在至少一个从库的中继日志RelayLog上，从而更进一步保证了数据的完整性。<br>在传统的半同步复制中，主库写数据到BINLOG，且执行Commit操作后，会一直等待从库的ACK，即从库写入RelayLog后，并将数据落盘，返回给主库消息，通知主库可以返回前端应用操作成功，这样会出现一个问题，就是实际上主库已经将该事务Commit到了事务引擎层，应用已经可以看到数据发生了变化，只是在等返回而已，如果此时主库岩机，有可能从库还没能写人RelayLog，就会发生主从库数据不一致。增强半同步就是为了解决这个问题，做了微调，即主库写数据到BINLOG后，就开始等待从库的应答ACK，直到至少一个从库写人RelayLog后，并将数据落盘，然后返回给主库消息，通知主库可以执行Commit操作，然后主库开始提交到事务引擎层，应用<br>此时可以看到数据发生了变化。增强半 Master<br>commlt<br>同步复制的大致流程如图30-9所示。<br>半同步复制模式下，假如在传送 Slave1 relay log applybinlocomi BINLOG日志到从库时，从库岩机或<br>rel yl<br>者网络故障，导致BINLOG并没有及<br>时地传送到从库上，此时主库上的事图30-9MySQL增强半同步复制务会等待一段时间（时间长短由参数rpl_semi_sync_master_timeout设置的毫秒数决定），如果 BINLOG在这段时间内都无法成功发送到从库上，则MySQL自动调整复制为异步模式，事务正常返回提交结果给客户端。<br>半同步复制很大程度上取决于主从库之间的网络情况，往返时延RTT越小决定了从库的实时性越好。通俗地说，主从库之间网络越快，从库越实时。<br>注意：往返时延RTT（Round-TripTime）在计算机网络中是一个重要的性能指标，它表示从发送<br>端发送数据开始到发送端接收到接收端的确认，总共经历的时长。<br>半同步模式是通过一个插件来实现的，主库和从库使用不同的插件。安装比较简单，在 30.2.2节多线程复制的环境上，安装半同步复制插件即可。<br>（1）首先，判断MySQL服务器是否支持动态增加插件： mysql&gt; select @@have dynamic_ loading;<br>|@@have_dynamic_loading| YES</p>
<p>≦ 573 ≧<br>30.2复制搭建 555<br>1 row in set (0.00 sec)<br>（2）确认支持动态增加插件后，检查MySQL的安装目录下是否存在插件，一般默认在 $MYSQL_HOME&#x2F;lib&#x2F;plugin目录下存在主库插件semisync_master.so和从库插件 semisync_ slave.so:<br>SMYSQL HOME&#x2F;lib&#x2F;plugin&#x2F;semisync_master.so $MYSQL HoME&#x2F;lib&#x2F;plugin&#x2F;semisync slave.so<br>在主库上安装semisync_master.so插件：<br>mysql&gt;install pluginrpl semisyncmaster soNAMEsemisyncmaster.so<br>在从库上安装semisync_slave.so插件：<br>mysql&gt;install pluginrpl semisync lave oNAMesemisync slave.so<br>安装完成后，从plugin表中能够看到刚才安装的插件： mysql&gt; select * from mysql.plugin;<br>Iname |dl<br>|rpl semi _sync master semisync master.so Irpl _semi_sync slave 1 semisync_slave.so<br>2 rows in set (o.00 sec)<br>也就是说，安装完成后，MySQL会在系统表plugin中记录刚才安装的插件，下次系统重启后会自动加载插件。<br>（3）需要分别在主库和从库上配置参数打开半同步semi-sync，默认半同步设置是不打开的，在主库上配置全局参数：<br>mysql&gt; set global rpl semi sync master_enabled&#x3D;on; Query ok, 0 rows affected (0.02 sec)<br>mysql&gt; set global rpl_semi _sync_master_timeout&#x3D;1000; Query ok, O rows affected (o.o0 sec)<br>mysql&gt; show variables like rpl semi sync master wait point’;<br>1variable name value Irpl_semi_sync_master_wait_point| AFTER_SYNc1<br>1 row in set (0.01 sec) 在从库上配置全局参数：<br>mysql&gt; set global rpl semi _sync slave enabled&#x3D;on; Query oK,O rows affected (o.o0 sec)<br>注意，参数rpl_semi_sync_master_wait_point的值默认是AFTER_SYNC，即上文中提到的增强半同步复制；另一个可选项是AFTERCOMMIT，即传统的半同步复制。由于之前配置的复制是异步复制，所以需要重启从库上的I&#x2F;O线程（如果是全新配置的半同步复制，则不需要）：<br>mysql&gt; stop slave io_thread for channel ‘channel_3307’; Query ok, 0 rows affected (o.o0 sec)<br>mysql&gt; start slave io thread for channel channel 3307’; Query ok, 0 rows affected (0.00 sec)<br>到此半同步配置完毕，下面可以进行验证。主库上通过SHOWSTATUS命令能够看到当前半同步复制的一些状态值：</p>
<p>≦ 574 ≧<br>556 第30章MySQL复制 mysql&gt; show status 1ike ‘%semi sync%’;<br>Variable name I Value IRpl semi sync master_clients<br>Rpl _semi_sync master _net avg wait time<br>Rpl semi sync master net wait time 0<br>Rpl _semi sync master net waits Rpl semi sync master_no times Rpl_semi_sync_master_no_tx<br>Rpl_semi_sync_master_status ON IRpl semi sync master_timefunc failures<br>Rpl semi sync master_tx avg wait_time 0 Rpl_semi sync_master_tx wait time<br>Rpl_semi _sync master_tx waits 0 Rpl semi sync_master wait pos backtraverse 0 Rpl semi sync master wait sessions o Rpl_semi_sync_master_yes_tx 0 I Rpl semi sync slave_status OFF<br>15 rows in set (0.01 sec)<br>注意：由于试验环境不同，所以SHOWSTATUS显示的状态值可能存在不一致，着重关注这些状<br>态值的变化，而不是这些状态的初始值。<br>着重关注以下3个状态值。<br>Rpl_semi_sync_master_status:值为ON，表示半同步复制目前处于打开状态。<br>Rpl_semi_sync_master_yes_tx：值为O，表示主库当前尚未有任何一个事务是通过半同步复制到从库。<br>Rpl_semi_sync_master_no_tx：值为2，表示当前有两个事务不是半同步模式下从库及时响应的（记住这个值，后面会有对比）。<br>执行一个事务，再检查一下状态：<br>mysql&gt; update salaries set salary&#x3D;66074 where emp no&#x3D;10001 and salary&#x3D;300; Query ok, 1 row affected (0.00 sec)<br>Rows matched:1Changed:1warnings:0 mysql&gt; show status like %semi sync%’;<br>1 Variable name Ivalue<br>Rpl semi sync_master_clients 1 Rpl semi sync_master_net_avg wait time O Rpl _semi sync master_net wait time 0<br>Rpl semi sync master net waits 2 Rpl_semi sync_master_no_times 2<br>Rpl_semi_sync_master_no_tx 2 Rpl semi sync master status ON Rpl semi sync master_timefunc failures o<br>Rpl semi _sync master tx avg wait time 427 Rpl semi sync master tx wait time 427<br>Rpl_semi _sync_master_tx waits 1 Rpl semi sync master wait pos backtraverse<br>IRpl semi sync master wait sessions o Rpl_semi_sync_master_yes_tx<br>I Rpl semi sync slave status IOFF 15 rows in set (0.01 sec)<br>此时会发现Rpl_semi_sync_master_yes_tx的值变为1，即刚才的UPDATE事务通过半同步复制到从库上了，Rpl_semi_sync_master_yes_tx计数增加1。到从库确认一下，数据确实被复制过去了： mysqT&gt; select * from salaries where emp no&#x3D;10001 and salary&#x3D;66074;</p>
<p>≦ 575 ≧<br>30.2复制搭建 557<br>|emp no|salary| fromdateI to date<br>11000116607411988-06-2511989-06-251 1 row in set (0.01 sec)<br>再尝试一下网络异常的场景下，主库在等待rpl_semi_sync_master_timeout毫秒超时后，自动转成异步复制的场景。<br>（1）首先，在主库上确认半同步复制会等待1s超时： mysql&gt; show variables like ‘rpl semi _sync master_timeout’;<br>|variable name Value| Irpl semi _syncmaster_timeout 1000 1 row in set (0.00 sec)<br>（2）在从库上通过停掉I&#x2F;O线程模拟复制故障（也可以使用Iptables等防火墙命令来模拟网络故障）：<br>mysql&gt; stop slave io thread for channel ‘channel 3307’; Query Ok,0 rows affected (o.o0 sec)<br>（3）在主库上执行一个事务并提交（默认提交即可），主库上的提交操作会被阻塞1s：<br>mysql&gt; update salaries set salary&#x3D;62102 where emp_no&#x3D;10001 and salary&#x3D;200; Query ok,1 row affected (1.00 sec)<br>Rows matched:1Changed:1 warnings:0<br>通过查看主库的错误日志，可以发现半同步复制已经关闭：<br>2018-07-31T14:57:32.648854+08:00 42 [warning] Timeout waiting for reply of binlog （file: mysql-bin.000043, pos: 2397), semi-sync up to file,position 0.<br>2018-07-31T14:57:32.648915+08:00 42 [Note] Semi-sync replication switched OFF.<br>（4）主库上再一次检查半同步复制的一些状态值： mysql&gt; show status like ‘%semi_sync%’;<br>IVariable_name Ivalue<br>Rpl_semi_sync_master_clients 0 Rpl _semi sync master net avg wait time 0<br>Rpl_semi sync_master_net wait time 0 Rpl semi sync master net waits 2 Rpl semi sync master_no_times 3<br>Rpl_semi_sync_master_no_tx 3 Rpl_semi_sync_master_status OFF Rpl semi _sync_master_timefunc_failures 0<br>Rpl semi sync master_tx avg wait time 427 Rpl_semi_sync_master_tx wait time 427 Rpl semi_sync_master_tx waits<br>Rpl semi sync master wait pos backtraverse 0 Rpl semi sync master _wait sessions o<br>Rpl_semi_sync_master_yes_tx 1 IRpl semi sync slave_status IOFF<br>15 rows in set (0.01 sec)<br>仍然看之前着重关注的3个状态值。<br>ORpl_semi_sync_master_status:值变为OFF了，表示主库上半同步复制已经关闭了，目前复制模式为异步复制。<br>ORpl_semi_sync_master_yes_tx:值仍然为1，表示刚才的事务并不是通过半同步复制完成的，所以半同步成功事务仍然为1，并不累加。<br>ORpl_semi_sync_master_no_tx:值更新为3，比原来的2累加了1，表示在半同步模式</p>
<p>≦ 576 ≧<br>558 第30章MySQL复制下，从库没有及时响应的事务增加1个。<br>当开启从库的IO线程之后，主库会从异步复制自动切换回半同步复制，此场景不再赘述。从半同步复制的整个过程可以发现，主库和从库数据不具有强一致性，即主库已经变更<br>的数据从库不一定发生了变更，如果想让主从库达到强一致，只能在组复制（Group Replication）实现了，关于组复制的内容可详见第31章。<br>到现在为止，文中涉及的复制均是以file和postion的方式进行的数据定位与同步，其实从MySQL5.6开始就引I人了GTID（GlobalTransactionIdentifiers），并且就多线程与组复制来说，离不开GTID，这些技术都是直接或间接地利用了GTID。那到底GTID是什么呢，接下来的章节将会进行详细介绍。<br>30.3 GTID ( Global Transaction Identifier )<br>从MySQL5.6开始引人了GTID（GlobalTransactionIdentifier）。GTID是每个提交的事务的唯一标识，该标识不仅在Master端具有唯一性，在整个复制拓扑关系中，一样具有唯一性。 30.3.1格式与存储<br>GTID由source_id和transaction_id构成，表示形式如下所示： GTID &#x3D; source_ id:transaction_id<br>其中，source_id通常由服务端的server_uuid表示，而transaction_id通常是由连续数字表示。举例如下：<br>GTID&#x3D; 3E11FA47-71CA-11E1-9E33-C80AA9429562:23<br>前半部分的“3E11FA47-71CA-11E1-9E33-C80AA9429562”表示执行该事务的Master的uuid，后半部分的“23”表示这是第23个事务，只有主库才能生成GTID，即能完成写事务的节点。<br>当gtid_mode为ON或者ON_PERMISSIVE时（参数解释详见下文），GTID集合存储在<br>表mysql.gtid_executed里，表中的记录样例如下所示： mysql&gt; seTect * from mysql.gtid executed;<br>source_uuid interval start | interval end<br>| b509f331-cd14-11e8-866a-0024e869b4d5| 11 18400 1 rows in set (0.10 sec)<br>Osource_uuid，表示生成该GTID事务的源实例的uuid;<br>interval_start，表示GTID的起始值； interval_end，表示GTID的结束值。<br>例如，“b509f331-cd14-11e8-866a-0024e869b4d5,1,18400”表示生成该GTID事务的源实例uuid为“b509f331-cd14-11e8-866a-0024e869b4d5”，此实例已经执行了事务集合b509f331-cd14-11e8-866a-0024e869b4d5:1-18400。<br>另外，表mysql.gtid_executed的记录也可能是下面这样的形式： mysql&gt; select * from mysql.gtid executed;<br>Isource uuid | interval start l interval_end</p>
<p>≦ 577 ≧<br>30.3 GTID（Global Transaction Identifier) 559<br>b509f331-cd14-11e8-866a-0024e869b4d5 11<br>11<br>b509f331-cd14-11e8-866a-0024e869b4d5<br>23<br>b509f331-cd14-11e8-866a-0024e869b4d51 b509f331-cd14-11e8-866a-0024e869b4d5 b509f331-cd14-11e8-866a-0024e869b4d5 1b509f331-cd14-11e8-866a-0024e869b4d51<br>6 rows in set (o.00 sec)<br>这是因为在从库上，如果关闭了log_slave_updates参数（即从库不写人BINLOG），当从库在应用RelayLog后，会在表mysql.gtid_executed记录每一次执行过的事务，如果一直这样下去，这势必会造成空间的大量浪费，也会影响性能，此时可以通过参数gtid_executed compression_period进行调节。<br>gtid_executed_compression_period参数从MySQL5.7.6版本引人，默认值为1000，表示每当处理完成1000个事务后，对表mysql.gtid_executed进行压缩。如果参数设置为0，表示禁用压缩特性，该参数支持动态调整。<br>例如，将参数gtid_executed_compression_period从1000调整为10：<br>mysql&gt; set global gtid executed compression_ period&#x3D;10; Query ok,O rows affected (o.oo sec)<br>当从库应用RelayLog数据超过10个事务后，开始对表mysql.gtid_executed进行压缩。 mysql&gt; select * from mysql.gtid_executed;<br>Lsource uuid |interval start |interval end 1 |b509f331-cd14-11e8-866a-0024e869b4d51 111 1 row in set (0.00 sec)<br>以上内容是从库关闭了log_slave_updates参数的情况，如果打开这个参数会怎么样呢？接下来继续往下看。<br>由于参数log_slave_updates是静态参数，需要重启实例。当完成重启操作后，主库执行<br>一些新事务，然后观察从库上表mysql.gtid_executed的内容和slave的执行情况： mysql&gt; select * from mysql.gtid executed;<br>I source uuid I interval start | interval end |<br>1b509f331-cd14-11e8-866a-0024e869b4d51 11 1 row in set (o.00 sec)<br>show slave status的信息如下：<br>Retrieved Gtid Set:b509f331-cd14-11e8-866a-0024e869b4d5:12-55 Executed Gtid_Set:b509f331-cd14-11e8-866a-0024e869b4d5:1-55 Auto Position:1<br>发现表mysql.gtid_executed与重启前没有变化，而通过show slave status命令，可以看到实际上该从库已经应用了很多RelayLog数据，如果此时再执行flushlogs命令，即切换一个<br>新的BINLOG文件，再看该表的数据： mysql&gt; flush 1ogs;<br>Query ok,0 rows affected (0.04 sec)<br>mysql&gt; select * from mysql.gtid executed;<br>Isource uuid |interval start | interval end<br>|b509f331-cd14-11e8-866a-0024e869b4d51 11 551</p>
<p>≦ 578 ≧<br>560 第30章MySQL复制<br>此时从库已经将最新的GTID事务集合写入了mysql.gtid_executed中，其实这也表明了，一旦启用binarylogging（将事务写人BINLOG文件）功能，参数gtid_executed_compression_period 也就不再起作用了。无论是在从库，还是在主库，只有当发生BINLOG文件切换，才会将执行过的GTID事务集合写人表mysql.gtid_executed中。<br>参数gtid_executed_compression_period的功能，是通过一个后台线程实现的。 mysql&gt; SELECT * FROM performance schema.threads WHERE NAME LIKE %gtid%’\G<br>THREAD_ID:45<br>NAME: thread&#x2F;sql&#x2F;compress_gtid_table TYPE:FOREGROUND<br>PROCESSLIST_ID:12 PROCESSLIST USER: NULL PROCESSLIST HOST: NULL PROCESSLIST DB: NULL<br>PROCESSLIST_COMMAND:Daemon PROCESSLIST TIME:2406<br>PROCESSLIST STATE: Suspending<br>PROCESSLIST INFO: NULL PARENT THREAD ID:1<br>ROLE:NULL<br>INSTRUMENTED:YES<br>HISTORY: YES<br>CONNECTION TYPE: NULL THREAD_OS ID:3708<br>1 row in set (o.00 sec)<br>通过以上的演示，读者已经发现表mysql.gtid_executed的记录会一直增加，那怎么样才能清空该表呢？换句话说，如何才能重置执行过的GTID的集合，让事务序号回归初始值1呢？<br>这就需要使用resetmaster命令，一旦执行了该命令，会删除所有当下的BINLOG文件，并生成一个新的BINLOG文件，同时用新生成的BINLOG文件名重置BINLOG索引文件，也会清空系统变量gtid_executed和gtid_purged的值，以及表mysql.gtid_executed。<br>例如：<br>mysqT&gt; select @@GLOBAL.gtid executed; 1@@GLOBAL.gtid executed<br>1 b509f331-cd14-11e8-866a-0024e869b4d5:1-551 1 row in set (0.00 sec)<br>mysql&gt; select @@GLOBAL.gtid purged; I@@GLOBAL.gtid_purged<br>1b509f331-cd14-11e8-866a-0024e869b4d5:1-551<br>1row in set (0.00 sec) mysql&gt; reset master<br>Query ok,0 rows affected (0.24 sec)<br>mysql&gt; select * from mysql.gtid executed; Empty set (0.00 sec)<br>mysql&gt; select @@GLoBAL.gtid purged;<br>@@GLOBAL.gtid purged | 1 row in set (0.00 sec)</p>
<p>≦ 579 ≧<br>30.3 GTID(Global Transaction Identifier) 561<br>mysql&gt; select @@GLOBAL.gtid executed;<br>I@@GLOBAL.gtid executed 1 row in set(0.00 sec)<br>这里又出现了GTID的另一个重要变量gtid_purged，该变量对于处理GTID问题有重要<br>意义，接下来的内容将围绕该变量进行讲述。 30.3.2gtid_purged<br>gtid_purged表示该实例的二进制日志（binarylog）已经被清除掉（purge）的事务集合，通俗地讲，就是这些事务的BINLOG已经没有了。如果该实例配置了从库，而从库在复制过程中，由于某些原因缺少这些数据，复制时就会发生错误。接下来介绍gtid_purged的变更会发生在什么时候，以及如何进行初始化。<br>gtid_purged的变更操作分为系统自动触发和手动干预两种情况，下面先介绍系统自动触发。当遇到purgebinarylogs操作或者binarylog超过阀值expire_logs_days时（该参数表示<br>binary log过期时间，前文也有过讲解，不再赘述），会触发gtid_purged的变更。<br>（1）首先，确认当前mysql-bin.000001文件中包含的GTID事务集合。<br>[mysq13307@hz_10_120_240_251 data]s grep “b509f331-cd14-11e8-866a-0024e869b4d5” mysq1-bin. 000001.1og<br>SET @@SESSION.GTID _NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:1&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:2’&#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:3&#x2F;<em>1</em>&#x2F;: SET @@SESSION.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:4’&#x2F;<em>1</em>&#x2F;; SET @@SESSI0N.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:5’&#x2F;<em>!</em>&#x2F;: SET @@SESSION.GTID_NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:6’&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:7&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:8&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:9’&#x2F;<em>1</em>&#x2F;; SET @@SESSI0N.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:10’&#x2F;<em>!</em>&#x2F;; 略过中间连续序号<br>SET @@SESSION.GTID NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:53’&#x2F;<em>!</em>&#x2F;; SET @@SESSI0N.GTID NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:54’&#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:55&#x2F;<em>!</em>&#x2F;;<br>可以看到该文件中，包含的GTID集合为b509f331-cd14-11e8-866a-0024e869b4d5:1-55。（2）确认当前gtid_purged的值。<br>mysql&gt; select @@gtid_purged; 1@@gtid_purged<br>1eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4 1 row in set (0.o0 sec)<br>由于该实例曾经执行过其他实例的BINLOG事务，但目前这些BINLOG已经不存在了，所以这里显示是有值的，而不是空值（这个不是重点，请继续往下看）。<br>（3）执行purgebinarylogs命令。 mysq1&gt;<br>mysql&gt; purge binary logs to ‘mysql-bin.000002’; Query Ok, O rows affected (o.o2 sec)<br>删除了mysql-bin.000001文件，即清除了GTID集合b509f331-cd14-11e8-866a-0024e869b4d5: 1-55的BINLOG数据。</p>
<p>≦ 580 ≧<br>562 第30章MySQL复制<br>（4）再次查看gtid_purged的值。<br>mysql&gt; select @@gtid purged; I@@gtid _purged<br>1b509f331-cd14-11e8-866a-0024e869b4d5:1-55,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-41 1row in set (0.o0 sec)<br>可以看到，此时gtid_purged已经从eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4变更为 b509f331-cd14-11e8-866a-0024e869b4d5:1-55,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4。<br>以上是通过调用系统命令purgebinarylogs执行的操作，而如果手动删除binarylog文件，会有什么结果呢？<br>（1）首先，确认当下的gtid_purged。<br>mysql&gt; select @@gtid purged;@@gtid purged<br>1b509f331-cd14-11e8-866a-0024e869b4d5:1-58,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-81 1row in set (o.00 sec)<br>b509f331-cd14-11e8-866a-0024e869b4d5:1-58,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-8<br>是当前该实例的gtid_purged的值，即已经被清除掉的 Binlog。（2）通过showbinarylogs命令观察此时的binary log文件。 mysql&gt; show binary logs;<br>Log name File size<br>|mysq1-bin.000004 3825 1mysql-bin.000005 257 1mysq1-bin.000006 234<br>3rows in set (o.00 sec)<br>可以看到，当前该实例的binarylog共包含3个文件，即mysql-bin.000004、mysql-bin.000005 和mysql-bin.000006。<br>mysql-bin索引文件如下所示：<br>[mysq13307@hz 10 120 240 251 data]s cat mysq1-bin.index<br>&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.000004&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.000005&#x2F;data2&#x2F;mysq13307&#x2F;data&#x2F;mysq1-bin.000006<br>通过以上观察，都可以确定mysql-bin.000004文件是目前存在的第一个binary log文件，即最旧的（oldest）文件。<br>（3）mysql-bin.000004文件包含的GTID集合。<br>[mysq13307@hz 10 120 240 251 data]s mysq1binlog -vv mysq1-bin.000004 &gt; mysq1-bin.000004.1og[mysq13307@hz 10 120240 251 data]$<br>[mysq13307@hz 10 120 240 251 data]s grep “GTID NEXT” mysq1-bin.000004.1og SET @@SESSION.GTID NEXT&#x3D; eab6f8ea-6ed7-11e8-a897-0024e869b4d5:9&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:10&#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;eab6f8ea-6ed7-11e8-a897-0024e869b4d5:11&#x2F;<em>1#&#x2F;; SET @@SESION.GTID NEXT&#x3D;eab6f8ea-6ed7-11e8-a897-0024e869b4d5:12</em>&#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:59&#x2F;<em>I</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D; ‘b509f331-cd14-11e8-866a-0024e869b4d5:60&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:61&#x2F;<em>1</em>&#x2F;； SET @@SESSION.GTID NEXT&#x3D;b509f331-cd14-11e8-866a-0024e869b4d5:62&#x2F;<em>1</em>&#x2F;: SET @@SESSION.GTID NEXT&#x3D;eab6f8ea-6ed7-11e8-a897-0024e869b4d5:13&#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;eab6f8ea-6ed7-11e8-a897-0024e869b4d5:14&#x2F;<em>1</em>&#x2F;:</p>
<p>≦ 581 ≧<br>30.3 GTID（Global Transaction Identifier) 563<br>SET @@SESSION.GTID_NEXT&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:15 ‘&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:16 &#x2F;<em>!</em>&#x2F;; SET @@SESSION.GTID_NEXT&#x3D;’b509f331-cd14-11e8-866a-0024e869b4d5:63*&#x2F;<em>1</em>&#x2F;; SET @@SESSION.GTID NEXT&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:17&#x2F;<em>I</em>&#x2F;; SET @@sESSION.GTID NEXT&#x3D;’AUTOMATIC’&#x2F;* added by mysqlbinlog *&#x2F;&#x2F;<em>1</em>&#x2F;；<br>该文件中包括两个GTID集合，其中一个集合是eab6f8ea-6ed7-11e8-a897-0024e869b4d5:9-17，<br>而另一个集合是b509f331-cd14-11e8-866a-0024e869b4d5:59-63。（4）然后，从操作系统层面删除文件mysql-bin.000004。[mysq13307@hz 10 120240 251 data]s rm-rf mysq1-bin.000004<br>（5）再通过showbinarylogs命令查看日志信息。 mysql&gt; show binary logs;<br>1Log_name File size<br>1mysq1-bin.000004 01 1mysq1-bin.000005 257 1mysq1-bin.000006 257<br>3rows in set (0.02 sec) gtid purged:<br>mysql&gt; select @@gtid purged; 1@@gtid_purged<br>1b509f331-cd14-11e8-866a-0024e869b4d5:1-58,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-81 1 row in set (o.00 sec)<br>虽然showbinarylogs的结果显示文件mysql-bin.00oo04的大小已经是0，但gtid_purged 发现和之前并没有什么差别，说明直接从操作系统层面删除mysql-bin文件，并不会触发 gtid_purged的更新。<br>（6）重启该实例后，再次查看gtid_purged。 mysql&gt; show binary logs;<br>Log_name IFile sizel<br>1mysq1-bin.000004 01 |mysql-bin.000005 257 1mysq1-bin.000006 257<br>1mysq1-bin.0000071 2341 4rows in set(0.02 sec)<br>mysql&gt; select @@gtid purged; l @@gtid_purged<br>|b509f331-cd14-11e8-866a-0024e869b4d5:1-63,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-171 1row in set (o.00 sec)<br>重启实例后，gtid_purged的值已经发生了变化，此时的结果是正确的，即GTID 集合 b509f331-cd14-11e8-866a-0024e869b4d5:1-63,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-17相关的binary log已经被清除了。<br>以上两个场景为了说明gtid_purged的值是如何受外在因素的影响，从而自动触发系统检查并进行变更。在第二个示例中，由于重启了MySQL实例，所以这涉及gtid_purged的初始化过程，该过程其实是受参数binlog_gtid_simple_recovery影响的。</p>
<p>≦ 582 ≧<br>564 第30章MySQL复制<br>binlog_gtid_simple_recovery参数控制着MySQL启动过程中，如何扫描binary log文件，从而获取正确的GTID集合，初始化 gtid_executed和 gtid_purged。在MySQL5.7.6版本以前，该参数的名字是simplified_binlog_gtid_recovery，默认值是FALSE，而到了5.7.6版本，参数更名为binlog_gtid_simple_recovery，默认值仍为FALSE。但从5.7.7版本以后，默认值调整为 TRUE，上文的两个测试场景使用的是默认值TRUE。<br>默认值TRUE，表示MySQL启动的过程中，仅需要读取最旧的（oldest）和最新的（newest）binarylog文件，查找文件中的Previous_gtids_log_event或者Gtid_log_event，用于初始化gtid_purged和gtid_executed，如第二个场景中，MySQL实例重启以后，由于 mysql-bin.000004文件已经不存在，最旧的文件是mysql-bin.000005，此时该文件中会包含类似如下字样的信息：<br>&#x2F;<em>!50530 SET @@SESSION.PSEUD0_SLAVE MODE&#x3D;1</em>&#x2F;;<br>&#x2F;<em>!50OO3 SET @OLD_COMPLETIONTYPE&#x3D;@@COMPLETION_TYPE,COMPLETION_TYPE&#x3D;O</em>&#x2F;;<br>DELIMITER&#x2F;<em>1</em>&#x2F;;#at4<br>#181213 16:12:48 server id 7238 end 1og pos 123 cRc32 0x24924068 start: binlog v4, server v5.7.22-1og created 181213 16:12:48<br>#warning: this binlog is either in use or was not closed properly. BINLOG<br>gBQSXA9GHAAAdWAAAHSAAAABAAQANS43LjIyLWXVZWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXWAEGggAAAAICAgCAAAACgoKKioAEjQA<br>AwhAkiQ&#x3D;<em>1</em>&#x2F;；#at 123<br>#181213 16:12:48 server id 7238 end 1og pos 250 cRc32 0x60d96f09 Previous-GTIDs<br>#b509f331-cd14-11e8-866a-0024e869b4d5:1-63,#eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-17<br>gtid_purged的值就可以确定出来了，gtid_executed同理，扫描完成最新的BinaryLog文件后，就可以知道该实例已经执行到哪里了。<br>可选值FALSE，表示MySQL启动过程中，为了初始化gtid_purged，系统会遍历扫描BinaryLog文件，首先从最旧的文件开始，如果发现Previous_gtids_log_event事件，就停止扫描，否则就继续扫描，直到最新的文件为止，gtid_executed也是同理，但扫描方向相反，首先扫描最新的BinaryLog文件，如果发现Previous_gtids_log_event事件，就停止扫描，否则就继续扫描，直到最旧的文件为止。<br>注意：建议不要更改参数binlog_gtid_simple_recovery的默认值，如果MySQL实例是从非GTID<br>升级为GTID模式，而且该实例有大量的BINLOG文件（非GTID模式下生成的），参数值在FALSE的情况下，会引发疯狂扫描BinaryLog文件问题，导致性能急剧下降。正确做法是备份好非GTID模式下的BINLOG文件，尽快删除。<br>上文介绍了系统自动触发gtid_purged的变更，但有时仍需要手动调整，例如主从复制间出现一些错误（详见常见问题），接下来介绍如何手动设置gtid_purged。<br>（1）确认当前gtid_purged和gtid_executed的值。<br>mysql&gt; show global variables where variable name in (‘gtid executed’,gtid purged’); I variable name | value<br>gtid_executed eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-10 gtid_purged eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-3<br>2 rows in set (0.01 sec)<br>如果在操作系统层面删除了BinaryLog文件，而MySQL实例又不能重启，此时gtid_purged</p>
<p>≦ 583 ≧<br>30.3 GTID（Global Transaction Identifier) 565<br>的值已经不正确，可能会影响到后续的主从切换，此时直接更改gtid_purged，会收到如下错误提示：<br>mysql&gt; set global gtid purged&#x3D;eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-5； ERROR 1840 (HYO0O): @@GLOBAL.GTID PURGED can only be set when @@GLOBAL.GTID EXECUTED is empty<br>该提示表明gtid_purged的变更，只有当gtid_executed为空时，才能被更改。<br>（2）执行reset master。 mysql&gt; reset master:<br>Query ok, 0 rows affected, 2 warnings (0.01 sec)<br>该命令会删除所有的BinaryLog文件，并重置BinaryLog索引l文件，生成序号为1的 BinaryLog文件（在MySQL8.0以后，可以指定新生成的BinaryLog序号文件），同时清空<br>gtid_purged、gtid_executed和表mysql.gtid_executed 的记录。（3）设置gtid_purged。<br>mysq1&gt; set g1oba1 gtid purged&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-5’; Query ok, 0 rows affected (o.oo sec)<br>mysql&gt; show global variables where variable name in (‘gtid executed’,’gtid purged’); I variable name | value<br>1gtid_executed | eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-51 1gtid_purged 1eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-51<br>2rows in set (0.01 sec)<br>gtid_purged应为gtid_executed的子集，当gtid_purged被设置完成后，gtid_executed也同样具有了相同的值，表明该MySQL实例已经执行过这些事务，并且这些binary log已经被清除。如果该实例后续还会成为一个从库，那么其不会再复制gtid_executed的GTID集合。<br>从以上可见，GTID其实理解起来也不难，只是事务的一种表示形式而已，接下来实际演<br>练一下。如果启用了GTID，应该如何搭建复制环境。 30.3.3复制搭建<br>基于GTID的方式搭建复制环境，较之前异步复制、多线程复制来说，并不复杂。下面分两种情况讨论：第一种情况是在创建环境最初，就直接启用了GTID，这个步骤最简单；第二种情况是建库之初并未启用GTID。<br>1.建库之初启用GTID<br>（1）根据前文描述，安装数据库软件、初始化数据库，并创建好复制用户，修改MySQL<br>配置文件，增加如下内容：[mysq1d]<br>gtid mode&#x3D;on<br>enforce gtid_consistency&#x3D;<br>配置启用GTID模式的参数gtid_mode和enforce_gtid_consistency。其中参数enforce_gtid consistency表示是否启用GTID的一致性检查，有3个可选值，分别为OFF、ON和WARN，默认值OFF。<br>OOFF：表示不检查GTID一致性，即执行的SQL语句可以违反GTID约束和限制（GTID 有很多使用上的限制，例如在同一个事务中，不能包含事务引擎（类似Innodb）的表和非事</p>
<p>≦ 584 ≧<br>566 第30章MySQL复制<br>务引擎（类似MyISAM）表的更新操作，不能使用CTAS（create tableas select）命令等，更详细的文档可以查看官方文档）。<br>OON：表示开启GTID一致性检查，如果需要执行的SQL违反该原则，操作会失败。 OWARN：介于OFF和ON之间，即允许执行违反原则的SQL语句，但会在错误日志<br>中打印Warnings信息。<br>参数gtid_mode表示GTID的模式，有4个可选值，分别为OFF、OFF_PERMISSIVE、 ON_PERMISSIVE和ON，默认值OFF，每个值含义如下。<br>OFF：表示不开启GTID模式，即执行的事务都属于ANONYMOUS事务（该事务的表示方式，可参考下文）。<br>OOFF_PERMISSIVE：表示新事务是ANONYMOUS，但是当从库复制时，允许应用 ANONYMOUS事务和GTID事务。<br>OON_PERMISSIVE：表示新事务是GTID事务，当从库复制时，允许应用 ANONYMOUS事务和GTID事务。所以参数值OFF_PERMISSIVE和ON_PERMISSIVE的区别仅仅针对新产生的事务，表示方式不同而已，也是为了将事务逐渐进行过渡，全部转向 GTID，并且不影响从库的复制。<br>OON：表示新事务是GTID事务，从库应用时也只接受GTID事务。<br>另外，如果gtid_mode设置为ON，则enforce_gtid_consistency必须同时设置为ON。以下是ANONYMOUS事务示例。<br>#at24092480<br>#181111 4:10:40 server id 703513 end 1og pos 24092545 cRc32 0xbb5393d3 Anonymous_GTID<br>last_committed&#x3D;61934 sequence_number&#x3D;61935 SET @@SESSION.GTID_NEXT&#x3D;ANONYMOUS&#x2F;<em>I</em>&#x2F;;#at 24092545<br>#181111 4:10:40 server id 703513 end 1og_pos 24092620 CRC32 0x2698b539 Query thread<br>id&#x3D;37exec time&#x3D;0error_code&#x3D;0 SET TIMESTAMP&#x3D;1541880640&#x2F;<em>!</em>&#x2F;；<br>BEGIN&#x2F;<em>！</em>&#x2F;；<br>（2）重启主从数据库，如下所示：<br>mysqladmin -uroot -s &#x2F;tmp&#x2F;mysql_3307.sock shutdown<br>mysqld_safe –defaults-fi1e&#x3D;&#x2F;home&#x2F;mysq13307&#x2F;mysq1home&#x2F;my.cnf –user&#x3D;mysq13307 &amp; mysqladmin -uroot -s &#x2F;tmp&#x2F;mysql_3308.sock shutdown<br>mysqld safe –defaults-file&#x3D;&#x2F;home&#x2F;mysq13308&#x2F;mysq1home&#x2F;my.cnf –user&#x3D;mysq13308 &amp;<br>（3）配置从库的复制进程，并启动。 mysql&gt; CHANGE MASTER TO<br>-&gt;MASTER HOST&#x3D;’10.120.240.251′，</p>
<blockquote>
<p>MASTER PORT&#x3D;3307,-&gt; MASTER USER&#x3D;’repl’,<br>MASTER_PASSWORD&#x3D;’repl’， &gt; MASTER AUTO_POSITION&#x3D;1;<br>Query ok, 0 rows affected (0.10 sec) mysql&gt; start slave;<br>Query oK,0 rows affected (0.03 sec)<br>注意：配置GTID模式下的主从复制关系时，不再需要指定MASTER_LOG_FILE和MASTER<br>LOG_POS，而是用MASTER_AUTO_POSITION&#x3D;1代替。<br>当从库配置MASTER_AUTO_POSITION&#x3D;1并启动slave后，从库会将当前接收到（RetrievedGtid_Set）的和已经提交（ExecutedGtidSet）的GTID集合做一个并集发给主库，主</p>
</blockquote>
<p>≦ 585 ≧<br>30.3 GTID（Global Transaction Identifier) 567<br>库收到这些信息后，会与自身的Executed_Gtid_Set做对比，将从库缺少的GTID事务发送过去。<br>例如：<br>从库show slave status:<br>Retrieved Gtid Set:eab6f8ea-6ed7-11e8-a897-0024e869b4d5:4-5 Executed Gtid Set:b509f331-cd14-11e8-866a-0024e869b4d5:1-10,<br>eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-5 主库：<br>mysql&gt; show master status\G;<br>北业省业会业会会业会会业业★省★业会会<br>File: mysq1-bin.000010<br>Position:764 Binlog Do DB:<br>Binlog Ignore DB:<br>Executed Gtid Set:b509f331-cd14-11e8-866a-0024e869b4d5:1-10,<br>eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-6 1 row in set (o.00 sec)<br>当从库执行startslave后，此时主库需要将eab6f8ea-6ed7-11e8-a897-0024e869b4d5:6的事务发给从库。<br>show slave status中的Retrieved_Gtid_Set和Executed_Gtid_Set解释如下。<br>ORetrieved_Gtid_Set：表示slave的I&#x2F;OThread已经接收到的GTID事务集合，这些GTID 集合可能仍然在Relaylog文件里，也可能已经被清除掉。另外，Retrieved_Gtid_Set受多种因素影响，值会被清空，例如，从库执行了reset slave或者changemaster to等，但如果启用了 relay_log_purge，即自动清理Relaylog功能；当Relay log被自动删除后，该值并不会被清空。 Retrieved_Gtid_Set也可以通过PerformanceSchema中的replication_connection_status查看，查询命令如下所示：<br>SELECT RECEIVED_TRANSACTION SET FROM PERFORMANCE SCHEMA.replication connection Status<br>OExecuted_Gtid_Set:表示slave的SQLThread已经执行的GTID事务集合，该值等同于变量gtid_executed，也与 showmaster status结果中的Executed_Gtid_Set一致。<br>这样就完成了GTID模式的主从复制搭建。 2.建库之初并未启用GTID<br>在实际工作中，可能在建库之初并未开启GTID，针对这种情况，可以采取如下步骤（需要主从的MySQL为5.7.6或更高的版本，本例中传统异步复制环境已搭建好，3307为主库， 3308为从库）。<br>（1）如果主库可以申请短时间的停机维护时间，首先可以设置主从库为ReadOnly模式，反之，则跳过该步骤。<br>root@localhost:mysq1 3307.sock [(none)]&gt;show variables like read only’; | Variable name I value1<br>Iread only ON 1row in set (o.00 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;show variables like‘read only’;<br>Variable name |value read only<br>1row in set (0.06 sec)</p>
<p>≦ 586 ≧<br>568 第30章MySQL复制<br>（2）如果主从库设置了ReadOnly模式，执行该步骤，确认从库是否已经完全追上了主库后停止复制进程。<br>root@localhost:mysql 3307.sock [(none)]&gt;show master status;<br>|File Position I Binlog Do DB I Binlog Ignore DB I Executed Gtid SetI<br>1 mysql-bin.000047 3366313 1row in set (0.03 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;show slave status\G;<br>slave Io state: waiting for master to send event Master_Host:10.120.240.251<br>Master user: repl Master_Port: 3307 Connect Retry: 60<br>Master_Log_File:mysql-bin.000047 Read Master_Log_Pos:3366313<br>Relay _Master_Log File: mysql-bin.000047<br>slave Io Running: Yes Slave SQL Running: Yes<br>Exec Master <em>Log Pos: 3366313<br>root@localhost:mysql 3308.sock [(none)]&gt;stop slave; Query ok, 0 rows affected (0.16 sec)<br>以上两个步骤如果条件不允许，可以从步骤（3）开始执行，如果步骤（1）（2）有条件执行，那么在完成以后，可以继续以下操作。<br>接下来在主从库上开启GTID模式。<br>（3）分别在主从库执行以下命令，并持续关注错误日志中可能出现的任何Warmings和 Errors信息，如果发现异常，需要先着手解决，才能继续操作。<br>root@localhost:mysql 3307.sock [(none)]&gt;set global enforce_gtid consistency&#x3D;WARN; Query ok,0 rows affected (o.o0 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;set global enforce_gtid consistency&#x3D;WARN; Query ok, O rows affected (o.o0 sec)<br>该步骤是非常重要的一步，一定要确保错误日志中不再出现任何Warnings信息。（4）继续在主从库执行以下命令（参数解释详见前文）。<br>root@localhost:mysql 3307.sock [(none)]&gt;set global enforce gtid_consistency&#x3D;on; Query ok,o rows affected (o.oo sec)<br>root@localhost:mysql_3308.sock [(none)]&gt;set global enforce gtid_consistency&#x3D;oN; Query oK,O rows affected (o.00 sec)<br>（5）在主从库执行以下命令，调整gtid_mode为OFF_PERMISSIVE。<br>root@localhost:mysql 3307.sock [(none)]&gt;set global gtid mode&#x3D;0FF_PERMIsSIVE; Query ok, 0 rows affected (0.20 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;set global gtid mode&#x3D;OFF PERMIsSIVE; Query ok,Orowsaffected （o.17 sec)<br>（6）在主从库升级gtid_mode从OFF_PERMISSIVE到ON_PERMISSIVE。 root@localhost:mysql 3307.sock [(none)]&gt;set global gtid mode&#x3D;ON_PERMIsSIVE; Query ok,0 rows affected (o.04 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;set global gtid_mode&#x3D;ON</em> PERMIssIVE; Query ok,O rows affected (o.o0 sec)</p>
<p>≦ 587 ≧<br>30.3 GTID(Global Transaction Identifier) 569<br>（7）分别在主从库上查看状态变量ONGOING_ANONYMOUS_TRANSACTION_COUNT 的值，需要等待直到该值为0。<br>mysql&gt; Show status like ONGOING_ANONYMOUS TRANSACTION COUNT Ivariable name |value|<br>1Ongoing anonymous transaction count |o 1 row in set(0.43 sec)<br>此处要注意查看从库的应用情况，确保从库已经接收了所有ANONYMOUS事务，然后才能继续操作。另外，还有一个办法可以检查从库是否已经应用完所需日志，具体步骤如下。<br>首先，在主库执行showmasterstatus命令。 mysql&gt; show master status\G;<br>File:mysq7-bin.000033 Position:5134<br>Binlog_Do DB: Binlog Ignore DB:<br>Executed Gtid Set:6fb578bb-572a-11e8-8aa5-0024e869b4d5:1-8247296 1 row in set (o.00 sec)<br>该命令会得到当前时刻，主库执行到的BINLOG位置，找到File和Position信息。<br>然后，在从库执行SELECTMASTER_POS_WAIT（file,position）命令，其中file和position<br>就是刚刚在主库查询出来的信息，替换参数后，执行命令如下： mysql&gt; SELECT MASTER POS_WAIT(‘mysq1-bin.000033’,5134);<br>1MASTER POS_WAITC’mysq1-bin.000033,5134)1 1 row in set (0.06 sec)<br>直到等待命令结束，会返回结果值O，表示从库已经应用完成所需要的BINLOG日志。如果从库延迟非常大，可以隔段时间后再执行。<br>以下示例是因为从库延迟很大，执行该命令后的情况。 mysqT&gt; SELECT MASTER POS WAIT(mysq1-bin.000034’, 5134）; 等<br>show processlist的结果：<br>**12.row<br>Id:42352 user:root<br>Host:10.120.240.251:22423<br>db:NULL Command: Query Time:24<br>State: waiting for the slave sQl thread to advance position Info: SELECT MASTER_POS WAIT(‘mySq1-bin.000034’,5134)<br>（8）当步骤（7）执行完成，并确认所有的从库应用无误之后，开启GTID模式。<br>root@localhost:mysql 3307.sock [(none)]&gt;set global gtid mode&#x3D;oN; Query ok,0 rows affected (0.3 sec)<br>root@loca1host:mysql_3308.sock [(none)]&gt;set global gtid_mode&#x3D;ON; Query OK,0 rows affected (o.oo sec)<br>成功执行上述命令后，主从库距离完成GTID模式的切换都还差一点点，继续如下的操作。<br>（9）在主从库确认此时的状态。</p>
<p>≦ 588 ≧<br>570 第30章MySQL复制 mysql&gt; show variables like %gtid%’;<br>1 Variable_name 1 value<br>binlog gtid _simple_recovery ION I enforce_gtid_consistency ION gtid_executed_compression_period 1000<br>gtid_mode gtid next<br>gtid owned AUTOMATIC gtid purged<br>I session track gtids 1OFF 8 rows in set (0.o0 sec)<br>（10）在参数文件中持久化变更的参数。<br>[mysq13307@hz 10 120 240_251 mysq1home]$ cat my.cnf Igrep “gtid gtid mode&#x3D;on<br>enforce gtid consistency&#x3D;on<br>[mysq13308@hz 10 120_240_251 mysq1home]$ cat my.cnf lgrep gtid gtid_mode&#x3D;on<br>enforce gtid consistency&#x3D;on<br>（11）改变从库复制为MASTERAUTOPOSITION&#x3D;1。<br>root@localhost:mysql 3308.sock [(none)]&gt;stop slave; Query ok,0rows affected (0.03 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;change master to MASTER AUTo POSITIoN&#x3D;1; Query ok, 0 rows affected (0.04 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;start slave; Query ok, 0 rows affected (0.o3 sec)<br>root@localhost:mysql 3308.sock [(none)]&gt;show slave status\G;<br>六<br>slave Io state : waiting for master to send event Master Host:10.120.240.251<br>Master user:repl Master_Port:3307 Connect Retry:60<br>Master Log_File :mysql-bin.000050 Read Master Log Pos:154<br>Relay Log File:hz 10 120 240 251-relay-bin.000002 Relay_Log_Pos:367<br>Relay Master Log File : mysql-bin.000050<br>slave_Io_Running: Yes slave_SQL_Running: Yes Master_Server Id:7237<br>Master UUID:400f59b6-5e55-11e8-bd15-0024e869b4d5<br>Master Info File: mysql.slave master info Auto_Position1<br>执行完成后，查看从库的复制状态等各项信息，是否正确。<br>（12）该步骤可选，如果在开始阶段，主从库打开了ReadOnly模式，此时需要关闭ReadOnly 模式（建议从库打开ReadOnly，避免一些误操作）。<br>root@localhost:mysql 3307.sock [employees]&gt;set global read only&#x3D;off; Query ok, 0 rows affected (o.o0 sec)<br>root@localhost:mysql 3307.sock [employees]&gt;show variables like ‘read only’;<br>IVariable name value|<br>read only OFF 1row in set (0.00 sec)</p>
<p>≦ 589 ≧<br>30.3 GTID（Global Transaction Identifier) 571<br>至此，完成了在线升级为GTID模式，接下来是一些验证工作（如果是线上环境，此时应该已经得到了检验）。<br>（13）在主库执行一个数据变更操作。<br>root@locaThost:mysq1 3307.sock [employees]&gt;update employees.salaries set salary&#x3D;62101 where salary&#x3D;100 and emp_no&#x3D;10001;<br>Query 0k,1 row affected (0.15 sec)<br>Rows matched:1Changed:1 warnings:0（14）从库验证复制是否成功。<br>root@localhost:mysql 3308.sock [employees]&gt;select * from employees.salaries where salary&#x3D; 62101 and emp_no&#x3D;10001;<br>Iemp no Isalary I from date 1to date |salary by 1k| 110001162101|1986-06-26丨1987-06-261 621 1row in set (o.00 sec)<br>root@localhost:mysql 3308.sock [employees]&gt;show slave status\G;<br>slave Io state: waiting for master to send event Master_Host:10.120.240.251<br>Master user: repl Master_Port: 3307 Connect Retry:60<br>Master_Log_File:mysql-bin.000050 Read Master _Log Pos: 461<br>Relay_Log_File:hz 10 120 240 251-relay-bin.000002 Relay Log Pos:674<br>Relay_Master_Log File: mysql-bin.000050<br>slave Io Running: Yes slave SQL Running: Yes Master server_Id:7237<br>Master_UUID:400f59b6-5e55-11e8-bd15-0024e869b4d5<br>Retrieved Gtid Set:400f59b6-5e55-11e8-bd15-0024e869b4d5:1 Executed Gtid_Set:400f59b6-5e55-11e8-bd15-0024e869b4d5:1<br>Auto Position:1<br>可以看到数据已经在从库得到正确应用，主从复制服务验证完成。<br>从以上的搭建过程，可以发现在使用GTID方式以后，复制进程的配置不再需要指定 MASTER_LOGFILE和MASTER_LOG_POS，从此省去了查找起始点的烦恼，只需指定 MASTER_AUTO_POSITION&#x3D;1即可，其余就交给系统去处理就好了。<br>这一点也极大地方便了日常运维，一旦主从出现切换，无须费时费力，需要从什么地点开始继续复制，系统自己会处理好，如果在一主多从的环境中，被提升为新主的节点，缺少部分数据，还可以先从具有全部数据的节点复制过来缺少的内容，然后开始对外提供服务，这在GTID方式出现之前，是比较麻烦的。<br>既然切换变得如此容易，接下来就实际演练一下。 30.3.4主从切换<br>关于主从切换，通常是自动触发，可以借助MHA（可以参考第31章）或者MySQL官方工具，这里不做过多介绍，接下来的内容是如何手动处理主从切换。<br>（1）首先将主从库设置为ReadOnly模式。<br>（2）主库执行flushlogs并确认从库是否已经完全追上了主库后（可以参考30.3.3节的方</p>
<p>≦ 590 ≧<br>572 第30章MySQL复制<br>法），停止复制进程，并执行reset slave all，即将作为新主库。 mysql&gt; stop slave;<br>Query ok,0 rows affected (0.12 sec) mysql&gt; reset slave all;<br>Query oK,O rows affected (o.o0 sec)<br>reset slave all执行的操作清除了slave复制位置相关信息，以及连接master的信息（清空 slave_master_info表和slave_relay_log_info表），并且删除所有relaylog和index文件，同时生成一个初始编号的的relaylog和index文件。<br>注意：reset slave与reset slave all命令稍有不同，执行reset salve all意味着完全清除了 slave上<br>的复制相关信息，该从库有计划提升为新主库的可能，而resetslave所做的工作虽然与 reset slave all几乎相同，但不同的是reset slave命令执行后，在MySQL内存里依然会记录该从库连接主库的一些信息，比如Master_Host、Master_User、Master_Port等。如果此时从库重启实例，这些连接信息会消失（在MySQL5.7.24&#x2F;8.0.13之后的版本中，resetslave 命令的作用又发生了变化，即当从库执行reset slave时，表mysql.slave_master_info的记录不会被清除，从而可以快速开启复制）。<br>（3）在原主库（新从库）创建复制进程，并启动slave。 mysql&gt; CHANGE MASTERTO<br>MASTER H0ST&#x3D;10.120.240.251′,<br>MASTER PORT &#x3D; 3308, MASTER USER &#x3D;rep<br>MASTER PASSWORD &#x3D;’repl, MASTER AUTO POSITION &#x3D;1;<br>Query ok, 0 rows affected, 2 warnings (0.o8 sec) mysql&gt; start slave;<br>Query ok,0 rows affected (0.02 sec)<br>现在主从已经完成了切换，原主库现在已经变成了从库，而原从库现在已经切换成了新主库，接下来就是主从复制验证环节。<br>（4）在新主库flush logs，确认从库复制是否正常。 mysql&gt; flush logs;<br>Query ok,O rows affected (o.o0 sec)（5）关闭新主库的ReadOnly模式。<br>mysql&gt; set global read only&#x3D;off; Query ok,0 rows affected (o.o0 sec)<br>以上介绍了主从切换的整个过程，并不复杂，相信大家都能轻松学会。但在从库应用Relay Log的过程中，难免会出现错误。接下来继续讨论GTID模式下的一些常见问题以及解决办法。 30.3.5常见问题<br>由于GTID的引I人，之前的方法（没有启用GTID）有些已经不再适用，例如从库复制时使用skip方法跳过这些错误，也有些工具悄然发生了改变，例如mysqldump，稍不注意，就会进入误区，接下来将分别进行介绍。<br>1.复制出现错误，如何忽略该事务？<br>（1）在主库模拟一个导致从库应用冲突的场景。</p>
<p>≦ 591 ≧<br>30.3 GTID（Global Transaction Identifier) 573<br>mysql&gt; create table ignore tran(id bigint auto_increment,primary key (id)):<br>Query OK,0 rows affected (o.04 sec)（2）从库查看复制情况。<br>mysqT&gt; select LAST SEEN_TRANSACTION,LAST_ERROR NUMBER,LAST ERROR MESSAGE from performance_ schema.replication_applier_status_by_worker where LAST ERROR NUMBER&lt;&gt;O\G;<br>LAST_SEEN_TRANSACTION:eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1<br>LAST_ERROR NUMBER:1049<br>LAST ERRoR MESSAGE: Worker 8 failed executing transaction ‘eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1’ at master 1og mysql-bin.000002,end 1og_pos 372; Error unknown database db master2’on query. Default database:’db master2’. Query:’create table ignore tran(id bigint<br>auto_increment,primary key (id)) 1 row in set(0.00 sec)<br>复制的执行情况，可以通过performance_schema.replication_applier_status_by_worker进行查看，该对象包括执行的线程号、服务状态、错误信息等。从以上信息，可以发现从库没有找到 db_mater2这个database，导致应用RelayLog时报错，接下来采取下面这个办法忽略这个错误。<br>（3）从库忽略这个事务，继续进行复制。<br>mysq1&gt; SET GTID_NEXT&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:17:<br>Query ok, 0 rows affected (o.o0 sec) mysql&gt; BEGIN;COMMIT;<br>Query oK,0 rows affected (o.oo sec) mysql&gt; SET GTID_NEXT&#x3D;’AUTOMATIC’; Query ok,0 rows affected (o.oo sec) mysql&gt; start slave;<br>Query ok,0 rows affected (0.o2 sec)<br>首先找到报错时候的GTID信息，以上为“eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1”，然后执行的BEGIN；COMMIT;表示这是一个空事务，接下来重置GTID_NEXT为 AUTOMATIC，完成这些之后，启动slave。<br>2.主从切换后，新从库不能获取缺少的GTID集合 Last I0 Errno:1236<br>Last I0 Error: Got fatal error 1236 from master when reading data from binary<br>log:’The slave is connecting using CHANGE MASTER To MASTER AUTo POSITION &#x3D; 1, but the master has purged binary logs containing GTIDs that the slave requires.<br>这个问题的出现，是因为主从切换前，从库已经清除了一部分BINLOG数据（从库在做维护时，没有开启read_only或者super_read_only，导致写人部分数据，并且对应的binary log 文件已经被清除掉），但随后该从库成为了新的主库，而原来的主库成为了新的从库，当新从库启动复制进程，开始复制数据的时候，发现此时主库的gtid_executed还包含另一个GTID 集合，即此前写入的部分数据，但BINLOG数据已经不在。<br>如果遇到以上问题，解决方法如下。（1）查看当前主库的GTID信息。 mysql&gt; show master status\G;<br>File: mysql-bin.000052 Position:234<br>Binlog Do DB: Binlog Ignore DB:<br>Executed_Gtid_Set:400f59b6-5e55-11e8-bd15-0024e869b4d5:1,<br>eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4 1 row in set (0.00 sec)<br>（2）查看从库的复制情况。</p>
<p>≦ 592 ≧<br>574 第30章MySQL复制<br>Last I0 Errno:1236<br>Last Io Error: Got fatal error 1236 from master when reading data from binary<br>log:’The slave is connecting using CHANGE MASTER To MASTER AUTo POSITION &#x3D; 1, but the master has purged binary logs containing GTIDs that the slave requires.<br>Master_UuID:400f59b6-5e55-11e8-bd15-0024e869b4d5<br>Executed Gtid Set:eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4 Auto Position1<br>可以看到，从库对比主库而言，缺少GTID集合“400f59b6-5e55-11e8-bd15-0024e869b4d5:1”。<br>（3）从库设置gtid_purged。 mysql&gt; reset master;<br>Query oK,0 rows affected (o.o9 sec)<br>mysq1&gt; set g1obal gtid_purged&#x3D;’400f59b6-5e55-11e8-bd15-0024e869b4d5:1,eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4;<br>Query ok,0 rows affected (o.oo sec)<br>设置从库的gtid_purged，从而放弃主库清除掉的部分BINLOG数据，当然这也意味着主从的数据不是完全一致的（如果主库清除掉的BINLOG数据仅仅是用户权限等相关内容，还是比较容易补录的）。另外关于参数gtid_purged在前文也有过详细介绍，不再赘述。<br>（4）查看从库gtid信息，并启动复制进程。 mysql&gt; select * from mysql.gtid executed;<br>Isource uuid interval start | interval_end| 400f59b6-5e55-11e8-bd15-0024e869b4d5<br>1eab6f8ea-6ed7-11e8-a897-0024e869b4d5 1i 41<br>2rows in set (o.00 sec) mysql&gt; start slave;<br>Query ok, 0 rows affected (0.03 sec) mysql&gt; show slave status\G;<br>slave Io state: waiting for master to send event Master Host:10.120.240.251<br>Master User: repl Master_Port:3307 connect Retry: 60<br>Master Log_File: mysql-bin.000052 Read Master <em>Log Pos: 234<br>Relay_Log_File: hz 10 120 240 251-relay-bin.000002 Relay_Log</em> Pos: 367<br>Relay _Master Log File: mysql-bin.000052<br>slave_Io_Running: Yes slave_SQL_Running: Yes Retrieved Gtid set:<br>Executed_Gtid_Set:400f59b6-5e55-11e8-bd15-0024e869b4d5:1,<br>eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-4<br>Auto Position:1<br>可以看到，此时从库已经可以正常复制。<br>3.主库导入mysqldump导出后的数据，从库并没有同步（1）通过mysqldump备份数据。<br>[mysq13308@hz 10 120240 251~]s mysq1dump -uroot -s&#x2F;tmp&#x2F;mysq1 3308.sock -d emp1oyees employees.sql<br>warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don’t want to restore GTIDs, pass –set-gtid-purged&#x3D;oFF. To make a complete dump, pass –all-databases –triggers –routines –events.<br>通过输出的warning信息，可以看到关于gtid_purged的提示–set-gtid-purged&#x3D;OFF，这个</p>
<p>≦ 593 ≧<br>30.3 GTID（Global Transaction Identifier) 575<br>有什么作用呢？请继续往下阅读。<br>（2）查看备份数据的前一小段内容。<br>[mysq13308@hz 10 120 240 251<del>]s head -30 emp1oyees.sq]<br>–MysQL dump 10.13 Distrib 5.7.22,for 1inux-g1ibc2.12 (x86 64)<br>Host:localhost Database: employees Serverversion5.7.22-1og<br>&#x2F;*!40101 SET @OLD CHARACTER SET CLIENT&#x3D;@@CHARACTER SET CLIENT *&#x2F;;&#x2F;*I40101 SET @OLD CHARACTER SET RESULTS&#x3D;@@CHARACTER SET RESULTS <em>&#x2F;;&#x2F;</em>!40101 SET @OLD_COLLATION_CONNECTION&#x3D;@@COLLATION CONNECTION <em>&#x2F;;&#x2F;</em>!40101 SET NAMES utf8 *&#x2F;;<br>&#x2F;<em>140103 SET @OLD TIME ZONE&#x3D;@@TIME ZONE <em>&#x2F;;</em>!40103 SETTIME ZONE&#x3D;+00:00</em>&#x2F;;<br>&#x2F;*140014 SET @OLD UNIQUE CHECKS&#x3D;@@UNIQUE CHECKS,UNIQUE CHECKS&#x3D;0 *&#x2F;;<br>&#x2F;*140014 SET @OLD_FOREIGN KEY_CHECKS&#x3D;@@FOREIGN KEY_CHECKS,FOREIGN KEY_CHECKS&#x3D;0 <em>&#x2F;;<br>&#x2F;<em>140101 SET @OLD SQL MODE&#x3D;@@SQL MODE,SQL MODE&#x3D;NO_AUTO VALUE_ON ZERO′</em>&#x2F;;&#x2F;</em>!40111 SET @OLD SQL NOTES&#x3D;@@SQL NOTES,SQL NOTES&#x3D;0 *&#x2F;;<br>SET @MYSQLDUMP TEMP_LOG BIN &#x3D; @@SESSION.SQL LOG_BIN; SET @@SESSION.SQL_LOG_BIN&#x3D;O;<br>GTID state at the beginning of the backup<br>SET @@GL0BAL.GTID_PURGED&#x3D;’eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-8’;<br>可以看到在备份文件的开头部分，标注了SQL_LOG_BIN&#x3D;O，即后续的命令均不写人 binarylog文件，并提示这些数据在导出时gtid_executed的集合为eab6f8ea-6ed7-11e8-a897-0024e869b4d5:1-8。<br>（3）指定-set-gtid-purged&#x3D;OFF导出数据。<br>[mysq13308@hz_10 120 240251</del>]$ mysq1dump -uroot-s&#x2F;tmp&#x2F;mysq1 3308.sock-d emp1oyees –set gtid-purged&#x3D;oFF&gt; employees gtid off.sql<br>[mysq13308@hz 10 120 240 251~]s head -30 emp1oyees_gtid off.sq]-MysQL dump 10.13 Distrib 5.7.22,for 1inux-g1ibc2.12 （x86 64)<br>Host:1ocalhost Database:employees<br>-Server version 5.7.22-1og<br>&#x2F;<em>I40101 SET @OLD CHARACTER SET CLIENT&#x3D;@@CHARACTER SET CLIENT <em>&#x2F;:&#x2F;</em>!40101 SET @OLD_CHARACTER SET _RESULTS&#x3D;@@CHARACTER SET RESULTS <em>&#x2F;;&#x2F;</em>!40101 SET @OLD COLLATION CONNECTION&#x3D;@@COLLATION CONNECTION</em>&#x2F;:&#x2F;<em>!40101 SET NAMES utf8 <em>&#x2F;;<br>&#x2F;<em>140103 SET @OLD_TIME ZONE&#x3D;@@TIME ZONE</em>&#x2F;;&#x2F;</em>!40103 SETTIMEZONE&#x3D;’+00:00′</em>&#x2F;;<br>&#x2F;<em>I40014 SET @OLD UNIQUE CHECKS&#x3D;@@UNIQUE_CHECKS,UNIQUE CHECKS&#x3D;0 <em>&#x2F;:<br>&#x2F;</em>!40014 SET @OLD_FOREIGN_KEY CHECKS&#x3D;@@FOREIGN_KEY_CHECKS,FOREIGN_KEY_CHECKS&#x3D;0 <em>&#x2F;;&#x2F;</em>!40101 SET @OLD_SQL MODE&#x3D;@@SQL _MODE,SQL_MODE&#x3D;’NO_AUTO_VALUE ON ZERO’</em>&#x2F;;<br>*!40111 SET @OLD SQL NOTES&#x3D;@@SQL NOTES,SQL NOTES&#x3D;O *&#x2F;;-Table structure for tablechecksums<br>与第一次的备份文件employees.sql对比，可以看到没有出现SQL_LOG_BIN&#x3D;O的字样，也没有相关gtid集合信息。<br>如果使用第一次导出的文件进行数据恢复，从库就不可能会同步数据了。SQL_LOG_BIN&#x3D;O 多用于维护操作，例如主从复制已经配置完成，开始同步数据，但发现从库并没有提前创建复制账号（防止主从故障切换，从库一旦被提升为主库，此时新主库如果没有相应的账号，新从库将</p>
<p>≦ 594 ≧<br>576 第30章MySQL复制<br>无法连接到新主库，复制就会终止），此时可以首先设置SQL_LOG_BIN&#x3D;O，然后创建账号。从这可以知晓，为防止GTID模式开启后，维护期间产生无用的GTID集合，可以通过此方法解决。<br>当然实际工作中还可能会遇到其他问题，只要对GTID理解清楚了，解决起来就没什么困难了。<br>30.4主要复制启动选项<br>下面介绍几个常用的启动选项，如log-slave-updates、read-only、slave-skip-errors等。 30.4.1log-slave-updates<br>log-slave-updates参数用来配置从库上的更新操作是否写二进制日志，默认是OFF，即不写人BINLOG（在MySQL8.0.3版本以后，默认值为ON）。如果这个从库同时也要作为其他服务器的主库，搭建一个链式的复制，或者高可用环境下（比如开启GTID模式下的MHA），那么就需要打开这个选项，这样它的从库将获得它的二进制日志以进行同步操作。该参数需要和–log-bin结合使用，即如果没有开启–log-bin，即便将该参数设置为ON，也不会写二进制日志。<br>注意：如果是启用了GTID模式的三节点以上的MHA环境，当主库故障的情况下，候选主库节<br>点在人为干预（指定某节点为候选master）影响之下可能不包含最新数据，此时需要从其他从库复制BINLOG数据来补足缺少的数据，这个场景下log-slave-updates就需要开启。<br>30.4.2 read-only&#x2F;super_read_only<br>read-only参数用来设置数据库只能接受超级用户的更新操作，从而限制应用程序错误地对数据库进行更新操作。该参数默认值是OFF，即不限制对数据库的更新操作。<br>super-read-only参数用来设置数据库不接受任何用户的更新操作，包括超级用户，对 read-only参数起到补充的作用。<br>关于这两个参数的关系，详见如下示例：（1）read-only打开，super-read-only关闭。 mysql&gt; show variables Tike %read only’;<br>|variable_name 1value|<br>Iinnodb_read only 1OFF Iread_only ION I super_read_only OFF Itransaction read only | OFF<br>Itx_read only OFF 5rows in set (o.00 sec)<br>（2）read-only关闭，super-read-only打开。 mysql&gt; set global read only&#x3D;off;<br>Query ok, 0 rows affected (o.o0 sec) mysql&gt; set global super _read only&#x3D;on; Query oK,0 rows affected (0.02 sec)<br>mysql&gt; show variables like ‘%read only’;</p>
<p>≦ 595 ≧<br>30.4主要复制启动选项 577<br>Variable name 1value innodb <em>read only OFF read_only ON super_read_only ION transaction_read only OFF I tx_read_only<br>5 rows in set (0.00 sec)<br>从以上可以发现，如果super-read-only一旦打开，read-only就会默认打开。<br>（3）super-read-only关闭，read-only不受影响。（4）read-only关闭，super-read-only一起关闭。<br>以上的逻辑也比较好理解，read-only仅限制普通用户，super-read-only限制所有用户。如果super-read-only打开了，那么read-only必然一起打开；如果read-only已经关闭， super-read-only就没必要再打开了。<br>30.4.3指定复制的数据库或者表<br>可以使用replicate-do-db、replicate-do-table、replicate-ignore-db、replicate-ignore-table、 replicate-wild-do-table和replicate_wild_ignore_table来指定从主数据库复制到从数据库的数据库或者表。有时用户只需要将关键表备份到从库上，或者只需要将提供查询操作的表复制到从库上，这样就可以通过配置这几个参数来筛选进行同步的数据库和表。<br>下面演示的例子是设置replicate-do-table的情况，首先在主数据库的employees数据库中创建两个表repl_filter和repl_normal，然后在从数据库的复制进程中，设置replicate_ignore</em> table&#x3D;employees.repl_filter，即忽略表employees.repl_filter。最后在主数据库中更新两个表，检查从数据库中数据复制的情况。<br>（1）首先检查主从数据库上两个表的记录，都是空表。<br>mysql&gt; select * from repl filter; Empty set (0.01 sec)<br>mysql&gt; select * from repl _normal; Empty set (o.00 sec)<br>（2）在从数据库，改变复制进程中的replicate_ignore_table。 mysql&gt; stop slave;<br>Query ok,0.rows affected (o.o0 sec)<br>mysql&gt; change replication filter REPLICATE IGNORE TABLE&#x3D;(employees.repl filter);<br>Query ok, 0 rows affected (o.o0 sec) mysql&gt; start slave;<br>Query ok, 0 rows affected (0.02 sec)<br>（3）下面更新主数据库上的两个表repl_filter和repl_normal。<br>mysql&gt; insert into repl normal(id) values(1); Query ok, 1 row affected (0.04 sec)<br>mysql&gt; insert into repl filter(id) values(1);<br>Query oK,1 row affected (0.o1 sec)（4）再检查从数据库的复制情况： mysql&gt; select * from repl_filter; Empty set (0.o0 sec)</p>
<p>≦ 596 ≧<br>578 第30章MySQL复制 mysql&gt; select * from repl _normal;<br>|id丨 111<br>1 row in set (0.03 sec)<br>从测试的结果可以看到，只有repl_normal表的记录被复制到从库上，而repl_filter表的记录被过滤掉。<br>这里有一点需要提醒，被过滤的内容也会同样复制到从库的，只不过在应用的过程中做了过滤而已。下面就对比一下RelayLog和BINLOG的内容。<br>[mysq13308@hz 10 120240 251 data]s mysq1binlog -vv hz 10_120 240 251-relay-bin.000003#at868<br>#180829 17:08:32 server id 7237 end 1og pos 120033 CRc32 0x5c2ecd57 Table map:employees<br>repl filtermapped to number 404#at927<br>#180829 17:08:32 server id 7237 end 1og pos 120073 cRC32 0x7a31ae01 Write rows: table id 404 flags: STMT _END_F<br>BINLOG<br>kGKGWxNFHAAAOWAAAOHUAQAAAJQBAAAAAAEACWVtCGxVeWV1cWALcmVwbF9maWxOZXIAAQMAAFfN L1W&#x3D;<br>kGKGWx5FHAAAKAAAAAnVAQAAAJQBAAAAAAEAAgAB&#x2F;&#x2F;4BAAAAAa4xeg&#x3D;&#x3D;&#x2F;1#&#x2F;;<br>###INSERT INToemployees.repl_filter###SET<br>###@1&#x3D;1&#x2F;<em>INT meta&#x3D;0 nullable&#x3D;0 is nul1&#x3D;0</em>&#x2F;#at967<br>#180829 17:08:32 server id 7237 end 1og pos 120104 CRc32 0x6747f7f7 xid&#x3D;129526 COMMIT&#x2F;<em>I</em>&#x2F;:<br>SET @@SESSION.GTID NEXT&#x3D;’AUTOMATIC’&#x2F;<em>added by mysqlbinlog</em>&#x2F; &#x2F;<em>1</em>&#x2F;; DELIMITER;<br>#End of log file<br>[mysq13308@hz 10 120_240 251 data]s mysq1binlog -vv mysql-bin.000001#at838<br>#180829 17:08:32 server id 7237 end 1og pos 903 cRc32 0x49b3d57d GTID last committed&#x3D;3 sequence number&#x3D;4rbr only&#x3D;no<br>SET @@SESSION.GTID NEXT&#x3D;400f59b6-5e55-11e8-bd15-0024e869b4d5:52’&#x2F;<em>1</em>&#x2F;;#at903<br>#180829 17:08:32 server id 7237 end log pos 966 cRc32 0x7c88d9f3 Query thread_id&#x3D;637<br>exec_time&#x3D;Oerror_code&#x3D;0 SET TIMESTAMP&#x3D;1535533712&#x2F;<em>1</em>&#x2F;;<br>SET @@session.sql_mode&#x3D;1143472162&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>1</em>&#x2F;;#at 966<br>#180829 17:08:32 server id 7237 end_1og_pos 1030 CRc32 0x5bb73c67 Query thread_id&#x3D;637 exec time&#x3D;0 error_code&#x3D;0 SET TIMESTAMP&#x3D;1535533712&#x2F;<em>1</em>&#x2F;;<br>COMMIT&#x2F;<em>！</em>&#x2F;;<br>SET @@SESSION.GTID NEXT&#x3D;AUTOMATIC&#x2F;*added by mysqlbinlog *&#x2F;&#x2F;<em>I</em>&#x2F;; DELIMITER;</p>
<h1 id="End-of-log-file"><a href="#End-of-log-file" class="headerlink" title="End of log file"></a>End of log file</h1><p>从以上对比的内容，可以发现复制进程在过滤后，对该事务执行了一个空事务（因为开启了GTID），这点正式使用了GTID模式下的跳过事务的方法。不过，如果启用了过滤复制功能，需要考虑该从库是否有可能会作为主库，如果切换为主库，会缺失很多数据。</p>
<p>≦ 597 ≧<br>30.5日常管理维护 579<br>30.4.4slave-skip-errors<br>在复制过程中，由于各种原因，从库可能会遇到执行BINLOG中的SQL出错的情况（比如主键冲突），默认情况下，从库将会停止复制进程，不再进行同步，等待用户介人处理。这种问题如果不能及时发现，将会对应用或者备份产生影响。此参数的作用就是用来定义复制过程中从库可以自动跳过的错误号，这样当复制过程中遇到定义中的错误号时，便可以自动跳过，直接执行后面的SQL语句，以此来最大限度地减少人工干预。此参数可以定义多个错<br>误号，或者通过定义成all跳过全部的错误，具体语法如下：–slave-skip-errors&#x3D;[err_codel,err_code2,…&#x2F; a71]<br>如果从库主要是作为主库的备份，那么就不应该使用这个启动参数，设置不当，很可能造成主从库的数据不同步。但是，如果从库仅仅是为了分担主库的查询压力，且对数据的完<br>整性要求不是很严格，那么这个选项的确可以减轻数据库管理员维护从库的工作量。 30.5日常管理维护<br>复制环境配置完成后，数据库管理员需要经常进行一些日常监控和管理维护工作，以便能及时发现复制中的一些问题，并尽快解决，以此来保持复制能够正常工作。本节将向读者介绍一些常用的监控和管理维护方法。<br>30.5.1查看从库复制状态和进度<br>为了防止复制过程中出现故障，从而导致复制进程停止，需要经常检查从库的复制状态。一般使用showslavestatus命令来检查。<br>在查询结果的各种指标中，主要关心“Slave_IO_Running”和“Slave_SQL_Running”这两个进程状态是否是“yes”，这两个进程的含义分别如下。<br>OSlave_IO_Running:此进程负责从库（Slave）从主库（Master）上读取BINLOG日志，并写入从库上的中继日志中。<br>OSlave_SQL_Running:此进程负责读取并且执行中继日志中的BINLOG日志。<br>只要其中有一个进程的状态是no，则表示复制进程停止，错误原因可以从“Last_Errno” 字段的值中看到。<br>除了查看上面的信息，用户还可以通过这个命令了解从库的配置情况以及当前和主库的同步情况，包括指向哪个主库、主库的端口、复制使用的用户、当前日志恢复到的位置等。这些信息都是记录在从库这一端的，主库上并没有相应的信息。<br>由于从库复制可能会出现延迟，影响线上业务，所以通常需要监控从库的复制进度指标。这个值可以通过show slave status中的Seconds_Behind_Master获得，单位是秒。由于该值是通过从库的I&#x2F;O进程与SQL进程间的差距计算出来的，预估的结果，并不是特别准确。<br>可以通过如下方法获得比较准确的延迟。<br>（1）通过心跳策略，即主库频繁插人当前的系统时间戳，然后从库去检查该值，并与系统时间做对比，可以借助pt-heartbeat工具，此处不再赘述。</p>
<p>≦ 598 ≧<br>580 第30章MySQL复制<br>（2）MySQL8.0版本以后，在每个事务中又增加了两个属性OriginalCommitTimestamp（OCT）和ImmediateCommitTimestamp（ICT）。前者表示原始master执行该事务时Commit 的时间戳，ICT表示执行该事务的节点（从节点）执行时Commit的时间戳，这两个的差值，即可以理解为延迟时间。<br>查看BINLOG文件，观察相关事务的延迟情况。#at124<br>#181113 16:09:59 server id 7238 end 1og pos 155 cRC32 0x2ac55a1b Previous-GTIDs<br>#[empty]#at155<br>#181113 16:07:45 server id 7237 end 1og_pos 237 cRc32 0x9c9e50de GTID ast_committed sequence_number&#x3D;1 rbr_only&#x3D;yes original_committed_timestamp&#x3D;1542096465712566<br>immediate_commit<br>timestamp&#x3D;1542096964014971 transaction_length&#x3D;467<br>&#x2F;<em>I5O718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED</em>&#x2F;&#x2F;<em>!</em>&#x2F;;<br>#original_commit_timestamp&#x3D;1542096465712566 (2018-11-13 16:07:45.712566 csT)#immediate_commit_timestamp&#x3D;1542096964014971 (2018-11-13 16:16:04.014971 CST)&#x2F;<em>180001 sET @@session.original_commit_timestamp&#x3D;1542096465712566</em>&#x2F;&#x2F;<em>!</em>&#x2F;;<br>SET @@SESSI0N.GTID_NEXT&#x3D;6fb578bb-572a-11e8-8aa5-0024e869b4d5:6608562’&#x2F;<em>1</em>&#x2F;;<br>从上面这个示例中可以知道，该事务在原主库执行的时间是2018-11-1316:07:45.712566，而从库执行的时间是2018-11-1316:16:04.014971。<br>另外，也可以查看性能视图performance_schema.replication_applier_status_by_worker、 performance_schema.replication_applier_status_by_coordinator或者performance_schema.replication connection_status中的相关记录，如下示例：<br>mysql&gt; select * from performance schema.replication applier status by_worker\G;<br>CHANNEL_NAME : slave8<br>WORKER ID : 1 THREAD ID:132<br>SERVICE STATE:ON LAST ERROR NUMBER:0 LAST ERROR MESSAGE<br>LAST ERROR TIMESTAMP:0000-00-00 00:00:00.000000<br>LAST APPLIED_TRANSACTION:6fb578bb-572a-11e8-8aa5-0024e869b4d5:2<br>LAST_APPLIED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP:2018-08-3112:01:22.380463 LAST_APPLIED_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP:2018-08-31 12:01:22.380463<br>LAST_APPLIED_TRANSACTION_START_APPLY_TIMESTAMP:2018-08-31 12:01:22.381192 LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP:2018-08-3112:01:22.388115<br>APPLYING TRANSACTION:<br>APPLYING TRANSACTION ORIGINAL COMMIT_TIMESTAMP:0000-00-OO 0O:0O:00.000000 APPLYING_TRANSACTION_IMMEDIATE COMMIT_TIMESTAMP:0000-00-00 0O:0O:00.000000 APPLYING TRANSACTION START APPLY TIMESTAMP0000-00-0000:00:00.000000<br>30.5.2主从复制问题集锦<br>在主从复制关系中，常见的问题就是主从库的数据不一致，原因多种多样，接下来总结一些常见原因以及解决办法，便于快速定位问题，处理故障。<br>当主从切换时，有可能因为一些原因（例如原主库保持业务端的连接未断开），导致切换期间在原主库发生了数据写入，建议使用成熟的高可用方案（例如MHA等工具）解决主从切换问题，或者在切换期间，原主库开启readonly&#x2F;superreadonly模式。另一个办法就是启用主从的半同步复制（after_sync模式），但这种方案在复制中断、网络延迟大的情况下，也存在丢失数据的风险。<br>在主从复制拓扑关系中，每个实例（主库或者从库）都需要有不一样的server_id。如果出现相同的值，会引起复制混乱，所以要在完成复制配置前确认每个实例具有不同的值。</p>
<p>≦ 599 ≧<br>30.5日常管理维护 581<br>主从复制中如果使用了不同的MySQL版本，首先要确认兼容性问题，因为复制技术演进很快，如果数据库版本相差较大，会出现这个问题。<br>在从库配置slave时可以指定复制哪些库表，也可以忽略一些库表，对于一些不怎么重要的数据（例如日志类数据），有可能会被过滤掉，这样做虽然能缓解从库的压力，但是如果该实例一旦被提升为主库，会缺少很多数据，所以在配置过滤规则时，需要慎重。<br>O主从库配置了不同的SQLmode（与SQLmode相关内容在前文有过介绍，不再赘述），导致主库写入数据后，从库得到了不同结果，建议配置主从复制环境初期，检查SQLmode 参数，保持一致。<br>BINLOG配置了非Row格式，例如Statement，当SQL语句中含有函数时，从库可能生成不同于主库的值，建议主从库的BINLOG格式统一配置为RoW格式。<br>以上列举了一些常见的故障情况，那么如果发生了主从库数据不一致，如何修复呢？除了利用前文介绍过的工具pt-table-sync进行数据修复，还有一个办法就是忽略错误（建议操作前先确认是否可以进行此操作），尽快恢复从库。如果拖延时间太久，会造成主从复制被长时间中断，积压大量的BINLOG数据，面临大量丢失数据的风险。<br>下面介绍一下忽略错误的方法。<br>在从库跳过来自主库的语句的命令为SETGLOBALSQL_SLAVE_SKIP_COUNTER&#x3D;n（如果启用了GTID复制，此方法不能采用，请详见30.3.5节），其中n表示n个事件（event），而实际上binarylog是由事件组（event group）按顺序组织起来的，每个事件组包括一系列的事件。如何理解事件组呢？<br>当执行一个insert&#x2F;update&#x2F;delete时，BINLOG中记录的是一组连续event，如下所示：前提：BINLOG格式&#x3D;ROW<br>mysql&gt; update employees.departments set dept name&#x3D;’a’ limit 1; Query ok, 1 row affected (0.01 sec)<br>Rows matched:1Changed:1 warnings:0<br>解析BINLOG数据：#at813<br>#181221 14:25:59 server id 7238 end 1og pos 878 cRc32 0x7ea2013a<br>committed&#x3D;2 sequence number&#x3D;3rbr only&#x3D;yes Anonymous_GTID last&#x2F;<em>!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED</em>&#x2F;&#x2F;<em>I</em>&#x2F;;<br>SET @SESSION.GTID_NEXT&#x3D;ANONYMOUS&#x2F;<em>!&#x2F;;#at 878<br>#181221 14:25:59 server id 7238 end 1og_pos 958 cRc32 0x9663bb8a Query thread_id&#x3D;3<br>exec_time&#x3D;Oerror_code&#x3D;o SETTIMESTAMP&#x3D;1545373559&#x2F;<em>1</em>&#x2F;;<br>BEGIN&#x2F;<em>1</em>&#x2F;;#at958<br>#181221 14:25:59 server id 7238 end_1og pos 1022 cRc32 0x1b15c8fa Table map:employees<br>.departmentsmapped to number 112#at 1022<br>#181221 14:25:59 server id 7238 end 1og pos 1074 cRc32 0x7bb7db4e<br>112 flags: STMT END_F Update_rows: table id BINLOG<br>d4ccXBNGHAAAQAAAAP4DAAAAAHAAAAAAAAMACWVtCGxVeWV1cWALZGVwYXJObWVudHMAAv4PBP4M eAAA+sgVGw&#x3D;&#x3D;<br>d4ccXB9GHAAANAAAADIEAAAAAHAAAAAAAAEAAgAC&#x2F;&#x2F;8BGQwMDEBY&#x2F;WEZDAwMQFhTtu3eW&#x3D;&#x3D;&#x2F;</em>!*&#x2F;;<br>###UPDATEemployeesdepartments###WHERE<br>###@1&#x3D;d001&#x2F;*STRING(12） meta&#x3D;65036nu11able&#x3D;0 is nu11&#x3D;0 *&#x2F;@2&#x3D;c&#x2F;<em>VARSTRING(120)meta&#x3D;120 nu1lab1e&#x3D;0 is nu11&#x3D;0</em>&#x2F;###</p>
<p>≦ 600 ≧<br>582 第30章MySQL复制###SET<br>###@1&#x3D;d001′&#x2F;*sTRING(12) meta&#x3D;65036nullable&#x3D;0 is nu11&#x3D;0 *&#x2F;###@2&#x3D;a′&#x2F;<em>VARSTRING（120) meta&#x3D;120 nu1lab1e&#x3D;0 is nu11&#x3D;0 <em>&#x2F;#at1074<br>#181221 14:25:59 server id 7238 end 1og pos 1105 cRc32 0x1d4362a0 xid &#x3D; 14 COMMIT&#x2F;</em>!</em>&#x2F;;<br>一次update操作，在BINLOG中主要分为begin、update、commit这3个阶段，多个event 事件，这就是一个事件组。对事务表而言（类似Innodb引擎的表），此事件组可以理解为一个事务；但对非事务表来说（类似MyISAM引擎的表），此事件组可以理解为单一SQL语句（因非事务表不支持事务，当执行一个数据变更操作时，不会等待commit，直接变更数据）。如果需要跳过的事件刚好在一个事件组中间，会直接跳至该事件组的结尾，即开始执行下一个事务。<br>举例如下：<br>（1）首先，在从库端先停止复制进程，并设置sql_slave_skip_counter&#x3D;2。 mysql&gt; select * from skip_test;<br>Empty set (o.00 sec) mysql&gt; stop slave;<br>Query ok,0 rows affected (o.oo sec)<br>mysql&gt; set global sql slave skip counter&#x3D;2;<br>Query oK,O rows affected (o.oo sec)（2）然后在主库写入两条记录。<br>mysql&gt; insert into skip_test valuesO; Query ok,1 row affected (0.o0 sec)<br>mysql&gt; insert into skip test valuesO; Query ok,1 row affected (o.o0 sec)<br>mysql&gt; select * from skip_test; lid<br>2rows in set (o.00 sec)（3）从库开启复制进程。 mysql&gt; start slave;<br>Query ok, 0 rows affected (0.o2 sec) mysql&gt; select * from skip test;<br>lid| 121<br>1 row in set (o.00 sec)<br>可以看到，此时从库只跳过了一条记录（一个事务），即第一次insert的数据，如果仍然是这个场景，只是将sql_slave_skip_counter-2改为sql_slave_skip_counter&#x3D;1或者3，其结果是一样的。<br>通过以上这些介绍，相信读者处理起主从复制故障，会变得容易得多。 30.5.3多主复制时的自增长变量冲突问题<br>在大多数情况下，一般只使用单主复制（一台主库对一台或者多台从库），但是在某些情况下，可能会需要使用多主复制（多台主库对一台从库）。这时，如果主库的表采用自动增长</p>
<p>≦ 601 ≧<br>30.5日常管理维护 583<br>变量，那么复制到从库的同一张表后很可能会引起主键冲突，因为系统参数auto_increment increment和auto_increment_offset的默认值为1，这样多台主库的自增变量列迟早会发生冲突。在单主复制时，可以采用默认设置，不会有主键冲突发生。但是使用多主复制时，就需要定制auto_increment_increment和auto_increment_offset的设置，保证多主之间复制到从数据库不会有重复冲突。比如，两个master的情况可以按照以下设置。<br>Master1 上：auto_increment_increment &#x3D;2,auto_increment_offset&#x3D; 1;（1,3,5,7..序列）。 OMaster2上: auto_increment_increment &#x3D; 2,auto_increment_offset &#x3D;0;(0,2,4,6…序列 ）。下面的例子在employees库中创建了测试表repl_increment，只有一个自增字段id，我们开始演示修改这两个参数的效果。首先在参数是默认值时，往表repl_increment中插入记录，可以看到自动增长列的值是连续的。<br>Mysql&gt; CREATE TABLErepl incrementC<br>id bigint(2O) NOT NULL AUTo INCREMENT, PRIMARY KEY (id)<br>Query ok,0 rows affected (0.12 sec)<br>mysql&gt; show variables like%auto_incr%’;<br>1Variable name value 1 auto_increment increment<br>I auto_increment offset 2 rows in set (o.oo sec)<br>mysql&gt; insert into rep1_increment values(null),(null),(nul1);<br>Query ok,3 rows affected (0.07 sec) Records:3Duplicates:0 warnings:0<br>然后把参数auto_incrementincrement的值修改成10，再插入记录：<br>mysql&gt; sET @@auto_increment_increment&#x3D;10; Query oK,0 rows affected (0.o2 sec)<br>mysql&gt; show variables like %auto incr%’;<br>|Variable_name |value | auto_increment_increment<br>1 auto_increment_offset 2 rows in set (o.00 sec)<br>mysql&gt; insert into rep1 increment values(null),(null),(nul1);<br>Query ok, 3 rows affected (0.o0 sec) Records: 3Duplicates:0warnings:0 mysql&gt; select * from repl increment;<br>|id| 2 11 21 31<br>6 rows in set (o.00 sec)<br>从测试的结果上看，新插入的记录不再连续了，每次增加10。接着再修改auto_increment</p>
<p>≦ 602 ≧<br>584 第30章MySQL复制 offset参数，了解插人记录的效果：<br>mysql&gt; sET @@auto_increment _offset&#x3D;5; Query ok, 0 rows affected (o.o0 sec)<br>mysql&gt; show variables like %auto_incr% |variable_name 丨value |<br>I auto_increment_offset 2rows in set (o.00 sec)<br>mysql&gt; insert into repl_increment values(nu11),(nu71),(nu11);<br>Query ok, 3 rows affected (o.o0 sec) Records:3 3Duplicates:Owarnings:0<br>mysql&gt; select * from repl increment;<br>|idl 11 21<br>9rows in set (o.00 sec)<br>从插人记录的结果上可以了解，auto_increment_offset参数设置的是每次增加后的偏移量，也就是每次按照10累加之后，还需要增加5个偏移量。<br>通过这两个参数可以方便地设置不同的主库上的自动增长列的值的范围，这样在这些数<br>据复制到从库上时可以有效地避免主键的重复。 30.5.4如何提高复制的性能<br>在某些业务繁忙的系统上，由于主库更新频繁，导致从库复制延迟，当然出现延迟的情况有很多种，比如主从数据库服务器硬件差异，从库硬件资源不足以支撑业务的发展规模，出现这种情况，除了提升硬件资源、优化业务系统的设计、重点解决高频SQL或热点数据这些办法（关于这方面内容，请参考优化篇），还可以考虑从复制环境上下手，比如调整一些参数或者调整系统架构。<br>1.几个重要参数<br>关于参数，重点讨论以下几个。<br>Osync_binlog和innodb_flush_log_at_trx_commit:关于这两个参数的解释在前文详细介绍过，在此不再赘述。为了加快从库的数据写入，可以在评估之后，调整该参数的值为非1，当然这也需要考虑带来的风险，例如该从库将来还可能切换为主库。<br>Obinlog_group_commit_sync_delay:该参数表示在binlog组提交下，BINLOG数据刷到磁盘的等待时间，默认值为0，即不等待，最大值为1000000（单位为毫秒）。如果该参数的值大于0（建议为10的倍数，否则容易引起BUG），则可以增加每次组提交的事务数量，</p>
<p>≦ 603 ≧<br>30.5日常管理维护 585<br>使得更多的事务在一次刷盘便能完成操作，对于I&#x2F;O负荷较大的系统，会有一些帮助，因为适当的等待时间能缓解高IOPS需求。另外，也会对事务并发复制有益处，因同一单位时间内能有更多的事务被处理，有效增加主从库并发执行效率。但也有负面影响，比如响应时延增加，如下所示。<br>参数binlog_group_commit_sync_delay值为0：<br>mysql&gt; show variables like’binlog_group_commit sync delay’; |Variable_name |value I<br>1binlog_group_commit_sync_delay |0 1row in set (0.00 sec)<br>mysql&gt; update employees.dept emp set to date&#x3D;’9999-02-02 1imit 3； Query oK,3 rows affected (0.04 sec)<br>Rows matched:3 Changed:3 warnings:0<br>参数binlog_group_commit_sync_delay的值为1000000: mysql&gt; set global binlog group_commit <em>sync_delay&#x3D;10000000;<br>Query ok,0 rows affected,1 warning (o.03 sec) mysq1&gt;<br>mysql&gt; show variables like binlog_group_commit sync_delay’; variable_name |value<br>I binlog_group_commit sync_delay| 100o0001 1row in set(0.00 sec)<br>mysql&gt; update employees.salaries set salary&#x3D;200 1imit 3; Query ok,3 rows affected (1.04 sec)<br>Rows matched:3 changed:3 warnings:0<br>从以上示例可以看到，默认情况下，执行例子中的SQL需要0.04s；增加参数的值为 1000000之后，该SQL需要执行1.04s。<br>所以在修改该参数时，需要考虑对前端应用的影响。<br>Obinlog_group_commit_sync_no_delay_count:该参数表示binlog组提交时需要等待的事务数量，需要与上一个参数binlog_group_commit_sync_delay结合使用。如果参数binlog</em> group_commit_sync_delay的值为0，则该参数即便设置大于0，也不会起作用。该参数默认值为0，最大值为1000000。由于该参数的含义同上类似，所以不再赘述。<br>Osync_master_info:该参数表示slave的IO线程更新master_info_repository的频率，默认值为10000，如何进行更新也与参数master_info_repository的值有关系。<br>master_info_repository&#x3D;FILE，当参数sync_master_info&#x3D;n（其中n大于O，例如默认值为 10000）的情况下，slave会在每经过n次事件（event）后，更新文件master.info，该文件记录了slave的I&#x2F;O线程与主库的BINLOG位置的映射关系；当参数sync_master_info&#x3D;O的时候，此时更新文件master.info工作将由MySQL转交给操作系统，即操作系统去控制何时刷新文件。由于master_info_repository参数当配置为FILE选项时，会引起很多问题，例如非原子性操作、效率低下等，建议使用TABLE选项。<br>master_info_repository&#x3D;TABLE，如果sync_master_info的值大于O，slave会在每经过n 次事件（event）后（而非事务，事件、事件组、事务的区别在前文有介绍，不再赘述），更新表mysql.slave_master_info。该表的内容如下所示：</p>
<p>≦ 604 ≧<br>586 第30章MySQL复制<br>mysql&gt; select * from mysql.slave master info\G;<br>Number of lines:25<br>Master_log_name: mysql-bin.000001 Master log pos: 5401<br>Host:10.120.240.251<br>1 row in set (0.00 sec)<br>接下来简要介绍当参数master_info_repository&#x3D;TABLE时，参数sync_master_info在不同值的环境下，如何影响表mysql.slave_master_info的更新。<br>（1）从库停止slave的I&#x2F;O进程。<br>mysql&gt; show variables like ‘sync master_info’; Variable_name 1value丨<br>I syncmaster_info | 10000 1 row in set (0.01 sec)<br>mysql&gt; stop slave io thread;<br>Query ok,0 rows affected (o.oo sec)<br>mysql&gt; select * from mysql.slave master_info\G;<br>Number_of_lines:25<br>Master_log_name: mysql-bin.000001 Master_log_pos:5401<br>Host:10.120.240.251<br>此时sync_master_info为默认值10000，mysql.slave_master_info对应主库的位置是文件 mysql-bin.000001,position:5401。<br>（2）调整从库参数sync_master_info从10000到10。<br>mysql&gt; set global sync master_info&#x3D;10; Query ok,0rows affected (o.o0 sec)<br>mysql&gt; show variables like ‘sync master_info’;<br>Ivariable name |value| I sync_master_info|<br>1row in set (0.00 sec)<br>（3）主库执行两次insert操作。<br>mysql&gt; insert into sync test valuesO;<br>Query ok, 1 row affected (0.00 sec) mysql&gt; insert into sync test valuesO; Query ok, 1 row affected (0.00 sec)（4）从库开启slave的I&#x2F;O线程。 mysql&gt; start slave io_thread;<br>Query ok,O rows affected (o.oo sec)<br>mysql&gt; select * from mysql.slave master_info\G;<br>Number_of_1ines:25<br>Master_log name: mysql-bin.000001 Master 1og pos:5914<br>Host: 10.120.240.251<br>可以看到mysql.slave_master_info表已经更新为mysql-bin.000001，position：5914。</p>
<p>≦ 605 ≧<br>30.5日常管理维护 587<br>如果将参数sync_master_info调整为0，mysql.slave_master_info将不再更新。所以如果从库复制性能较差，磁盘IO很高，可以考虑调整该参数。<br>2.直接利用多从架构来解决<br>通过拆分减少一个从库上需要数据同步的表来解决。首先考虑配置一主多从的架构，然后在不同的从库上，通过设置不同的replicate-do-db、replicate-do-table、replicate-ignore-db、 replicate-ignore-table、replicate-wild-do-table和replicate_wild_ignore_table参数，使得不同的从库复制不同的库&#x2F;表，减少每个从库上需要写人的数据。<br>例如，假设主库为M1，从库为S1、S2、S3，其中设置从库S1仅需要复制databaseA，而从库S2仅需要复制databaseB，从库S3<br>仅需要复制databaseC，那么每个从库只需要 databaseA— MySQL SI 执行自已需要复制的库&#x2F;表相关的SQL就可<br>databaseB<br>以了，如图30-10所示。 MySQL M1 MySQL S2<br>这时，由于主库M1需要给S1、S2、<br>S3这3个从库（或者更多从库）都发送完 databaseC MySQLS3<br>整的BINLOG日志，I&#x2F;O和网络压力较大，图30-10MySQL拆分database复制再改进一下架构：配置MySQL多级主从架构减轻主库压力，如图30-11所示。<br>MySQL S1<br>MySQLMI MySQLM2 MySQL S2<br>MySQLS3<br>图30-11MySQL多级复制<br>（1）主库M1首先给二级主库M2发送完整的BINLOG。<br>（2）二级主库M2打开log-slave-updates配置，保证主库M1传送过来的BINLOG能够被记录在二级主库M2的RelayLog和BINLOG中；二级主库M2选择BLACKHOLE引擎作为表引擎，降低二级主库上I&#x2F;O的压力。<br>（3）为二级主库M2配置3个从库S1、S2、S3，这3个从库通过配置不同的replicate-do-db 等参数让S1、S2、S3复制不同的库&#x2F;表。<br>通过多级主从的方式提高从库的复制性能，同时尽量降低对主库的影响。<br>注意：BLACKHOLE引擎就是一个“黑洞”引擎，在创建表的时候，选择BLACKHOLE引擎，<br>那么写入表的数据不会真实地写入磁盘，仅仅记录Binlog日志，极大地降低了磁盘的IO。<br>该方案的优点在于能够自由拆分从库，方便地把热点数据分散开来；缺点在于维护起来不够简洁，并且由于从库S1、S2、S3上都没有主库完整的数据，在主库M1出现意外岩机的情况，应用处理较为麻烦。需要提前和应用沟通好异常的处理解决方案。<br>3.升级MySQL版本<br>可以利用MySQL5.7的多线程复制技术，较之前的版本性能提高了很多，当然就是主库的并发度要比较高，这样才更明显。如果主库的更新操作以串行为主，那该技术带来的性能</p>
<p>≦ 606 ≧<br>588 第30章MySQL复制<br>提升就大打折扣了，甚至没有提升。不过针对这种情况，我们还可以选择直接升级至MySQL8.0 的GA版本，使用复制中的writeset技术，这样即便主库以串行为主，从库依然可以并行执行，正好解决了MySQL5.7多线程复制遗露的问题。<br>4.使用MySQL中间件<br>MySQL中间件产品有很多可供选择，比如开源的或者商业化的，大多都提供丰富的垂直扩展或者水平扩展功能，也相应的提供了连接池功能，从而减少反复创建连接、销毁连接的资源开销，提高MySQL的性能。另外，中间件也有负载均衡、读写分离功能，可以分担线上业务的部分压力，亦可以成为高可用架构中的一员，对整体架构起着举足轻重的作用。关<br>于该部分内容，可以参考第32章，此处不再详述。 30.6小结<br>复制是MySQL数据库中经常使用的一个功能，也是MySQL技术发展的重要关注点，它可以有效地保证主数据库的数据安全，并减轻主数据库的备份压力，以及分担主数据库的一部分查询压力。<br>MySQL复制环境的搭建非常简单，在实际使用中，建议给重要的数据库配置复制，如果没有足够的服务器可以使用，那么也可以在一个主数据库上启动另外一个MySQL服务，以作为另外一个MySQL服务的从数据库。<br>本章重点介绍了复制环境的搭建、GTID、日常管理和主要启动选项等，希望对读者在搭建和日常使用复制功能时有所帮助。由于MySQL的复制技术在不断迭代，功能越来越强大，读者也可以参考MySQL最新的官方文档。</p>
<p>≦ 607 ≧<br>第31章 高可用架构<br>对于一个企业来讲，设计一个高可用的架构非常重要，包括前端的高可用和后端数据库的高可用。企业业务上每暂停一分钟，可能会造成大量的金钱流失，因此只有在整个架构的设计上足够的高可用，才可以保证应用程序对外提供不间断的服务，进而把因软件、硬件、人为造成的故障对业务的影响降低到最小程度，把损失降低到最低。本章将重点介绍数据库<br>高可用方面的3个主流架构：MHA、MGR和InnodbCluster。 31.1MHA 架构<br>MHA（MasterHighAvailability）目前在MySQL高可用方面是一个相对成熟的解决方案，它由日本籍工程师youshimaton开发，是一套在MySQL高可用性环境下进行故障切换和主从提升的优秀软件。在MySQL故障切换过程中，MHA能做到在0～30s之内自动完成数据库的故障切换操作，并且在故障切换过程中，最大程度地保证数据的完整性和一致性，以达到真正意义上的高可用。<br>MHA由两部分组成：MHAManager（管理节点）和MHANode（数据节点）。MHAManager 建议单独部署在一台独立的机器上，可以管理多个master-slave集群。MHANode运行在每台 MySQL服务器上，MHAManager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的 master。整个故障转移过程对应用程序是完全透明的。<br>在MHA自动故障切换过程中，MHA试图从岩掉的主服务器上保存二进制日志，最大程度地保证数据不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过SSH 访问，MHA没法保存二进制日志，只进行故障转移而丢失了最新数据，又或者MySQL环境启用了GTID复制模式，即便主服务器可以通过SSH访问，MHA也不会考虑复制二进制日志应用到新主库。为了最大程度地避免主库日志的丢失，建议MHA与5.7的增强半同步复制结合起来。即使只有一个slave已经收到了最新的二进制日志，MHA也可以将最新的二进制日志应用于其他所有的slave服务器上，来保持彼此的一致性。<br>目前MHA主要支持一主多从的架构，当然如果非要使用一主一从，技术上也是没问题的，不过为了安全考虑，一个复制集群中建议最少有3台数据库服务器，一主二从，即一台充当master，一台slave充当切换后的备用master，另一台slave充当从库，因为需要3台服务器。出于机器成本考虑，可以考虑选用其中一台服务器（备用master或者从库）作为共用</p>
<p>≦ 608 ≧<br>590 第31章高可用架构<br>备机，即可以将两套或者多套环境的备库都搭建在该机器上。<br>图31-1所示为如何通过MHAManager管理多组主从复制。我们可以将MHA工作原理总结为以下几条。<br>传统复制模式（非GTID复制模式）如下：<br>（1）从岩机崩溃的master保存二进制日志事件（BINLOGevent）；（2）识别含有最新更新的slave；<br>（3）应用差异的中继日志（RelayLog）到其他slave；<br>MHA<br>Manager 复制组三<br>slavel<br>master<br>slave<br>复制组<br>复制组-<br>slavel master slavel slave2<br>图31-1MHA集群监控图<br>（4）应用从master保存的二进制日志事件（BINLOGevent）；（5）提升一个slave为新master;<br>（6）使其他的 slave连接新的master进行复制。 GTID复制模式如下：<br>（1）识别含有最新更新的slave；<br>（2）复制差异的BINLOG数据到其他slave；（3）提升一个slave为新master;<br>（4）使其他的 slave连接新的master进行复制。<br>从以上可以看到，传统复制模式和GTID复制模式，处理方式上有一些不同，也就是说如果启用了GTID，需要打开从库的log-slave-updates（该参数在第30章有过介绍），以减少数据丢失的风险。<br>MHA软件由两部分组成，即Manager工具包和Node工具包。 Manager工具包主要包括以下几个工具。<br>6 masterha_check_ssh:检查MHA的SSH配置状况。<br>0 masterha_check_repl:检查MySQL复制状况。</p>
<p>≦ 609 ≧<br>31.1MHA架构 591<br>0 masterha_manager:启动MHA.<br>masterha_check_status：检测当前MHA运行状态。 Omasterha_master_monitor:监测master是否宕机。<br>masterha_master_switch：控制故障转移（自动或手动）。 Omasterha_conf host:添加或删除配置的server信息。<br>Node工具包（这些工具通常由MHAManager的脚本触发，无须人手操作）主要包括以下几个工具。<br>Osave_binary_logs:保存和复制master的二进制日志。<br>Oapply_diff_relay_logs:识别差异的中继日志事件并将其差异的事件应用于其他slave。 purge_relay_logs:清除中继日志（不会阻塞SQL线程）。<br>注意：为了尽可能地减少因为主库硬件损坏宕机造成的数据丢失，因此在配置MHA的同时建议<br>配置增强半同步复制。<br>31.1.1安装部署MHA<br>接下来开始安装部署MHA，具体搭建环境如表31-1所示。表31-1 搭建环境信息<br>角色 IP地址主机名 Server ID 类型<br>master 192.168.7.81 ip81 1 写入 candicate master 192.168.7.83 ip83 2 读 slave 192.168.7.185 ip185 3 读<br>monitor host 192.168.7.186 ip186 监控集群组<br>其中master对外提供写服务，candicatemaster提供读服务，slave也提供相关的读服务，一旦master岩机，将会把candicate master提升为新的master，slave指向新的master。<br>1.安装MHANode<br>（1）在所有的MySQL服务器上安装MHANode所需的Perl模块（DBD::mysql）。<br>本环境为CentOS部署MHA，需要在所有MHANode上安装Perl模块（DBD:mysql）。安装脚本（install.sh）如下：<br>install.sh#!&#x2F;bin&#x2F;bash<br>wget <a target="_blank" rel="noopener" href="http://xr1.us/cpanm">http://xr1.us/cpanm</a> –no-check-certificate mv cpanm &#x2F;usr&#x2F;bin&#x2F;<br>chmod 755&#x2F;usr&#x2F;bin&#x2F;cpanm<br>cat&gt;&#x2F;root&#x2F;list&lt;&lt;EOF install DBD::mysq1 EOF<br>for package incat&#x2F;root&#x2F;list<br>cpanm Spackage done<br>（2）在所有的节点上安装MHANode：<br>二进制安装包git地址https：&#x2F;&#x2F;github.com&#x2F;cuichunhua&#x2F;MHA.git<br>下载文件mha4mysq1-node-0.57.tar.gz tar xvzf mha4mysql-node-0.57.tar.gz</p>
<p>≦ 610 ≧<br>592 第31章高可用架构 cd mha4mysq1-node-0.57<br>perl Makefile.PL make<br>make install<br>安装后会在&#x2F;usr&#x2F;bin&#x2F;下生成以下脚本文件：&#x2F;usr&#x2F;bin&#x2F;save binary_logs<br>&#x2F;usr&#x2F;bin&#x2F;apply_diff_relay_logs&#x2F;usr&#x2F;bin&#x2F;fi1ter_mysqlbinlog&#x2F;usr&#x2F;bin&#x2F;purge_relay_logs<br>关于上述脚本的功能MHA介绍已经在上文中介绍，这里不再赘述。 2.安装MHAManager<br>MHAManager中主要包括了儿个管理员的命令行工具，例如masterha_manager、 masterha_master_switch等。MHAManager也是依赖于一些Perl模块的，具体如下。<br>（1）安装MHANode软件包。注意在MHAManager的主机上也要安装MHANode。<br>install.sh#!&#x2F;bin&#x2F;bash<br>wget <a target="_blank" rel="noopener" href="http://xrl.us/cpanm">http://xrl.us/cpanm</a> –no-check-certificate mv cpanm &#x2F;usr&#x2F;bin&#x2F;<br>chmod 755 &#x2F;usr&#x2F;bin&#x2F;cpanm<br>cat &gt;&#x2F;root&#x2F;list&lt;&lt;EOF install DBD::mysql EOF<br>for package in cat &#x2F;root&#x2F;list do<br>cpanm $package done<br>安装MHANode软件包：<br>二进制安装包git地址https：&#x2F;&#x2F;github.com&#x2F;cuichunhua&#x2F;MHA.git<br>下载文件mha4mysq1-node-0.57.tar.gz tar xvzf mha4mysq1-node-0.57.tar.gz cd mha4mysq1-node-0.57<br>perl Makefile.PL make<br>make install<br>（2）安装MHAManager软件。<br>安装MHAManager所需要的Perl模块：#!&#x2F;bin&#x2F;bash<br>wget <a target="_blank" rel="noopener" href="http://xrl.us/cpanm">http://xrl.us/cpanm</a> –no-check-certificate mv cpanm&#x2F;usr&#x2F;bin&#x2F;<br>chmod 755&#x2F;usr&#x2F;bin&#x2F;cpanm<br>cat &gt;&#x2F;root&#x2F;list&lt;&lt;EOF install DBD::mysql install config::Tiny install Log::Dispatch<br>install Parallel::ForkManager<br>install Time::HiRes EOF<br>for package in cat &#x2F;root&#x2F;list do<br>cpanm $package done<br>安装MHAManager软件包：<br>二进制安装包git地址<a target="_blank" rel="noopener" href="https://github.com/cuichunhua/MHA.git">https://github.com/cuichunhua/MHA.git</a><br>下载文件mha4mysq1-manager-0.57.tar.gz tar -zxf mha4mysq1-manager-0.57.tar.gz cd mha4mysq1-manager-0.57</p>
<p>≦ 611 ≧<br>31.1MHA架构 593<br>perl Makefile.PL make<br>make install<br>安装后会在&#x2F;usr&#x2F;bin&#x2F;下生成以下脚本文件：<br>&#x2F;usr&#x2F;bin&#x2F;masterha_check repl&#x2F;usr&#x2F;bin&#x2F;masterha check ssh&#x2F;usr&#x2F;bin&#x2F;masterha_check_status&#x2F;usr&#x2F;bin&#x2F;masterha conf host&#x2F;usr&#x2F;bin&#x2F;masterha manager<br>&#x2F;usr&#x2F;bin&#x2F;masterha_master_monitor&#x2F;usr&#x2F;bin&#x2F;masterha master switch&#x2F;usr&#x2F;bin&#x2F;masterha_secondary_check&#x2F;usr&#x2F;bin&#x2F;masterha stop<br>3.配置SSH登录无密码验证<br>（1）在manager上配置到所有Node节点的无密码验证： ssh-keygen -t rsa<br>ssh-copy-id -i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#55;&#x2e;&#49;&#x38;&#x35;">&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#55;&#x2e;&#49;&#x38;&#x35;</a> ssh-copy-id -i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#x72;&#x6f;&#111;&#x74;&#x40;&#49;&#x39;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x37;&#46;&#56;&#x33;">&#x72;&#x6f;&#111;&#x74;&#x40;&#49;&#x39;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x37;&#46;&#56;&#x33;</a> ssh-copy-id -i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#57;&#50;&#46;&#49;&#x36;&#56;&#x2e;&#x37;&#46;&#56;&#49;">&#x72;&#x6f;&#x6f;&#x74;&#64;&#49;&#57;&#50;&#46;&#49;&#x36;&#56;&#x2e;&#x37;&#46;&#56;&#49;</a><br>（2）在MHANode ip81上： ssh-keygen -t rsa<br>ssh-copy-id-i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#114;&#x6f;&#111;&#x74;&#x40;&#49;&#57;&#x32;&#46;&#x31;&#x36;&#56;&#x2e;&#x37;&#x2e;&#x38;&#x33;">&#114;&#x6f;&#111;&#x74;&#x40;&#49;&#57;&#x32;&#46;&#x31;&#x36;&#56;&#x2e;&#x37;&#x2e;&#x38;&#x33;</a> ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#x39;&#x32;&#x2e;&#x31;&#54;&#x38;&#x2e;&#55;&#x2e;&#x31;&#56;&#53;">&#114;&#x6f;&#x6f;&#116;&#x40;&#49;&#x39;&#x32;&#x2e;&#x31;&#54;&#x38;&#x2e;&#55;&#x2e;&#x31;&#56;&#53;</a><br>（3）在MHANodeip83上： ssh-keygen -t rsa<br>ssh-copy-id -i &#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#x39;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#55;&#x2e;&#x38;&#49;">&#114;&#x6f;&#x6f;&#116;&#64;&#49;&#x39;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#55;&#x2e;&#x38;&#49;</a> ssh-copy-id -i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#x72;&#x6f;&#x6f;&#116;&#64;&#x31;&#x39;&#x32;&#46;&#49;&#54;&#56;&#46;&#x37;&#x2e;&#49;&#x38;&#x35;">&#x72;&#x6f;&#x6f;&#116;&#64;&#x31;&#x39;&#x32;&#46;&#49;&#54;&#56;&#46;&#x37;&#x2e;&#49;&#x38;&#x35;</a><br>（4）在MHANodeip185上： ssh-keygen -t rsa<br>ssh-copy-id-i&#x2F;root&#x2F;.ssh&#x2F;id <a href="mailto:&#x72;&#x73;&#97;&#46;&#x70;&#117;&#98;&#x72;&#111;&#111;&#116;&#64;&#x31;&#x39;&#50;&#x2e;&#49;&#54;&#56;&#46;&#x37;&#x2e;&#56;&#x31;">&#x72;&#x73;&#97;&#46;&#x70;&#117;&#98;&#x72;&#111;&#111;&#116;&#64;&#x31;&#x39;&#50;&#x2e;&#49;&#54;&#56;&#46;&#x37;&#x2e;&#56;&#x31;</a> ssh-copy-id -i&#x2F;root&#x2F;.ssh&#x2F;id rsa.pub <a href="mailto:&#x72;&#111;&#111;&#x74;&#x40;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#x37;&#x2e;&#x38;&#51;">&#x72;&#111;&#111;&#x74;&#x40;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#46;&#x37;&#x2e;&#x38;&#51;</a><br>4.搭建主从复制环境（1）在ip81上执行备份：<br>[mysql@ip81<del>]$mysqldump –master-data&#x3D;2–single-transaction –default-character-set&#x3D; utf8-R-triggres -A &gt;all.sql<br>其中，–master-data&#x3D;2代表备份时刻记录master的BINLOG位置和Position；-single-transaction 表示获取一致性快照；-R表示备份相关的存储过程；–triggres表示备份触发器相关信息；-A 表示备份所有schema。<br>（2）在ip81上创建复制用户：<br>mysql&gt;grant replication slave on *.*to repl‘@’192.168.7.%identified by 123456’;<br>（3）查看主库上备份时刻BINLOG的名称和位置，MASTER_LOG_FILE和MASTER LOG_POS:<br>head -n 30 backup.sql Igrep -i “CHANGE MASTER TO”<br>-CHANGE MASTER TO MASTER LOG FILE&#x3D;’mySq1-bin.000043’, MASTER LOG POS&#x3D;178;（4）将备份复制到ip83和ip185：<br>[mysq1@ip81</del>]$scp backup.sq1 ip83:&#x2F;home&#x2F;mysql&#x2F;[mysq1@ip81 <del>]$scp backup.sql ip185:&#x2F;home&#x2F;mysql&#x2F;<br>（5）在ip83上搭建备库：<br>[mysql@ip83 ~]mysql-f-default-character-set&#x3D;utf8 &lt;all.sq][mysq1@ip83</del>]mysql-s&#x2F;tmp&#x2F;mysq]_3307.sock</p>
<p>≦ 612 ≧<br>594 第31章高可用架构<br>Mysql&gt;change master to master <em>host&#x3D;’192.168.7.81’,master user&#x3D;’rep1’,master</em> password&#x3D;’123456<br>，master Port&#x3D;3307,MASTER LOG FILE&#x3D;′ mysq1-bin.000043, MASTER LOG POS&#x3D;178; start slave；<br>查看复制状态： show slave status\G;<br>Master_Host:192.168.7.81<br>Master User:repl Master_Port:3307<br>slave_Io_Running: Yes Slave_SQL_Running: Yes<br>可以看到复制成功。<br>（6）在ip185上搭建备库：<br>[mysql@ip185<del>]mysq] -f-default-character-set&#x3D;utf8 &lt;all.sq][mysq1@ip185</del>]mysq1-s&#x2F;tmp&#x2F;mysq13307.sock<br>mysql&gt;change master to master host&#x3D;’192.168.7.81’,master_user&#x3D;’repl’,master_password&#x3D;123456’ master_Port&#x3D;3307,MASTER LOG FILE&#x3D; mysq1-bin.000043’, MASTER LOG_ POS&#x3D;178;<br>mysql&gt;start slave; 查看复制状态： show slave status\G;<br>Master Host: 192.168.7.81<br>Master user:repl Master_Port:3307<br>slave_Io_Running: Yes slave_SQL_Running: Yes<br>可以看到复制成功。<br>（7）slave服务器设置readonly。将每个 slave设置为readonly：<br>Mysql&gt;mysql -e “set global read only&#x3D;l;”<br>从库对外提供读操作，这里将read_only设置为1。（8）创建监控用户。<br>整个复制集群已经搭建完毕，这时还需要创建监控所需的用户，在ip81上执行： mysql&gt;grant all privileges on <em>.</em> to *root‘@’192.168.7.%’ identified by ‘123456’;<br>至此，MHA软件已经基本安装完毕。接下来就开始配置MHA软件。 5.配置MHA<br>配置MHA的大体步骤如下。<br>（1）创建MHA工作目录，并且创建相关配置文件：<br>mkdir -p&#x2F;etc&#x2F;masterha&#x2F; vi&#x2F;etc&#x2F;masterha&#x2F;appl.cnf[server default]<br>manager_1og&#x3D;&#x2F;masterha&#x2F;app1&#x2F;app1.1og&#x2F;&#x2F;设置manager的日志 manager_workdir&#x3D;&#x2F;masterha&#x2F;app1&#x2F;&#x2F;设置manager的工作日志 master_ip failover_script&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;master_ip_failover&#x2F;&#x2F;设置自动failover时候的<br>&#x2F;&#x2F;切换脚本<br>master_ip_online change script&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;master_iponline change&#x2F;&#x2F;设置手动切换时候的切换脚本<br>user&#x3D;root&#x2F;&#x2F;设置mysql中具有super权限的用户名 password&#x3D;123456&#x2F;&#x2F;设置user对应的密码 ping interval&#x3D;1&#x2F;&#x2F;设置监控主库，发送检测命令的时间间隔，默认的是每隔3s，尝试3次没有回应<br>&#x2F;&#x2F;的时候进行自动failover<br>ping_type&#x3D;connect&#x2F;&#x2F;设置检测方式，也可以选择select、insert方式 remote workdir&#x3D;&#x2F;tmp&#x2F;&#x2F;设置远端mysql在发生切换时保存binlog的具体位置 rep1_password&#x3D;123456&#x2F;&#x2F;设置复制用户的密码<br>repl_user&#x3D;repl&#x2F;&#x2F;设置复制环境中的复制用户名 report_script&#x3D;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;send_report &#x2F;&#x2F;设置发生切换后发送报警的脚本</p>
<p>≦ 613 ≧<br>31.1MHA架构 595<br>secondary_check script&#x3D;&#x2F;usr&#x2F;bin&#x2F;masterha secondary_check -s ip83 -s ip81 –user&#x3D;root –master_ host&#x3D;ip81 –master_ip&#x3D;192.168.7.81 –master_port&#x3D;3306&#x2F;&#x2F;一旦MHA到ip81的监控之间网络出现问题， MHAManager将会尝试从ip83登录到ip81<br>shutdown script&#x3D; &#x2F;&#x2F;设置故障发生后关闭故障主机脚本（该脚本主要作用是关闭主机防止发生脑裂）<br>ssh user&#x3D;root &#x2F;&#x2F;设置ssh的登录用户名 ssh_port&#x3D;22 &#x2F;&#x2F;设置ssh使用的端口<br>[serverl]<br>hostname&#x3D;192.168.7.81<br>master binlog_dir&#x3D;&#x2F;home&#x2F;binlog&#x2F;&#x2F;设置MysQL实例的binlog存储目录<br>port&#x3D;3307[server2]<br>hostname&#x3D;192.168.7.83<br>master binlog_dir&#x3D;&#x2F;home&#x2F;binlog&#x2F;&#x2F;设置MysQL实例的binlog存储目录 port&#x3D;3307<br>candidate master&#x3D;1 &#x2F;&#x2F;设置为候选master，如果设置该参数后，发生主从切换后将会将此从库提升为<br>&#x2F;&#x2F;主，即使这个库不是集群中最新的slave<br>check repl_delay&#x3D;0 &#x2F;&#x2F;默认情况下如果一个s1ave落后master 100M的relay1ogs的话，MHA<br>&#x2F;&#x2F;将不会选择该slave作为一个新的master，因为对于这个slave的恢复需要&#x2F;&#x2F;花费很长时间，通过设置checkrep1_delay&#x3D;O，MHA触发切换在选择一个&#x2F;&#x2F;新的master的时候将会忽略复制延时，这个参数对于设置candidatemaster&#x3D;1&#x2F;&#x2F;的主机非常有用，因为它保证了这个候选主在切换过程中一定是新的master<br>[server3]<br>hostname&#x3D;192.168.7.185<br>master_binlog_dir&#x3D;&#x2F;home&#x2F;binlog&#x2F;&#x2F;设置MysQL实例的binlog存储目录 port&#x3D;3307<br>（2）设置RelayLog清除方式（在每个slave上）： Mysq1&gt;mysq1 -e”set global relay log purge&#x3D;0;<br>MHA在发生切换过程中，从库的恢复过程中可能会需要RelayLog的相关信息，所以这里我们要将RelayLog的自动清除设置为OFF，采用手动清除RelayLog的方式。<br>注意：如果MySQL主从复制环境使用了GTID模式，可以将参数relay_log_purge设置为1，即<br>采用自动清除RelayLog的方式。<br>MHA提供了清除RelayLog的工具pure_relay_logs，该工具参数如下所示：<br>–user mysq1用户名–password mysq1密码–host mysq1服务器地址–port 端口号<br>workdir指定创建relay1og的硬链接的位置，默认的是&#x2F;var&#x2F;tmp，由于系统不通分区创建硬链接文件会失败，故需要执行硬链接具体位置，成功执行脚本后，硬链接的中继日志文件将被删除<br>–disablerelay log purge默认情况下，如果relay_log_purge&#x3D;1的情况下，脚本会什么都不处理，自动退出。通过设定这个参数，当relay_log_purge&#x3D;1的情况下将会将relay_1og_purge设置为0.清理relay1og，清理之后，最后将参数设置为OFF<br>（3）设置定期清理relay脚本。<br>使用如下命令设置crontab来定期清理RelayLog： vi&#x2F;etc&#x2F;cron.d&#x2F;purge_relay_logs<br>0 4***&#x2F;usr&#x2F;bin&#x2F;purge relay_logs –user&#x3D;root –password&#x3D;123456 -disable relay_log purge–port&#x3D;3307–workdir&#x3D;&#x2F;home&#x2F;mysq1_3307&#x2F;mysq1home&#x2F;-disable_relay_1og_purge&gt;&gt;&#x2F;usr&#x2F;loca1&#x2F; masterha&#x2F;log&#x2F;purge_relay_logs.log 2&gt;&amp;1<br>purge_relay_logs脚本删除中继日志不会阻塞SQL线程。因此在每台从服务器上设置计划任务定期清除中继日志。最好在每台从服务器上的不同时间点执行计划任务。<br>下面列出了脚本清理过程：<br>[root@ip83 ~]#&#x2F;usr&#x2F;bin&#x2F;purge_relay_logs –user&#x3D;root -disable relay_log purge –port&#x3D;3307 –workdir&#x3D;&#x2F;home&#x2F;mysq1_3307&#x2F;mysq1home&#x2F;<br>2018-07-23 19:42:42: purge relay logs script started.<br>Found relay 1og.info:&#x2F;home&#x2F;mysql 3307&#x2F;mysq1home&#x2F;data&#x2F;relay-1og.info<br>Removing hard 1inked relay 1og files ip185-relay-bin* under &#x2F;home&#x2F;mysql 3307&#x2F;mysq1home.. done.</p>
<p>≦ 614 ≧<br>596 第31章高可用架构<br>Current relay 1og fiTe:&#x2F;home&#x2F;mysq1_3307&#x2F;mysq1home&#x2F;data&#x2F;ip185-relay-bin.000005 Archiving unused relay log files （up to<br>&#x2F;home&#x2F;mysql 3307&#x2F;mysq1home&#x2F;data&#x2F;ip185-relay-bin.000004)<br>Creating hard 1ink for &#x2F;home&#x2F;mysql 3307&#x2F;mysq1home&#x2F;data&#x2F;ip185-relay-bin.000004 under &#x2F;home&#x2F; mysq1_3307&#x2F;mysq1home&#x2F;ip185-relay-bin.000004.. ok.<br>Creating hard links for unused relay log files completed.<br>Executing SET GLoBAL relay log purge&#x3D;1; FLuSH LoGS; sleeping a few seconds so that SQL thread can delete older relay log files （if it keeps up);SET GLoBAL relay_log_purge&#x3D;0;.. ok.<br>Removing hard linked relay log files ip185-relay-bin*under &#x2F;home&#x2F;mysql 3307&#x2F;mysqlhome.. done. 2018-07-23 19:42:45:A11 relay 1og purging operations succeeded.<br>（4）设置mysqlbinlog（在每个slave上），编辑～&#x2F;.bashr或者&#x2F;etc&#x2F;bashrc文件，在文件的末尾处添加以下内容：<br>PATH&#x3D;”$PATH:&#x2F;home&#x2F;mysq1&#x2F;mysqThome&#x2F;bin”” export PATH<br>MHA在切换过程中会直接调用mysqlbinlog命令，故需要在环境变量中指定mysqlbinlog 的具体路径。<br>6.检查SSH的配置<br>检查MHA Manager到所有MHA Node的SSH连接状态：<br>[root@ip186 home]# masterha_check ssh –conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;app1.cnf<br>Fri Jul 19 18:21:09 2018- [warning] Global configuration file &#x2F;etc&#x2F;masterha default.cnf not found. skipping.<br>Fri Jul 19 18:21:09 2018-[info] Reading application default configurations from &#x2F;etc&#x2F;masterha&#x2F; appl.cnf..<br>Fri jul 19 18:21:09 2018 -[info] Reading server configurations from &#x2F;etc&#x2F;masterha&#x2F;app1.cnf..<br>Fri Jul 19 18:21:09 2018 -[info] Starting SsH connection tests.. Fri ju1 19 18:21:12 2018-[debug]<br>Fri Jul 19 18:21:09 2018 - [debug] connecting via SSH from <a href="mailto:&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#x39;&#x32;&#46;&#x31;&#54;&#x38;&#46;&#55;&#46;&#56;&#x33;">&#x72;&#111;&#x6f;&#x74;&#x40;&#x31;&#x39;&#x32;&#46;&#x31;&#54;&#x38;&#46;&#55;&#46;&#56;&#x33;</a>(192.168.7.83:<br>22) to <a href="mailto:&#114;&#111;&#x6f;&#x74;&#64;&#x31;&#57;&#50;&#46;&#49;&#54;&#56;&#x2e;&#55;&#46;&#x38;&#49;">&#114;&#111;&#x6f;&#x74;&#64;&#x31;&#57;&#50;&#46;&#49;&#54;&#56;&#x2e;&#55;&#46;&#x38;&#49;</a>(192.168.7.81:22).. Fri Ju] 19 18:21:12 2018-[debug] ok.<br>Fri Jul 19 18:21:12 2018 - [debug] Connecting via SSH from <a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#x2e;&#x37;&#x2e;&#x38;&#x33;">&#114;&#111;&#111;&#x74;&#64;&#49;&#57;&#50;&#x2e;&#49;&#54;&#x38;&#x2e;&#x37;&#x2e;&#x38;&#x33;</a>(192.168.7.83: 22) to <a href="mailto:&#114;&#111;&#111;&#116;&#64;&#x31;&#57;&#x32;&#46;&#49;&#x36;&#x38;&#x2e;&#x37;&#x2e;&#49;&#56;&#x35;">&#114;&#111;&#111;&#116;&#64;&#x31;&#57;&#x32;&#46;&#49;&#x36;&#x38;&#x2e;&#x37;&#x2e;&#49;&#56;&#x35;</a>(192.168.7.185:22)..<br>Fri Jul 19 18:21:12 2018-[debug] ok. Fri Ju] 19 18:21:12 2018-[debug]<br>Fri Jul 19 18:21:10 2018 -[debug] connecting via ssH from <a href="mailto:&#x72;&#111;&#111;&#116;&#64;&#49;&#57;&#50;&#46;&#49;&#x36;&#x38;&#x2e;&#55;&#x2e;&#x31;&#56;&#x35;">&#x72;&#111;&#111;&#116;&#64;&#49;&#57;&#50;&#46;&#49;&#x36;&#x38;&#x2e;&#55;&#x2e;&#x31;&#56;&#x35;</a>(192.168.7.<br>185:22) to <a href="mailto:&#114;&#48;&#48;&#x74;&#x40;&#49;&#x39;&#x32;&#46;&#49;&#x36;&#56;&#46;&#55;&#x2e;&#x38;&#x31;">&#114;&#48;&#48;&#x74;&#x40;&#49;&#x39;&#x32;&#46;&#49;&#x36;&#56;&#46;&#55;&#x2e;&#x38;&#x31;</a>(192.168.7.81:22).. Fri Jul 19 18:21:12 2018-[debug]ok.<br>Fri Jul 19 18:21:12 2018 - [debug] Connecting via ssH from <a href="mailto:&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x39;&#50;&#x2e;&#49;&#x36;&#x38;&#46;&#55;&#46;&#49;&#56;&#x35;">&#x72;&#x6f;&#x6f;&#x74;&#x40;&#x31;&#x39;&#50;&#x2e;&#49;&#x36;&#x38;&#46;&#55;&#46;&#49;&#56;&#x35;</a>(192.168.7. 185:22) <a href="mailto:&#116;&#111;&#114;&#x6f;&#x30;&#116;&#64;&#49;&#x39;&#50;&#x2e;&#x31;&#x36;&#56;&#46;&#55;&#46;&#56;&#x33;">&#116;&#111;&#114;&#x6f;&#x30;&#116;&#64;&#49;&#x39;&#50;&#x2e;&#x31;&#x36;&#56;&#46;&#55;&#46;&#56;&#x33;</a>(192.168.7.83:22).<br>Fri Ju] 19 18:21:12 2018-[debug] ok. Fri Jul 19 18:21:13 2018-[debug]<br>Fri Jul 19 18:21:09 2018-[debug] Connecting via SSH from <a href="mailto:&#114;&#111;&#x6f;&#116;&#64;&#x31;&#57;&#x32;&#x2e;&#x31;&#54;&#x38;&#x2e;&#55;&#x2e;&#x38;&#x31;">&#114;&#111;&#x6f;&#116;&#64;&#x31;&#57;&#x32;&#x2e;&#x31;&#54;&#x38;&#x2e;&#55;&#x2e;&#x38;&#x31;</a>(192.168.7. 81:22) <a href="mailto:&#116;&#x6f;&#114;&#x30;&#x30;&#x74;&#x40;&#x31;&#x39;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x37;&#x2e;&#x38;&#51;">&#116;&#x6f;&#114;&#x30;&#x30;&#x74;&#x40;&#x31;&#x39;&#x32;&#x2e;&#49;&#54;&#56;&#x2e;&#x37;&#x2e;&#x38;&#51;</a>(192.168.7.83:22)..<br>Fri Jul 19 18:21:11 2018-[debug] ok. Fri Jul 19 18:21:11 2018 - [debug] connecting Via SSH from <a href="mailto:&#114;&#x6f;&#111;&#x74;&#64;&#x31;&#x39;&#50;&#x2e;&#x31;&#x36;&#56;&#46;&#x37;&#x2e;&#x38;&#49;">&#114;&#x6f;&#111;&#x74;&#64;&#x31;&#x39;&#50;&#x2e;&#x31;&#x36;&#56;&#46;&#x37;&#x2e;&#x38;&#49;</a>(192.168.7.<br>81:22) to <a href="mailto:&#114;&#111;&#111;&#116;&#x40;&#49;&#57;&#x32;&#x2e;&#x31;&#x36;&#56;&#46;&#x37;&#x2e;&#x31;&#56;&#x35;">&#114;&#111;&#111;&#116;&#x40;&#49;&#57;&#x32;&#x2e;&#x31;&#x36;&#56;&#46;&#x37;&#x2e;&#x31;&#56;&#x35;</a>(192.168.7.185:22). Fri Jul 19 18:21:13 2018-[debug] ok.<br>Fri Jul 19 18:21:13 2018 - [info] All sSH connection tests passed successfu1ly.<br>从输出可以看出，ip83到ip81和ip85SSHok，ip85到ip81和ip83SSHok，ip81到ip83和ip185 SSH ok<br>7.检查整个复制环境状况<br>通过masterha_check_repl脚本查看整个集群的状态：<br>masterha check_repl–conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;app1.cnf 192.168.7.81 (current master)<br>+–192.168.7.83 +–192.168.7.185<br>Fri Nov 23 09:45:03 2018 - [info] checking replication health on 192.168.7.83.. Fri Nov 2309:45:03 2018-[info] ok.<br>Fri Nov 23 09:45:03 2018 - [info] checking replication health on 192.168.7.185.</p>
<p>≦ 615 ≧<br>31.1MHA架构 597<br>Fri Nov 23 09:45:03 2018-[info] ok. MySQL Replication Health is OK.<br>8.检查MHAManager的状态<br>通过masterha_check_status脚本查看Manager的状态：<br>[root@ip186 home]# masterha_check status –conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;appl.cnf app1 is stopped(2:NOT RUNNING)<br>注意：如果正常，会显示“PING_OK”，否则会显示“NOT_RUNNING”，这代表MHA监控没有开启。 9.开启MHAManager监控<br>[root@ip186 home]# nohup masterha manager -conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;appl.cnf – remove dead master conf –ignore last_failover&lt;&#x2F;dev&#x2F;null &gt;&#x2F;masterha&#x2F;app1&#x2F;manager.log 2&gt;&amp;1 &amp;<br>对启动中的参数说明如下。<br>O–remove_dead_master_conf:该参数代表当发生主从切换后，老的主库的IP将会从配置文件中删除。<br>O–ignore_last_failover:在默认情况下，如果MHA检测到连续发生宕机，且两次宕机时间间隔不足8h的话，则不会进行Failover，之所以这样限制是为了避免ping-pong效应。该参数代表忽略上次MHA触发切换产生的文件，默认情况下，MHA发生切换后将会在&#x2F;masterha&#x2F;appl下产生appl.failover.complete文件，下次再次切换的时候如果发现目录下存在该文件将不允许触发切换，除非在第一次切换后手动rm-f&#x2F;masterha&#x2F;app1&#x2F;appl.failover. complete，出于方便考虑，我们每次在启动MHA时会添加–ignore_last_failover参数。<br>查看MHAManager监控是否正常：<br>[root@ip186 home]# masterha_check status –conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;appl.cnf app1 (pid:2960) is running(0:PING_oK), master:192.168.7.81<br>在默认情况下，10s内状态会为10:INITIALIZING_MONITOR，当状态转变为0:PING_OK 后表明已经开启了到master端的监控，master主机为192.168.7.81。<br>10.查看启动日志<br>通过tail命令查看启动过程中的日志输出信息：[root@ip186 home]# tail -f &#x2F;masterha&#x2F;app1&#x2F;app1.1og 192.168.7.81（192.168.7.81:3307) (current master)<br>+–192.168.7.83(192.168.7.83:3307) +–192.168.7.185(192.168.7.185:3307)<br>wed Aug 29 11:59:33 2018 -[warning] master_ip_failover script is not defined.<br>Wed Aug 29 11:59:33 2018 - [warning] shutdown_script is not defined. Wed Aug 29 11:59:33 2018 -[info] Set master ping interval 3 seconds.<br>wed Aug 29 11:59:33 2018 - [info] set secondary check script:&#x2F;usr&#x2F;bin&#x2F;masterha secondary check –user&#x3D;root –master_ip&#x3D;192.168.7.81 –master _port&#x3D;3307 -s 192.168.7.185 -s 192.168.7.83 Wed Aug 29 11:59:33 2018 -[info] starting ping health check on 192.168.7.81 (192.168.7.81:3307). Wed Aug 29 11:59:33 2018-[info] Ping(SELECT) succeeded, waiting unti1 MysQL doesn’t respond.<br>其中“Ping(SELECT)succeeded”输出说明整个系统监控已经开始了。<br>11.关闭MHAManager监控关闭MHA命令如下：<br>masterha_stop –conf&#x3D;&#x2F;etc&#x2F;masterha&#x2F;app1.cnf stopped appl successfully</p>
<p>≦ 616 ≧<br>598 第31章高可用架构 31.1.2应用连接配置<br>实际应用中，如果MHA成功完成了MySQL主从的切换，但由于切换前后主从IP发生了变更，需要修改连接信息来适配新环境，这个过程在线业务会受到影响。有3种办法来解决这个问题，第一种方式是通过keepalived来管理VIP，即通过对浮动IP的管理来解决IP的改变；第二种方式是通过自定义脚本方式，自动迁移VIP，原理与第一个办法类似；第三种方式是采用MySQL中间件，即应用与后端MySQL环境之间，增加中间件，从而通过中间件来“感知”后端环境的变化。<br>接下来对这3种方式进行详细介绍。 1.keepalived方式<br>keepalived配置步骤如下。<br>（1）下载集群心跳软件keepalived，并进行安装：<br>wget <a target="_blank" rel="noopener" href="http://www.keepalived.org/software/keepalived-1.4.2.tar.gz">www.keepalived.org/software/keepalived-1.4.2.tar.gz</a><br>tar -xvzf keepalived-1.4.2.tar.gz cd keepalived-1.4.2.tar.gz<br>.&#x2F;configure –prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;keepalived make &amp;&amp; make install<br>cp&#x2F;usr&#x2F;local&#x2F;keepalived&#x2F;etc&#x2F;sysconfig&#x2F;keepalived&#x2F;etc&#x2F;sysconfig&#x2F; mkdir &#x2F;etc&#x2F;keepalived<br>cp &#x2F;usr&#x2F;local&#x2F;keepalived&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf &#x2F;etc&#x2F;keepalived&#x2F; cp &#x2F;usr&#x2F;local&#x2F;keepalived&#x2F;sbin&#x2F;keepalived &#x2F;usr&#x2F;sbin&#x2F;<br>（2）配置keepalived。在ip81上设置：<br>[root@ip81 tools]# cat &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf! Configuration File for keepalived<br>global_defs {<br>notification email {<br><a href="mailto:&#x6f;&#x6e;&#100;&#x75;&#116;&#x79;&#64;&#99;&#x6f;&#114;&#112;&#x2e;&#110;&#x65;&#x74;&#101;&#97;&#x73;&#101;&#46;&#99;&#x6f;&#x6d;">&#x6f;&#x6e;&#100;&#x75;&#116;&#x79;&#64;&#99;&#x6f;&#114;&#112;&#x2e;&#110;&#x65;&#x74;&#101;&#97;&#x73;&#101;&#46;&#99;&#x6f;&#x6d;</a><br>notification_email_from <a href="mailto:&#x64;&#x62;&#97;&#64;&#99;&#111;&#x72;&#x70;&#x2e;&#110;&#101;&#116;&#x65;&#97;&#115;&#101;&#x2e;&#x63;&#x6f;&#109;">&#x64;&#x62;&#97;&#64;&#99;&#111;&#x72;&#x70;&#x2e;&#110;&#101;&#116;&#x65;&#97;&#115;&#101;&#x2e;&#x63;&#x6f;&#109;</a><br>smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id MysQL-ha<br>vrrp instance VI 1<br>state BACKUP interface etho<br>virtual _router_id 51<br>priority 150 advert int 1 nopreempt<br>authentication { auth_type PASS auth_pass 1111<br>virtual_ipaddress 192.168.7.201&#x2F;23<br>注意黑体部分的代码，其中router_idMySQL-ha表示设定keepalived组的名称，将 192.168.7.201&#x2F;23这个IP绑定到ip81主机interfaceeth0上，并且设置了状态为backup模式，将keepalived的模式设置为非抢占模式（nopreempt），priority150优先级别设置为150。</p>
<p>≦ 617 ≧<br>31.1MHA架构 599<br>在候选主ip83上设置：<br>[root@ip83~]# cat&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf onfiguration File for keepalived<br>global defs<br>notification email<br><a href="mailto:&#x6f;&#110;&#100;&#x75;&#x74;&#121;&#64;&#x63;&#x6f;&#x72;&#x70;&#46;&#110;&#101;&#116;&#101;&#x61;&#115;&#101;&#46;&#99;&#x6f;&#109;">&#x6f;&#110;&#100;&#x75;&#x74;&#121;&#64;&#x63;&#x6f;&#x72;&#x70;&#46;&#110;&#101;&#116;&#101;&#x61;&#115;&#101;&#46;&#99;&#x6f;&#109;</a><br>notification_email_from <a href="mailto:&#100;&#x62;&#x61;&#x40;&#x63;&#111;&#x72;&#112;&#x2e;&#x6e;&#101;&#x74;&#x65;&#97;&#x73;&#x65;&#46;&#99;&#111;&#x6d;">&#100;&#x62;&#x61;&#x40;&#x63;&#111;&#x72;&#112;&#x2e;&#x6e;&#101;&#x74;&#x65;&#97;&#x73;&#x65;&#46;&#99;&#111;&#x6d;</a><br>smtp_server 127.0.0.1 smtp_ connect_timeout 30 router_id MySQL-ha<br>vrrp instance VI 1{<br>state BACKUP interface etho<br>virtual_router_id 51<br>priority 120 advert int 1 nopreempt<br>authentication auth type PASS auth pass 1111<br>virtual_ipaddress{ 192.168.7.201&#x2F;23 小<br>注意黑体部分的代码，其中router_idMySQL-ha表示设定keepalived组的名称，并且设置了状态为backup模式，将keepalived的模式设置为非抢占模式（nopreempt），priority120 优先级别设置为120。<br>这里ip81和ip83都要设置为BACKUP模式。在keepalived中有两种模式，分别是master backup模式和backup→backup模式，这两种模式分别有什么区别呢？<br>在master→backup模式下，一旦主库宕掉，虚拟IP会自动漂移到从库，当主库修复好， keepalived启动后，还会把虚拟IP抢过来，即使设置了nopreempt（不抢占）的方式抢占IP的动作也会发生。在backup一backup模式下，当主库宕掉后虚拟IP会自动漂移到从库上，当原主恢复之后重启keepalived服务，并不会抢占新主的虚拟IP，即使是优先级高于从库的优先级别，也不会抢占IP。为了减少IP的漂移次数，生产中通常是把修复好的主库当作新主库的备库。<br>（3）启动keepalived服务。<br>在ip81上启动keepalived服务：<br>[root@ip81 tools]#&#x2F;usr&#x2F;sbin&#x2F;keepalived -D[root@ip81 tools]# tail -f&#x2F;var&#x2F;log&#x2F;messages<br>Nov 23 16:07:15 ip81 Keepalived[25214]: Starting Keepalived v1.4.2 (02&#x2F;24,2018), git commit v1.4.1-41-g6a2987e+<br>Nov 23 16:07:15 ip81 Keepa1ived[25214]: Running on Linux 2.6.32-642.1.1.e16.x86 64 #1 SMP Fri May 614:54:05 EDT 2016 (built for Linux 2.6.32)<br>Nov 23 16:07:15 ip81 Keepalived[25214]: opening file’&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf’. Nov 23 16:07:15 ip81 Keepalived_healthcheckers[25216]:0pening file&#x2F;etc&#x2F;keepalived&#x2F; keepalived.conf’<br>Nov 23 16:07:15 ip81 Keepalived[25215]:Starting Healthcheck chi1d process,pid&#x3D;25216 Nov 23 16:07:15 ip81 Keepa1ived[25215]:Starting VRRP chi1d process,pid&#x3D;25217<br>Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:Registering Kernel netlink reflector<br>Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:Registering Kernel netlink command channe] Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:Registering gratuitous ARP shared channe]<br>Nov 23 16:07:15ip81 Keepalived vrrp[25217]:0pening file&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf<br>Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:VRRP Instance(VI 1) removing protoco1 VIPs. Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:Using Linkwatch kernel netlink reflector. Nov 23 16:07:15 ip81 Keepalived vrrp[25217]:VRRP_Instance(VI_1) Entering BACKUP STATE<br>Nov 23 16:07:15 ip81 Keepalived_vrrp[25217]:VRRP sockpoo1:[ifindex(2),proto(112),unicast</p>
<p>≦ 618 ≧<br>600 第31章高可用架构(0),fd(10,11)]<br>Nov 23 16:07:18 ip81 Keepalived vrrp[25217]: VRRP_Instance(VI 1) Transition to MAsTER sTATE<br>Nov 23 16:07:19 ip81 Keepalived vrrp[25217]: VRRP_Instance(VI 1) Entering MASTER STATE Nov 23 16:07:19 ip81 Keepalived vrrp[25217]: VRRP Instance(VI 1) setting protoco1 VIPs.<br>Nov 23 16:07:19 ip81 Keepalived vrrp[25217]: sending gratuitous ARP on eth0 for 192.168.7.201 Nov 23 16:07:24 ip81 Keepalived vrrp[25217]: VRRP_Instance(VI_1) Sending&#x2F;queueing gratuitous ARPs on eth0 for 192.168.7.201<br>Nov 23 16:07:24 ip81 Keepalived vrrp[25217]: sending gratuitous ARP on eth0 for 192.168.7.201 Nov 23 16:07:24 ip81 Keepalived vrrp[25217]: Sending gratuitous ARP on eth0 for 192.168.7.201 Nov 23 16:07:24 ip81 Keepalived vrrp[25217]: Sending gratuitous ARP on eth0 for 192.168.7.201 Nov 23 16:07:24 ip81 Keepalived vrrp[25217]: Sending gratuitous ARP on eth0 for 192.168.7.201<br>通过输出可以看到虚拟IP（192.168.7.201）已经绑定到ip81的eth0网卡上了。（4）查看绑定情况。<br>在ip81上查看IP地址绑定情况：[root@ip81 mysqlhome]# ip addr<br>2:ethO:BROADCASTMULTICAST,UP,LOWER UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>1ink&#x2F;ether 00:11:43:de:78:78 brd ff:ff:ff:ff:ff:f<br>inet 192.168.7.81&#x2F;23 brd 192.168.7.255 scope g1obal eth0 inet 192.168.7.201&#x2F;23 scope g1oba1 secondary eth0<br>inet6 fe80::211:43ff:fede:7878&#x2F;64 scope 1ink valid lft forever preferred lft forever<br>从keepalived的输出信息和系统的网卡信息可以看到，虚拟IP（192.168.7.201）已经添加成功。在ip83上：<br>[root@ip83 ~]# &#x2F;usr&#x2F;sbin&#x2F;keepalived -D[root@ip83 ~]# tail -f &#x2F;var&#x2F;log&#x2F;messages<br>Nov 23 03:28:08 ip83 Keepalived[26040]: Starting Keepalived v1.4.2 (02&#x2F;24,2018),git commit v1.4.1-41-g6a2987e+<br>Nov 23 03:28:08 ip83 Keepa7ived[26040]: Running on Linux 3.10.0-327.e17.x86 64 #1 SMP Thu Oct 29 17:29:29 EDT 2015 (built for Linux 3.10.0)<br>Nov 23 03:28:08 ip83 Keepalived[26040]: opening file&#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf Nov 23 03:28:08 ip83 Keepalived[26041]:Starting Healthcheck chi1d process,pid&#x3D;26042 Nov 23 03:28:08 ip83 Keepalived[26041]:Starting VRRP child process,pid&#x3D;26043<br>Nov 23 03:28:08 ip83 Keepalived healthcheckers[26042]:opening fi1e &#x2F;etc&#x2F;keepa1ived&#x2F; keepalived.conf’.<br>Nov 23 03:28:08 ip83 Keepalived vrrp[26043]: Registering Kernel net1ink reflector<br>Nov 23 03:28:08 ip83 Keepalived vrrp[26043]:Registering kernel netlink command channe] Nov 23 03:28:08 ip83 Keepalived vrrp[26043]: Registering gratuitous ARP shared channel<br>Nov 23 03:28:08 ip83 Keepalived vrrp[26043]:0pening fi1e &#x2F;etc&#x2F;keepalived&#x2F;keepalived.conf’<br>Nov 23 03:28:08 ip83 Keepalived vrrp[26043]: VRRP_Instance(VI 1) removing protoco1 VIPs. Nov 23 03:28:08 ip83 Keepalived vrrp[26043]:using Linkwatch kernel netlink reflector.. Nov 23 03:28:08 ip83 Keepalived vrrp[26043]:VRRP_Instance(VI_1) Entering BAcKUP STATE<br>Nov 23 03:28:08 ip83 Keepalived vrrp[26043]:VRRP sockpoo1:[ifindex(2),proto(112）,unicast（0），fd（10,11）]<br>从上面的输出可以看到keepalived已经配置成功。<br>需要注意的是，keepalived存在一种脑裂状况，当主从间网络出现问题，这时主库会持有虚拟IP不变，从库失去和主库的联系后，从库也会抢夺IP（即便采用backup一backup非抢占模式），这样造成的后果是主从数据库都持有虚拟IP。于是造成IP冲突，业务也会受到影响，因此在网络不是很好的状况下，不建议采用keepavlived服务。<br>（5）MHA引I人keepalived<br>那么如何才能把keepalived服务引人MHA呢？很简单，只需修改切换时触发的脚本文件 master_ip_failover即可，在该脚本中添加在master发生岩机时对keepalived的处理。<br>例如，编辑MHA切换时调用的配置文件master_ip_failover，如下所示：<br>vi &#x2F;usr&#x2F;local&#x2F;bin&#x2F;master_ip_failover#!&#x2F;usr&#x2F;bin&#x2F;env perl</p>
<p>≦ 619 ≧<br>31.1MHA架构 601<br>#Copyright （C) 2011 DeNA Co.,Ltd.#<br>This program is free software; you can redistribute it and&#x2F;or modify 井<br>it under the terms of the GNu General Public License as published by#<br>the Free Software Foundation; either version 2 of the License,or#<br>(at your option) any later version.#<br>#This program is distributed in the hope that it will be useful.#but WITHouT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the<br>GNU General Public License for more details.#<br>You should have received a copy of the GNu General Public License along with this program; if not, write to the Free Software<br>#<br>#Foundation,Inc.,<br>#51 Franklin Street,Fifth Floor, Boston,MA 02110-1301 USA</p>
<h2 id="Note-This-is-a-sample-script-and-is-not-complete-Modify-the-script-based-on-your-environment-use-strict"><a href="#Note-This-is-a-sample-script-and-is-not-complete-Modify-the-script-based-on-your-environment-use-strict" class="headerlink" title="Note: This is a sample script and is not complete. Modify the script based on your environment. use strict;"></a>Note: This is a sample script and is not complete. Modify the script based on your environment. use strict;</h2><p>use warnings FATAL &#x3D;&gt;’all’;<br>use Getopt::Long: use MHA::DBHelper;<br>my(<br>$command, $ssh user, $orig master_host, sorig master_ip, Sorig master port, Snew master host, Snew master ip, $new_master_port,<br>Snew master_user, $new_master_password):<br>Getoptions(<br>‘command&#x3D;s’ &#x3D;&gt;$command,’ssh_user&#x3D;s’ &#x3D;&gt;\sssh_user,’orig master host&#x3D;s’&#x3D;&gt; \sorig master host,<br>‘orig master ip&#x3D;s’ &#x3D;&gt;\sorig master_ip,’orig master port&#x3D;i’ &#x3D;&gt;\sorig master port，<br>‘new master_host&#x3D;s’ &#x3D;&gt;\Snewmaster _host,’new master_ip&#x3D;s’ &#x3D;&gt;$new master_ip,’newmaster_port&#x3D;i’\snew_master_port,<br>new master user &#x3D;s’ &#x3D;&gt;\s new master_user,’new master password &#x3D;s’ &#x3D;&gt;\s new_master_password,);<br>exit &amp;main（）; sub main<br>if（$command eq“stop”1l Scommand eq”stopssh”）{</p>
<h1 id="orig-master-host-orig-master-ip-orig-master-port-are-passed"><a href="#orig-master-host-orig-master-ip-orig-master-port-are-passed" class="headerlink" title="$orig master host, $orig master_ip, $orig master_port are passed."></a>$orig master host, $orig master_ip, $orig master_port are passed.</h1><h1 id="If-you-manage-master-ip-address-at-global-catalog-database-invalidate-orig-master-ip-here"><a href="#If-you-manage-master-ip-address-at-global-catalog-database-invalidate-orig-master-ip-here" class="headerlink" title="If you manage master ip address at global catalog database,# invalidate orig master ip here."></a>If you manage master ip address at global catalog database,# invalidate orig master ip here.</h1><p>my Sexit code &#x3D; 1; eval<br>#updating global catalog,etc<br>$exit code &#x3D;0; 3:<br>if-（s@){<br>warn “Got Error: s@\n”;<br>exit $exit code; exit $exit_code; 了<br>elsif（$command eq“start”）</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">DingQuan Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/07/28/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E3%80%81%E4%BC%98%E5%8C%96%E4%B8%8E%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%EF%BC%9A%E7%AC%AC3%E7%89%88/">http://example.com/2024/07/28/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E3%80%81%E4%BC%98%E5%8C%96%E4%B8%8E%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%EF%BC%9A%E7%AC%AC3%E7%89%88/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">ccbigs blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%BB%91%E7%9A%AE%E4%B9%A6/">黑皮书</a><a class="post-meta__tags" href="/tags/MySQL/">MySQL</a></div><div class="post_share"><div class="social-share" data-image="/img/ahead.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/09/15/Rust%20%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80/" title="Rust 程序设计语言"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Rust 程序设计语言</div></div></a></div><div class="next-post pull-right"><a href="/2024/06/28/appInstall%E2%80%94%E2%80%94mysql_windows%E7%89%88%E8%87%AA%E5%AE%9A%E4%B9%89%E7%AE%80%E6%98%93%E5%8C%96%E5%AE%89%E8%A3%85/" title="appInstall——mysql_windows版自定义简易化安装"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">appInstall——mysql_windows版自定义简易化安装</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/10/22/%E9%BB%91%E7%9A%AE%E4%B9%A6%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/" title="黑皮书——计算机网络自顶向下方法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-22</div><div class="title">黑皮书——计算机网络自顶向下方法</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/ahead.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">DingQuan Zuo</div><div class="author-info__description">计算机很适合我这样的蠢人学，因为代码就在那里</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">28</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">22</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ccbigs" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://blog.csdn.net/zuodingquan666" target="_blank" title="CSDN"><i class="fas fa-c" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1692062014@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAMySQL%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E3%80%81%E4%BC%98%E5%8C%96%E4%B8%8E%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%EF%BC%9A%E7%AC%AC3%E7%89%88"><span class="toc-text">深入浅出MySQL：数据库开发、优化与管理维护：第3版</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-%E5%9F%BA%E7%A1%80%E7%AF%87"><span class="toc-text">第一部分 基础篇</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC1%E7%AB%A0-MySQL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE"><span class="toc-text">第1章 MySQL的安装与配置</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-MySQL%E7%9A%84%E4%B8%8B%E8%BD%BD"><span class="toc-text">1.1 MySQL的下载</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-1-%E5%9C%A8Windows%E5%B9%B3%E5%8F%B0%E4%B8%8B%E4%B8%8B%E8%BD%BDMySQL"><span class="toc-text">1.1.1 在Windows平台下下载MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-2-%E5%9C%A8Linux%E5%B9%B3%E5%8F%B0%E4%B8%8B%E4%B8%8B%E8%BD%BDMySQL"><span class="toc-text">1.1.2 在Linux平台下下载MySQL</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-MySQL%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-text">1.2 MySQL的安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-1-%E5%9C%A8Windows%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%AE%89%E8%A3%85MySQL"><span class="toc-text">1.2.1 在Windows平台下安装MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-2-%E5%9C%A8Linux%E5%B9%B3%E5%8F%B0%E4%B8%8B%E5%AE%89%E8%A3%85MySQL"><span class="toc-text">1.2.2 在Linux平台下安装MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E7%9B%B4%E6%8E%A5%E5%AE%89%E8%A3%85RPM%E5%8C%85"><span class="toc-text">1. 直接安装RPM包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%80%9A%E8%BF%87Yum-Repository%E5%AE%89%E8%A3%85"><span class="toc-text">2.通过Yum Repository安装</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-default-authentication-plugin-to-be-used-when-connecting-to-the-server-default-authentication-plugin-x3D-caching-sha2-password"><span class="toc-text">The default authentication plugin to be used when connecting to the server default authentication plugin&#x3D;caching_sha2_password</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#The-default-storage-engine-that-will-be-used-when-create-new-tables-when"><span class="toc-text">The default storage engine that will be used when create new tables when</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Rows-examine-60-71G-98-119-07M-182-92M-182-41M-1-67M-182-41M-Query-size-16-35k-44-69-46-12-44-60-1-58-44-60"><span class="toc-text">Rows examine 60.71G 98 119.07M 182.92M 182.41M 1.67M 182.41M#Query size 16.35k 44 69 46.12 44.60 1.58 44.60</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-0X2E5C1AA8E628621B6AF18E03-38076-0023-98-2"><span class="toc-text">1 0X2E5C1AA8E628621B6AF18E03.. 38076.0023 98.2%</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Query-1-0-04-QPs-46-10x-concurrency-ID-0x2E5C1AA8E628621B6AF18E035F2716DB-at-byte-176863585"><span class="toc-text">Query 1: 0.04 QPs, 46.10x concurrency, ID 0x2E5C1AA8E628621B6AF18E035F2716DB at byte 176863585</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#This-item-is-included-in-the-report-because-it-matches-%E2%80%93limit-Scores-v-x2F-M-x3D-0-05"><span class="toc-text">This item is included in the report because it matches –limit.#Scores:v&#x2F;M &#x3D; 0.05</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exec-time-98-38076s-1031s-1259s-1067s-1248s-72s-1028s-Lock-time-41-23ms-48us-327us-63us-125us-26us-54us-Rows-sent-0-0-0-0-0-0"><span class="toc-text">Exec time 98 38076s 1031s 1259s 1067s 1248s 72s 1028s#Lock time 41 23ms 48us 327us 63us 125us 26us 54us#Rows sent 0 0 0 0 0 0</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86-%E7%AE%A1%E7%90%86%E7%BB%B4%E6%8A%A4%E7%AF%87"><span class="toc-text">第四部分 管理维护篇</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC22%E7%AB%A0-MySQL%E9%AB%98%E7%BA%A7%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%87%E7%BA%A7"><span class="toc-text">第22章 MySQL高级安装和升级</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#22-1-Linux-x2F-UNIX%E5%B9%B3%E5%8F%B0%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-text">22.1 Linux&#x2F;UNIX平台下的安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#22-1-1-%E5%AE%89%E8%A3%85%E5%8C%85%E6%AF%94%E8%BE%83"><span class="toc-text">22.1.1 安装包比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-1-2-%E5%AE%89%E8%A3%85%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8C%85"><span class="toc-text">22.1.2 安装二进制包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-1-3-%E5%AE%89%E8%A3%85%E6%BA%90%E7%A0%81%E5%8C%85"><span class="toc-text">22.1.3 安装源码包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-1-4-%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95"><span class="toc-text">22.1.4 参数设置方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-2-%E5%8D%87%E7%BA%A7MySQL"><span class="toc-text">22.2 升级MySQL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-3-%E5%B0%8F%E7%BB%93"><span class="toc-text">22.3 小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hostname-localhost-Files-slow3307-1og"><span class="toc-text">Hostname:localhost#Files:slow3307.1og</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Exec-time-85-386ms-35-873ms-35-920ms-412ms-Lock-time-6ms-176us-5ms-71lus-5ms-1ms-185us-Rows-sent-9-1-1-o-1-Rows-examine-12-74M924-17k-2-71M-1-42M-2-62M-739-82k915-49k-Query-size-438-47-49-48-67-46-83-o-46-83"><span class="toc-text">Exec time 85 386ms 35 873ms 35 920ms 412ms#Lock time 6ms 176us 5ms 71lus 5ms 1ms 185us#Rows sent 9 1 1 o 1#Rows examine 12.74M924.17k 2.71M 1.42M 2.62M 739.82k915.49k#Query size 438 47 49 48.67 46.83 o 46.83</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#This-item-is-included-in-the-report-because-it-matches-%E2%80%93limit-Scores-V-x2F-M-x3D-0-97"><span class="toc-text">This item is included in the report because it matches –limit.#Scores:V&#x2F;M&#x3D; 0.97</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#test"><span class="toc-text">服务器信息</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/23/vmware%E5%AE%89%E8%A3%85Linux/" title="vmware安装Linux">vmware安装Linux</a><time datetime="2024-10-23T00:20:33.000Z" title="发表于 2024-10-23 08:20:33">2024-10-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/22/%E9%BB%91%E7%9A%AE%E4%B9%A6%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%96%B9%E6%B3%95/" title="黑皮书——计算机网络自顶向下方法">黑皮书——计算机网络自顶向下方法</a><time datetime="2024-10-22T12:14:56.000Z" title="发表于 2024-10-22 20:14:56">2024-10-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/10/21/appInstall%E2%80%94%E2%80%94Java%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4/" title="appInstall——Java安装步骤">appInstall——Java安装步骤</a><time datetime="2024-10-21T02:20:13.000Z" title="发表于 2024-10-21 10:20:13">2024-10-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/1558.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By DingQuan Zuo</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">道可道，非恒道也！</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>